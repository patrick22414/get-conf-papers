<ul class="list-unstyled submissions-list">
    <li class="note " data-id="Syx4wnEtvH" data-number="1">
      <h4>
        <a href="/forum?id=Syx4wnEtvH">
            Large Batch Optimization for Deep Learning: Training BERT in 76 minutes
        </a>
      
        
          <a href="/pdf?id=Syx4wnEtvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=youyang%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="youyang@cs.berkeley.edu">Yang You</a>, <a href="/profile?email=jingli%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jingli@google.com">Jing Li</a>, <a href="/profile?email=sashank%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sashank@google.com">Sashank Reddi</a>, <a href="/profile?email=jhseu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jhseu@google.com">Jonathan Hseu</a>, <a href="/profile?email=sanjivk%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanjivk@google.com">Sanjiv Kumar</a>, <a href="/profile?email=bsrinadh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bsrinadh@google.com">Srinadh Bhojanapalli</a>, <a href="/profile?email=xiaodansong%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaodansong@google.com">Xiaodan Song</a>, <a href="/profile?email=demmel%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="demmel@berkeley.edu">James Demmel</a>, <a href="/profile?email=keutzer%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="keutzer@berkeley.edu">Kurt Keutzer</a>, <a href="/profile?email=chohsieh%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chohsieh@cs.ucla.edu">Cho-Jui Hsieh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#Syx4wnEtvH-details-322" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Syx4wnEtvH-details-322"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A fast optimizer for general applications and large-batch training.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Training large deep neural networks on massive datasets is  computationally very challenging. There has been recent surge in interest in using large batch stochastic optimization methods to tackle this issue. The most prominent algorithm in this line of research is LARS, which by  employing layerwise adaptive learning rates trains ResNet on ImageNet in a few minutes. However, LARS performs poorly for attention models like BERT, indicating that its performance gains are not consistent across tasks. In this paper, we first study a principled layerwise adaptation strategy to accelerate training of deep neural networks using large mini-batches. Using this strategy, we develop a new layerwise adaptive large batch optimization technique called LAMB; we then provide convergence analysis of LAMB as well as LARS, showing convergence to a stationary point in general nonconvex settings. Our empirical results demonstrate the superior performance of LAMB across various tasks such as BERT and ResNet-50 training with very little hyperparameter tuning. In particular, for BERT training, our optimizer enables use of very large batch sizes of 32868 without any degradation of performance.  By increasing the batch size to the memory limit of a TPUv3 Pod, BERT training time can be reduced from 3 days to just 76 minutes.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">large-batch optimization, distributed training, fast optimizer</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/tensorflow/addons/blob/master/tensorflow_addons/optimizers/lamb.py</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Syx4wnEtvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkgsPhNYPS" data-number="16">
      <h4>
        <a href="/forum?id=HkgsPhNYPS">
            SELF: Learning to Filter Noisy Labels with Self-Ensembling
        </a>
      
        
          <a href="/pdf?id=HkgsPhNYPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ductam.nguyen08%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ductam.nguyen08@gmail.com">Duc Tam Nguyen</a>, <a href="/profile?email=chaithanyakumar.mummadi%40de.bosch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chaithanyakumar.mummadi@de.bosch.com">Chaithanya Kumar Mummadi</a>, <a href="/profile?email=thiphuongnhung.ngo%40de.bosch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thiphuongnhung.ngo@de.bosch.com">Thi Phuong Nhung Ngo</a>, <a href="/profile?email=hoai.phuong.nguyen198%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hoai.phuong.nguyen198@gmail.com">Thi Hoai Phuong Nguyen</a>, <a href="/profile?email=laura.beggel%40de.bosch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="laura.beggel@de.bosch.com">Laura Beggel</a>, <a href="/profile?email=brox%40cs.uni-freiburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="brox@cs.uni-freiburg.de">Thomas Brox</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#HkgsPhNYPS-details-618" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkgsPhNYPS-details-618"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a self-ensemble framework to train more robust deep learning models under noisy labeled datasets.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep neural networks (DNNs) have been shown to over-fit a dataset when being trained with noisy labels for a long enough time. To overcome this problem, we present a simple and effective method self-ensemble label filtering (SELF) to progressively filter out the wrong labels during training. Our method improves the task performance by gradually allowing supervision only from the potentially non-noisy (clean) labels and stops learning on the filtered noisy labels. For the filtering, we form running averages of predictions over the entire training dataset using the network output at different training epochs. We show that these ensemble estimates yield more accurate identification of inconsistent predictions throughout training than the single estimates of the network at the most recent training epoch. While filtered samples are removed entirely from the supervised training loss, we dynamically leverage them via semi-supervised learning in the unsupervised loss. We demonstrate the positive effect of such an approach on various image classification tasks under both symmetric and asymmetric label noise and at different noise ratios. It substantially outperforms all previous works on noise-aware learning across different datasets and can be applied to a broad set of network architectures.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Ensemble Learning, Robust Learning, Noisy Labels, Labels Filtering</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkgsPhNYPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HygnDhEtvr" data-number="18">
      <h4>
        <a href="/forum?id=HygnDhEtvr">
            Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation
        </a>
      
        
          <a href="/pdf?id=HygnDhEtvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=cheny39%40rpi.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cheny39@rpi.edu">Yu Chen</a>, <a href="/profile?email=lwu%40email.wm.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lwu@email.wm.edu">Lingfei Wu</a>, <a href="/profile?email=zaki%40cs.rpi.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zaki@cs.rpi.edu">Mohammed J. Zaki</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#HygnDhEtvr-details-734" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HygnDhEtvr-details-734"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, reinforcement learning, graph neural networks, natural language processing, question generation</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Natural question generation (QG) aims to generate questions from a passage and an answer. Previous works on QG either (i) ignore the rich structure information hidden in text, (ii) solely rely on cross-entropy loss that leads to issues like exposure bias and inconsistency between train/test measurement, or (iii) fail to fully exploit the answer information. To address these limitations, in this paper, we propose a reinforcement learning (RL) based graph-to-sequence (Graph2Seq) model for QG. Our model consists of a Graph2Seq generator with a novel Bidirectional Gated Graph Neural Network based encoder to embed the passage, and a hybrid evaluator with a mixed objective combining both cross-entropy and RL losses to ensure the generation of syntactically and semantically valid text. We also introduce an effective Deep Alignment Network for incorporating the answer information into the passage at both the word and contextual levels. Our model is end-to-end trainable and achieves new state-of-the-art scores, outperforming existing methods by a significant margin on the standard SQuAD benchmark.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/hugochan/RL-based-Graph2Seq-for-NQG</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HygnDhEtvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgpv2VFvr" data-number="22">
      <h4>
        <a href="/forum?id=rkgpv2VFvr">
            Sharing Knowledge in Multi-Task Deep Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=rkgpv2VFvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=carlo%40robot-learning.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="carlo@robot-learning.de">Carlo D'Eramo</a>, <a href="/profile?email=davide%40robot-learning.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="davide@robot-learning.de">Davide Tateo</a>, <a href="/profile?email=andrea.bonarini%40polimi.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="andrea.bonarini@polimi.it">Andrea Bonarini</a>, <a href="/profile?email=marcello.restelli%40polimi.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="marcello.restelli@polimi.it">Marcello Restelli</a>, <a href="/profile?email=peters%40ias.tu-darmstadt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="peters@ias.tu-darmstadt.de">Jan Peters</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rkgpv2VFvr-details-523" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgpv2VFvr-details-523"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study the benefit of sharing representations among tasks to enable the effective use of deep neural networks in Multi-Task Reinforcement Learning. We leverage the assumption that learning from different tasks, sharing common properties, is helpful to generalize the knowledge of them resulting in a more effective feature extraction compared to learning a single task. Intuitively, the resulting set of features offers performance benefits when used by Reinforcement Learning algorithms. We prove this by providing theoretical guarantees that highlight the conditions for which is convenient to share representations among tasks, extending the well-known finite-time bounds of Approximate Value-Iteration to the multi-task setting. In addition, we complement our analysis by proposing multi-task extensions of three Reinforcement Learning algorithms that we empirically evaluate on widely used Reinforcement Learning benchmarks showing significant improvements over the single-task counterparts in terms of sample efficiency and performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep Reinforcement Learning, Multi-Task</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A study on the benefit of sharing representation in Multi-Task Reinforcement Learning.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/carloderamo/shared/tree/master</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgpv2VFvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1eCw3EKvH" data-number="24">
      <h4>
        <a href="/forum?id=H1eCw3EKvH">
            On the Weaknesses of Reinforcement Learning for Neural Machine Translation
        </a>
      
        
          <a href="/pdf?id=H1eCw3EKvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=leshem.choshen%40mail.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="leshem.choshen@mail.huji.ac.il">Leshem Choshen</a>, <a href="/profile?email=lior.fox%40mail.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="lior.fox@mail.huji.ac.il">Lior Fox</a>, <a href="/profile?email=zohar.aizenbud%40mail.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="zohar.aizenbud@mail.huji.ac.il">Zohar Aizenbud</a>, <a href="/profile?email=oabend%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="oabend@cs.huji.ac.il">Omri Abend</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#H1eCw3EKvH-details-517" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1eCw3EKvH-details-517"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement learning, MRT, minimum risk training, reinforce, machine translation, peakkiness, generation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Reinforcment practices for machine translation performance gains might not come from better predictions.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Reinforcement learning (RL) is frequently used to increase performance in text generation tasks,
      including machine translation (MT), 
      notably through the use of Minimum Risk Training (MRT) and Generative Adversarial Networks (GAN). 
      However, little is known about what and how these methods learn in the context of MT. 
      We prove that one of the most common RL methods for MT does not optimize the 
      expected reward, as well as show that other methods take an infeasibly long time to converge.
      In fact, our results suggest that RL practices in MT are likely to improve performance
      only where the pre-trained parameters are already close to yielding the correct translation.
      Our findings further suggest that observed gains may be due to effects unrelated to the training signal, concretely, changes in the shape of the distribution curve.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1eCw3EKvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJxg_hVtwH" data-number="29">
      <h4>
        <a href="/forum?id=BJxg_hVtwH">
            StructPool: Structured Graph Pooling via Conditional Random Fields
        </a>
      
        
          <a href="/pdf?id=BJxg_hVtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=hao.yuan%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hao.yuan@tamu.edu">Hao Yuan</a>, <a href="/profile?email=sji%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sji@tamu.edu">Shuiwang Ji</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#BJxg_hVtwH-details-355" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJxg_hVtwH-details-355"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Learning high-level representations for graphs is of great importance for graph analysis tasks. In addition to graph convolution, graph pooling is an important but less explored research area. In particular, most of existing graph pooling techniques do not consider the graph structural information explicitly. We argue that such information is important and develop a novel graph pooling technique, know as the StructPool, in this work. We consider the graph pooling as a node clustering problem, which requires the learning of a cluster assignment matrix. We propose to formulate it as a structured prediction problem and employ conditional random fields to capture the relationships among assignments of different nodes.  We also generalize our method to incorporate graph topological information in designing the Gibbs energy function.  Experimental results on multiple datasets demonstrate the effectiveness of our proposed StructPool.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Graph Pooling, Representation Learning, Graph Analysis</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A novel graph pooling method considering relationships between different nodes via conditional random fields.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJxg_hVtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJgBd2NYPH" data-number="40">
      <h4>
        <a href="/forum?id=rJgBd2NYPH">
            Learning deep graph matching with channel-independent embedding and Hungarian attention
        </a>
      
        
          <a href="/pdf?id=rJgBd2NYPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tianshuy%40asu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianshuy@asu.edu">Tianshu Yu</a>, <a href="/profile?email=runzhong.wang%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="runzhong.wang@sjtu.edu.cn">Runzhong Wang</a>, <a href="/profile?email=yanjunchi%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanjunchi@sjtu.edu.cn">Junchi Yan</a>, <a href="/profile?email=baoxin.li%40asu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="baoxin.li@asu.edu">Baoxin Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rJgBd2NYPH-details-327" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJgBd2NYPH-details-327"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep graph matching, edge embedding, combinatorial problem, Hungarian loss</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We proposed a deep graph matching method with novel channel-independent embedding and Hungarian loss, which achieved state-of-the-art performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Graph matching aims to establishing node-wise correspondence between two graphs, which is a classic combinatorial problem and in general NP-complete. Until very recently, deep graph matching methods start to resort to deep networks to achieve unprecedented matching accuracy. Along this direction, this paper makes two complementary contributions which can also be reused as plugin in existing works: i) a novel node and edge embedding strategy which stimulates the multi-head strategy in attention models and allows the information in each channel to be merged independently. In contrast, only node embedding is accounted in previous works; ii) a general masking mechanism over the loss function is devised to improve the smoothness of objective learning for graph matching. Using Hungarian algorithm, it dynamically constructs a structured and sparsely connected layer, taking into account the most contributing matching pairs as hard attention. Our approach performs competitively, and can also improve state-of-the-art methods as plugin, regarding with matching accuracy on three public benchmarks.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJgBd2NYPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1evOhEKvH" data-number="45">
      <h4>
        <a href="/forum?id=r1evOhEKvH">
            Graph inference learning for semi-supervised classification
        </a>
      
        
          <a href="/pdf?id=r1evOhEKvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=cyx%40njust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="cyx@njust.edu.cn">Chunyan Xu</a>, <a href="/profile?email=zhen.cui%40njust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhen.cui@njust.edu.cn">Zhen Cui</a>, <a href="/profile?email=xbhong%40njust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xbhong@njust.edu.cn">Xiaobin Hong</a>, <a href="/profile?email=tong.zhang%40njust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="tong.zhang@njust.edu.cn">Tong Zhang</a>, <a href="/profile?email=csjyang%40njust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="csjyang@njust.edu.cn">Jian Yang</a>, <a href="/profile?email=wl2223%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wl2223@columbia.edu">Wei Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="#r1evOhEKvH-details-687" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1evOhEKvH-details-687"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">semi-supervised classification, graph inference learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In this work, we address the semi-supervised classification of graph data, where the categories of those unlabeled nodes are inferred from labeled nodes as well as graph structures. Recent works often solve this problem with the advanced graph convolution in a conventional supervised manner, but the performance could be heavily affected when labeled data is scarce. Here we propose a Graph Inference Learning (GIL) framework to boost the performance of node classification by learning the inference of node labels on graph topology. To bridge the connection of two nodes, we formally define a structure relation by encapsulating node attributes, between-node paths and local topological structures together, which can make inference conveniently deduced from one node to another node. For learning the inference process, we further introduce meta-optimization on structure relations from training nodes to validation nodes, such that the learnt graph inference capability can be better self-adapted into test nodes. Comprehensive evaluations on four benchmark datasets (including Cora, Citeseer, Pubmed and NELL) demonstrate the superiority of our GIL when compared with other state-of-the-art methods in the semi-supervised node classification task.</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value "> We propose a novel graph inference learning framework by building structure relations to infer unknown node labels from those labeled nodes in an end-to-end way.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1evOhEKvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1xKd24twB" data-number="50">
      <h4>
        <a href="/forum?id=S1xKd24twB">
            SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards
        </a>
      
        
          <a href="/pdf?id=S1xKd24twB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sgr%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sgr@berkeley.edu">Siddharth Reddy</a>, <a href="/profile?email=anca%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="anca@berkeley.edu">Anca D. Dragan</a>, <a href="/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#S1xKd24twB-details-772" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1xKd24twB-details-772"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Imitation Learning, Reinforcement Learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A simple and effective alternative to adversarial imitation learning: initialize experience replay buffer with demonstrations, set their reward to +1, set reward for all other data to 0, run Q-learning or soft actor-critic to train.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Learning to imitate expert behavior from demonstrations can be challenging, especially in environments with high-dimensional, continuous observations and unknown dynamics. Supervised learning methods based on behavioral cloning (BC) suffer from distribution shift: because the agent greedily imitates demonstrated actions, it can drift away from demonstrated states due to error accumulation. Recent methods based on reinforcement learning (RL), such as inverse RL and generative adversarial imitation learning (GAIL), overcome this issue by training an RL agent to match the demonstrations over a long horizon. Since the true reward function for the task is unknown, these methods learn a reward function from the demonstrations, often using complex and brittle approximation techniques that involve adversarial training. We propose a simple alternative that still uses RL, but does not require learning a reward function. The key idea is to provide the agent with an incentive to match the demonstrations over a long horizon, by encouraging it to return to demonstrated states upon encountering new, out-of-distribution states. We accomplish this by giving the agent a constant reward of r=+1 for matching the demonstrated action in a demonstrated state, and a constant reward of r=0 for all other behavior. Our method, which we call soft Q imitation learning (SQIL), can be implemented with a handful of minor modifications to any standard Q-learning or off-policy actor-critic algorithm. Theoretically, we show that SQIL can be interpreted as a regularized variant of BC that uses a sparsity prior to encourage long-horizon imitation. Empirically, we show that SQIL outperforms BC and achieves competitive results compared to GAIL, on a variety of image-based and low-dimensional tasks in Box2D, Atari, and MuJoCo. This paper is a proof of concept that illustrates how a simple imitation method based on RL with constant rewards can be as effective as more complex methods that use learned rewards.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1xKd24twB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1eiu2VtwH" data-number="53">
      <h4>
        <a href="/forum?id=r1eiu2VtwH">
            Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data
        </a>
      
        
          <a href="/pdf?id=r1eiu2VtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sapopov%40yandex-team.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="sapopov@yandex-team.ru">Sergei Popov</a>, <a href="/profile?email=stanis-morozov%40yandex.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="stanis-morozov@yandex.ru">Stanislav Morozov</a>, <a href="/profile?email=artem.babenko%40phystech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="artem.babenko@phystech.edu">Artem Babenko</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#r1eiu2VtwH-details-160" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1eiu2VtwH-details-160"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">tabular data, architectures, DNN</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a new DNN architecture for deep learning on tabular data</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Nowadays, deep neural networks (DNNs) have become the main instrument for machine learning tasks within a wide range of domains, including vision, NLP, and speech. Meanwhile, in an important case of heterogenous tabular data, the advantage of DNNs over shallow counterparts remains questionable. In particular, there is no sufficient evidence that deep learning machinery allows constructing methods that outperform gradient boosting decision trees (GBDT), which are often the top choice for tabular problems. In this paper, we introduce Neural Oblivious Decision Ensembles (NODE), a new deep learning architecture, designed to work with any tabular data. In a nutshell, the proposed NODE architecture generalizes ensembles of oblivious decision trees, but benefits from both end-to-end gradient-based optimization and the power of multi-layer hierarchical representation learning. With an extensive experimental comparison to the leading GBDT packages on a large number of tabular datasets, we demonstrate the advantage of the proposed NODE architecture, which outperforms the competitors on most of the tasks. We open-source the PyTorch implementation of NODE and believe that it will become a universal framework for machine learning on tabular data.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/anonICLR2020/node</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1eiu2VtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJlnOhVYPS" data-number="55">
      <h4>
        <a href="/forum?id=rJlnOhVYPS">
            Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised Domain Adaptation on Person Re-identification
        </a>
      
        
          <a href="/pdf?id=rJlnOhVYPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yxge%40link.cuhk.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yxge@link.cuhk.edu.hk">Yixiao Ge</a>, <a href="/profile?email=chendapeng%40sensetime.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chendapeng@sensetime.com">Dapeng Chen</a>, <a href="/profile?email=hsli%40ee.cuhk.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="hsli@ee.cuhk.edu.hk">Hongsheng Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rJlnOhVYPS-details-932" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJlnOhVYPS-details-932"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Label Refinery, Unsupervised Domain Adaptation, Person Re-identification</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A framework that conducts online refinement of pseudo labels with a novel soft softmax-triplet loss for unsupervised domain adaptation on person re-identification.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Person re-identification (re-ID) aims at identifying the same persons' images across different cameras. However, domain diversities between different datasets pose an evident challenge for adapting the re-ID model trained on one dataset to another one. State-of-the-art unsupervised domain adaptation methods for person re-ID transferred the learned knowledge from the source domain by optimizing with pseudo labels created by clustering algorithms on the target domain. Although they achieved state-of-the-art performances, the inevitable label noise caused by the clustering procedure was ignored. Such noisy pseudo labels substantially hinders the model's capability on further improving feature representations on the target domain. In order to mitigate the effects of noisy pseudo labels, we propose to softly refine the pseudo labels in the target domain by proposing an unsupervised framework, Mutual Mean-Teaching (MMT), to learn better features from the target domain via off-line refined hard pseudo labels and on-line refined soft pseudo labels in an alternative training manner.  In addition, the common practice is to adopt both the classification loss and the triplet loss jointly for achieving optimal performances in person re-ID models. However, conventional triplet loss cannot work with softly refined labels. To solve this problem, a novel soft softmax-triplet loss is proposed to support learning with soft pseudo triplet labels for achieving the optimal domain adaptation performance. The proposed MMT framework achieves considerable improvements of 14.4%, 18.2%, 13.1% and 16.4% mAP on Market-to-Duke, Duke-to-Market, Market-to-MSMT and Duke-to-MSMT unsupervised domain adaptation tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/yxgeee/MMT</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJlnOhVYPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJl2_nVFPB" data-number="57">
      <h4>
        <a href="/forum?id=BJl2_nVFPB">
            Automatically Discovering and Learning New Visual Categories with Ranking Statistics
        </a>
      
        
          <a href="/pdf?id=BJl2_nVFPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=khan%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="khan@robots.ox.ac.uk">Kai Han</a>, <a href="/profile?email=srebuffi%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="srebuffi@robots.ox.ac.uk">Sylvestre-Alvise Rebuffi</a>, <a href="/profile?email=hyenal%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="hyenal@robots.ox.ac.uk">Sebastien Ehrhardt</a>, <a href="/profile?email=vedaldi%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="vedaldi@robots.ox.ac.uk">Andrea Vedaldi</a>, <a href="/profile?email=az%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="az@robots.ox.ac.uk">Andrew Zisserman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#BJl2_nVFPB-details-423" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJl2_nVFPB-details-423"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, classification, novel classes, transfer learning, clustering, incremental learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A method to automatically discover new categories in unlabelled data, by effectively transferring knowledge from labelled data of other different categories using feature rank statistics.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We tackle the problem of discovering novel classes in an image collection given labelled examples of other classes. This setting is similar to semi-supervised learning, but significantly harder because there are no labelled examples for the new classes. The challenge, then, is to leverage the information contained in the labelled images in order to learn a general-purpose clustering model and use the latter to identify the new classes in the unlabelled data. In this work we address this problem by combining three ideas: (1) we suggest that the common approach of bootstrapping an image representation using the labeled data only introduces an unwanted bias, and that this can be avoided by using self-supervised learning to train the representation from scratch on the union of labelled and unlabelled data; (2) we use rank statistics to transfer the model's knowledge of the labelled classes to the problem of clustering the unlabelled images; and, (3) we train the data representation by optimizing a joint objective function on the labelled and unlabelled subsets of the data, improving both the supervised classification of the labelled data, and the clustering of the unlabelled data. We evaluate our approach on standard classification benchmarks and outperform current methods for novel category discovery by a significant margin.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">http://www.robots.ox.ac.uk/~vgg/research/auto_novel/</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJl2_nVFPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bkg0u3Etwr" data-number="61">
      <h4>
        <a href="/forum?id=Bkg0u3Etwr">
            Maxmin Q-learning: Controlling the Estimation Bias of Q-learning
        </a>
      
        
          <a href="/pdf?id=Bkg0u3Etwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=qlan3%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="qlan3@ualberta.ca">Qingfeng Lan</a>, <a href="/profile?email=pan6%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="pan6@ualberta.ca">Yangchen Pan</a>, <a href="/profile?email=alona%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="alona@ualberta.ca">Alona Fyshe</a>, <a href="/profile?email=whitem%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="whitem@ualberta.ca">Martha White</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="#Bkg0u3Etwr-details-531" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bkg0u3Etwr-details-531"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, bias and variance reduction</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a new variant of Q-learning algorithm called Maxmin Q-learning which provides a parameter-tuning mechanism to flexibly control bias.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Q-learning suffers from overestimation bias, because it approximates the maximum action value using the maximum estimated action value. Algorithms have been proposed to reduce overestimation bias, but we lack an understanding of how bias interacts with performance, and the extent to which existing algorithms mitigate bias. In this paper, we 1) highlight that the effect of overestimation bias on learning efficiency is environment-dependent; 2) propose a generalization of Q-learning, called \emph{Maxmin Q-learning}, which provides a parameter to flexibly control bias; 3) show theoretically that there exists a parameter choice for Maxmin Q-learning that leads to unbiased estimation with a lower approximation variance than Q-learning; and 4) prove the convergence of our algorithm in the tabular case, as well as convergence of several previous Q-learning variants, using a novel Generalized Q-learning framework. We empirically verify that our algorithm better controls estimation bias in toy environments, and that it achieves superior performance on several benchmark problems. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/qlan3/Explorer</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Bkg0u3Etwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJezF3VYPB" data-number="70">
      <h4>
        <a href="/forum?id=HJezF3VYPB">
            Federated Adversarial Domain Adaptation
        </a>
      
        
          <a href="/pdf?id=HJezF3VYPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xpeng%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xpeng@bu.edu">Xingchao Peng</a>, <a href="/profile?email=zijun.huang%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zijun.huang@columbia.edu">Zijun Huang</a>, <a href="/profile?email=yizhe.zhu%40rutgers.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yizhe.zhu@rutgers.edu">Yizhe Zhu</a>, <a href="/profile?email=saenko%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="saenko@bu.edu">Kate Saenko</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#HJezF3VYPB-details-499" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJezF3VYPB-details-499"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Federated Learning, Domain Adaptation, Transfer Learning, Feature Disentanglement</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">we present a principled approach to the problem of federated domain adaptation, which aims to align the representations learned among the different nodes with the data distribution of the target node.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Federated learning improves data privacy and efficiency in machine learning performed over networks of distributed devices, such as mobile phones, IoT and wearable devices, etc. Yet models trained with federated learning can still fail to generalize to new devices due to the problem of domain shift. Domain shift occurs when the labeled data collected by source nodes statistically differs from the target node's unlabeled data. In this work, we present a principled approach to the problem of federated domain adaptation, which aims to align the representations learned among the different nodes with the data distribution of the target node. Our approach extends adversarial adaptation techniques to the constraints of the federated setting. In addition, we devise a dynamic attention mechanism and leverage feature disentanglement to enhance knowledge transfer. Empirically, we perform extensive experiments on several image and text classification tasks and show promising results under unsupervised federated domain adaptation setting.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/file/d/1OekTpqB6qLfjlE2XUjQPm3F110KDMFc0/view?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJezF3VYPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJg7KhVKPH" data-number="73">
      <h4>
        <a href="/forum?id=SJg7KhVKPH">
            Depth-Adaptive Transformer
        </a>
      
        
          <a href="/pdf?id=SJg7KhVKPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=maha.elbayad%40inria.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="maha.elbayad@inria.fr">Maha Elbayad</a>, <a href="/profile?email=thomagram%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomagram@gmail.com">Jiatao Gu</a>, <a href="/profile?email=egrave%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="egrave@fb.com">Edouard Grave</a>, <a href="/profile?email=michael.auli%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael.auli@gmail.com">Michael Auli</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#SJg7KhVKPH-details-284" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJg7KhVKPH-details-284"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep learning, natural language processing, sequence modeling</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Sequence model that dynamically adjusts the amount of computation for each input.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">State of the art sequence-to-sequence models for large scale tasks perform a fixed number of computations for each input sequence regardless of whether it is easy or hard to process. In this paper, we train Transformer models which can make output predictions at different stages of the network and we investigate different ways to predict how much computation is required for a particular sequence. Unlike dynamic computation in Universal Transformers, which applies the same set of layers iteratively, we apply different layers at every step to adjust both the amount of computation as well as the model capacity. On IWSLT German-English translation our approach matches the accuracy of a well tuned baseline Transformer while using less than a quarter of the decoder layers.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJg7KhVKPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylBK34FDS" data-number="77">
      <h4>
        <a href="/forum?id=rylBK34FDS">
            DeepHoyer: Learning Sparser Neural Network with Differentiable Scale-Invariant Sparsity Measures
        </a>
      
        
          <a href="/pdf?id=rylBK34FDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=huanrui.yang%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="huanrui.yang@duke.edu">Huanrui Yang</a>, <a href="/profile?email=wei.wen%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wei.wen@duke.edu">Wei Wen</a>, <a href="/profile?email=hai.li%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hai.li@duke.edu">Hai Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rylBK34FDS-details-448" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylBK34FDS-details-448"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep neural network, Sparsity inducing regularizer, Model compression</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose almost everywhere differentiable and scale invariant regularizers for DNN pruning, which can lead to supremum sparsity through standard SGD training.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In seeking for sparse and efficient neural network models, many previous works investigated on enforcing L1 or L0 regularizers to encourage weight sparsity during training. The L0 regularizer measures the parameter sparsity directly and is invariant to the scaling of parameter values. But it cannot provide useful gradients and therefore requires complex optimization techniques. The L1 regularizer is almost everywhere differentiable and can be easily optimized with gradient descent. Yet it is not scale-invariant and causes the same shrinking rate to all parameters, which is inefficient in increasing sparsity. Inspired by the Hoyer measure (the ratio between L1 and L2 norms) used in traditional compressed sensing problems, we present DeepHoyer, a set of sparsity-inducing regularizers that are both differentiable almost everywhere and scale-invariant. Our experiments show that enforcing DeepHoyer regularizers can produce even sparser neural network models than previous works, under the same accuracy level. We also show that DeepHoyer can be applied to both element-wise and structural pruning.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/yanghr/DeepHoyer</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rylBK34FDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1loF2NFwr" data-number="91">
      <h4>
        <a href="/forum?id=H1loF2NFwr">
            Evaluating The Search Phase of Neural Architecture Search
        </a>
      
        
          <a href="/pdf?id=H1loF2NFwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kaicheng.yu%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="kaicheng.yu@epfl.ch">Kaicheng Yu</a>, <a href="/profile?email=sciutochristian%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sciutochristian@gmail.com">Christian Sciuto</a>, <a href="/profile?email=martin.jaggi%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="martin.jaggi@epfl.ch">Martin Jaggi</a>, <a href="/profile?email=claudiu.musat%40swisscom.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="claudiu.musat@swisscom.com">Claudiu Musat</a>, <a href="/profile?email=mathieu.salzmann%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="mathieu.salzmann@epfl.ch">Mathieu Salzmann</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#H1loF2NFwr-details-895" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1loF2NFwr-details-895"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Neural architecture search, parameter sharing, random search, evaluation framework</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We empirically disprove a fundamental hypothesis of the widely-adopted weight sharing strategy in neural architecture search and explain why the state-of-the-arts NAS algorithms performs similarly to random search.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">
      Neural Architecture Search (NAS) aims to facilitate the design of deep networks for new tasks. Existing techniques rely on two stages: searching over the architecture space and validating the best architecture. NAS algorithms are currently compared solely based on their results on the downstream task. While intuitive, this fails to explicitly evaluate the effectiveness of their search strategies. In this paper, we propose to evaluate the NAS search phase.
      To this end, we compare the quality of the solutions obtained by NAS search policies with that of random architecture selection. We find that: (i) On average, the state-of-the-art NAS algorithms perform similarly to the random policy; (ii) the widely-used weight sharing strategy degrades the ranking of the NAS candidates to the point of not reflecting their true performance, thus reducing the effectiveness of the search process.
      We believe that our evaluation framework will be key to designing NAS strategies that consistently discover architectures superior to random ones.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/kcyu2014/eval-nas</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1loF2NFwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxnY3NYPS" data-number="93">
      <h4>
        <a href="/forum?id=ryxnY3NYPS">
            Diverse Trajectory Forecasting with Determinantal Point Processes
        </a>
      
        
          <a href="/pdf?id=ryxnY3NYPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yyuan2%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yyuan2@cs.cmu.edu">Ye Yuan</a>, <a href="/profile?email=kkitani%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kkitani@cs.cmu.edu">Kris M. Kitani</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#ryxnY3NYPS-details-756" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxnY3NYPS-details-756"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We learn a diversity sampling function with DPPs to obtain a diverse set of samples from a generative model.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The ability to forecast a set of likely yet diverse possible future behaviors of an agent (e.g., future trajectories of a pedestrian) is essential for safety-critical perception systems (e.g., autonomous vehicles). In particular, a set of possible future behaviors generated by the system must be diverse to account for all possible outcomes in order to take necessary safety precautions. It is not sufficient to maintain a set of the most likely future outcomes because the set may only contain perturbations of a dominating single outcome (major mode). While generative models such as variational autoencoders (VAEs) have been shown to be a powerful tool for learning a distribution over future trajectories, randomly drawn samples from the learned implicit likelihood model may not be diverse -- the likelihood model is derived from the training data distribution and the samples will concentrate around the major mode of the data. In this work, we propose to learn a diversity sampling function (DSF) that generates a diverse yet likely set of future trajectories. The DSF maps forecasting context features to a set of latent codes which can be decoded by a generative model (e.g., VAE) into a set of diverse trajectory samples. Concretely, the process of identifying the diverse set of samples is posed as DSF parameter estimation. To learn the parameters of the DSF, the diversity of the trajectory samples is evaluated by a diversity loss based on a determinantal point process (DPP). Gradient descent is performed over the DSF parameters, which in turn moves the latent codes of the sample set to find an optimal set of diverse yet likely trajectories. Our method is a novel application of DPPs to optimize a set of items (forecasted trajectories) in continuous space. We demonstrate the diversity of the trajectories produced by our approach on both low-dimensional 2D trajectory data and high-dimensional human motion data.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Diverse Inference, Generative Models, Trajectory Forecasting</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxnY3NYPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HygpthEtvr" data-number="95">
      <h4>
        <a href="/forum?id=HygpthEtvr">
            ProxSGD: Training Structured Neural Networks under Regularization and Constraints
        </a>
      
        
          <a href="/pdf?id=HygpthEtvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yang.yang%40itwm.fraunhofer.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="yang.yang@itwm.fraunhofer.de">Yang Yang</a>, <a href="/profile?email=yaxiong.yuan%40uni.lu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaxiong.yuan@uni.lu">Yaxiong Yuan</a>, <a href="/profile?email=avraam.chatzimichailidis%40itwm.fraunhofer.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="avraam.chatzimichailidis@itwm.fraunhofer.de">Avraam Chatzimichailidis</a>, <a href="/profile?email=r.j.g.v.sloun%40tue.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="r.j.g.v.sloun@tue.nl">Ruud JG van Sloun</a>, <a href="/profile?email=lei.lei%40uni.lu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lei.lei@uni.lu">Lei Lei</a>, <a href="/profile?email=symeon.chatzinotas%40uni.lu" class="profile-link" data-toggle="tooltip" data-placement="top" title="symeon.chatzinotas@uni.lu">Symeon Chatzinotas</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HygpthEtvr-details-608" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HygpthEtvr-details-608"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a convergent proximal-type stochastic gradient descent algorithm for constrained nonsmooth nonconvex optimization problems</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In this paper, we consider the problem of training neural networks (NN). To promote a NN with specific structures, we explicitly take into consideration the nonsmooth regularization (such as L1-norm) and constraints (such as interval constraint). This is formulated as a constrained nonsmooth nonconvex optimization problem, and we propose a convergent proximal-type stochastic gradient descent (Prox-SGD) algorithm. We show that under properly selected learning rates, momentum eventually resembles the unknown real gradient and thus is crucial in analyzing the convergence. We establish that with probability 1, every limit point of the sequence generated by the proposed Prox-SGD is a stationary point. Then the Prox-SGD is tailored to train a sparse neural network and a binary neural network, and the theoretical analysis is also supported by extensive numerical tests.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">stochastic gradient descent, regularization, constrained optimization, nonsmooth optimization</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/optyang/proxsgd; https://github.com/cc-hpc-itwm/proxsgd</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HygpthEtvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skgxcn4YDS" data-number="103">
      <h4>
        <a href="/forum?id=Skgxcn4YDS">
            LAMOL: LAnguage MOdeling for Lifelong Language Learning
        </a>
      
        
          <a href="/pdf?id=Skgxcn4YDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=fankeng%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fankeng@mit.edu">Fan-Keng Sun*</a>, <a href="/profile?email=jojotenya%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jojotenya@gmail.com">Cheng-Hao Ho*</a>, <a href="/profile?email=hungyilee%40ntu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="hungyilee@ntu.edu.tw">Hung-Yi Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#Skgxcn4YDS-details-718" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skgxcn4YDS-details-718"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">NLP, Deep Learning, Lifelong Learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Language modeling for lifelong language learning.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Most research on lifelong learning applies to images or games, but not language.
      We present LAMOL, a simple yet effective method for lifelong language learning (LLL) based on language modeling.
      LAMOL replays pseudo-samples of previous tasks while requiring no extra memory or model capacity.
      Specifically, LAMOL is a language model that simultaneously learns to solve the tasks and generate training samples.
      When the model is trained for a new task, it generates pseudo-samples of previous tasks for training alongside data for the new task.
      The results show that LAMOL prevents catastrophic forgetting without any sign of intransigence and can perform five very different language tasks sequentially with only one model. 
      Overall, LAMOL outperforms previous methods by a considerable margin and is only 2-3% worse than multitasking, which is usually considered the LLL upper bound.
      The source code is available at https://github.com/jojotenya/LAMOL.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/jojotenya/LAMOL</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Skgxcn4YDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryeG924twB" data-number="108">
      <h4>
        <a href="/forum?id=ryeG924twB">
            Learning Expensive Coordination: An Event-Based Deep RL Approach
        </a>
      
        
          <a href="/pdf?id=ryeG924twB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=shizhy6%40mail2.sysu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="shizhy6@mail2.sysu.edu.cn">Zhenyu Shi*</a>, <a href="/profile?email=runsheng.yu%40ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="runsheng.yu@ntu.edu.sg">Runsheng Yu*</a>, <a href="/profile?email=xwang033%40e.ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="xwang033@e.ntu.edu.sg">Xinrun Wang*</a>, <a href="/profile?email=rundong001%40e.ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="rundong001@e.ntu.edu.sg">Rundong Wang</a>, <a href="/profile?email=yzhang137%40e.ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="yzhang137@e.ntu.edu.sg">Youzhi Zhang</a>, <a href="/profile?email=laihanj3%40mail.sysu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="laihanj3@mail.sysu.edu.cn">Hanjiang Lai</a>, <a href="/profile?email=boan%40ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="boan@ntu.edu.sg">Bo An</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#ryeG924twB-details-836" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryeG924twB-details-836"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose an event-based policy gradient  to train the leader and an action abstraction policy gradient to train the followers in leader-follower Markov game.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Existing works in deep Multi-Agent Reinforcement Learning (MARL) mainly focus on coordinating cooperative agents to complete certain tasks jointly. However, in many cases of the real world, agents are self-interested such as employees in a company and clubs in a league. Therefore, the leader, i.e., the manager of the company or the league, needs to provide bonuses to followers for efficient coordination, which we call expensive coordination. The main difficulties of expensive coordination are that i) the leader has to consider the long-term effect and predict the followers' behaviors when assigning bonuses and ii) the complex interactions between followers make the training process hard to converge, especially when the leader's policy changes with time. In this work, we address this problem through an event-based deep RL approach. Our main contributions are threefold. (1) We model the leader's decision-making process as a semi-Markov Decision Process and propose a novel multi-agent event-based policy gradient to learn the leader's long-term policy. (2) We exploit the leader-follower consistency scheme to design a follower-aware module and a follower-specific attention module to predict the followers' behaviors and make accurate response to their behaviors. (3) We propose an action abstraction-based policy gradient algorithm to reduce the followers' decision space and thus accelerate the training process of followers. Experiments in resource collections, navigation, and the predator-prey game reveal that our approach outperforms the state-of-the-art methods dramatically.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Multi-Agent Deep Reinforcement Learning, Deep Reinforcement Learning, Leader–Follower Markov Game, Expensive Coordination</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryeG924twB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BylEqnVFDB" data-number="112">
      <h4>
        <a href="/forum?id=BylEqnVFDB">
            Curvature Graph Network
        </a>
      
        
          <a href="/pdf?id=BylEqnVFDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yeze16159%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yeze16159@gmail.com">Ze Ye</a>, <a href="/profile?email=kiliu%40cs.stonybrook.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kiliu@cs.stonybrook.edu">Kin Sum Liu</a>, <a href="/profile?email=tengfei.ma1%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tengfei.ma1@ibm.com">Tengfei Ma</a>, <a href="/profile?email=jgao%40cs.stonybrook.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jgao@cs.stonybrook.edu">Jie Gao</a>, <a href="/profile?email=chao.chen.1%40stonybrook.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chao.chen.1@stonybrook.edu">Chao Chen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#BylEqnVFDB-details-651" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BylEqnVFDB-details-651"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Graph-structured data is prevalent in many domains. Despite the widely celebrated success of deep neural networks, their power in graph-structured data is yet to be fully explored. We propose a novel network architecture that incorporates advanced graph structural features. In particular, we leverage discrete graph curvature, which measures how the neighborhoods of a pair of nodes are structurally related. The curvature of an edge (x, y) defines the distance taken to travel from neighbors of x to neighbors of y, compared with the length of edge (x, y). It is a much more descriptive feature compared to previously used features that only focus on node specific attributes or limited topological information such as degree. Our curvature graph convolution network outperforms state-of-the-art on various synthetic and real-world graphs, especially the larger and denser ones.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep Learning, Graph Convolution, Ricci Curvature.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BylEqnVFDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJeB5hVtvB" data-number="113">
      <h4>
        <a href="/forum?id=BJeB5hVtvB">
            Distance-Based Learning from Errors for Confidence Calibration
        </a>
      
        
          <a href="/pdf?id=BJeB5hVtvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xingchen1113%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xingchen1113@gmail.com">Chen Xing</a>, <a href="/profile?email=soarik%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="soarik@google.com">Sercan Arik</a>, <a href="/profile?email=zizhaoz%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zizhaoz@google.com">Zizhao Zhang</a>, <a href="/profile?email=tpfister%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tpfister@google.com">Tomas Pfister</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#BJeB5hVtvB-details-89" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJeB5hVtvB-details-89"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep neural networks (DNNs) are poorly calibrated when trained in conventional ways. To improve confidence calibration of DNNs, we propose a novel training method, distance-based learning from errors (DBLE). DBLE bases its confidence estimation on distances in the representation space. In DBLE, we first adapt prototypical learning to train classification models. It yields a representation space where the distance between a test sample and its ground truth class center can calibrate the model's classification performance. At inference, however, these distances are not available due to the lack of ground truth labels. To circumvent this by inferring the distance for every test sample, we propose to train a confidence model jointly with the classification model. We integrate this into training by merely learning from mis-classified training samples, which we show to be highly beneficial for effective learning. On multiple datasets and DNN architectures, we demonstrate that DBLE outperforms alternative single-model confidence calibration approaches. DBLE also achieves comparable performance with computationally-expensive ensemble approaches with lower computational cost and lower number of parameters.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Confidence Calibration, Uncertainty Estimation, Prototypical Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/open?id=1UThGvkkvFvKX8ogsfwvdA3uY8xzDlIuL</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJeB5hVtvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkeIq2VYPr" data-number="117">
      <h4>
        <a href="/forum?id=rkeIq2VYPr">
            Deep Learning of Determinantal Point Processes via Proper Spectral Sub-gradient
        </a>
      
        
          <a href="/pdf?id=rkeIq2VYPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tianshuy%40asu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianshuy@asu.edu">Tianshu Yu</a>, <a href="/profile?email=yikang.li%40asu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yikang.li@asu.edu">Yikang Li</a>, <a href="/profile?email=baoxin.li%40asu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="baoxin.li@asu.edu">Baoxin Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rkeIq2VYPr-details-526" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkeIq2VYPr-details-526"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">determinantal point processes, deep learning, optimization</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We proposed a specific back-propagation method via proper spectral sub-gradient to integrate determinantal point process to deep learning framework.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Determinantal point processes (DPPs) is an effective tool to deliver diversity on multiple machine learning and computer vision tasks. Under deep learning framework, DPP is typically optimized via approximation, which is not straightforward and has some conflict with diversity requirement. We note, however, there has been no deep learning paradigms to optimize DPP directly since it involves matrix inversion which may result in highly computational instability. This fact greatly hinders the wide use of DPP on some specific objectives where DPP serves as a term to measure the feature diversity. In this paper, we devise a simple but effective algorithm to address this issue to optimize DPP term directly expressed with L-ensemble in spectral domain over gram matrix, which is more flexible than learning on parametric kernels. By further taking into account some geometric constraints, our algorithm seeks to generate valid sub-gradients of DPP term in case when the DPP gram matrix is not invertible (no gradients exist in this case). In this sense, our algorithm can be easily incorporated with multiple deep learning tasks. Experiments show the effectiveness of our algorithm, indicating promising performance for practical learning problems. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkeIq2VYPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1ecqn4YwB" data-number="125">
      <h4>
        <a href="/forum?id=r1ecqn4YwB">
            N-BEATS: Neural basis expansion analysis for interpretable time series forecasting
        </a>
      
        
          <a href="/pdf?id=r1ecqn4YwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=boris%40elementai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="boris@elementai.com">Boris N. Oreshkin</a>, <a href="/profile?email=dmitri.carpov%40elementai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dmitri.carpov@elementai.com">Dmitri Carpov</a>, <a href="/profile?email=chapados%40elementai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chapados@elementai.com">Nicolas Chapados</a>, <a href="/profile?email=yoshua.bengio%40mila.quebec" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.bengio@mila.quebec">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#r1ecqn4YwB-details-565" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1ecqn4YwB-details-565"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A novel deep interpretable architecture that achieves state of the art on three large scale univariate time series forecasting datasets </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We focus on solving the univariate times series point forecasting problem using deep learning. We propose a deep neural architecture based on backward and forward residual links and a very deep stack of fully-connected layers. The architecture has a number of desirable properties, being interpretable, applicable without modification to a wide array of target domains, and fast to train. We test the proposed architecture on several well-known datasets, including M3, M4 and TOURISM competition datasets containing time series from diverse domains. We demonstrate state-of-the-art performance for two configurations of N-BEATS for all the datasets, improving forecast accuracy by 11% over a statistical benchmark and by 3% over last year's winner of the M4 competition, a domain-adjusted hand-crafted hybrid between neural network and statistical time series models. The first configuration of our model does not employ any time-series-specific components and its performance on heterogeneous datasets strongly suggests that, contrarily to received wisdom, deep learning primitives such as residual blocks are by themselves sufficient to solve a wide range of forecasting problems. Finally, we demonstrate how the proposed architecture can be augmented to provide outputs that are interpretable without considerable loss in accuracy.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">time series forecasting, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1ecqn4YwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rklp93EtwH" data-number="132">
      <h4>
        <a href="/forum?id=rklp93EtwH">
            Automated Relational Meta-learning
        </a>
      
        
          <a href="/pdf?id=rklp93EtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=huaxiuyao%40psu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="huaxiuyao@psu.edu">Huaxiu Yao</a>, <a href="/profile?email=xwu9%40nd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xwu9@nd.edu">Xian Wu</a>, <a href="/profile?email=zqtao%40ece.neu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zqtao@ece.neu.edu">Zhiqiang Tao</a>, <a href="/profile?email=yaliangl.ub%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaliangl.ub@gmail.com">Yaliang Li</a>, <a href="/profile?email=bolin.ding%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bolin.ding@alibaba-inc.com">Bolin Ding</a>, <a href="/profile?email=rrli%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rrli@cs.ucla.edu">Ruirui Li</a>, <a href="/profile?email=jessieli%40ist.psu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jessieli@ist.psu.edu">Zhenhui Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#rklp93EtwH-details-475" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rklp93EtwH-details-475"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Addressing task heterogeneity problem in meta-learning by introducing meta-knowledge graph</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In order to efficiently learn with small amount of data on new tasks, meta-learning transfers knowledge learned from previous tasks to the new ones. However, a critical challenge in meta-learning is the task heterogeneity which cannot be well handled by traditional globally shared meta-learning methods. In addition, current task-specific meta-learning methods may either suffer from hand-crafted structure design or lack the capability to capture complex relations between tasks. In this paper, motivated by the way of knowledge organization in knowledge bases, we propose an automated relational meta-learning (ARML) framework that automatically extracts the cross-task relations and constructs the meta-knowledge graph. When a new task arrives, it can quickly find the most relevant structure and tailor the learned structure knowledge to the meta-learner. As a result, the proposed framework not only addresses the challenge of task heterogeneity by a learned meta-knowledge graph, but also increases the model interpretability. We conduct extensive experiments on 2D toy regression and few-shot image classification and the results demonstrate the superiority of ARML over state-of-the-art baselines.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">meta-learning, task heterogeneity, meta-knowledge graph</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/huaxiuyao/ARML</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rklp93EtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sylgsn4Fvr" data-number="140">
      <h4>
        <a href="/forum?id=Sylgsn4Fvr">
            To Relieve Your Headache of Training an MRF, Take AdVIL
        </a>
      
        
          <a href="/pdf?id=Sylgsn4Fvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=chongxuanli1991%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chongxuanli1991@gmail.com">Chongxuan Li</a>, <a href="/profile?email=duchao0726%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="duchao0726@gmail.com">Chao Du</a>, <a href="/profile?email=kunxu.thu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kunxu.thu@gmail.com">Kun Xu</a>, <a href="/profile?email=m.welling%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.welling@uva.nl">Max Welling</a>, <a href="/profile?email=dcszj%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dcszj@mail.tsinghua.edu.cn">Jun Zhu</a>, <a href="/profile?email=dcszb%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dcszb@mail.tsinghua.edu.cn">Bo Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#Sylgsn4Fvr-details-637" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sylgsn4Fvr-details-637"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose a black-box algorithm called {\it Adversarial Variational Inference and Learning} (AdVIL)  to perform inference and learning on a general Markov random field (MRF). AdVIL employs two variational distributions to approximately infer the latent variables and estimate the partition function of an MRF, respectively. The two variational distributions provide an estimate of the negative log-likelihood of the MRF as a minimax optimization problem, which is solved by stochastic gradient descent. AdVIL is proven convergent under certain conditions. On one hand, compared with contrastive divergence, AdVIL requires a minimal assumption about the model structure and can deal with a broader family of MRFs. On the other hand, compared with existing black-box methods, AdVIL provides a tighter estimate of the log partition function and achieves much better empirical results. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://anonymous.4open.science/r/8c779fbc-6394-40c7-8273-e52504814703/</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Markov Random Fields, Undirected Graphical Models, Variational Inference, Black-box Infernece</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a black-box algorithm called AdVIL  to perform inference and learning on a general Markov random field.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Sylgsn4Fvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1lBj2VFPS" data-number="150">
      <h4>
        <a href="/forum?id=H1lBj2VFPS">
            Linear Symmetric Quantization of Neural Networks for Low-precision Integer Hardware
        </a>
      
        
          <a href="/pdf?id=H1lBj2VFPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zhaoxiandong%40ict.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaoxiandong@ict.ac.cn">Xiandong Zhao</a>, <a href="/profile?email=wangying2009%40ict.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wangying2009@ict.ac.cn">Ying Wang</a>, <a href="/profile?email=caixuyi18s%40ict.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="caixuyi18s@ict.ac.cn">Xuyi Cai</a>, <a href="/profile?email=liucheng%40ict.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="liucheng@ict.ac.cn">Cheng Liu</a>, <a href="/profile?email=zlei%40ict.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zlei@ict.ac.cn">Lei Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#H1lBj2VFPS-details-326" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1lBj2VFPS-details-326"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">quantization, integer-arithmetic-only DNN accelerator, acceleration</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce an efficient quantization process that allows for performance acceleration on specialized integer-only neural network accelerator.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">With the proliferation of specialized neural network processors that operate on low-precision integers, the performance of Deep Neural Network inference becomes increasingly dependent on the result of quantization. Despite plenty of prior work on the quantization of weights or activations for neural networks, there is still a wide gap between the software quantizers and the low-precision accelerator implementation, which degrades either the efficiency of networks or that of the hardware for the lack of software and hardware coordination at design-phase. In this paper, we propose a learned linear symmetric quantizer for integer neural network processors, which not only quantizes neural parameters and activations to low-bit integer but also accelerates hardware inference by using batch normalization fusion and low-precision accumulators (e.g., 16-bit) and multipliers (e.g., 4-bit). We use a unified way to quantize weights and activations, and the results outperform many previous approaches for various networks such as AlexNet, ResNet, and lightweight models like MobileNet while keeping friendly to the accelerator architecture. Additional, we also apply the method to object detection models and witness high performance and accuracy in YOLO-v2. Finally, we deploy the quantized models on our specialized integer-arithmetic-only DNN accelerator to show the effectiveness of the proposed quantizer. We show that even with linear symmetric quantization, the results can be better than asymmetric or non-linear methods in 4-bit networks. In evaluation, the proposed quantizer induces less than 0.4\% accuracy drop in ResNet18, ResNet34, and AlexNet when quantizing the whole network as required by the integer processors.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://anonymous.4open.science/r/c05a5b6a-1d0c-4201-926f-e7b52034f7a5/</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1lBj2VFPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1xIj3VYvr" data-number="153">
      <h4>
        <a href="/forum?id=B1xIj3VYvr">
            Weakly Supervised Clustering by Exploiting Unique Class Count
        </a>
      
        
          <a href="/pdf?id=B1xIj3VYvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=umitoner%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="umitoner@comp.nus.edu.sg">Mustafa Umit Oner</a>, <a href="/profile?email=leehk%40bii.a-star.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="leehk@bii.a-star.edu.sg">Hwee Kuan Lee</a>, <a href="/profile?email=ksung%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="ksung@comp.nus.edu.sg">Wing-Kin Sung</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#B1xIj3VYvr-details-786" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1xIj3VYvr-details-786"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">weakly supervised clustering, weakly supervised learning, multiple instance learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A weakly supervised learning based clustering framework performs comparable to that of fully supervised learning models by exploiting unique class count.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">A weakly supervised learning based clustering framework is proposed in this paper. As the core of this framework, we introduce a novel multiple instance learning task based on a bag level label called unique class count (ucc), which is the number of unique classes among all instances inside the bag. In this task, no annotations on individual instances inside the bag are needed during training of the models. We mathematically prove that with a perfect ucc classifier, perfect clustering of individual instances inside the bags is possible even when no annotations on individual instances are given during training. We have constructed a neural network based ucc classifier and experimentally shown that the clustering performance of our framework with our weakly supervised ucc classifier is comparable to that of fully supervised learning models where labels for all instances are known. Furthermore, we have tested the applicability of our framework to a real world task of semantic segmentation of breast cancer metastases in histological lymph node sections and shown that the performance of our weakly supervised framework is comparable to the performance of a fully supervised Unet model.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">http://bit.ly/uniqueclasscount</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1xIj3VYvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1gdj2EKPB" data-number="157">
      <h4>
        <a href="/forum?id=r1gdj2EKPB">
            Scalable and Order-robust Continual Learning with Additive Parameter Decomposition
        </a>
      
        
          <a href="/pdf?id=r1gdj2EKPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jaehong.yoon%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaehong.yoon@kaist.ac.kr">Jaehong Yoon</a>, <a href="/profile?email=shkim%40aitrics.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shkim@aitrics.com">Saehoon Kim</a>, <a href="/profile?email=eunhoy%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="eunhoy@kaist.ac.kr">Eunho Yang</a>, <a href="/profile?email=sjhwang82%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjhwang82@kaist.ac.kr">Sung Ju Hwang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>20 Replies</span>
        
        
      </div>
      
        <a href="#r1gdj2EKPB-details-964" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1gdj2EKPB-details-964"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">While recent continual learning methods largely alleviate the catastrophic problem on toy-sized datasets, there are issues that remain to be tackled in order to apply them to real-world problem domains. First, a continual learning model should effectively handle catastrophic forgetting and be efficient to train even with a large number of tasks. Secondly, it needs to tackle the problem of order-sensitivity, where the performance of the tasks largely varies based on the order of the task arrival sequence, as it may cause serious problems where fairness plays a critical role (e.g. medical diagnosis). To tackle these practical challenges, we propose a novel continual learning method that is scalable as well as order-robust, which instead of learning a completely shared set of weights, represents the parameters  for each task as a sum of task-shared and sparse task-adaptive parameters. With our Additive Parameter Decomposition (APD), the task-adaptive parameters for earlier tasks remain mostly unaffected, where we update them only to reflect the changes made to the task-shared parameters. This decomposition of parameters effectively prevents catastrophic forgetting and order-sensitivity, while being computation- and memory-efficient. Further, we can achieve even better scalability with APD using hierarchical knowledge consolidation, which clusters the task-adaptive parameters to obtain hierarchically shared parameters. We validate our network with APD, APD-Net, on multiple benchmark datasets against state-of-the-art continual learning methods, which it largely outperforms in accuracy, scalability, and order-robustness.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/iclr2020-apd/anonymous_iclr2020_apd_code</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Continual Learning, Lifelong Learning, Catastrophic Forgetting, Deep Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1gdj2EKPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hklso24Kwr" data-number="165">
      <h4>
        <a href="/forum?id=Hklso24Kwr">
            Continual Learning with Adaptive Weights (CLAW)
        </a>
      
        
          <a href="/pdf?id=Hklso24Kwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tah47%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="tah47@cam.ac.uk">Tameem Adel</a>, <a href="/profile?email=han.zhao%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="han.zhao@cs.cmu.edu">Han Zhao</a>, <a href="/profile?email=ret26%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="ret26@cam.ac.uk">Richard E. Turner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#Hklso24Kwr-details-522" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hklso24Kwr-details-522"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A continual learning framework which learns to automatically adapt its architecture based on a proposed variational inference algorithm. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Approaches to continual learning aim to successfully learn a set of related tasks that arrive in an online manner. Recently, several frameworks have been developed which enable deep learning to be deployed in this learning scenario. A key modelling decision is to what extent the architecture should be shared across tasks. On the one hand, separately modelling each task avoids catastrophic forgetting but it does not support transfer learning and leads to large models. On the other hand, rigidly specifying a shared component and a task-specific part enables task transfer and limits the model size, but it is vulnerable to catastrophic forgetting and restricts the form of task-transfer that can occur. Ideally, the network should adaptively identify which parts of the network to share in a data driven way. Here we introduce such an approach called Continual Learning with Adaptive Weights (CLAW), which is based on probabilistic modelling and variational inference. Experiments show that CLAW achieves state-of-the-art performance on six benchmarks in terms of overall continual learning performance, as measured by classification accuracy, and in terms of addressing catastrophic forgetting. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Continual learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hklso24Kwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJxAo2VYwr" data-number="172">
      <h4>
        <a href="/forum?id=rJxAo2VYwr">
            Transferable Perturbations of Deep Feature Distributions
        </a>
      
        
          <a href="/pdf?id=rJxAo2VYwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=nathan.inkawhich%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nathan.inkawhich@duke.edu">Nathan Inkawhich</a>, <a href="/profile?email=kevin.liang%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kevin.liang@duke.edu">Kevin Liang</a>, <a href="/profile?email=lcarin%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lcarin@duke.edu">Lawrence Carin</a>, <a href="/profile?email=yiran.chen%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yiran.chen@duke.edu">Yiran Chen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rJxAo2VYwr-details-356" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJxAo2VYwr-details-356"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Almost all current adversarial attacks of CNN classifiers rely on information derived from the output layer of the network. This work presents a new adversarial attack based on the modeling and exploitation of class-wise and layer-wise deep feature distributions. We achieve state-of-the-art targeted blackbox transfer-based attack results for undefended ImageNet models. Further, we place a priority on explainability and interpretability of the attacking process. Our methodology affords an analysis of how adversarial attacks change the intermediate feature distributions of CNNs, as well as a measure of layer-wise and class-wise feature distributional separability/entanglement. We also conceptualize a transition from task/data-specific to model-specific features within a CNN architecture that directly impacts the transferability of adversarial examples. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial attacks, transferability, interpretability</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We show that perturbations based-on intermediate feature distributions yield more transferable adversarial examples and allow for analysis of the affects of adversarial perturbations on intermediate representations.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJxAo2VYwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJe1334YDH" data-number="173">
      <h4>
        <a href="/forum?id=BJe1334YDH">
            A Learning-based Iterative Method for Solving Vehicle Routing Problems
        </a>
      
        
          <a href="/pdf?id=BJe1334YDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=haolu%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="haolu@princeton.edu">Hao Lu</a>, <a href="/profile?email=xingwen.zhang%40antfin.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xingwen.zhang@antfin.com">Xingwen Zhang</a>, <a href="/profile?email=shuang.yang%40antfin.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shuang.yang@antfin.com">Shuang Yang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#BJe1334YDH-details-347" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJe1334YDH-details-347"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">vehicle routing, reinforcement learning, optimization, heuristics</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper is concerned with solving combinatorial optimization problems, in particular, the capacitated vehicle routing problems (CVRP). Classical Operations Research (OR) algorithms such as LKH3 (Helsgaun, 2017) are extremely inefficient (e.g., 13 hours on CVRP of only size 100) and difficult to scale to larger-size problems. Machine learning based approaches have recently shown to be promising, partly because of their efficiency (once trained, they can perform solving within minutes or even seconds). However, there is still a considerable gap between the quality of a machine learned solution and what OR methods can offer (e.g., on CVRP-100, the best result of learned solutions is between 16.10-16.80, significantly worse than LKH3's 15.65). In this paper, we present ’‘learn to Improve’‘ (L2I), the first learning based approach for CVRP that is efficient in solving speed and at the same time outperforms OR methods. Starting with a random initial solution, L2I learns to iteratively refine the solution with an improvement operator, selected by a reinforcement learning based controller. The improvement operator is selected from a pool of powerful operators that are customized for routing problems. By combining the strengths of the two worlds, our approach achieves the new state-of-the-art results on CVRP, e.g., an average cost of 15.57 on CVRP-100.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJe1334YDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkxgnnNFvH" data-number="175">
      <h4>
        <a href="/forum?id=SkxgnnNFvH">
            Poly-encoders: Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring
        </a>
      
        
          <a href="/pdf?id=SkxgnnNFvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=samuelhumeau%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="samuelhumeau@fb.com">Samuel Humeau</a>, <a href="/profile?email=kshuster%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kshuster@fb.com">Kurt Shuster</a>, <a href="/profile?email=malachaux%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="malachaux@fb.com">Marie-Anne Lachaux</a>, <a href="/profile?email=jaseweston%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaseweston@gmail.com">Jason Weston</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 26 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="#SkxgnnNFvH-details-988" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkxgnnNFvH-details-988"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The use of deep pre-trained transformers has led to remarkable progress in a number of applications (Devlin et al., 2018). For tasks that make pairwise comparisons between sequences, matching a given input with a corresponding label, two approaches are common: Cross-encoders performing full self-attention over the pair and Bi-encoders encoding the pair separately. The former often performs better, but is too slow for practical use. In this work, we develop a new transformer architecture, the Poly-encoder, that learns global rather than token level self-attention features. We perform a detailed comparison of all three approaches, including what pre-training and fine-tuning strategies work best. We show our models achieve state-of-the-art results on four tasks; that Poly-encoders are faster than Cross-encoders and more accurate than Bi-encoders; and that the best results are obtained by pre-training on large datasets similar to the downstream tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkxgnnNFvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rygfnn4twS" data-number="181">
      <h4>
        <a href="/forum?id=rygfnn4twS">
            AutoQ: Automated Kernel-Wise Neural Network Quantization 
        </a>
      
        
          <a href="/pdf?id=rygfnn4twS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=louqian%40iu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="louqian@iu.edu">Qian Lou</a>, <a href="/profile?email=fengguo%40iu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fengguo@iu.edu">Feng Guo</a>, <a href="/profile?email=minje%40indiana.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="minje@indiana.edu">Minje Kim</a>, <a href="/profile?email=lantao%40iu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lantao@iu.edu">Lantao Liu</a>, <a href="/profile?email=jiang60%40iu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiang60@iu.edu">Lei Jiang.</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rygfnn4twS-details-885" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rygfnn4twS-details-885"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">AutoML, Kernel-Wise Neural Networks Quantization, Hierarchical Deep Reinforcement Learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Accurate, Fast and Automated Kernel-Wise Neural Network Quantization with Mixed Precision using Hierarchical Deep Reinforcement Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Network quantization is one of the most hardware friendly techniques to enable the deployment of convolutional neural networks (CNNs) on low-power mobile devices. Recent network quantization techniques quantize each weight kernel in a convolutional layer independently for higher inference accuracy, since the weight kernels in a layer exhibit different variances and hence have different amounts of redundancy. The quantization bitwidth or bit number (QBN) directly decides the inference accuracy, latency, energy and hardware overhead. To effectively reduce the redundancy and accelerate CNN inferences, various weight kernels should be quantized with different QBNs. However, prior works use only one QBN to quantize each convolutional layer or the entire CNN, because the design space of searching a QBN for each weight kernel is too large. The hand-crafted heuristic of the kernel-wise QBN search is so sophisticated that domain experts can obtain only sub-optimal results. It is difficult for even deep reinforcement learning (DRL) DDPG-based agents to find a kernel-wise QBN configuration that can achieve reasonable inference accuracy. In this paper, we propose a hierarchical-DRL-based kernel-wise network quantization technique, AutoQ, to automatically search a QBN for each weight kernel, and choose another QBN for each activation layer. Compared to the models quantized by the state-of-the-art DRL-based schemes, on average, the same models quantized by AutoQ reduce the inference latency by 54.06%, and decrease the inference energy consumption by 50.69%, while achieving the same inference accuracy.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rygfnn4twS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJxH22EKPS" data-number="187">
      <h4>
        <a href="/forum?id=BJxH22EKPS">
            Understanding Architectures Learnt by Cell-based Neural Architecture Search
        </a>
      
        
          <a href="/pdf?id=BJxH22EKPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=shuyao%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="shuyao@comp.nus.edu.sg">Yao Shu</a>, <a href="/profile?email=wangwei%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="wangwei@comp.nus.edu.sg">Wei Wang</a>, <a href="/profile?email=shaofeng%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="shaofeng@comp.nus.edu.sg">Shaofeng Cai</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#BJxH22EKPS-details-770" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJxH22EKPS-details-770"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Neural architecture search (NAS) searches architectures automatically for given tasks, e.g., image classification and language modeling. Improving the search efficiency and effectiveness has attracted increasing attention in recent years. However, few efforts have been devoted to understanding the generated architectures. In this paper, we first reveal that existing NAS algorithms (e.g., DARTS, ENAS) tend to favor architectures with wide and shallow cell structures. These favorable architectures consistently achieve fast convergence and are consequently selected by NAS algorithms. Our empirical and theoretical study further confirms that their fast convergence derives from their smooth loss landscape and accurate gradient information. Nonetheless, these architectures may not necessarily lead to better generalization performance compared with other candidate architectures in the same search space, and therefore further improvement is possible by revising existing NAS algorithms.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Neural Architecture Search, connection pattern, optimization, convergence, Lipschitz smoothness, gradient variance, generalization</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/shuyao95/Understanding-NAS.git</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJxH22EKPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1xPh2VtPB" data-number="192">
      <h4>
        <a href="/forum?id=r1xPh2VtPB">
            SVQN: Sequential Variational Soft Q-Learning Networks
        </a>
      
        
          <a href="/pdf?id=r1xPh2VtPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=huangsy1314%40163.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="huangsy1314@163.com">Shiyu Huang</a>, <a href="/profile?email=suhangss%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="suhangss@mail.tsinghua.edu.cn">Hang Su</a>, <a href="/profile?email=dcszj%40tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dcszj@tsinghua.edu.cn">Jun Zhu</a>, <a href="/profile?email=tingchen%40tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="tingchen@tsinghua.edu.cn">Ting Chen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="#r1xPh2VtPB-details-828" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1xPh2VtPB-details-828"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, POMDP, variational inference, generative model</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">SVQNs  formalizes the inference of hidden states and maximum entropy reinforcement learning under a unified graphical model and optimizes the two modules jointly.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Partially Observable Markov Decision Processes (POMDPs) are popular and flexible models for real-world decision-making applications that demand the information from past observations to make optimal decisions. Standard reinforcement learning algorithms for solving Markov Decision Processes (MDP) tasks are not applicable, as they cannot infer the unobserved states. In this paper, we propose a novel algorithm for POMDPs, named sequential variational soft Q-learning networks (SVQNs), which formalizes the inference of hidden states and maximum entropy reinforcement learning (MERL) under a unified graphical model and optimizes the two modules jointly. We further design a deep recurrent neural network to reduce the computational complexity of the algorithm. Experimental results show that SVQNs can utilize past information to help decision making for efficient inference, and outperforms other baselines on several challenging tasks. Our ablation study shows that SVQNs have the generalization ability over time and are robust to the disturbance of the observation.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1xPh2VtPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJld3hEYvS" data-number="195">
      <h4>
        <a href="/forum?id=rJld3hEYvS">
            Ranking Policy Gradient
        </a>
      
        
          <a href="/pdf?id=rJld3hEYvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=linkaixi%40msu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="linkaixi@msu.edu">Kaixiang Lin</a>, <a href="/profile?email=jiayuz%40msu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiayuz@msu.edu">Jiayu Zhou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rJld3hEYvS-details-408" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJld3hEYvS-details-408"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Sample-efficient reinforcement learning, off-policy learning.</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose ranking policy gradient that learns the optimal rank of actions to maximize return. We propose a general off-policy learning framework with the properties of optimality preserving, variance reduction, and sample-efficiency.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Sample inefficiency is a long-lasting problem in reinforcement learning (RL). The state-of-the-art estimates the optimal action values while it usually involves an extensive search over the state-action space and unstable optimization. Towards the sample-efficient RL, we propose ranking policy gradient (RPG), a policy gradient method that learns the optimal rank of a set of discrete actions. To accelerate the learning of policy gradient methods, we establish the equivalence between maximizing the lower bound of return and imitating a near-optimal policy without accessing any oracles. These results lead to a general off-policy learning framework, which preserves the optimality, reduces variance, and improves the sample-efficiency. We conduct extensive experiments showing that when consolidating with the off-policy learning framework, RPG substantially reduces the sample complexity, comparing to the state-of-the-art.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJld3hEYvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkxoh24FPH" data-number="202">
      <h4>
        <a href="/forum?id=rkxoh24FPH">
            On Mutual Information Maximization for Representation Learning
        </a>
      
        
          <a href="/pdf?id=rkxoh24FPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mi.tschannen%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mi.tschannen@gmail.com">Michael Tschannen</a>, <a href="/profile?email=josip%40djolonga.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="josip@djolonga.com">Josip Djolonga</a>, <a href="/profile?email=paruby%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="paruby@gmail.com">Paul K. Rubenstein</a>, <a href="/profile?email=sylvaingelly%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sylvaingelly@google.com">Sylvain Gelly</a>, <a href="/profile?email=lucic%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lucic@google.com">Mario Lucic</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rkxoh24FPH-details-483" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkxoh24FPH-details-483"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Many recent methods for unsupervised or self-supervised representation learning train feature extractors by maximizing an estimate of the mutual information (MI) between different views of the data. This comes with several immediate problems: For example, MI is notoriously hard to estimate, and using it as an objective for representation learning may lead to highly entangled representations due to its invariance under arbitrary invertible transformations. Nevertheless, these methods have been repeatedly shown to excel in practice. In this paper we argue, and provide empirical evidence, that the success of these methods cannot be attributed to the properties of MI alone, and that they strongly depend on the inductive bias in both the choice of feature extractor architectures and the parametrization of the employed MI estimators. Finally, we establish a connection to deep metric learning and argue that this interpretation may be a plausible explanation for the success of the recently introduced methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://storage.googleapis.com/mi_for_rl_files/code.zip</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">mutual information, representation learning, unsupervised learning, self-supervised learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">The success of recent mutual information (MI)-based representation learning approaches strongly depends on the inductive bias in both the choice of network architectures and the parametrization of the employed MI estimators.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkxoh24FPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJli2hNKDH" data-number="203">
      <h4>
        <a href="/forum?id=HJli2hNKDH">
            Observational Overfitting in Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=HJli2hNKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xsong%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xsong@berkeley.edu">Xingyou Song</a>, <a href="/profile?email=ydjiang%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ydjiang@google.com">Yiding Jiang</a>, <a href="/profile?email=stephentu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="stephentu@google.com">Stephen Tu</a>, <a href="/profile?email=yilundu%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yilundu@mit.edu">Yilun Du</a>, <a href="/profile?email=neyshabur%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="neyshabur@google.com">Behnam Neyshabur</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HJli2hNKDH-details-72" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJli2hNKDH-details-72"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">observational, overfitting, reinforcement, learning, generalization, implicit, regularization, overparametrization</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We isolate one factor of RL generalization by analyzing the case when the agent only overfits to the observations. We show that architectural implicit regularizations occur in this regime.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">A major component of overfitting in model-free reinforcement learning (RL) involves the case where the agent may mistakenly correlate reward with certain spurious features from the observations generated by the Markov Decision Process (MDP). We provide a general framework for analyzing this scenario, which we use to design multiple synthetic benchmarks from only modifying the observation space of an MDP. When an agent overfits to different observation spaces even if the underlying MDP dynamics is fixed, we term this observational overfitting. Our experiments expose intriguing properties especially with regards to implicit regularization, and also corroborate results from previous works in RL generalization and supervised learning (SL). </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJli2hNKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkgWahEFvr" data-number="216">
      <h4>
        <a href="/forum?id=BkgWahEFvr">
            Enhancing Transformation-Based Defenses Against Adversarial Attacks with a Distribution Classifier
        </a>
      
        
          <a href="/pdf?id=BkgWahEFvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=conniekoukl%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="conniekoukl@gmail.com">Connie Kou</a>, <a href="/profile?email=leehk%40bii.a-star.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="leehk@bii.a-star.edu.sg">Hwee Kuan Lee</a>, <a href="/profile?email=changec%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="changec@comp.nus.edu.sg">Ee-Chien Chang</a>, <a href="/profile?email=ngtk%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="ngtk@comp.nus.edu.sg">Teck Khim Ng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="#BkgWahEFvr-details-703" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkgWahEFvr-details-703"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial attack, transformation defenses, distribution classifier</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We enhance existing transformation-based defenses by using a distribution classifier on the distribution of softmax obtained from transformed images.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Adversarial attacks on convolutional neural networks (CNN) have gained significant attention and there have been active research efforts on defense mechanisms. Stochastic input transformation methods have been proposed, where the idea is to recover the image from adversarial attack by random transformation, and to take the majority vote as consensus among the random samples. However, the transformation improves the accuracy on adversarial images at the expense of the accuracy on clean images. While it is intuitive that the accuracy on clean images would deteriorate, the exact mechanism in which how this occurs is unclear. In this paper, we study the distribution of softmax induced by stochastic transformations. We observe that with random transformations on the clean images, although the mass of the softmax distribution could shift to the wrong class, the resulting distribution of softmax could be used to correct the prediction. Furthermore, on the adversarial counterparts, with the image transformation, the resulting shapes of the distribution of softmax are similar to the distributions from the clean images. With these observations, we propose a method to improve existing transformation-based defenses. We train a separate lightweight distribution classifier to recognize distinct features in the distributions of softmax outputs of transformed images. Our empirical studies show that our distribution classifier, by training on distributions obtained from clean images only, outperforms majority voting for both clean and adversarial images. Our method is generic and can be integrated with existing transformation-based defenses.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BkgWahEFvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkgXT24tDS" data-number="220">
      <h4>
        <a href="/forum?id=BkgXT24tDS">
            Additive Powers-of-Two Quantization: An Efficient Non-uniform Discretization for Neural Networks
        </a>
      
        
          <a href="/pdf?id=BkgXT24tDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=loafyuhang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="loafyuhang@gmail.com">Yuhang Li</a>, <a href="/profile?email=xindong%40g.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xindong@g.harvard.edu">Xin Dong</a>, <a href="/profile?email=wangwei%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="wangwei@comp.nus.edu.sg">Wei Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#BkgXT24tDS-details-767" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkgXT24tDS-details-767"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose Additive Powers-of-Two~(APoT) quantization, an efficient non-uniform quantization scheme for the bell-shaped and long-tailed distribution of weights and activations in neural networks. By constraining all quantization levels as the sum of Powers-of-Two terms, APoT quantization enjoys high computational efficiency and a good match with the distribution of weights. A simple reparameterization of the clipping function is applied to generate a better-defined gradient for learning the clipping threshold. Moreover, weight normalization is presented to refine the distribution of weights to make the training more stable and consistent. Experimental results show that our proposed method outperforms state-of-the-art methods, and is even competitive with the full-precision models, demonstrating the effectiveness of our proposed APoT quantization. For example, our 4-bit quantized ResNet-50 on ImageNet achieves 76.6% top-1 accuracy without bells and whistles; meanwhile, our model reduces 22% computational cost compared with the uniformly quantized counterpart.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Quantization, Efficient Inference, Neural Networks</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/yhhhli/APoT_Quantization</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BkgXT24tDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJx4p3NYDB" data-number="223">
      <h4>
        <a href="/forum?id=rJx4p3NYDB">
            Lazy-CFR: fast and near-optimal regret minimization for extensive games with imperfect information
        </a>
      
        
          <a href="/pdf?id=rJx4p3NYDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=vofhqn%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vofhqn@gmail.com">Yichi Zhou</a>, <a href="/profile?email=rtz19970824%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rtz19970824@gmail.com">Tongzheng Ren</a>, <a href="/profile?email=lijialia16%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="lijialia16@mails.tsinghua.edu.cn">Jialian Li</a>, <a href="/profile?email=sproblvem%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sproblvem@gmail.com">Dong Yan</a>, <a href="/profile?email=dcszj%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dcszj@mail.tsinghua.edu.cn">Jun Zhu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rJx4p3NYDB-details-967" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJx4p3NYDB-details-967"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Counterfactual regret minimization (CFR) methods are effective for solving two-player zero-sum extensive games with imperfect information with  state-of-the-art results.  However,  the vanilla CFR has to traverse the whole game tree in each round, which is time-consuming in large-scale games. In this paper, we present Lazy-CFR, a CFR algorithm that adopts a lazy update strategy to avoid traversing the whole game tree in each round.  We prove that the regret of Lazy-CFR is almost the same to the regret of the vanilla CFR and only needs to visit a small portion of the game tree.  Thus, Lazy-CFR is provably faster than CFR. Empirical results consistently show that Lazy-CFR is significantly faster than the vanilla CFR.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJx4p3NYDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJeS62EtwH" data-number="225">
      <h4>
        <a href="/forum?id=BJeS62EtwH">
            Knowledge Consistency between Neural Networks and Beyond
        </a>
      
        
          <a href="/pdf?id=BJeS62EtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=nexuslrf%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="nexuslrf@sjtu.edu.cn">Ruofan Liang</a>, <a href="/profile?email=litl%40act.buaa.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="litl@act.buaa.edu.cn">Tianlin Li</a>, <a href="/profile?email=1776752575%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="1776752575@sjtu.edu.cn">Longfei Li</a>, <a href="/profile?email=wangjing215%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wangjing215@huawei.com">Jing Wang</a>, <a href="/profile?email=zqs1022%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zqs1022@sjtu.edu.cn">Quanshi Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#BJeS62EtwH-details-66" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJeS62EtwH-details-66"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep Learning, Interpretability, Convolutional Neural Networks</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper aims to analyze knowledge consistency between pre-trained deep neural networks. We propose a generic definition for knowledge consistency between neural networks at different fuzziness levels. A task-agnostic method is designed to disentangle feature components, which represent the consistent knowledge, from raw intermediate-layer features of each neural network. As a generic tool, our method can be broadly used for different applications. In preliminary experiments, we have used knowledge consistency as a tool to diagnose representations of neural networks. Knowledge consistency provides new insights to explain the success of existing deep-learning techniques, such as knowledge distillation and network compression. More crucially, knowledge consistency can also be used to refine pre-trained networks and boost performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJeS62EtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hyg9anEFPS" data-number="237">
      <h4>
        <a href="/forum?id=Hyg9anEFPS">
            Image-guided Neural Object Rendering
        </a>
      
        
          <a href="/pdf?id=Hyg9anEFPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=justus.thies%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="justus.thies@tum.de">Justus Thies</a>, <a href="/profile?email=michael%40zollhoefer.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael@zollhoefer.com">Michael Zollhöfer</a>, <a href="/profile?email=marc.stamminger%40fau.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="marc.stamminger@fau.de">Christian Theobalt</a>, <a href="/profile?email=theobalt%40mpi-inf.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="theobalt@mpi-inf.mpg.de">Marc Stamminger</a>, <a href="/profile?email=niessner%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="niessner@tum.de">Matthias Nießner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="#Hyg9anEFPS-details-99" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hyg9anEFPS-details-99"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose a learned image-guided rendering technique that combines the benefits of image-based rendering and GAN-based image synthesis. The goal of our method is to generate photo-realistic re-renderings of reconstructed objects for virtual and augmented reality applications (e.g., virtual showrooms, virtual tours and sightseeing, the digital inspection of historical artifacts). A core component of our work is the handling of view-dependent effects. Specifically, we directly train an object-specific deep neural network to synthesize the view-dependent appearance of an object.
      As input data we are using an RGB video of the object. This video is used to reconstruct a proxy geometry of the object via multi-view stereo. Based on this 3D proxy, the appearance of a captured view can be warped into a new target view as in classical image-based rendering. This warping assumes diffuse surfaces, in case of view-dependent effects, such as specular highlights, it leads to artifacts. To this end, we propose EffectsNet, a deep neural network that predicts view-dependent effects. Based on these estimations, we are able to convert observed images to diffuse images. These diffuse images can be projected into other views. In the target view, our pipeline reinserts the new view-dependent effects. To composite multiple reprojected images to a final output, we learn a composition network that outputs photo-realistic results. Using this image-guided approach, the network does not have to allocate capacity on ``remembering'' object appearance, instead it learns how to combine the appearance of captured images. We demonstrate the effectiveness of our approach both qualitatively and quantitatively on synthetic as well as on real data.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Neural Rendering, Neural Image Synthesis</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a learned image-guided rendering technique that combines the benefits of image-based rendering and GAN-based image synthesis while considering view-dependent effects.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hyg9anEFPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkgTTh4FDH" data-number="244">
      <h4>
        <a href="/forum?id=HkgTTh4FDH">
            Implicit Bias of Gradient Descent based Adversarial Training on Separable Data
        </a>
      
        
          <a href="/pdf?id=HkgTTh4FDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yli939%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yli939@gatech.edu">Yan Li</a>, <a href="/profile?email=xxf13%40psu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xxf13@psu.edu">Ethan X.Fang</a>, <a href="/profile?email=huan.xu%40isye.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="huan.xu@isye.gatech.edu">Huan Xu</a>, <a href="/profile?email=tourzhao%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tourzhao@gatech.edu">Tuo Zhao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 25 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HkgTTh4FDH-details-33" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkgTTh4FDH-details-33"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Adversarial training is a principled approach for training robust neural networks. Despite of tremendous successes in practice, its theoretical properties still remain largely unexplored. In this paper, we provide new theoretical insights of gradient descent based adversarial training by studying its computational properties, specifically on its implicit bias. We take the binary classification task on linearly separable data as an illustrative example, where the loss asymptotically attains its infimum as the parameter diverges to infinity along certain directions. Specifically, we show that for any fixed iteration <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="383" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></mjx-assistive-mml></mjx-container>, when the adversarial perturbation during training has proper bounded L2 norm,  the classifier learned by gradient descent based adversarial training converges in direction to the maximum L2 norm margin classifier at the rate of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="384" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.169em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mrow><mo>/</mo></mrow><msqrt><mi>T</mi></msqrt><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>, significantly faster than the rate <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="385" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-merror><mjx-mtext><mjx-utext variant="-explicitFont" style="font-size: 88.4%; padding: 0.848em 0px 0.226em;">Extra close brace or missing open brace</mjx-utext></mjx-mtext></mjx-merror></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><merror><mtext>Extra close brace or missing open brace</mtext></merror></math></mjx-assistive-mml></mjx-container> of training with clean data. In addition, when the adversarial perturbation during training has bounded Lq norm, the resulting classifier converges in direction to a maximum mixed-norm margin classifier, which has a natural interpretation of robustness, as being the maximum L2 norm margin classifier under worst-case bounded Lq norm perturbation to the data.  Our findings provide theoretical backups for adversarial training that it indeed promotes robustness against adversarial perturbation.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">implicit bias, adversarial training, robustness, gradient descent</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">The solution of gradient descent based adversarial training converges in direction to a robust max margin solution that is adapted to adversary geometry, using L2 perturbation also shows significant speed-up in convergence compared to clean training.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkgTTh4FDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkeJRhNYDH" data-number="248">
      <h4>
        <a href="/forum?id=rkeJRhNYDH">
            TabFact: A Large-scale Dataset for Table-based Fact Verification
        </a>
      
        
          <a href="/pdf?id=rkeJRhNYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wenhuchen%40ucsb.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wenhuchen@ucsb.edu">Wenhu Chen</a>, <a href="/profile?email=hongmin%40ucsb.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hongmin@ucsb.edu">Hongmin Wang</a>, <a href="/profile?email=chenjianshu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenjianshu@gmail.com">Jianshu Chen</a>, <a href="/profile?email=yunkai_zhang%40ucsb.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yunkai_zhang@ucsb.edu">Yunkai Zhang</a>, <a href="/profile?email=hongwang600%40ucsb.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hongwang600@ucsb.edu">Hong Wang</a>, <a href="/profile?email=shiyangli%40ucsb.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shiyangli@ucsb.edu">Shiyang Li</a>, <a href="/profile?email=xiyou%40ucsb.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiyou@ucsb.edu">Xiyou Zhou</a>, <a href="/profile?email=william%40cs.ucsb.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="william@cs.ucsb.edu">William Yang Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 15 Jun 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#rkeJRhNYDH-details-963" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkeJRhNYDH-details-963"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Fact Verification, Tabular Data, Symbolic Reasoning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a new dataset to investigate the entailment problem under semi-structured table as premise</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The problem of verifying whether a textual hypothesis holds based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are mainly restricted to dealing with unstructured evidence (e.g., natural language sentences and documents, news, etc), while verification under structured evidence, such as tables, graphs, and databases, remains unexplored. This paper specifically aims to study the fact verification given semi-structured data as evidence. To this end, we construct a large-scale dataset called TabFact with 16k Wikipedia tables as the evidence for 118k human-annotated natural language statements, which are labeled as either ENTAILED or REFUTED. TabFact is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning. To address these reasoning challenges, we design two different models: Table-BERT and Latent Program Algorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language model to encode the linearized tables and statements into continuous vectors for verification. LPA parses statements into LISP-like programs and executes them against the tables to obtain the returned binary value for verification. Both methods achieve similar accuracy but still lag far behind human performance. We also perform a comprehensive analysis to demonstrate great future opportunities.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/wenhuchen/Table-Fact-Checking</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkeJRhNYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1exA2NtDB" data-number="250">
      <h4>
        <a href="/forum?id=S1exA2NtDB">
            ES-MAML: Simple Hessian-Free Meta Learning
        </a>
      
        
          <a href="/pdf?id=S1exA2NtDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xsong%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xsong@berkeley.edu">Xingyou Song</a>, <a href="/profile?email=wg2279%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wg2279@columbia.edu">Wenbo Gao</a>, <a href="/profile?email=yxyang%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yxyang@google.com">Yuxiang Yang</a>, <a href="/profile?email=kchoro%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kchoro@google.com">Krzysztof Choromanski</a>, <a href="/profile?email=pacchiano%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pacchiano@berkeley.edu">Aldo Pacchiano</a>, <a href="/profile?email=yt2541%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yt2541@columbia.edu">Yunhao Tang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#S1exA2NtDB-details-553" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1exA2NtDB-details-553"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">ES, MAML, evolution, strategies, meta, learning, gaussian, perturbation, reinforcement, learning, adaptation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We provide a new framework for MAML in the ES/blackbox setting, and show that it allows deterministic and linear policies, better exploration, and non-differentiable adaptation operators.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We introduce ES-MAML, a new framework for solving the model agnostic meta learning (MAML) problem based on Evolution Strategies (ES). Existing algorithms for MAML are based on policy gradients, and incur significant difficulties when attempting to estimate second derivatives using backpropagation on stochastic policies. We show how ES can be applied to MAML to obtain an algorithm which avoids the problem of estimating second derivatives, and is also conceptually simple and easy to implement. Moreover, ES-MAML can handle new types of nonsmooth adaptation operators, and other techniques for improving performance and estimation of ES methods become applicable. We show empirically that ES-MAML is competitive with existing methods and often yields better adaptation with fewer queries.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1exA2NtDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkxxA24FDr" data-number="251">
      <h4>
        <a href="/forum?id=rkxxA24FDr">
            Neural Stored-program Memory
        </a>
      
        
          <a href="/pdf?id=rkxxA24FDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=lethai%40deakin.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="lethai@deakin.edu.au">Hung Le</a>, <a href="/profile?email=truyen.tran%40deakin.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="truyen.tran@deakin.edu.au">Truyen Tran</a>, <a href="/profile?email=svetha.venkatesh%40deakin.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="svetha.venkatesh@deakin.edu.au">Svetha Venkatesh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#rkxxA24FDr-details-460" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkxxA24FDr-details-460"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Neural networks powered with external memory simulate computer behaviors. These models, which use the memory to store data for a neural controller, can learn algorithms and other complex tasks. In this paper, we introduce a new memory to store weights for the controller, analogous to the stored-program memory in modern computer architectures. The proposed model, dubbed Neural Stored-program Memory, augments current memory-augmented neural networks, creating differentiable machines that can switch programs through time, adapt to variable contexts and thus fully resemble the Universal Turing Machine. A wide range of experiments demonstrate that the resulting machines not only excel in classical algorithmic problems, but also have potential for compositional, continual, few-shot learning and question-answering tasks. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Memory Augmented Neural Networks, Universal Turing Machine, fast-weight</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A neural simulation of Universal Turing Machine</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/thaihungle/NSM</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkxxA24FDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1gzR2VKDH" data-number="256">
      <h4>
        <a href="/forum?id=H1gzR2VKDH">
            Hierarchical Foresight: Self-Supervised Learning of Long-Horizon Tasks via Visual Subgoal Generation
        </a>
      
        
          <a href="/pdf?id=H1gzR2VKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=surajn%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="surajn@stanford.edu">Suraj Nair</a>, <a href="/profile?email=chelseaf%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chelseaf@google.com">Chelsea Finn</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 21 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="#H1gzR2VKDH-details-521" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1gzR2VKDH-details-521"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Video prediction models combined with planning algorithms have shown promise in enabling robots to learn to perform many vision-based tasks through only self-supervision, reaching novel goals in cluttered scenes with unseen objects. However, due to the compounding uncertainty in long horizon video prediction and poor scalability of sampling-based planning optimizers, one significant limitation of these approaches is the ability to plan over long horizons to reach distant goals. To that end, we propose a framework for subgoal generation and planning, hierarchical visual foresight (HVF), which generates subgoal images conditioned on a goal image, and uses them for planning. The subgoal images are directly optimized to decompose the task into easy to plan segments, and as a result, we observe that the method naturally identifies semantically meaningful states as subgoals. Across three out of four simulated vision-based manipulation tasks, we find that our method achieves more than 20% absolute performance improvement over planning without subgoals and model-free RL approaches. Further, our experiments illustrate that our approach extends to real, cluttered visual scenes.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/suraj-nair-1/google-research/tree/master/hierarchical_foresight</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">video prediction, reinforcement learning, planning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Hierarchical visual foresight learns to generate visual subgoals that break down long-horizon tasks into subtasks, using only self-supervision.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1gzR2VKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Syx7A3NFvH" data-number="259">
      <h4>
        <a href="/forum?id=Syx7A3NFvH">
            Multi-agent Reinforcement Learning for Networked System Control
        </a>
      
        
          <a href="/pdf?id=Syx7A3NFvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=cts198859%40hotmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cts198859@hotmail.com">Tianshu Chu</a>, <a href="/profile?email=csandeep%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="csandeep@stanford.edu">Sandeep Chinchali</a>, <a href="/profile?email=skatti%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="skatti@stanford.edu">Sachin Katti</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#Syx7A3NFvH-details-743" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Syx7A3NFvH-details-743"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep reinforcement learning, multi-agent reinforcement learning, decision and control</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper proposes a new formulation and a new communication protocol for networked multi-agent control problems</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper considers multi-agent reinforcement learning (MARL) in networked system control. Specifically, each agent learns a decentralized control policy based on local observations and messages from connected neighbors. We formulate such a networked MARL (NMARL) problem as a spatiotemporal Markov decision process and introduce a spatial discount factor to stabilize the training of each local agent. Further, we propose a new differentiable communication protocol, called NeurComm, to reduce information loss and non-stationarity in NMARL. Based on experiments in realistic NMARL scenarios of adaptive traffic signal control and cooperative adaptive cruise control, an appropriate spatial discount factor effectively enhances the learning curves of non-communicative MARL algorithms, while NeurComm outperforms existing communication protocols in both learning efficiency and control performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/cts198859/deeprl_network</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Syx7A3NFvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJgBA2VYwH" data-number="263">
      <h4>
        <a href="/forum?id=HJgBA2VYwH">
            FSPool: Learning Set Representations with Featurewise Sort Pooling
        </a>
      
        
          <a href="/pdf?id=HJgBA2VYwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yz5n12%40ecs.soton.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yz5n12@ecs.soton.ac.uk">Yan Zhang</a>, <a href="/profile?email=jsh2%40ecs.soton.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jsh2@ecs.soton.ac.uk">Jonathon Hare</a>, <a href="/profile?email=apb%40ecs.soton.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="apb@ecs.soton.ac.uk">Adam Prügel-Bennett</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 01 May 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HJgBA2VYwH-details-667" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJgBA2VYwH-details-667"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">set auto-encoder, set encoder, pooling</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Sort in encoder and undo sorting in decoder to avoid responsibility problem in set auto-encoders</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Traditional set prediction models can struggle with simple datasets due to an issue we call the responsibility problem. We introduce a pooling method for sets of feature vectors based on sorting features across elements of the set. This can be used to construct a permutation-equivariant auto-encoder that avoids this responsibility problem. On a toy dataset of polygons and a set version of MNIST, we show that such an auto-encoder produces considerably better reconstructions and representations. Replacing the pooling function in existing set encoders with FSPool improves accuracy and convergence speed on a variety of datasets.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/Cyanogenoid/fspool</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJgBA2VYwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1xPR3NtPB" data-number="267">
      <h4>
        <a href="/forum?id=H1xPR3NtPB">
            Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction
        </a>
      
        
          <a href="/pdf?id=H1xPR3NtPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=taeuk%40europa.snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="taeuk@europa.snu.ac.kr">Taeuk Kim</a>, <a href="/profile?email=jhchoi%40europa.snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jhchoi@europa.snu.ac.kr">Jihun Choi</a>, <a href="/profile?email=danedmiston%40uchicago.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="danedmiston@uchicago.edu">Daniel Edmiston</a>, <a href="/profile?email=sglee%40europa.snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="sglee@europa.snu.ac.kr">Sang-goo Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#H1xPR3NtPB-details-504" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1xPR3NtPB-details-504"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">With the recent success and popularity of pre-trained language models (LMs) in natural language processing, there has been a rise in efforts to understand their inner workings. 
      In line with such interest, we propose a novel method that assists us in investigating the extent to which pre-trained LMs capture the syntactic notion of constituency. 
      Our method provides an effective way of extracting constituency trees from the pre-trained LMs without training. 
      In addition, we report intriguing findings in the induced trees, including the fact that pre-trained LMs outperform other approaches in correctly demarcating adverb phrases in sentences.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1xPR3NtPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkeuAhVKvB" data-number="271">
      <h4>
        <a href="/forum?id=rkeuAhVKvB">
            Dynamically Pruned Message Passing Networks for Large-scale Knowledge Graph Reasoning
        </a>
      
        
          <a href="/pdf?id=rkeuAhVKvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xiaoran.xu%40hulu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaoran.xu@hulu.com">Xiaoran Xu</a>, <a href="/profile?email=wei.feng%40hulu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wei.feng@hulu.com">Wei Feng</a>, <a href="/profile?email=yunsheng.jiang%40hulu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yunsheng.jiang@hulu.com">Yunsheng Jiang</a>, <a href="/profile?email=xiaohui.xie%40hulu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaohui.xie@hulu.com">Xiaohui Xie</a>, <a href="/profile?email=zhiqings%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhiqings@andrew.cmu.edu">Zhiqing Sun</a>, <a href="/profile?email=zhdeng%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhdeng@pku.edu.cn">Zhi-Hong Deng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rkeuAhVKvB-details-921" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkeuAhVKvB-details-921"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">knowledge graph reasoning, graph neural networks, attention mechanism</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value "> We propose to learn an input-dependent subgraph, dynamically and selectively expanded, to explicitly model a sequential reasoning process.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose Dynamically Pruned Message Passing Networks (DPMPN) for large-scale knowledge graph reasoning. In contrast to existing models, embedding-based or path-based, we learn an input-dependent subgraph to explicitly model a sequential reasoning process. Each subgraph is dynamically constructed, expanding itself selectively under a flow-style attention mechanism. In this way, we can not only construct graphical explanations to interpret prediction, but also prune message passing in Graph Neural Networks (GNNs) to scale with the size of graphs. We take the inspiration from the consciousness prior proposed by Bengio to design a two-GNN framework to encode global input-invariant graph-structured representation and learn local input-dependent one coordinated by an attention module. Experiments show the reasoning capability in our model that is providing a clear graphical explanation as well as predicting results accurately, outperforming most state-of-the-art methods in knowledge base completion tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/netpaladinx/DPMPN</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkeuAhVKvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByxtC2VtPB" data-number="272">
      <h4>
        <a href="/forum?id=ByxtC2VtPB">
            Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks
        </a>
      
        
          <a href="/pdf?id=ByxtC2VtPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=pty17%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="pty17@mails.tsinghua.edu.cn">Tianyu Pang*</a>, <a href="/profile?email=kunxu.thu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kunxu.thu@gmail.com">Kun Xu*</a>, <a href="/profile?email=dcszj%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dcszj@mail.tsinghua.edu.cn">Jun Zhu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="#ByxtC2VtPB-details-550" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByxtC2VtPB-details-550"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Trustworthy Machine Learning, Adversarial Robustness, Inference Principle, Mixup</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We exploit the global linearity of the mixup-trained models in inference to break the locality of the adversarial perturbations.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">It has been widely recognized that adversarial examples can be easily crafted to fool deep networks, which mainly root from the locally non-linear behavior nearby input examples. Applying mixup in training provides an effective mechanism to improve generalization performance and model robustness against adversarial perturbations, which introduces the globally linear behavior in-between training examples. However, in previous work, the mixup-trained models only passively defend adversarial attacks in inference by directly classifying the inputs, where the induced global linearity is not well exploited. Namely, since the locality of the adversarial perturbations, it would be more efficient to actively break the locality via the globality of the model predictions. Inspired by simple geometric intuition, we develop an inference principle, named mixup inference (MI), for mixup-trained models. MI mixups the input with other random clean samples, which can shrink and transfer the equivalent perturbation if the input is adversarial. Our experiments on CIFAR-10 and CIFAR-100 demonstrate that MI can further improve the adversarial robustness for the models trained by mixup and its variants.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/P2333/Mixup-Inference</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByxtC2VtPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJgK0h4Ywr" data-number="273">
      <h4>
        <a href="/forum?id=HJgK0h4Ywr">
            Theory and Evaluation Metrics for Learning Disentangled Representations
        </a>
      
        
          <a href="/pdf?id=HJgK0h4Ywr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=dkdo%40deakin.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="dkdo@deakin.edu.au">Kien Do</a>, <a href="/profile?email=truyen.tran%40deakin.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="truyen.tran@deakin.edu.au">Truyen Tran</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#HJgK0h4Ywr-details-220" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJgK0h4Ywr-details-220"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">disentanglement, metrics</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We make two theoretical contributions to disentanglement learning by (a) defining precise semantics of disentangled representations, and (b) establishing robust metrics for evaluation. First, we characterize the concept “disentangled representations” used in supervised and unsupervised methods along three dimensions–informativeness, separability and interpretability–which can be expressed and quantified explicitly using information-theoretic constructs. This helps explain the behaviors of several well-known disentanglement learning models. We then propose robust metrics for measuring informativeness, separability and interpretability. Through a comprehensive suite of experiments, we show that our metrics correctly characterize the representations learned by different methods and are consistent with qualitative (visual) results. Thus, the metrics allow disentanglement learning methods to be compared on a fair ground. We also empirically uncovered new interesting properties of VAE-based methods and interpreted them with our formulation. These findings are promising and hopefully will encourage the design of more theoretically driven models for learning disentangled representations. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJgK0h4Ywr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SygcCnNKwr" data-number="274">
      <h4>
        <a href="/forum?id=SygcCnNKwr">
            Measuring Compositional Generalization: A Comprehensive Method on Realistic Data
        </a>
      
        
          <a href="/pdf?id=SygcCnNKwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=keysers%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="keysers@google.com">Daniel Keysers</a>, <a href="/profile?email=schaerli%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="schaerli@google.com">Nathanael Schärli</a>, <a href="/profile?email=nkscales%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nkscales@google.com">Nathan Scales</a>, <a href="/profile?email=hylke%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hylke@google.com">Hylke Buisman</a>, <a href="/profile?email=danielfurrer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="danielfurrer@google.com">Daniel Furrer</a>, <a href="/profile?email=sergik%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sergik@google.com">Sergii Kashubin</a>, <a href="/profile?email=nikola%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nikola@google.com">Nikola Momchev</a>, <a href="/profile?email=sinopalnikov%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sinopalnikov@google.com">Danila Sinopalnikov</a>, <a href="/profile?email=lukstafi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukstafi@google.com">Lukasz Stafiniak</a>, <a href="/profile?email=ttihon%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ttihon@google.com">Tibor Tihon</a>, <a href="/profile?email=tsar%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tsar@google.com">Dmitry Tsarkov</a>, <a href="/profile?email=wangxiao%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wangxiao@google.com">Xiao Wang</a>, <a href="/profile?email=marcvanzee%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="marcvanzee@google.com">Marc van Zee</a>, <a href="/profile?email=obousquet%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="obousquet@google.com">Olivier Bousquet</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SygcCnNKwr-details-73" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SygcCnNKwr-details-73"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">compositionality, generalization, natural language understanding, benchmark, compositional generalization, compositional modeling, semantic parsing, generalization measurement</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Benchmark and method to measure compositional generalization by maximizing divergence of compound frequency at small divergence of atom frequency.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">State-of-the-art machine learning methods exhibit limited compositional generalization. At the same time, there is a lack of realistic benchmarks that comprehensively measure this ability, which makes it challenging to find and evaluate improvements. We introduce a novel method to systematically construct such benchmarks by maximizing compound divergence while guaranteeing a small atom divergence between train and test sets, and we quantitatively compare this method to other approaches for creating compositional generalization benchmarks. We present a large and realistic natural language question answering dataset that is constructed according to this method, and we use it to analyze the compositional generalization ability of three machine learning architectures. We find that they fail to generalize compositionally and that there is a surprisingly strong negative correlation between compound divergence and accuracy. We also demonstrate how our method can be used to create new compositionality benchmarks on top of the existing SCAN dataset, which confirms these findings.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/google-research/google-research/tree/master/cfq</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SygcCnNKwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byg9A24tvB" data-number="275">
      <h4>
        <a href="/forum?id=Byg9A24tvB">
            Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness
        </a>
      
        
          <a href="/pdf?id=Byg9A24tvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=pty17%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="pty17@mails.tsinghua.edu.cn">Tianyu Pang</a>, <a href="/profile?email=kunxu.thu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kunxu.thu@gmail.com">Kun Xu</a>, <a href="/profile?email=dyp17%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dyp17@mails.tsinghua.edu.cn">Yinpeng Dong</a>, <a href="/profile?email=duchao0726%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="duchao0726@gmail.com">Chao Du</a>, <a href="/profile?email=ningchen%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ningchen@mail.tsinghua.edu.cn">Ning Chen</a>, <a href="/profile?email=dcszj%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dcszj@mail.tsinghua.edu.cn">Jun Zhu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="#Byg9A24tvB-details-594" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byg9A24tvB-details-594"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Trustworthy Machine Learning, Adversarial Robustness, Training Objective, Sample Density</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Applying the softmax function in training leads to indirect and unexpected supervision on features. We propose a new training objective to explicitly induce dense feature regions for locally sufficient samples to benefit adversarial robustness.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Previous work shows that adversarially robust generalization requires larger sample complexity, and the same dataset, e.g., CIFAR-10, which enables good standard accuracy may not suffice to train robust models. Since collecting new training data could be costly, we focus on better utilizing the given data by inducing the regions with high sample density in the feature space, which could lead to locally sufficient samples for robust learning. We first formally show that the softmax cross-entropy (SCE) loss and its variants convey inappropriate supervisory signals, which encourage the learned feature points to spread over the space sparsely in training. This inspires us to propose the Max-Mahalanobis center (MMC) loss to explicitly induce dense feature regions in order to benefit robustness. Namely, the MMC loss encourages the model to concentrate on learning ordered and compact representations, which gather around the preset optimal centers for different classes. We empirically demonstrate that applying the MMC loss can significantly improve robustness even under strong adaptive attacks, while keeping state-of-the-art accuracy on clean inputs with little extra computation compared to the SCE loss.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/P2333/Max-Mahalanobis-Training</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Byg9A24tvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1lj0nNFwB" data-number="277">
      <h4>
        <a href="/forum?id=H1lj0nNFwB">
            The Implicit Bias of Depth: How Incremental Learning Drives Generalization
        </a>
      
        
          <a href="/pdf?id=H1lj0nNFwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=daniel.gissin%40mail.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel.gissin@mail.huji.ac.il">Daniel Gissin</a>, <a href="/profile?email=shais%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="shais@cs.huji.ac.il">Shai Shalev-Shwartz</a>, <a href="/profile?email=amit.daniely%40mail.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="amit.daniely@mail.huji.ac.il">Amit Daniely</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#H1lj0nNFwB-details-799" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1lj0nNFwB-details-799"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">A leading hypothesis for the surprising generalization of neural networks is that the dynamics of gradient descent bias the model towards simple solutions, by searching through the solution space in an incremental order of complexity. We formally define the notion of incremental learning dynamics and derive the conditions on depth and initialization for which this phenomenon arises in deep linear models. Our main theoretical contribution is a dynamical depth separation result, proving that while shallow models can exhibit incremental learning dynamics, they require the initialization to be exponentially small for these dynamics to present themselves. However, once the model becomes deeper, the dependence becomes polynomial and incremental learning can arise in more natural settings. We complement our theoretical findings by experimenting with deep matrix sensing, quadratic neural networks and with binary classification using diagonal and convolutional linear networks, showing all of these models exhibit incremental learning.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">gradient flow, gradient descent, implicit regularization, implicit bias, generalization, optimization, quadratic network, matrix sensing</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We study the sparsity-inducing bias of deep models, caused by their learning dynamics.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/dsgissin/Incremental-Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1lj0nNFwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hye1kTVFDS" data-number="285">
      <h4>
        <a href="/forum?id=Hye1kTVFDS">
            The Variational Bandwidth Bottleneck: Stochastic Evaluation on an Information Budget
        </a>
      
        
          <a href="/pdf?id=Hye1kTVFDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=anirudhgoyal9119%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anirudhgoyal9119@gmail.com">Anirudh Goyal</a>, <a href="/profile?email=yoshua.bengio%40mila.quebec" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.bengio@mila.quebec">Yoshua Bengio</a>, <a href="/profile?email=botvinick%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="botvinick@google.com">Matthew Botvinick</a>, <a href="/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="#Hye1kTVFDS-details-297" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hye1kTVFDS-details-297"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Variational Information Bottleneck, Reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Training agents with adaptive computation based on information bottleneck can promote generalization. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In many applications, it is desirable to extract only the relevant information from complex input data, which involves making a decision about which input features are relevant.
      The information bottleneck method formalizes this as an information-theoretic optimization problem by maintaining an optimal tradeoff between compression (throwing away irrelevant input information), and predicting the target. In many problem settings, including the reinforcement learning problems we consider in this work, we might prefer to compress only part of the input. This is typically the case when we have a standard conditioning input, such as a state observation, and a ``privileged'' input, which might correspond to the goal of a task, the output of a costly planning algorithm, or communication with another agent. In such cases, we might prefer to compress the privileged input, either to achieve better generalization (e.g., with respect to goals) or to minimize access to costly information (e.g., in the case of communication). Practical implementations of the information bottleneck based on variational inference require access to the privileged input in order to compute the bottleneck variable, so although they perform compression, this compression operation itself needs unrestricted, lossless access. In this work, we propose the variational bandwidth bottleneck, which decides for each example on the estimated value of the privileged information before seeing it, i.e., only based on the standard input, and then accordingly chooses stochastically, whether to access the privileged input or not. We formulate a tractable approximation to this framework and demonstrate in a series of reinforcement learning experiments that it can improve generalization and reduce access to computationally costly information.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hye1kTVFDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylJkpEtwS" data-number="287">
      <h4>
        <a href="/forum?id=rylJkpEtwS">
            Learning the Arrow of Time for Problems in Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=rylJkpEtwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=nasim.rahaman%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="nasim.rahaman@tuebingen.mpg.de">Nasim Rahaman</a>, <a href="/profile?email=steffen.wolf%40iwr.uni-heidelberg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="steffen.wolf@iwr.uni-heidelberg.de">Steffen Wolf</a>, <a href="/profile?email=anirudhgoyal9119%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anirudhgoyal9119@gmail.com">Anirudh Goyal</a>, <a href="/profile?email=roman.remme%40iwr.uni-heidelberg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="roman.remme@iwr.uni-heidelberg.de">Roman Remme</a>, <a href="/profile?email=yoshua.bengio%40mila.quebec" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.bengio@mila.quebec">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>20 Replies</span>
        
        
      </div>
      
        <a href="#rylJkpEtwS-details-673" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylJkpEtwS-details-673"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We learn the arrow of time for MDPs and use it to measure reachability, detect side-effects and obtain a curiosity reward signal. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We humans have an innate understanding of the asymmetric progression of time, which we use to efficiently and safely perceive and manipulate our environment. Drawing inspiration from that, we approach the problem of learning an arrow of time in a Markov (Decision) Process. We illustrate how a learned arrow of time can capture salient information about the environment, which in turn can be used to measure reachability, detect side-effects and to obtain an intrinsic reward signal. Finally, we propose a simple yet effective algorithm to parameterize the problem at hand and learn an arrow of time with a function approximator (here, a deep neural network). Our empirical results span a selection of discrete and continuous environments, and demonstrate for a class of stochastic processes that the learned arrow of time agrees reasonably well with a well known notion of an arrow of time due to Jordan, Kinderlehrer and Otto (1998). </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://www.sendspace.com/file/0mx0en</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Arrow of Time, Reinforcement Learning, AI-Safety</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rylJkpEtwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxgJTEYDr" data-number="288">
      <h4>
        <a href="/forum?id=ryxgJTEYDr">
            Reinforcement Learning with Competitive  Ensembles of Information-Constrained Primitives
        </a>
      
        
          <a href="/pdf?id=ryxgJTEYDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=anirudhgoyal9119%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anirudhgoyal9119@gmail.com">Anirudh Goyal</a>, <a href="/profile?email=sshagunsodhani%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sshagunsodhani@gmail.com">Shagun Sodhani</a>, <a href="/profile?email=jbinas%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jbinas@gmail.com">Jonathan Binas</a>, <a href="/profile?email=xbpeng%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xbpeng@berkeley.edu">Xue Bin Peng</a>, <a href="/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>, <a href="/profile?email=yoshua.bengio%40mila.quebec" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.bengio@mila.quebec">Yoshua Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#ryxgJTEYDr-details-875" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxgJTEYDr-details-875"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement Learning, Variational Information Bottleneck, Learning primitives</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Learning an implicit master policy, as a master policy in HRL can fail to generalize.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Reinforcement learning agents that operate in diverse and complex environments can benefit from the structured decomposition of their behavior. Often, this is addressed in the context of hierarchical reinforcement learning, where the aim is to decompose a policy into lower-level primitives or options, and a higher-level meta-policy that triggers the appropriate behaviors for a given situation. However, the meta-policy must still produce appropriate decisions in all states.
      In this work, we propose a policy design that decomposes into primitives, similarly to hierarchical reinforcement learning, but without a high-level meta-policy. Instead, each primitive can decide for themselves whether they wish to act in the current state.
      We use an information-theoretic mechanism for enabling this decentralized decision: each primitive chooses how much information it needs about the current state to make a decision and the primitive that requests the most information about the current state acts in the world. The primitives are regularized to use as little information as possible, which leads to natural competition and specialization. We experimentally demonstrate that this policy architecture improves over both flat and hierarchical policies in terms of generalization. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxgJTEYDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1lZJpVFvr" data-number="291">
      <h4>
        <a href="/forum?id=H1lZJpVFvr">
            Robust Local Features for Improving the Generalization of Adversarial Training
        </a>
      
        
          <a href="/pdf?id=H1lZJpVFvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=cbsong%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="cbsong@hust.edu.cn">Chuanbiao Song</a>, <a href="/profile?email=brooklet60%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="brooklet60@hust.edu.cn">Kun He</a>, <a href="/profile?email=jdlin%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jdlin@hust.edu.cn">Jiadong Lin</a>, <a href="/profile?email=wanglw%40cis.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanglw@cis.pku.edu.cn">Liwei Wang</a>, <a href="/profile?email=jeh%40cs.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jeh@cs.cornell.edu">John E. Hopcroft</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#H1lZJpVFvr-details-76" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1lZJpVFvr-details-76"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a new stream of adversarial training approach called Robust Local Features for Adversarial Training (RLFAT) that significantly improves both the adversarially robust generalization and the standard generalization.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Adversarial training has been demonstrated as one of the most effective methods for training robust models to defend against adversarial examples. However, adversarially trained models often lack adversarially robust generalization on unseen testing data. Recent works show that adversarially trained models are more biased towards global structure features. Instead, in this work, we would like to investigate the relationship between the generalization of adversarial training and the robust local features, as the robust local features generalize well for unseen shape variation. To learn the robust local features, we develop a Random Block Shuffle (RBS) transformation to break up the global structure features on normal adversarial examples. We continue to propose a new approach called Robust Local Features for Adversarial Training (RLFAT), which first learns the robust local features by adversarial training on the RBS-transformed adversarial examples, and then transfers the robust local features into the training of normal adversarial examples. To demonstrate the generality of our argument, we implement RLFAT in currently state-of-the-art adversarial training frameworks. Extensive experiments on STL-10, CIFAR-10 and CIFAR-100 show that RLFAT significantly improves both the adversarially robust generalization and the standard generalization of adversarial training. Additionally, we demonstrate that our models capture more local features of the object on the images, aligning better with human perception.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/JHL-HUST/RLFAT</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial robustness, adversarial training, adversarial example, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1lZJpVFvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJgQkT4twH" data-number="295">
      <h4>
        <a href="/forum?id=rJgQkT4twH">
            Analysis of Video Feature Learning in Two-Stream CNNs on the Example of Zebrafish Swim Bout Classification
        </a>
      
        
          <a href="/pdf?id=rJgQkT4twH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=b.breier%40sms.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="b.breier@sms.ed.ac.uk">Bennet Breier</a>, <a href="/profile?email=aonken%40inf.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="aonken@inf.ed.ac.uk">Arno Onken</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rJgQkT4twH-details-635" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJgQkT4twH-details-635"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">convolutional neural networks, neural network transparency, AI explainability, deep Taylor decomposition, supervised classification, zebrafish, transparency, behavioral research, optical flow</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We demonstrate the utility of a recent AI explainability technique by visualizing the learned features of a CNN trained on binary classification of zebrafish movements.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Semmelhack et al. (2014) have achieved high classification accuracy in distinguishing swim bouts of zebrafish using a Support Vector Machine (SVM). Convolutional Neural Networks (CNNs) have reached superior performance in various image recognition tasks over SVMs, but these powerful networks remain a black box. Reaching better transparency helps to build trust in their classifications and makes learned features interpretable to experts. Using a recently developed technique called Deep Taylor Decomposition, we generated heatmaps to highlight input regions of high relevance for predictions. We find that our CNN makes predictions by analyzing the steadiness of the tail's trunk, which markedly differs from the manually extracted features used by Semmelhack et al. (2014). We further uncovered that the network paid attention to experimental artifacts. Removing these artifacts ensured the validity of predictions. After correction, our best CNN beats the SVM by 6.12%, achieving a classification accuracy of 96.32%. Our work thus demonstrates the utility of AI explainability for CNNs.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/Benji4/zebrafish-learning.git</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJgQkT4twH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkxBJT4YvB" data-number="300">
      <h4>
        <a href="/forum?id=HkxBJT4YvB">
            Learning Disentangled Representations for CounterFactual Regression
        </a>
      
        
          <a href="/pdf?id=HkxBJT4YvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=hassanpo%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="hassanpo@ualberta.ca">Negar Hassanpour</a>, <a href="/profile?email=rgreiner%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="rgreiner@ualberta.ca">Russell Greiner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#HkxBJT4YvB-details-63" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkxBJT4YvB-details-63"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Counterfactual Regression, Causal Effect Estimation, Selection Bias, Off-policy Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We consider the challenge of estimating treatment effects from observational data; and point out that, in general, only some factors based on the observed covariates X contribute to selection of the treatment T, and only some to determining the outcomes Y. We model this by considering three underlying sources of {X, T, Y} and show that explicitly modeling these sources offers great insight to guide designing models that better handle selection bias. This paper is an attempt to conceptualize this line of thought and provide a path to explore it further.
      In this work, we propose an algorithm to (1) identify disentangled representations of the above-mentioned underlying factors from any given observational dataset D and (2) leverage this knowledge to reduce, as well as account for, the negative impact of selection bias on estimating the treatment effects from D. Our empirical results show that the proposed method achieves state-of-the-art performance in both individual and population based evaluation measures.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://www.dropbox.com/sh/vrux2exqwc9uh7k/AAAR4tlJLScPlkmPruvbrTJQa?dl=0</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkxBJT4YvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkeIyaVtwB" data-number="303">
      <h4>
        <a href="/forum?id=SkeIyaVtwB">
            Exploration in Reinforcement Learning with Deep Covering Options
        </a>
      
        
          <a href="/pdf?id=SkeIyaVtwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yuu_jinnai%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuu_jinnai@brown.edu">Yuu Jinnai</a>, <a href="/profile?email=jee_won_park%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jee_won_park@brown.edu">Jee Won Park</a>, <a href="/profile?email=marlosm%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="marlosm@google.com">Marlos C. Machado</a>, <a href="/profile?email=gdk%40cs.brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gdk@cs.brown.edu">George Konidaris</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#SkeIyaVtwB-details-603" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkeIyaVtwB-details-603"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement learning, temporal abstraction, exploration</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce a method to automatically discover task-agnostic options that encourage exploration for reinforcement learning.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">While many option discovery methods have been proposed to accelerate exploration in reinforcement learning, they are often heuristic. Recently, covering options was proposed to discover a set of options that provably reduce the upper bound of the environment's cover time, a measure of the difficulty of exploration. Covering options are computed using the eigenvectors of the graph Laplacian, but they are constrained to tabular tasks and are not applicable to tasks with large or continuous state-spaces. 
      We introduce deep covering options, an online method that extends covering options to large state spaces,  automatically discovering task-agnostic options that encourage exploration. We evaluate our method in several challenging sparse-reward domains and we show that our approach identifies less explored regions of the state-space and successfully generates options to visit these regions, substantially improving both the exploration and the total accumulated reward.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkeIyaVtwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkldyTNYwH" data-number="308">
      <h4>
        <a href="/forum?id=HkldyTNYwH">
            AE-OT: A NEW GENERATIVE MODEL BASED ON EXTENDED SEMI-DISCRETE OPTIMAL TRANSPORT
        </a>
      
        
          <a href="/pdf?id=HkldyTNYwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=doan%40cs.stonybrook.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="doan@cs.stonybrook.edu">Dongsheng An</a>, <a href="/profile?email=yangguo%40cs.stonybrook.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yangguo@cs.stonybrook.edu">Yang Guo</a>, <a href="/profile?email=nalei%40dlut.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="nalei@dlut.edu.cn">Na Lei</a>, <a href="/profile?email=zxluo%40dlut.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zxluo@dlut.edu.cn">Zhongxuan Luo</a>, <a href="/profile?email=yau%40math.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yau@math.harvard.edu">Shing-Tung Yau</a>, <a href="/profile?email=gu%40cs.stonybrook.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gu@cs.stonybrook.edu">Xianfeng Gu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HkldyTNYwH-details-713" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkldyTNYwH-details-713"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Generative adversarial networks (GANs) have attracted huge attention due to
      its capability to generate visual realistic images. However, most of the existing
      models suffer from the mode collapse or mode mixture problems. In this work, we
      give a theoretic explanation of the both problems by Figalli’s regularity theory of
      optimal transportation maps. Basically, the generator compute the transportation
      maps between the white noise distributions and the data distributions, which are
      in general discontinuous. However, DNNs can only represent continuous maps.
      This intrinsic conflict induces mode collapse and mode mixture. In order to
      tackle the both problems, we explicitly separate the manifold embedding and the
      optimal transportation; the first part is carried out using an autoencoder to map the
      images onto the latent space; the second part is accomplished using a GPU-based
      convex optimization to find the discontinuous transportation maps. Composing the
      extended OT map and the decoder, we can finally generate new images from the
      white noise. This AE-OT model avoids representing discontinuous maps by DNNs,
      therefore effectively prevents mode collapse and mode mixture.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Generative model, auto-encoder, optimal transport, mode collapse, regularity</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkldyTNYwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkecJ6VFvr" data-number="311">
      <h4>
        <a href="/forum?id=rkecJ6VFvr">
            Logic and the 2-Simplicial Transformer
        </a>
      
        
          <a href="/pdf?id=rkecJ6VFvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jamesedwardclift%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jamesedwardclift@gmail.com">James Clift</a>, <a href="/profile?email=dmitry.doryn%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dmitry.doryn@gmail.com">Dmitry Doryn</a>, <a href="/profile?email=d.murfet%40unimelb.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="d.murfet@unimelb.edu.au">Daniel Murfet</a>, <a href="/profile?email=james.wallbridge%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="james.wallbridge@gmail.com">James Wallbridge</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#rkecJ6VFvr-details-140" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkecJ6VFvr-details-140"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We introduce the 2-simplicial Transformer, an extension of the Transformer which includes a form of higher-dimensional attention generalising the dot-product attention, and uses this attention to update entity representations with tensor products of value vectors. We show that this architecture is a useful inductive bias for logical reasoning in the context of deep reinforcement learning.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/dmurfet/2simplicialtransformer</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">transformer, logic, reinforcement learning, reasoning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce the 2-simplicial Transformer and show that this architecture is a useful inductive bias for logical reasoning in the context of deep reinforcement learning.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkecJ6VFvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJg5J6NtDr" data-number="312">
      <h4>
        <a href="/forum?id=SJg5J6NtDr">
            Watch, Try, Learn: Meta-Learning from Demonstrations and Rewards
        </a>
      
        
          <a href="/pdf?id=SJg5J6NtDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ayz%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ayz@stanford.edu">Allan Zhou</a>, <a href="/profile?email=ejang%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ejang@google.com">Eric Jang</a>, <a href="/profile?email=kappler%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kappler@google.com">Daniel Kappler</a>, <a href="/profile?email=alexherzog%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexherzog@google.com">Alex Herzog</a>, <a href="/profile?email=khansari%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="khansari@google.com">Mohi Khansari</a>, <a href="/profile?email=wohlhart%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wohlhart@google.com">Paul Wohlhart</a>, <a href="/profile?email=yunfeibai%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yunfeibai@google.com">Yunfei Bai</a>, <a href="/profile?email=kalakris%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kalakris@google.com">Mrinal Kalakrishnan</a>, <a href="/profile?email=slevine%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="slevine@google.com">Sergey Levine</a>, <a href="/profile?email=cbfinn%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cbfinn@cs.stanford.edu">Chelsea Finn</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SJg5J6NtDr-details-881" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJg5J6NtDr-details-881"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Imitation learning allows agents to learn complex behaviors from demonstrations. However, learning a complex vision-based task may require an impractical number of demonstrations. Meta-imitation learning is a promising approach towards enabling agents to learn a new task from one or a few demonstrations by leveraging experience from learning similar tasks. In the presence of task ambiguity or unobserved dynamics, demonstrations alone may not provide enough information; an agent must also try the task to successfully infer a policy. In this work, we propose a method that can learn to learn from both demonstrations and trial-and-error experience with sparse reward feedback. In comparison to meta-imitation, this approach enables the agent to effectively and efficiently improve itself autonomously beyond the demonstration data. In comparison to meta-reinforcement learning, we can scale to substantially broader distributions of tasks, as the demonstration reduces the burden of exploration. Our experiments show that our method significantly outperforms prior approaches on a set of challenging, vision-based control tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/open?id=1f1LzO0fe1m-kINY8DTgL6JGimVGiQOuz</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">meta-learning, reinforcement learning, imitation learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJg5J6NtDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJl31TNYPr" data-number="316">
      <h4>
        <a href="/forum?id=rJl31TNYPr">
            Fooling Detection Alone is Not Enough: Adversarial Attack against Multiple Object Tracking
        </a>
      
        
          <a href="/pdf?id=rJl31TNYPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jack0082010%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jack0082010@gmail.com">Yunhan Jia</a>, <a href="/profile?email=ylu25%40syr.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ylu25@syr.edu">Yantao Lu</a>, <a href="/profile?email=junjies1%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="junjies1@uci.edu">Junjie Shen</a>, <a href="/profile?email=alfchen%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="alfchen@uci.edu">Qi Alfred Chen</a>, <a href="/profile?email=chen%40ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chen@ucdavis.edu">Hao Chen</a>, <a href="/profile?email=edwardzhong%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="edwardzhong@baidu.com">Zhenyu Zhong</a>, <a href="/profile?email=lenx.wei%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lenx.wei@gmail.com">Tao Wei</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rJl31TNYPr-details-941" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJl31TNYPr-details-941"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Adversarial examples, object detection, object tracking, security, autonomous vehicle, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We study the adversarial machine learning attacks against the Multiple Object Tracking mechanisms for the first time. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recent work in adversarial machine learning started to focus on the visual perception in autonomous driving and studied Adversarial Examples (AEs) for object detection models. However, in such visual perception pipeline the detected objects must also be tracked, in a process called Multiple Object Tracking (MOT), to build the moving trajectories of surrounding obstacles. Since MOT is designed to be robust against errors in object detection, it poses a general challenge to existing attack techniques that blindly target objection detection: we find that a success rate of over 98% is needed for them to actually affect the tracking results, a requirement that no existing attack technique can satisfy. In this paper, we are the first to study adversarial machine learning attacks against the complete visual perception pipeline in autonomous driving, and discover a novel attack technique, tracker hijacking, that can effectively fool MOT using AEs on object detection. Using our technique, successful AEs on as few as one single frame can move an existing object in to or out of the headway of an autonomous vehicle to cause potential safety hazards. We perform evaluation using the Berkeley Deep Drive dataset and find that on average when 3 frames are attacked, our attack can have a nearly 100% success rate while attacks that blindly target object detection only have up to 25%.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/anonymousjack/hijacking</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJl31TNYPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJgExaVtwr" data-number="335">
      <h4>
        <a href="/forum?id=HJgExaVtwr">
            DivideMix: Learning with Noisy Labels as Semi-supervised Learning
        </a>
      
        
          <a href="/pdf?id=HJgExaVtwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=junnan.li%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="junnan.li@salesforce.com">Junnan Li</a>, <a href="/profile?email=rsocher%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsocher@salesforce.com">Richard Socher</a>, <a href="/profile?email=shoi%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shoi@salesforce.com">Steven C.H. Hoi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="#HJgExaVtwr-details-566" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJgExaVtwr-details-566"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">label noise, semi-supervised learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a novel semi-supervised learning approach with SOTA performance on combating learning with noisy labels.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep neural networks are known to be annotation-hungry. Numerous efforts have been devoted to reducing the annotation cost when learning with deep networks. Two prominent directions include learning with noisy labels and semi-supervised learning by exploiting unlabeled data. In this work, we propose DivideMix, a novel framework for learning with noisy labels by leveraging semi-supervised learning techniques. In particular, DivideMix models the per-sample loss distribution with a mixture model to dynamically divide the training data into a labeled set with clean samples and an unlabeled set with noisy samples, and trains the model on both the labeled and unlabeled data in a semi-supervised manner. To avoid confirmation bias, we simultaneously train two diverged networks where each network uses the dataset division from the other network. During the semi-supervised training phase, we improve the MixMatch strategy by performing label co-refinement and label co-guessing on labeled and unlabeled samples, respectively. Experiments on multiple benchmark datasets demonstrate substantial improvements over state-of-the-art methods. Code is available at https://github.com/LiJunnan1992/DivideMix .</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJgExaVtwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rklOg6EFwS" data-number="343">
      <h4>
        <a href="/forum?id=rklOg6EFwS">
            Improving Adversarial Robustness Requires Revisiting Misclassified Examples
        </a>
      
        
          <a href="/pdf?id=rklOg6EFwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=eewangyisen%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="eewangyisen@gmail.com">Yisen Wang</a>, <a href="/profile?email=knowzou%40ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="knowzou@ucla.edu">Difan Zou</a>, <a href="/profile?email=jinfengyi.ustc%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jinfengyi.ustc@gmail.com">Jinfeng Yi</a>, <a href="/profile?email=baileyj%40unimelb.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="baileyj@unimelb.edu.au">James Bailey</a>, <a href="/profile?email=xingjun.ma%40unimelb.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="xingjun.ma@unimelb.edu.au">Xingjun Ma</a>, <a href="/profile?email=qgu%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qgu@cs.ucla.edu">Quanquan Gu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rklOg6EFwS-details-618" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rklOg6EFwS-details-618"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">By differentiating misclassified and correctly classified data, we propose a new misclassification aware defense that improves the state-of-the-art adversarial robustness.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep neural networks (DNNs) are vulnerable to adversarial examples crafted by imperceptible perturbations. A range of defense techniques have been proposed to improve DNN robustness to adversarial examples, among which adversarial training has been demonstrated to be the most effective. Adversarial training is often formulated as a min-max optimization problem, with the inner maximization for generating adversarial examples. However, there exists a simple, yet easily overlooked fact that adversarial examples are only defined on correctly classified (natural) examples, but inevitably, some (natural) examples will be misclassified during training. In this paper, we investigate the distinctive influence of misclassified and correctly classified examples on the final robustness of adversarial training. Specifically, we find that misclassified examples indeed have a significant impact on the final robustness. More surprisingly, we find that different maximization techniques on misclassified examples may have a negligible influence on the final robustness, while different minimization techniques are crucial. Motivated by the above discovery, we propose a new defense algorithm called {\em Misclassification Aware adveRsarial Training} (MART), which explicitly differentiates the misclassified and correctly classified examples during the training. We also propose a semi-supervised extension of MART, which can leverage the unlabeled data to further improve the robustness. Experimental results show that MART and its variant could significantly improve the state-of-the-art adversarial robustness.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Robustness, Adversarial Defense, Adversarial Training</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rklOg6EFwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SylOlp4FvH" data-number="345">
      <h4>
        <a href="/forum?id=SylOlp4FvH">
            V-MPO: On-Policy Maximum a Posteriori Policy Optimization for Discrete and Continuous Control
        </a>
      
        
          <a href="/pdf?id=SylOlp4FvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=songf%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="songf@google.com">H. Francis Song</a>, <a href="/profile?email=aabdolmaleki%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aabdolmaleki@google.com">Abbas Abdolmaleki</a>, <a href="/profile?email=springenberg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="springenberg@google.com">Jost Tobias Springenberg</a>, <a href="/profile?email=aidanclark%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aidanclark@google.com">Aidan Clark</a>, <a href="/profile?email=soyer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="soyer@google.com">Hubert Soyer</a>, <a href="/profile?email=jwrae%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jwrae@google.com">Jack W. Rae</a>, <a href="/profile?email=snoury%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="snoury@google.com">Seb Noury</a>, <a href="/profile?email=arahuja%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="arahuja@google.com">Arun Ahuja</a>, <a href="/profile?email=liusiqi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liusiqi@google.com">Siqi Liu</a>, <a href="/profile?email=dhruvat%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dhruvat@google.com">Dhruva Tirumala</a>, <a href="/profile?email=heess%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="heess@google.com">Nicolas Heess</a>, <a href="/profile?email=danbelov%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="danbelov@google.com">Dan Belov</a>, <a href="/profile?email=riedmiller%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="riedmiller@google.com">Martin Riedmiller</a>, <a href="/profile?email=botvinick%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="botvinick@google.com">Matthew M. Botvinick</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="#SylOlp4FvH-details-420" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SylOlp4FvH-details-420"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, policy iteration, multi-task learning, continuous control</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A state-value function-based version of MPO that achieves good results in a wide range of tasks in discrete and continuous control.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Some of the most successful applications of deep reinforcement learning to challenging domains in discrete and continuous control have used policy gradient methods in the on-policy setting. However, policy gradients can suffer from large variance that may limit performance, and in practice require carefully tuned entropy regularization to prevent policy collapse. As an alternative to policy gradient algorithms, we introduce V-MPO, an on-policy adaptation of Maximum a Posteriori Policy Optimization (MPO) that performs policy iteration based on a learned state-value function. We show that V-MPO surpasses previously reported scores for both the Atari-57 and DMLab-30 benchmark suites in the multi-task setting, and does so reliably without importance weighting, entropy regularization, or population-based tuning of hyperparameters. On individual DMLab and Atari levels, the proposed algorithm can achieve scores that are substantially higher than has previously been reported. V-MPO is also applicable to problems with high-dimensional, continuous action spaces, which we demonstrate in the context of learning to control simulated humanoids with 22 degrees of freedom from full state observations and 56 degrees of freedom from pixel observations, as well as example OpenAI Gym tasks where V-MPO achieves substantially higher asymptotic scores than previously reported.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SylOlp4FvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1xFl64tDr" data-number="346">
      <h4>
        <a href="/forum?id=S1xFl64tDr">
            Interpretable Complex-Valued Neural Networks for Privacy Protection
        </a>
      
        
          <a href="/pdf?id=S1xFl64tDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xiangliyao08%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiangliyao08@sjtu.edu.cn">Liyao Xiang</a>, <a href="/profile?email=1603023-zh%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="1603023-zh@sjtu.edu.cn">Hao Zhang</a>, <a href="/profile?email=11612807%40mail.sustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="11612807@mail.sustc.edu.cn">Haotian Ma</a>, <a href="/profile?email=zhangyf_sjtu%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhangyf_sjtu@sjtu.edu.cn">Yifan Zhang</a>, <a href="/profile?email=ariesrj%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ariesrj@sjtu.edu.cn">Jie Ren</a>, <a href="/profile?email=zqs1022%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zqs1022@sjtu.edu.cn">Quanshi Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#S1xFl64tDr-details-500" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1xFl64tDr-details-500"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep Learning, Privacy Protection, Complex-Valued Neural Networks</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Previous studies have found that an adversary attacker can often infer unintended input information from intermediate-layer features. We study the possibility of preventing such adversarial inference, yet without too much accuracy degradation. We propose a generic method to revise the neural network to boost the challenge of inferring input attributes from features, while maintaining highly accurate outputs. In particular, the method transforms real-valued features into complex-valued ones, in which the input is hidden in a randomized phase of the transformed features. The knowledge of the phase acts like a key, with which any party can easily recover the output from the processing result, but without which the party can neither recover the output nor distinguish the original input. Preliminary experiments on various datasets and network structures have shown that our method significantly diminishes the adversary's ability in inferring about the input while largely preserves the resulting accuracy.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1xFl64tDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1gixp4FPH" data-number="350">
      <h4>
        <a href="/forum?id=r1gixp4FPH">
            Accelerating SGD with momentum for over-parameterized learning
        </a>
      
        
          <a href="/pdf?id=r1gixp4FPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=liu.2656%40buckeyemail.osu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liu.2656@buckeyemail.osu.edu">Chaoyue Liu</a>, <a href="/profile?email=mbelkin%40cse.ohio-state.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mbelkin@cse.ohio-state.edu">Mikhail Belkin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 04 Oct 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#r1gixp4FPH-details-450" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1gixp4FPH-details-450"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This work proves the non-acceleration of Nesterov SGD with any hyper-parameters, and proposes new algorithm which provably accelerates SGD in the over-parameterized setting.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">
      Nesterov SGD is widely used for training modern neural networks and other machine learning models. Yet, its advantages over SGD have not been theoretically clarified. Indeed, as we show  in this paper, both theoretically and empirically, Nesterov SGD with any parameter selection does not in general provide acceleration over ordinary SGD. Furthermore, Nesterov SGD may diverge for step sizes that ensure convergence of ordinary SGD. This is in contrast to the classical results in the deterministic setting, where the same step size ensures accelerated convergence of the Nesterov's method over optimal gradient descent.
      
      To address the non-acceleration issue, we  introduce a compensation term to Nesterov SGD. The resulting  algorithm, which we call MaSS, converges  for same step sizes as SGD. We prove that MaSS obtains an accelerated convergence rates over SGD for any mini-batch size in the linear setting.  For full batch, the convergence rate of MaSS matches the well-known accelerated rate of the Nesterov's method. 
      
      We also analyze the  practically important question of the dependence of the convergence rate and  optimal hyper-parameters on the mini-batch size, demonstrating three distinct regimes: linear scaling, diminishing returns and saturation.
      
      Experimental evaluation of MaSS for several standard  architectures of deep networks, including ResNet and convolutional networks, shows improved performance over SGD, Nesterov SGD  and Adam. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/ts66395/MaSS</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">SGD, acceleration, momentum, stochastic, over-parameterized, Nesterov</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1gixp4FPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1esx6EYvr" data-number="351">
      <h4>
        <a href="/forum?id=B1esx6EYvr">
            A critical analysis of self-supervision, or what we can learn from a single image
        </a>
      
        
          <a href="/pdf?id=B1esx6EYvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yuki%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuki@robots.ox.ac.uk">Asano YM.</a>, <a href="/profile?email=chrisr%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="chrisr@robots.ox.ac.uk">Rupprecht C.</a>, <a href="/profile?email=vedaldi%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="vedaldi@robots.ox.ac.uk">Vedaldi A.</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#B1esx6EYvr-details-187" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1esx6EYvr-details-187"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">self-supervision, feature representation learning, CNN</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We evaluate self-supervised feature learning methods and find that with sufficient data augmentation early layers can be learned using just one image.  This is informative about self-supervision and the role of augmentations.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We look critically at popular self-supervision techniques for learning deep convolutional neural networks without manual labels. We show that three different and representative methods, BiGAN, RotNet and DeepCluster, can learn the first few layers of a convolutional network from a single image as well as using millions of images and manual labels, provided that strong data augmentation is used. However, for deeper layers the gap with manual supervision cannot be closed even if millions of unlabelled images are used for training.
      We conclude that:
      (1) the weights of the early layers of deep networks contain limited information about the statistics of natural images, that
      (2) such low-level statistics can be learned through self-supervision just as well as through strong supervision, and that
      (3) the low-level statistics can be captured via synthetic transformations instead of using a large image dataset.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1esx6EYvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SygagpEKwB" data-number="355">
      <h4>
        <a href="/forum?id=SygagpEKwB">
            Disentangling Factors of Variations Using Few Labels
        </a>
      
        
          <a href="/pdf?id=SygagpEKwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=flocatello%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="flocatello@tuebingen.mpg.de">Francesco Locatello</a>, <a href="/profile?email=tschannen%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tschannen@google.com">Michael Tschannen</a>, <a href="/profile?email=stefan.bauer%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="stefan.bauer@tuebingen.mpg.de">Stefan Bauer</a>, <a href="/profile?email=raetsch%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="raetsch@inf.ethz.ch">Gunnar Rätsch</a>, <a href="/profile?email=bs%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="bs@tuebingen.mpg.de">Bernhard Schölkopf</a>, <a href="/profile?email=bachem%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bachem@google.com">Olivier Bachem</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SygagpEKwB-details-241" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SygagpEKwB-details-241"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Learning disentangled representations is considered a cornerstone problem in representation learning. Recently, Locatello et al. (2019) demonstrated that unsupervised disentanglement learning without inductive biases is theoretically impossible and that existing inductive biases and unsupervised methods do not allow to consistently learn disentangled representations. However, in many practical settings, one might have access to a limited amount of supervision, for example through manual labeling of (some) factors of variation in a few training examples. In this paper, we investigate the impact of such supervision on state-of-the-art disentanglement methods and perform a large scale study, training over 52000 models under well-defined and reproducible experimental conditions.  We observe that a small number of labeled examples (0.01--0.5% of the data set), with potentially imprecise and incomplete labels, is sufficient to perform model selection on state-of-the-art unsupervised models. Further, we investigate the benefit of incorporating supervision into the training process. Overall, we empirically validate that with little and imprecise supervision it is possible to reliably learn disentangled representations.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SygagpEKwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bylx-TNKvH" data-number="362">
      <h4>
        <a href="/forum?id=Bylx-TNKvH">
            Functional vs. parametric equivalence of ReLU networks
        </a>
      
        
          <a href="/pdf?id=Bylx-TNKvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=bphuong%40ist.ac.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="bphuong@ist.ac.at">Mary Phuong</a>, <a href="/profile?email=chl%40ist.ac.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="chl@ist.ac.at">Christoph H. Lampert</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#Bylx-TNKvH-details-148" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bylx-TNKvH-details-148"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">ReLU networks, symmetry, functional equivalence, over-parameterization</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We prove that there exist ReLU networks whose parameters are almost uniquely determined by the function they implement.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We address the following question: How redundant is the parameterisation of ReLU networks? Specifically, we consider transformations of the weight space which leave the function implemented by the network intact. Two such transformations are known for feed-forward architectures: permutation of neurons within a layer, and positive scaling of all incoming weights of a neuron coupled with inverse scaling of its outgoing weights. In this work, we show for architectures with non-increasing widths that permutation and scaling are in fact the only function-preserving weight transformations. For any eligible architecture we give an explicit construction of a neural network such that any other network that implements the same function can be obtained from the original one by the application of permutations and rescaling. The proof relies on a geometric understanding of boundaries between linear regions of ReLU networks, and we hope the developed mathematical tools are of independent interest.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Bylx-TNKvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyxIWpVYvr" data-number="377">
      <h4>
        <a href="/forum?id=SyxIWpVYvr">
            Input Complexity and Out-of-distribution Detection with Likelihood-based Generative Models
        </a>
      
        
          <a href="/pdf?id=SyxIWpVYvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=joansj%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="joansj@gmail.com">Joan Serrà</a>, <a href="/profile?email=davidalvarezdlt%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="davidalvarezdlt@gmail.com">David Álvarez</a>, <a href="/profile?email=vicen.gomez%40upf.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vicen.gomez@upf.edu">Vicenç Gómez</a>, <a href="/profile?email=oslizovskaia%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="oslizovskaia@gmail.com">Olga Slizovskaia</a>, <a href="/profile?email=jfn237%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jfn237@nyu.edu">José F. Núñez</a>, <a href="/profile?email=jordi.luqueserrano%40telefonica.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jordi.luqueserrano@telefonica.com">Jordi Luque</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SyxIWpVYvr-details-894" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyxIWpVYvr-details-894"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">OOD, generative models, likelihood</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We pose that generative models' likelihoods are excessively influenced by the input's complexity, and propose a way to compensate it when detecting out-of-distribution inputs</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Likelihood-based generative models are a promising resource to detect out-of-distribution (OOD) inputs which could compromise the robustness or reliability of a machine learning system. However, likelihoods derived from such models have been shown to be problematic for detecting certain types of inputs that significantly differ from training data. In this paper, we pose that this problem is due to the excessive influence that input complexity has in generative models' likelihoods. We report a set of experiments supporting this hypothesis, and use an estimate of input complexity to derive an efficient and parameter-free OOD score, which can be seen as a likelihood-ratio, akin to Bayesian model comparison. We find such score to perform comparably to, or even better than, existing OOD detection approaches under a wide range of data sets, models, model sizes, and complexity estimates.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SyxIWpVYvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJgob6NKvH" data-number="387">
      <h4>
        <a href="/forum?id=SJgob6NKvH">
            RTFM: Generalising to New Environment Dynamics via Reading
        </a>
      
        
          <a href="/pdf?id=SJgob6NKvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=victor%40victorzhong.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="victor@victorzhong.com">Victor Zhong</a>, <a href="/profile?email=tim.rocktaeschel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tim.rocktaeschel@gmail.com">Tim Rocktäschel</a>, <a href="/profile?email=egrefen%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="egrefen@gmail.com">Edward Grefenstette</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SJgob6NKvH-details-267" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJgob6NKvH-details-267"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, policy learning, reading comprehension, generalisation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We show language understanding via reading is promising way to learn policies that generalise to new environments.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Obtaining policies that can generalise to new environments in reinforcement learning is challenging. In this work, we demonstrate that language understanding via a reading policy learner is a promising vehicle for generalisation to new environments. We propose a grounded policy learning problem, Read to Fight Monsters (RTFM), in which the agent must jointly reason over a language goal, relevant dynamics described in a document, and environment observations. We procedurally generate environment dynamics and corresponding language descriptions of the dynamics, such that agents must read to understand new environment dynamics instead of memorising any particular information. In addition, we propose txt2π, a model that captures three-way interactions between the goal, document, and observations. On RTFM, txt2π generalises to new environments with dynamics not seen during training via reading. Furthermore, our model outperforms baselines such as FiLM and language-conditioned CNNs on RTFM. Through curriculum learning, txt2π produces policies that excel on complex RTFM tasks requiring several reasoning and coreference steps.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJgob6NKvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1l2bp4YwS" data-number="390">
      <h4>
        <a href="/forum?id=B1l2bp4YwS">
            What graph neural networks cannot learn: depth vs width
        </a>
      
        
          <a href="/pdf?id=B1l2bp4YwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=andreas.loukas%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="andreas.loukas@epfl.ch">Andreas Loukas</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#B1l2bp4YwS-details-911" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1l2bp4YwS-details-911"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper studies the expressive power of graph neural networks falling within the message-passing framework (GNNmp). Two results are presented. First, GNNmp are shown to be Turing universal under sufficient conditions on their depth, width, node attributes, and layer expressiveness. Second, it is discovered that GNNmp can lose a significant portion of their power when their depth and width is restricted. The proposed impossibility statements stem from a new technique that enables the repurposing of seminal results from distributed computing and leads to lower bounds for an array of decision, optimization, and estimation problems involving graphs. Strikingly, several of these problems are deemed impossible unless the product of a GNNmp's depth and width exceeds a polynomial of the graph size; this dependence remains significant even for tasks that appear simple or when considering approximation.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">graph neural networks, capacity, impossibility results, lower bounds, expressive power</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Several graph problems are impossible unless the product of a graph neural network's depth and width exceeds a polynomial of the graph size.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1l2bp4YwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkepbpNFwr" data-number="392">
      <h4>
        <a href="/forum?id=BkepbpNFwr">
            Progressive Memory Banks for Incremental Domain Adaptation
        </a>
      
        
          <a href="/pdf?id=BkepbpNFwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=nasghar%40uwaterloo.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="nasghar@uwaterloo.ca">Nabiha Asghar</a>, <a href="/profile?email=doublepower.mou%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="doublepower.mou@gmail.com">Lili Mou</a>, <a href="/profile?email=kaselby%40uwaterloo.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="kaselby@uwaterloo.ca">Kira A. Selby</a>, <a href="/profile?email=kevin.pantasdo%40uwaterloo.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="kevin.pantasdo@uwaterloo.ca">Kevin D. Pantasdo</a>, <a href="/profile?email=ppoupart%40uwaterloo.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="ppoupart@uwaterloo.ca">Pascal Poupart</a>, <a href="/profile?email=jiang.xin%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiang.xin@huawei.com">Xin Jiang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="#BkepbpNFwr-details-924" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkepbpNFwr-details-924"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">natural language processing, domain adaptation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present a neural memory-based architecture for incremental domain adaptation, and provide theoretical and empirical results.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper addresses the problem of incremental domain adaptation (IDA) in natural language processing (NLP). We assume each domain comes one after another, and that we could only access data in the current domain. The goal of IDA is  to build a unified model performing well on all the domains that we have encountered. We adopt the recurrent neural network (RNN) widely used in NLP, but augment it with a directly parameterized memory bank, which is retrieved by an attention mechanism at each step of RNN transition. The memory bank provides a natural way of IDA: when adapting our model to a new domain, we progressively add new slots to the memory bank, which increases the number of parameters, and thus the model capacity. We learn the new memory slots and fine-tune existing parameters by back-propagation. Experimental results show that our approach achieves significantly better performance than fine-tuning alone. Compared with expanding hidden states, our approach is more robust for old domains, shown by both empirical and theoretical results. Our model also outperforms previous work of IDA including elastic weight consolidation and progressive neural networks in the experiments.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/nabihach/IDA</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BkepbpNFwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1e0Wp4KvH" data-number="395">
      <h4>
        <a href="/forum?id=H1e0Wp4KvH">
            Automated curriculum generation through setter-solver interactions
        </a>
      
        
          <a href="/pdf?id=H1e0Wp4KvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=lampinen%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lampinen@stanford.edu">Sebastien Racaniere</a>, <a href="/profile?email=sracaniere%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sracaniere@google.com">Andrew Lampinen</a>, <a href="/profile?email=adamsantoro%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adamsantoro@google.com">Adam Santoro</a>, <a href="/profile?email=reichert%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="reichert@google.com">David Reichert</a>, <a href="/profile?email=vladfi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vladfi@google.com">Vlad Firoiu</a>, <a href="/profile?email=countzero%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="countzero@google.com">Timothy Lillicrap</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#H1e0Wp4KvH-details-747" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1e0Wp4KvH-details-747"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep Reinforcement Learning, Automatic Curriculum</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We investigate automatic curriculum generation and identify a number of losses useful to learn to generate a curriculum of tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Reinforcement learning algorithms use correlations between policies and rewards to improve agent performance.   But in dynamic or sparsely rewarding environments these correlations are often too small,  or rewarding events are too infrequent to make learning feasible. Human education instead relies on curricula –the breakdown of tasks into simpler, static challenges with dense rewards– to build up to complex behaviors.  While curricula are also useful for artificial agents, hand-crafting them is time consuming.  This has lead researchers to explore automatic curriculum generation. Here we explore automatic curriculum generation in rich,dynamic environments.  Using a setter-solver paradigm we show the importance of considering goal validity, goal feasibility, and goal coverage to construct useful curricula.  We demonstrate the success of our approach in rich but sparsely rewarding 2D and 3D environments, where an agent is tasked to achieve a single goal selected from a set of possible goals that varies between episodes, and identify challenges for future work.  Finally, we demonstrate the value of a novel technique that guides agents towards a desired goal distribution. Altogether, these results represent a substantial step towards applying automatic task curricula to learn complex,  otherwise unlearnable goals,  and to our knowledge are the first to demonstrate automated curriculum generation for goal-conditioned agents in environments where the possible goals vary between episodes.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1e0Wp4KvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJg1f6EFDB" data-number="396">
      <h4>
        <a href="/forum?id=BJg1f6EFDB">
            On Identifiability in Transformers
        </a>
      
        
          <a href="/pdf?id=BJg1f6EFDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=brunnegi%40ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="brunnegi@ethz.ch">Gino Brunner</a>, <a href="/profile?email=liu.yang%40alumni.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="liu.yang@alumni.ethz.ch">Yang Liu</a>, <a href="/profile?email=dpascual%40ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="dpascual@ethz.ch">Damian Pascual</a>, <a href="/profile?email=richtero%40ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="richtero@ethz.ch">Oliver Richter</a>, <a href="/profile?email=massi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="massi@google.com">Massimiliano Ciaramita</a>, <a href="/profile?email=wattenhofer%40ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="wattenhofer@ethz.ch">Roger Wattenhofer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#BJg1f6EFDB-details-322" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJg1f6EFDB-details-322"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Self-attention, interpretability, identifiability, BERT, Transformer, NLP, explanation, gradient attribution</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We investigate the identifiability and interpretability of attention distributions and tokens within contextual embeddings in the self-attention based BERT model.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In this paper we delve deep in the Transformer architecture by investigating two of its core components: self-attention and contextual embeddings. In particular, we study the identifiability of attention weights and token embeddings, and the aggregation of context into hidden tokens. We show that, for sequences longer than the attention head dimension, attention weights are not identifiable. We propose effective attention as a complementary tool for improving explanatory interpretations based on attention. Furthermore, we show that input tokens retain to a large degree their identity across the model. We also find evidence suggesting that identity information is mainly encoded in the angle of the embeddings and gradually decreases with depth. Finally, we demonstrate strong mixing of input information in the generation of contextual embeddings by means of a novel quantification method based on gradient attribution. Overall, we show that self-attention distributions are not directly interpretable and present tools to better understand and further investigate Transformer models.   </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJg1f6EFDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1exf64KwH" data-number="400">
      <h4>
        <a href="/forum?id=H1exf64KwH">
            Exploring Model-based Planning with Policy Networks
        </a>
      
        
          <a href="/pdf?id=H1exf64KwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tingwuwang%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tingwuwang@cs.toronto.edu">Tingwu Wang</a>, <a href="/profile?email=jba%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jba@cs.toronto.edu">Jimmy Ba</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#H1exf64KwH-details-139" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1exf64KwH-details-139"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Model-based reinforcement learning (MBRL) with model-predictive control or
      online planning has shown great potential for locomotion control tasks in both
      sample efficiency and asymptotic performance. Despite the successes, the existing
      planning methods search from candidate sequences randomly generated in the
      action space, which is inefficient in complex high-dimensional environments. In
      this paper, we propose a novel MBRL algorithm, model-based policy planning
      (POPLIN), that combines policy networks with online planning. More specifically,
      we formulate action planning at each time-step as an optimization problem using
      neural networks. We experiment with both optimization w.r.t. the action sequences
      initialized from the policy network, and also online optimization directly w.r.t. the
      parameters of the policy network. We show that POPLIN obtains state-of-the-art
      performance in the MuJoCo benchmarking environments, being about 3x more
      sample efficient than the state-of-the-art algorithms, such as PETS, TD3 and SAC.
      To explain the effectiveness of our algorithm, we show that the optimization surface
      in parameter space is smoother than in action space. Further more, we found the
      distilled policy network can be effectively applied without the expansive model
      predictive control during test time for some environments such as Cheetah. Code
      is released.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, model-based reinforcement learning, planning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">how to achieve state-of-the-art performance by combining policy network in model-based planning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1exf64KwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rke-f6NKvS" data-number="401">
      <h4>
        <a href="/forum?id=rke-f6NKvS">
            Learning Self-Correctable Policies and Value Functions from Demonstrations with Negative Sampling
        </a>
      
        
          <a href="/pdf?id=rke-f6NKvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yupingl%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yupingl@cs.princeton.edu">Yuping Luo</a>, <a href="/profile?email=huazhe_xu%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="huazhe_xu@eecs.berkeley.edu">Huazhe Xu</a>, <a href="/profile?email=tengyuma%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tengyuma@stanford.edu">Tengyu Ma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#rke-f6NKvS-details-910" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rke-f6NKvS-details-910"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce a notion of conservatively-extrapolated value functions, which provably lead to policies that can self-correct to stay close to the demonstration states, and learn them with a novel negative sampling technique.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Imitation learning, followed by reinforcement learning algorithms, is a promising paradigm to solve complex control tasks sample-efficiently. However, learning from demonstrations often suffers from the covariate shift problem, which results
      in cascading errors of the learned policy. We introduce a notion of conservatively extrapolated value functions, which provably lead to policies with self-correction. We design an algorithm Value Iteration with Negative Sampling (VINS) that practically learns such value functions with conservative extrapolation. We show that VINS can correct mistakes of the behavioral cloning policy on simulated robotics benchmark tasks. We also propose the algorithm of using VINS to initialize a reinforcement learning algorithm, which is shown to outperform prior works in sample efficiency.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">imitation learning, model-based imitation learning, model-based RL, behavior cloning, covariate shift</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rke-f6NKvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJezGp4YPr" data-number="403">
      <h4>
        <a href="/forum?id=SJezGp4YPr">
            Geometric Insights into the Convergence of Nonlinear TD Learning
        </a>
      
        
          <a href="/pdf?id=SJezGp4YPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=david.brandfonbrener%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.brandfonbrener@nyu.edu">David Brandfonbrener</a>, <a href="/profile?email=bruna%40cims.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bruna@cims.nyu.edu">Joan Bruna</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SJezGp4YPr-details-540" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJezGp4YPr-details-540"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">While there are convergence guarantees for temporal difference (TD) learning when using linear function approximators, the situation for nonlinear models is far less understood, and divergent examples are known. Here we take a first step towards extending theoretical convergence guarantees to TD learning with nonlinear function approximation. More precisely, we consider the expected learning dynamics of the TD(0) algorithm for value estimation. As the step-size converges to zero, these dynamics are defined by a nonlinear ODE which depends on the geometry of the space of function approximators, the structure of the underlying Markov chain, and their interaction. We find a set of function approximators that includes ReLU networks and has geometry amenable to TD learning regardless of environment, so that the solution performs about as well as linear TD in the worst case. Then, we show how environments that are more reversible induce dynamics that are better for TD learning and prove global convergence to the true value function for well-conditioned function approximators. Finally, we generalize a divergent counterexample to a family of divergent problems to demonstrate how the interaction between approximator and environment can go wrong and to motivate the assumptions needed to prove convergence. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">TD, nonlinear, convergence, value estimation, reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJezGp4YPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1emfT4twB" data-number="407">
      <h4>
        <a href="/forum?id=H1emfT4twB">
            Few-shot Text Classification with Distributional Signatures
        </a>
      
        
          <a href="/pdf?id=H1emfT4twB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yujia%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yujia@csail.mit.edu">Yujia Bao</a>, <a href="/profile?email=rmwu%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rmwu@mit.edu">Menghua Wu</a>, <a href="/profile?email=shiyu.chang%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shiyu.chang@ibm.com">Shiyu Chang</a>, <a href="/profile?email=regina%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="regina@csail.mit.edu">Regina Barzilay</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#H1emfT4twB-details-757" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1emfT4twB-details-757"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In this paper, we explore meta-learning for few-shot text classification. Meta-learning has shown strong performance in computer vision, where low-level patterns are transferable across learning tasks. However, directly applying this approach to text is challenging--lexical features highly informative for one task may be insignificant for another. Thus, rather than learning solely from words, our model also leverages their distributional signatures, which encode pertinent word occurrence patterns. Our model is trained within a meta-learning framework to map these signatures into attention scores, which are then used to weight the lexical representations of words. We demonstrate that our model consistently outperforms prototypical networks learned on lexical knowledge (Snell et al., 2017) in both few-shot text classification and relation classification by a significant margin across six benchmark datasets (20.0% on average in 1-shot classification).</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/YujiaBao/Distributional-Signatures</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">text classification, meta learning, few shot learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Meta-learning methods used for vision, directly applied to NLP, perform worse than nearest neighbors on new classes; we can do better with distributional signatures.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1emfT4twB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkeNfp4tPr" data-number="408">
      <h4>
        <a href="/forum?id=rkeNfp4tPr">
            Escaping Saddle Points Faster with Stochastic Momentum
        </a>
      
        
          <a href="/pdf?id=rkeNfp4tPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jimwang%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jimwang@gatech.edu">Jun-Kun Wang</a>, <a href="/profile?email=cl3385%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cl3385@gatech.edu">Chi-Heng Lin</a>, <a href="/profile?email=prof%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="prof@gatech.edu">Jacob Abernethy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#rkeNfp4tPr-details-967" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkeNfp4tPr-details-967"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">SGD, momentum, escaping saddle point</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Higher momentum parameter <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="386" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FD TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>β</mi></math></mjx-assistive-mml></mjx-container> helps for escaping saddle points faster</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Stochastic gradient descent (SGD) with stochastic momentum is popular in nonconvex stochastic optimization and particularly for the training of deep neural networks. In standard SGD, parameters are updated by improving along the path of the gradient at the current iterate on a batch of examples, where the addition of a ``momentum'' term biases the update in the direction of the previous change in parameters. In non-stochastic convex optimization one can show that a momentum adjustment provably reduces convergence time in many settings, yet such results have been elusive in the stochastic and non-convex settings. At the same time, a widely-observed empirical phenomenon is that in training deep networks stochastic momentum appears to significantly improve convergence time, variants of it have flourished in the development of other popular update methods, e.g. ADAM, AMSGrad, etc. Yet theoretical justification for the use of stochastic momentum has remained a significant open question. In this paper we propose an answer: stochastic momentum improves deep network training because it modifies SGD to escape saddle points faster and, consequently, to more quickly find a second order stationary point. Our theoretical results also shed light on the related question of how to choose the ideal momentum parameter--our analysis suggests that <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="387" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FD TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c5B"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="2"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>β</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> should be large (close to 1), which comports with empirical findings. We also provide experimental findings that further validate these conclusions.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkeNfp4tPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJgEMpVFwB" data-number="409">
      <h4>
        <a href="/forum?id=HJgEMpVFwB">
            Adversarial Policies: Attacking Deep Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=HJgEMpVFwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=gleave%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gleave@berkeley.edu">Adam Gleave</a>, <a href="/profile?email=michael_dennis%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael_dennis@berkeley.edu">Michael Dennis</a>, <a href="/profile?email=codywild%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="codywild@berkeley.edu">Cody Wild</a>, <a href="/profile?email=kantneel%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kantneel@berkeley.edu">Neel Kant</a>, <a href="/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>, <a href="/profile?email=russell%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="russell@cs.berkeley.edu">Stuart Russell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#HJgEMpVFwB-details-444" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJgEMpVFwB-details-444"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep RL, adversarial examples, security, multi-agent</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Deep RL policies can be attacked by other agents taking actions so as to create natural observations that are adversarial.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep reinforcement learning (RL) policies are known to be vulnerable to adversarial perturbations to their observations, similar to adversarial examples for classifiers. However, an attacker is not usually able to directly modify another agent's observations. This might lead one to wonder: is it possible to attack an RL agent simply by choosing an adversarial policy acting in a multi-agent environment so as to create natural observations that are adversarial? We demonstrate the existence of adversarial policies in zero-sum games between simulated humanoid robots with proprioceptive observations, against state-of-the-art victims trained via self-play to be robust to opponents. The adversarial policies reliably win against the victims but generate seemingly random and uncoordinated behavior. We find that these policies are more successful in high-dimensional environments, and induce substantially different activations in the victim policy network than when the victim plays against a normal opponent. Videos are available at https://adversarialpolicies.github.io/.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/humancompatibleai/adversarial-policies</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJgEMpVFwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJgUfTEYvH" data-number="413">
      <h4>
        <a href="/forum?id=rJgUfTEYvH">
            VideoFlow: A Conditional Flow-Based Model for Stochastic Video Generation
        </a>
      
        
          <a href="/pdf?id=rJgUfTEYvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=manojkumarsivaraj334%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="manojkumarsivaraj334@gmail.com">Manoj Kumar</a>, <a href="/profile?email=mb2%40uiuc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mb2@uiuc.edu">Mohammad Babaeizadeh</a>, <a href="/profile?email=dumitru%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dumitru@google.com">Dumitru Erhan</a>, <a href="/profile?email=cbfinn%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cbfinn@eecs.berkeley.edu">Chelsea Finn</a>, <a href="/profile?email=slevine%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="slevine@google.com">Sergey Levine</a>, <a href="/profile?email=laurentdinh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="laurentdinh@google.com">Laurent Dinh</a>, <a href="/profile?email=d.p.kingma%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="d.p.kingma@uva.nl">Durk Kingma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#rJgUfTEYvH-details-917" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJgUfTEYvH-details-917"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Video generation, flow-based generative models, stochastic video prediction</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We demonstrate that flow-based generative models offer a viable and competitive approach to generative modeling of video.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Generative models that can model and predict sequences of future events can, in principle, learn to capture complex real-world phenomena, such as physical interactions. However, a central challenge in video prediction is that the future is highly uncertain: a sequence of past observations of events can imply many possible futures. Although a number of recent works have studied probabilistic models that can represent uncertain futures, such models are either extremely expensive computationally as in the case of pixel-level autoregressive models, or do not directly optimize the likelihood of the data. To our knowledge, our work is the first to propose multi-frame video prediction with normalizing flows, which allows for direct optimization of the data likelihood, and produces high-quality stochastic predictions. We describe an approach for modeling the latent space dynamics, and demonstrate that flow-based generative models offer a viable and competitive approach to generative modeling of video.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://storage.googleapis.com/iclr_code/videoflow_code.zip</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJgUfTEYvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkxpMTEtPB" data-number="430">
      <h4>
        <a href="/forum?id=BkxpMTEtPB">
            GLAD: Learning Sparse Graph Recovery
        </a>
      
        
          <a href="/pdf?id=BkxpMTEtPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=hshrivastava3%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hshrivastava3@gatech.edu">Harsh Shrivastava</a>, <a href="/profile?email=xinshi.chen%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xinshi.chen@gatech.edu">Xinshi Chen</a>, <a href="/profile?email=binghong%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="binghong@gatech.edu">Binghong Chen</a>, <a href="/profile?email=george.lan%40isye.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="george.lan@isye.gatech.edu">Guanghui Lan</a>, <a href="/profile?email=aluru%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aluru@cc.gatech.edu">Srinivas Aluru</a>, <a href="/profile?email=hanliu%40northwestern.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanliu@northwestern.edu">Han Liu</a>, <a href="/profile?email=lsong%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lsong@cc.gatech.edu">Le Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#BkxpMTEtPB-details-661" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkxpMTEtPB-details-661"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Meta learning, automated algorithm design, learning structure recovery, Gaussian graphical models</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A data-driven learning algorithm based on unrolling the Alternating Minimization optimization for sparse graph recovery.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recovering sparse conditional independence graphs from data is a fundamental problem in machine learning with wide applications. A popular formulation of the problem is an <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="388" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mn>1</mn></msub></math></mjx-assistive-mml></mjx-container> regularized maximum likelihood estimation. Many convex optimization algorithms have been designed to solve this formulation to recover the graph structure. Recently, there is a surge of interest to learn algorithms directly based on data, and in this case, learn to map empirical covariance to the sparse precision matrix. However, it is a challenging task in this case, since the symmetric positive definiteness (SPD) and sparsity of the matrix are not easy to enforce in learned algorithms, and a direct mapping from data to precision matrix may contain many parameters. We propose a deep learning architecture, GLAD, which uses an Alternating Minimization (AM) algorithm as our model inductive bias, and learns the model parameters via supervised learning. We show that GLAD learns a very compact and effective model for recovering sparse graphs from data.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/Harshs27/GLAD</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BkxpMTEtPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJeg7TEYwB" data-number="436">
      <h4>
        <a href="/forum?id=rJeg7TEYwB">
            Pruned Graph Scattering Transforms
        </a>
      
        
          <a href="/pdf?id=rJeg7TEYwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ioann006%40umn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ioann006@umn.edu">Vassilis N. Ioannidis</a>, <a href="/profile?email=schen%40merl.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="schen@merl.com">Siheng Chen</a>, <a href="/profile?email=georgios%40umn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="georgios@umn.edu">Georgios B. Giannakis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#rJeg7TEYwB-details-313" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJeg7TEYwB-details-313"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Graph convolutional networks (GCNs) have achieved remarkable performance in a variety of network science learning tasks. However, theoretical analysis of such approaches is still at its infancy. Graph scattering transforms (GSTs) are non-trainable deep GCN models that are amenable to generalization and stability analyses. The present work addresses some limitations of GSTs by introducing a novel so-termed pruned (p)GST approach. The resultant pruning algorithm is guided by a graph-spectrum-inspired criterion, and retains informative scattering features on-the-fly while bypassing the exponential complexity associated with GSTs. It is further established that pGSTs are stable to perturbations of the input graph signals with bounded energy. Experiments showcase that i) pGST performs comparably to the baseline GST that uses all scattering features, while achieving significant computational savings; ii) pGST achieves comparable performance to state-of-the-art GCNs; and iii) Graph data from various domains lead to different scattering patterns, suggesting domain-adaptive pGST network architectures.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Graph scattering transforms, pruning, graph convolutional networks, stability, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJeg7TEYwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJlzm64tDH" data-number="440">
      <h4>
        <a href="/forum?id=BJlzm64tDH">
            Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model
        </a>
      
        
          <a href="/pdf?id=BJlzm64tDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xwhan%40cs.ucsb.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xwhan@cs.ucsb.edu">Wenhan Xiong</a>, <a href="/profile?email=jingfeidu%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jingfeidu@fb.com">Jingfei Du</a>, <a href="/profile?email=william%40cs.ucsb.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="william@cs.ucsb.edu">William Yang Wang</a>, <a href="/profile?email=ves%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ves@fb.com">Veselin Stoyanov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#BJlzm64tDH-details-404" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJlzm64tDH-details-404"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value "> Recent breakthroughs of pretrained language models have shown the effectiveness of self-supervised learning for a wide range of natural language processing (NLP) tasks. In addition to standard syntactic and semantic NLP tasks, pretrained models achieve strong improvements on tasks that involve real-world knowledge, suggesting that large-scale language modeling could be an implicit method to capture knowledge. In this work, we further investigate the extent to which pretrained models such as BERT capture knowledge using a zero-shot fact completion task. Moreover, we propose a simple yet effective weakly supervised pretraining objective, which explicitly forces the model to incorporate knowledge about real-world entities. Models trained with our new objective yield significant improvements on the fact completion task. When applied to downstream tasks, our model consistently outperforms BERT on four entity-related question answering datasets (i.e., WebQuestions, TriviaQA, SearchQA and Quasar-T) with an average 2.7 F1 improvements and a standard fine-grained entity typing dataset (i.e., FIGER) with 5.7 accuracy gains.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJlzm64tDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rklB76EKPr" data-number="447">
      <h4>
        <a href="/forum?id=rklB76EKPr">
            Can gradient clipping mitigate label noise?
        </a>
      
        
          <a href="/pdf?id=rklB76EKPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=adityakmenon%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adityakmenon@google.com">Aditya Krishna Menon</a>, <a href="/profile?email=ankitsrawat%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ankitsrawat@google.com">Ankit Singh Rawat</a>, <a href="/profile?email=sashank%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sashank@google.com">Sashank J. Reddi</a>, <a href="/profile?email=sanjivk%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanjivk@google.com">Sanjiv Kumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rklB76EKPr-details-236" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rklB76EKPr-details-236"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Gradient clipping doesn't endow robustness to label noise, but a simple loss-based variant does.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Gradient clipping is a widely-used technique in the training of deep networks, and is generally motivated from an optimisation lens: informally, it controls the dynamics of iterates, thus enhancing the rate of convergence to a local minimum. This intuition has been made precise in a line of recent works, which show that suitable clipping  can yield significantly faster convergence than vanilla gradient descent. In this paper, we propose a new lens for studying gradient clipping, namely, robustness: informally, one expects clipping to provide robustness to noise, since one does not overly trust any single sample. Surprisingly, we prove that  for the common problem of label noise in classification, standard gradient clipping does not in general provide robustness. On the other hand, we show that  a simple variant of gradient clipping is provably robust, and corresponds to suitably modifying the underlying loss function. This yields a simple, noise-robust alternative to the standard cross-entropy loss which performs well empirically.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rklB76EKPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJedXaEtvS" data-number="455">
      <h4>
        <a href="/forum?id=HJedXaEtvS">
            Editable Neural Networks
        </a>
      
        
          <a href="/pdf?id=HJedXaEtvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ant.sinitsin%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ant.sinitsin@gmail.com">Anton Sinitsin</a>, <a href="/profile?email=vsevolod-pl%40yandex.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="vsevolod-pl@yandex.ru">Vsevolod Plokhotnyuk</a>, <a href="/profile?email=alagaster%40yandex.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="alagaster@yandex.ru">Dmitry Pyrkin</a>, <a href="/profile?email=sapopov%40yandex-team.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="sapopov@yandex-team.ru">Sergei Popov</a>, <a href="/profile?email=artem.babenko%40phystech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="artem.babenko@phystech.edu">Artem Babenko</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#HJedXaEtvS-details-141" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJedXaEtvS-details-141"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">editing, editable, meta-learning, maml</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Training neural networks so you can efficiently patch them later.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">These days deep neural networks are ubiquitously used in a wide range of tasks, from image classification and machine translation to face identification and self-driving cars. In many applications, a single model error can lead to devastating financial, reputational and even life-threatening consequences. Therefore, it is crucially important to correct model mistakes quickly as they appear. In this work, we investigate the problem of neural network editing - how one can efficiently patch a mistake of the model on a particular sample, without influencing the model behavior on other samples. Namely, we propose Editable Training, a model-agnostic training technique that encourages fast editing of the trained model. We empirically demonstrate the effectiveness of this method on large-scale image classification and machine translation tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/editable-ICLR2020/editable</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJedXaEtvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJetQpEYvB" data-number="458">
      <h4>
        <a href="/forum?id=SJetQpEYvB">
            LEARNING EXECUTION THROUGH NEURAL CODE FUSION
        </a>
      
        
          <a href="/pdf?id=SJetQpEYvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zshi17%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zshi17@cs.utexas.edu">Zhan Shi</a>, <a href="/profile?email=kswersky%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kswersky@google.com">Kevin Swersky</a>, <a href="/profile?email=dtarlow%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dtarlow@google.com">Daniel Tarlow</a>, <a href="/profile?email=parthas%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="parthas@google.com">Parthasarathy Ranganathan</a>, <a href="/profile?email=miladh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="miladh@google.com">Milad Hashemi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SJetQpEYvB-details-891" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJetQpEYvB-details-891"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">code understanding, graph neural networks, learning program execution, execution traces, program performance</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">As the performance of computer systems stagnates due to the end of Moore’s Law,
      there is a need for new models that can understand and optimize the execution
      of general purpose code. While there is a growing body of work on using Graph
      Neural Networks (GNNs) to learn static representations of source code, these
      representations do not understand how code executes at runtime. In this work, we
      propose a new approach using GNNs to learn fused representations of general
      source code and its execution. Our approach defines a multi-task GNN over
      low-level representations of source code and program state (i.e., assembly code
      and dynamic memory states), converting complex source code constructs and data
      structures into a simpler, more uniform format. We show that this leads to improved
      performance over similar methods that do not use execution and it opens the door
      to applying GNN models to new tasks that would not be feasible from static code
      alone. As an illustration of this, we apply the new model to challenging dynamic
      tasks (branch prediction and prefetching) from the SPEC CPU benchmark suite,
      outperforming the state-of-the-art by 26% and 45% respectively. Moreover, we
      use the learned fused graph embeddings to demonstrate transfer learning with high
      performance on an indirectly related algorithm classification task.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://www.dropbox.com/s/yrjhx8ifowdktwh/ncf_code.zip?dl=0</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJetQpEYvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJgqQ6NYvB" data-number="459">
      <h4>
        <a href="/forum?id=BJgqQ6NYvB">
            FasterSeg: Searching for Faster Real-time Semantic Segmentation
        </a>
      
        
          <a href="/pdf?id=BJgqQ6NYvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wuyang.chen%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wuyang.chen@tamu.edu">Wuyang Chen</a>, <a href="/profile?email=xy_gong%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xy_gong@tamu.edu">Xinyu Gong</a>, <a href="/profile?email=xianming.liu%40horizon.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="xianming.liu@horizon.ai">Xianming Liu</a>, <a href="/profile?email=qian01.zhang%40horizon.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="qian01.zhang@horizon.ai">Qian Zhang</a>, <a href="/profile?email=yuan.li%40horizon.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuan.li@horizon.ai">Yuan Li</a>, <a href="/profile?email=atlaswang%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="atlaswang@tamu.edu">Zhangyang Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#BJgqQ6NYvB-details-630" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJgqQ6NYvB-details-630"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">neural architecture search, real-time, segmentation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present a real-time segmentation model automatically discovered by a multi-scale NAS framework, achieving 30% faster than state-of-the-art models.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present FasterSeg, an automatically designed semantic segmentation network with not only state-of-the-art performance but also faster speed than current methods. Utilizing neural architecture search (NAS), FasterSeg is discovered from a novel and broader search space integrating multi-resolution branches, that has been recently found to be vital in manually designed segmentation models. To better calibrate the balance between the goals of high accuracy and low latency, we propose a decoupled and fine-grained latency regularization, that effectively overcomes our observed phenomenons that the searched networks are prone to "collapsing" to low-latency yet poor-accuracy models. Moreover, we seamlessly extend FasterSeg to a new collaborative search (co-searching) framework, simultaneously searching for a teacher and a student network in the same single run. The teacher-student distillation further boosts the student model’s accuracy. Experiments on popular segmentation benchmarks demonstrate the competency of FasterSeg. For example, FasterSeg can run over 30% faster than the closest manually designed competitor on Cityscapes, while maintaining comparable accuracy.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/TAMU-VITA/FasterSeg</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJgqQ6NYvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rygjmpVFvB" data-number="461">
      <h4>
        <a href="/forum?id=rygjmpVFvB">
            Difference-Seeking Generative Adversarial Network--Unseen Sample Generation
        </a>
      
        
          <a href="/pdf?id=rygjmpVFvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=r06942076%40ntu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="r06942076@ntu.edu.tw">Yi Lin Sung</a>, <a href="/profile?email=parvaty316%40hotmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="parvaty316@hotmail.com">Sung-Hsien Hsieh</a>, <a href="/profile?email=peisc%40ntu.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="peisc@ntu.edu.tw">Soo-Chang Pei</a>, <a href="/profile?email=lcs%40iis.sinica.edu.tw" class="profile-link" data-toggle="tooltip" data-placement="top" title="lcs@iis.sinica.edu.tw">Chun-Shien Lu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#rygjmpVFvB-details-44" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rygjmpVFvB-details-44"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">generative adversarial network, semi-supervised learning, novelty detection</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We proposed a novel GAN framework to generate unseen data.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">
      Unseen data, which are not samples from the distribution of training data and are difficult to collect, have exhibited importance in numerous applications, ({\em e.g.,} novelty detection, semi-supervised learning, and adversarial training).  In this paper, we introduce a general framework called  \textbf{d}ifference-\textbf{s}eeking \textbf{g}enerative \textbf{a}dversarial \textbf{n}etwork (DSGAN), to generate various types of unseen data. Its novelty is the consideration of the probability density of the unseen data distribution as the difference between two distributions <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="389" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.283em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.06em; padding-left: 0.177em; margin-bottom: -0.544em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-cAF"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>p</mi><mrow><mrow><mover><mi>d</mi><mo stretchy="false">¯</mo></mover></mrow></mrow></msub></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="390" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>p</mi><mrow><mi>d</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> whose samples are relatively easy to collect.
      
      The DSGAN can learn the target distribution, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="391" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>p</mi><mrow><mi>t</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>, (or the unseen data distribution)  from only the samples from the two distributions, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="392" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>p</mi><mrow><mi>d</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="393" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.283em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.06em; padding-left: 0.177em; margin-bottom: -0.544em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-cAF"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>p</mi><mrow><mrow><mover><mi>d</mi><mo stretchy="false">¯</mo></mover></mrow></mrow></msub></math></mjx-assistive-mml></mjx-container>. In our scenario, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="394" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>p</mi><mi>d</mi></msub></math></mjx-assistive-mml></mjx-container> is the distribution of the seen data, and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="395" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.283em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.06em; padding-left: 0.177em; margin-bottom: -0.544em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-cAF"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>p</mi><mrow><mrow><mover><mi>d</mi><mo stretchy="false">¯</mo></mover></mrow></mrow></msub></math></mjx-assistive-mml></mjx-container> can be obtained from <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="396" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>p</mi><mrow><mi>d</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> via simple operations, so that  we only need the samples of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="397" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>p</mi><mrow><mi>d</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> during the training. 
      Two key applications, semi-supervised learning and novelty detection, are taken as case studies to illustrate that the DSGAN enables the production of various unseen data. We also provide theoretical analyses about the convergence of the DSGAN.
      
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/open?id=18aQzyPbTT7_4fdkFjxL2MLjxMLK_hCuH</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rygjmpVFvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJepXaVYDr" data-number="466">
      <h4>
        <a href="/forum?id=HJepXaVYDr">
            Stochastic AUC Maximization with Deep Neural Networks
        </a>
      
        
          <a href="/pdf?id=HJepXaVYDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mingrui-liu%40uiowa.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mingrui-liu@uiowa.edu">Mingrui Liu</a>, <a href="/profile?email=zhuoning-yuan%40uiowa.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhuoning-yuan@uiowa.edu">Zhuoning Yuan</a>, <a href="/profile?email=yying%40albany.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yying@albany.edu">Yiming Ying</a>, <a href="/profile?email=tianbao-yang%40uiowa.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianbao-yang@uiowa.edu">Tianbao Yang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 30 Jun 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HJepXaVYDr-details-454" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJepXaVYDr-details-454"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Stochastic AUC Maximization, Deep Neural Networks</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">The paper designs two algorithms for the stochastic AUC maximization problem with state-of-the-art complexities when using deep neural network as predictive model, which are also verified by empirical studies.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Stochastic AUC maximization has garnered an increasing interest due to better fit to imbalanced data classification. However, existing works are limited to stochastic AUC maximization with a linear predictive model, which restricts its predictive power when dealing with extremely complex data. In this paper, we consider stochastic AUC maximization problem with a deep neural network as the predictive model. Building on the saddle point reformulation of a surrogated loss of AUC, the problem can be cast into a {\it non-convex concave} min-max problem. The main contribution made in this paper is to make stochastic AUC maximization more practical for deep neural networks and big data with theoretical insights as well. In particular, we propose to explore Polyak-\L{}ojasiewicz (PL) condition that has been proved and observed in deep learning, which enables us to develop new stochastic algorithms with even faster convergence rate and more practical step size scheme. An AdaGrad-style algorithm is also analyzed under the PL condition with adaptive convergence rate. Our experimental results demonstrate the effectiveness of the proposed algorithms.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/drive/folders/1nPM6fmvN5fTsSaWsOcGFbhMVW7Fxso-Y</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJepXaVYDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByxT7TNFvH" data-number="467">
      <h4>
        <a href="/forum?id=ByxT7TNFvH">
            Semantically-Guided Representation Learning for Self-Supervised Monocular Depth
        </a>
      
        
          <a href="/pdf?id=ByxT7TNFvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=vitor.guizilini%40tri.global" class="profile-link" data-toggle="tooltip" data-placement="top" title="vitor.guizilini@tri.global">Vitor Guizilini</a>, <a href="/profile?email=rayhou%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rayhou@umich.edu">Rui Hou</a>, <a href="/profile?email=jie.li%40tri.global" class="profile-link" data-toggle="tooltip" data-placement="top" title="jie.li@tri.global">Jie Li</a>, <a href="/profile?email=rares.ambrus%40tri.global" class="profile-link" data-toggle="tooltip" data-placement="top" title="rares.ambrus@tri.global">Rares Ambrus</a>, <a href="/profile?email=adrien.gaidon%40tri.global" class="profile-link" data-toggle="tooltip" data-placement="top" title="adrien.gaidon@tri.global">Adrien Gaidon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#ByxT7TNFvH-details-877" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByxT7TNFvH-details-877"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">computer vision, machine learning, deep learning, monocular depth estimation, self-supervised learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a novel semantically-guided architecture for self-supervised monocular depth estimation</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Self-supervised learning is showing great promise for monocular depth estimation, using geometry as the only source of supervision. Depth networks are indeed capable of learning representations that relate visual appearance to 3D properties by implicitly leveraging category-level patterns. In this work we investigate how to leverage more directly this semantic structure to guide geometric representation learning, while remaining in the self-supervised regime. Instead of using semantic labels and proxy losses in a multi-task approach, we propose a new architecture leveraging fixed pretrained semantic segmentation networks to guide self-supervised representation learning via pixel-adaptive convolutions. Furthermore, we propose a two-stage training process to overcome a common semantic bias on dynamic objects via resampling. Our method improves upon the state of the art for self-supervised monocular depth prediction over all pixels, fine-grained details, and per semantic categories.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/tri-ml/packnet-sfm</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByxT7TNFvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJx1Na4Fwr" data-number="470">
      <h4>
        <a href="/forum?id=rJx1Na4Fwr">
            MACER: Attack-free and Scalable Robust Training via Maximizing Certified Radius
        </a>
      
        
          <a href="/pdf?id=rJx1Na4Fwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zhairuntian%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhairuntian@pku.edu.cn">Runtian Zhai</a>, <a href="/profile?email=cdan%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cdan@cs.cmu.edu">Chen Dan</a>, <a href="/profile?email=dihe%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dihe@microsoft.com">Di He</a>, <a href="/profile?email=huan%40huan-zhang.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="huan@huan-zhang.com">Huan Zhang</a>, <a href="/profile?email=boqinggo%40outlook.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="boqinggo@outlook.com">Boqing Gong</a>, <a href="/profile?email=pradeepr%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pradeepr@cs.cmu.edu">Pradeep Ravikumar</a>, <a href="/profile?email=chohsieh%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chohsieh@cs.ucla.edu">Cho-Jui Hsieh</a>, <a href="/profile?email=wanglw%40cis.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanglw@cis.pku.edu.cn">Liwei Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rJx1Na4Fwr-details-742" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJx1Na4Fwr-details-742"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Adversarial Robustness, Provable Adversarial Defense, Randomized Smoothing, Robustness Certification</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose MACER: a provable defense algorithm that trains robust models by maximizing the certified radius. It does not use adversarial training but performs better than all existing provable l2-defenses.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Adversarial training is one of the most popular ways to learn robust models but is usually attack-dependent and time costly. In this paper, we propose the MACER algorithm, which learns robust models without using adversarial training but performs better than all existing provable l2-defenses. Recent work shows that randomized smoothing can be used to provide a certified l2 radius to smoothed classifiers, and our algorithm trains provably robust smoothed classifiers via MAximizing the CErtified Radius (MACER). The attack-free characteristic makes MACER faster to train and easier to optimize. In our experiments, we show that our method can be applied to modern deep neural networks on a wide range of datasets, including Cifar-10, ImageNet, MNIST, and SVHN. For all tasks, MACER spends less training time than state-of-the-art adversarial training algorithms, and the learned models achieve larger average certified radius.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/RuntianZ/macer</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJx1Na4Fwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skgy464Kvr" data-number="471">
      <h4>
        <a href="/forum?id=Skgy464Kvr">
            Detecting and Diagnosing Adversarial Images with Class-Conditional Capsule Reconstructions
        </a>
      
        
          <a href="/pdf?id=Skgy464Kvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yaq007%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaq007@eng.ucsd.edu">Yao Qin</a>, <a href="/profile?email=frosst%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="frosst@google.com">Nicholas Frosst</a>, <a href="/profile?email=sasabour%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sasabour@google.com">Sara Sabour</a>, <a href="/profile?email=craffel%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="craffel@google.com">Colin Raffel</a>, <a href="/profile?email=gary%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gary@eng.ucsd.edu">Garrison Cottrell</a>, <a href="/profile?email=geoffhinton%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="geoffhinton@google.com">Geoffrey Hinton</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#Skgy464Kvr-details-22" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skgy464Kvr-details-22"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Adversarial Examples, Detection of adversarial attacks</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Adversarial examples raise questions about whether neural network models are sensitive to the same visual features as humans. In this paper, we first detect adversarial examples or otherwise corrupted images based on a class-conditional reconstruction of the input. To specifically attack our detection mechanism, we propose the Reconstructive Attack which seeks both to cause a misclassification and a low reconstruction error. This reconstructive attack produces undetected adversarial examples but with much smaller success rate. Among all these attacks, we find that CapsNets always perform better than convolutional networks. Then, we diagnose the adversarial examples for CapsNets and find that the success of the reconstructive attack is highly related to the visual similarity between the source and target class. Additionally, the resulting perturbations can cause the input image to appear visually more like the target class and hence become non-adversarial. This suggests that CapsNets use features that are more aligned with human perception and have the potential to address the central issue raised by adversarial examples.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Skgy464Kvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJeQEp4YDH" data-number="480">
      <h4>
        <a href="/forum?id=SJeQEp4YDH">
            GAT: Generative Adversarial Training for Adversarial Example Detection and Robust Classification
        </a>
      
        
          <a href="/pdf?id=SJeQEp4YDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xy4cm%40virginia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xy4cm@virginia.edu">Xuwang Yin</a>, <a href="/profile?email=skolouri%40hrl.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="skolouri@hrl.com">Soheil Kolouri</a>, <a href="/profile?email=gustavo%40virginia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gustavo@virginia.edu">Gustavo K Rohde</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 09 May 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#SJeQEp4YDH-details-836" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJeQEp4YDH-details-836"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose an objective that could be used for training adversarial example detection and robust classification systems.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The vulnerabilities of deep neural networks against adversarial examples have become a significant concern for deploying these models in sensitive domains. Devising a definitive defense against such attacks is proven to be challenging, and the methods relying on detecting adversarial samples are only valid when the attacker is oblivious to the detection mechanism. In this paper we present an adversarial example detection method that provides performance guarantee to norm constrained adversaries. The method is based on the idea of training adversarial robust subspace detectors using generative adversarial training (GAT). The novel GAT objective presents a saddle point problem similar to that of GANs; it has the same convergence property, and consequently supports the learning of class conditional distributions. We demonstrate that the saddle point problem could be reasonably solved by PGD attack, and further use the learned class conditional generative models to define generative detection/classification models that are both robust and more interpretable. We provide comprehensive evaluations of the above methods, and demonstrate their competitive performances and compelling properties on adversarial detection and robust classification problems.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial example detection, adversarial examples classification, robust optimization, ML security, generative modeling, generative classification</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/xuwangyin/GAT-Generative-Adversarial-Training</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJeQEp4YDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1lL4a4tDB" data-number="486">
      <h4>
        <a href="/forum?id=r1lL4a4tDB">
            Variational Recurrent Models for Solving Partially Observable Control Tasks
        </a>
      
        
          <a href="/pdf?id=r1lL4a4tDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=dongqi.han%40oist.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="dongqi.han@oist.jp">Dongqi Han</a>, <a href="/profile?email=doya%40oist.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="doya@oist.jp">Kenji Doya</a>, <a href="/profile?email=jun.tani%40oist.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="jun.tani@oist.jp">Jun Tani</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#r1lL4a4tDB-details-185" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1lL4a4tDB-details-185"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A deep RL algorithm for solving POMDPs by auto-encoding the underlying states using a variational recurrent model</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In partially observable (PO) environments, deep reinforcement learning (RL) agents often suffer from unsatisfactory performance, since two problems need to be tackled together: how to extract information from the raw observations to solve the task, and how to improve the policy. In this study, we propose an RL algorithm for solving PO tasks. Our method comprises two parts: a variational recurrent model (VRM) for modeling the environment, and an RL controller that has access to both the environment and the VRM. The proposed algorithm was tested in two types of PO robotic control tasks, those in which either coordinates or velocities were not observable and those that require long-term memorization. Our experiments show that the proposed algorithm achieved better data efficiency and/or learned more optimal policy than other alternative approaches in tasks in which unobserved states cannot be inferred from raw observations in a simple manner.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/oist-cnru/Variational-Recurrent-Models</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement Learning, Deep Learning, Variational Inference, Recurrent Neural Network, Partially Observable, Robotic Control, Continuous Control</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1lL4a4tDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJeINp4KwH" data-number="488">
      <h4>
        <a href="/forum?id=rJeINp4KwH">
            Population-Guided Parallel Policy Search for Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=rJeINp4KwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wy.jung%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="wy.jung@kaist.ac.kr">Whiyoung Jung</a>, <a href="/profile?email=gs.park%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="gs.park@kaist.ac.kr">Giseung Park</a>, <a href="/profile?email=ycsung%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="ycsung@kaist.ac.kr">Youngchul Sung</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rJeINp4KwH-details-295" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJeINp4KwH-details-295"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement Learning, Parallel Learning, Population Based Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In this paper, a new population-guided parallel learning scheme is proposed to enhance the performance of off-policy reinforcement learning (RL). In the proposed scheme, multiple identical learners with their own value-functions and policies share a common experience replay buffer, and search a good policy in collaboration with the guidance of the best policy information. The key point is that the information of the best policy  is fused in a soft manner by constructing an augmented loss function for policy update to enlarge the overall search region by the multiple learners. The guidance by the previous best policy and the enlarged  range enable faster and better policy search, and monotone improvement of the expected cumulative return by the proposed scheme is proved theoretically. Working algorithms are constructed by applying the proposed scheme to the twin delayed deep deterministic (TD3) policy gradient algorithm, and numerical results show that the constructed P3S-TD3 outperforms most of the current state-of-the-art RL algorithms, and the gain is significant in the case of sparse reward environment.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJeINp4KwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkePNpVKPB" data-number="489">
      <h4>
        <a href="/forum?id=HkePNpVKPB">
            Compositional languages emerge in a neural iterated learning model
        </a>
      
        
          <a href="/pdf?id=HkePNpVKPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=y.ren-18%40sms.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="y.ren-18@sms.ed.ac.uk">Yi Ren</a>, <a href="/profile?email=s.guo-16%40sms.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="s.guo-16@sms.ed.ac.uk">Shangmin Guo</a>, <a href="/profile?email=matthieu.labeau%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthieu.labeau@gmail.com">Matthieu Labeau</a>, <a href="/profile?email=scohen%40inf.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="scohen@inf.ed.ac.uk">Shay B. Cohen</a>, <a href="/profile?email=simon.kirby%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="simon.kirby@ed.ac.uk">Simon Kirby</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="#HkePNpVKPB-details-812" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkePNpVKPB-details-812"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Compositionality, Multi-agent, Emergent language, Iterated learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Use iterated learning framework to facilitate the dominance of high compositional language in multi-agent games.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The principle of compositionality, which enables natural language to represent complex concepts via a structured combination of simpler ones, allows us to convey an open-ended set of messages using a limited vocabulary. If compositionality is indeed a natural property of language, we may expect it to appear in communication protocols that are created by neural agents via grounded language learning. Inspired by the iterated learning framework, which simulates the process of language evolution, we propose an effective neural iterated learning algorithm that, when applied to interacting neural agents, facilitates the emergence of a more structured type of language. Indeed, these languages provide specific advantages to neural agents during training, which translates as a larger posterior probability, which is then incrementally amplified via the iterated learning procedure. Our experiments confirm our analysis, and also demonstrate that the emerged languages largely improve the generalization of the neural agent communication.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/Joshua-Ren/Neural_Iterated_Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkePNpVKPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJxhNTNYwB" data-number="501">
      <h4>
        <a href="/forum?id=SJxhNTNYwB">
            Black-Box Adversarial Attack with Transferable Model-based Embedding
        </a>
      
        
          <a href="/pdf?id=SJxhNTNYwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zhuangbx%40connect.ust.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhuangbx@connect.ust.hk">Zhichao Huang</a>, <a href="/profile?email=tongzhang%40tongzhang-ml.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="tongzhang@tongzhang-ml.org">Tong Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SJxhNTNYwB-details-602" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJxhNTNYwB-details-602"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present a new method that combines transfer-based and scored black-box adversarial attack, improving the success rate and query efficiency of black-box adversarial attack across different network architectures.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present a new method for black-box adversarial attack. Unlike previous methods that combined transfer-based and scored-based methods by using the gradient or initialization of a surrogate white-box model, this new method tries to learn a low-dimensional embedding using a pretrained model, and then performs efficient search within the embedding space to attack an unknown target network. The method produces adversarial perturbations with high level semantic patterns that are easily transferable. We show that this approach can greatly improve the query efficiency of black-box adversarial attack across different target network architectures. We evaluate our approach on MNIST, ImageNet and Google Cloud Vision API, resulting in a significant reduction on the number of queries. We also attack adversarially defended networks on CIFAR10 and ImageNet, where our method not only reduces the number of queries, but also improves the attack success rate.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/TransEmbedBA/TREMBA</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial examples, black-box attack, embedding</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJxhNTNYwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJehNT4YPr" data-number="502">
      <h4>
        <a href="/forum?id=rJehNT4YPr">
            I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively
        </a>
      
        
          <a href="/pdf?id=rJehNT4YPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=htwang%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="htwang@tamu.edu">Haotao Wang</a>, <a href="/profile?email=wiwjp619%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wiwjp619@tamu.edu">Tianlong Chen</a>, <a href="/profile?email=atlaswang%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="atlaswang@tamu.edu">Zhangyang Wang</a>, <a href="/profile?email=kede.ma%40cityu.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="kede.ma@cityu.edu.hk">Kede Ma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#rJehNT4YPr-details-111" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJehNT4YPr-details-111"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">model comparison</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present an efficient and adaptive framework for comparing image classifiers to maximize the discrepancies between the classifiers, in place of comparing on fixed test sets.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The learning of hierarchical representations for image classification has experienced an impressive series of successes due in part to the availability of large-scale labeled data for training. On the other hand, the trained classifiers have traditionally been evaluated on small and fixed sets of test images, which are deemed to be extremely sparsely distributed in the space of all natural images. It is thus questionable whether recent performance improvements on the excessively re-used test sets generalize to real-world natural images with much richer content variations. Inspired by efficient stimulus selection for testing perceptual models in psychophysical and physiological studies, we present an alternative framework for comparing image classifiers, which we name the MAximum Discrepancy (MAD) competition. Rather than comparing image classifiers using fixed test images, we adaptively sample a small test set from an arbitrarily large corpus of unlabeled images so as to maximize the discrepancies between the classifiers, measured by the distance over WordNet hierarchy. Human labeling on the resulting model-dependent image sets reveals the relative performance of the competing classifiers, and provides useful insights on potential ways to improve them. We report the MAD competition results of eleven ImageNet classifiers while noting that the framework is readily extensible and cost-effective to add future classifiers into the competition. Codes can be found at https://github.com/TAMU-VITA/MAD.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/TAMU-VITA/MAD</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJehNT4YPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkgaETNtDB" data-number="503">
      <h4>
        <a href="/forum?id=HkgaETNtDB">
            Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models
        </a>
      
        
          <a href="/pdf?id=HkgaETNtDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=bloodwass%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="bloodwass@kaist.ac.kr">Cheolhyoung Lee</a>, <a href="/profile?email=kyunghyun.cho%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kyunghyun.cho@nyu.edu">Kyunghyun Cho</a>, <a href="/profile?email=wanmo.kang%40kaist.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanmo.kang@kaist.edu">Wanmo Kang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#HkgaETNtDB-details-161" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkgaETNtDB-details-161"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">regularization, finetuning, dropout, dropconnect, adaptive L2-penalty, BERT, pretrained language model</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In natural language processing, it has been observed recently that generalization could be greatly improved by finetuning a large-scale language model pretrained on a large unlabeled corpus. Despite its recent success and wide adoption, finetuning a large pretrained language model on a downstream task is prone to degenerate performance when there are only a small number of training instances available. In this paper, we introduce a new regularization technique, to which we refer as “mixout”, motivated by dropout. Mixout stochastically mixes the parameters of two models. We show that our mixout technique regularizes learning to minimize the deviation from one of the two models and that the strength of regularization adapts along the optimization trajectory. We empirically evaluate the proposed mixout and its variants on finetuning a pretrained language model on downstream tasks. More specifically, we demonstrate that the stability of finetuning and the average accuracy greatly increase when we use the proposed approach to regularize finetuning of BERT on downstream tasks in GLUE.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/bloodwass/mixout</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkgaETNtDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkglSTNFDB" data-number="509">
      <h4>
        <a href="/forum?id=BkglSTNFDB">
            Q-learning with UCB Exploration is Sample Efficient for Infinite-Horizon MDP
        </a>
      
        
          <a href="/pdf?id=BkglSTNFDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yuanhao-16%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuanhao-16@mails.tsinghua.edu.cn">Yuanhao Wang</a>, <a href="/profile?email=dkf16%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="dkf16@mails.tsinghua.edu.cn">Kefan Dong</a>, <a href="/profile?email=cxy30%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="cxy30@pku.edu.cn">Xiaoyu Chen</a>, <a href="/profile?email=wanglw%40cis.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanglw@cis.pku.edu.cn">Liwei Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#BkglSTNFDB-details-876" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkglSTNFDB-details-876"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">theory, reinforcement learning, sample complexity</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We adapt Q-learning with UCB-exploration bonus to infinite-horizon MDP with discounted rewards without accessing a generative model, and improves the previously best known result.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">A fundamental question in reinforcement learning is whether model-free algorithms are sample efficient. Recently,  Jin et al. (2018) proposed a Q-learning algorithm with UCB exploration policy, and proved it has nearly optimal regret bound for finite-horizon episodic MDP. In this paper, we adapt Q-learning with UCB-exploration bonus to infinite-horizon MDP with discounted rewards \emph{without} accessing a generative model. We show that the \textit{sample complexity of exploration} of our algorithm is bounded by <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="398" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.06em; padding-left: 0.215em; margin-bottom: -0.215em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7E"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.289em;"><mjx-mn class="mjx-n" style="font-size: 83.3%;"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FE TEX-I"></mjx-c></mjx-mi><mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-script style="vertical-align: 0.289em;"><mjx-mn class="mjx-n" style="font-size: 83.3%;"><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mi>O</mi><mo stretchy="false">~</mo></mover></mrow><mo stretchy="false">(</mo><mrow><mfrac><mrow><mi>S</mi><mi>A</mi></mrow><mrow><msup><mi>ϵ</mi><mn>2</mn></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>γ</mi><msup><mo stretchy="false">)</mo><mn>7</mn></msup></mrow></mfrac></mrow><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>. This improves the previously best known result of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="399" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.06em; padding-left: 0.215em; margin-bottom: -0.215em;"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7E"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.289em;"><mjx-mn class="mjx-n" style="font-size: 83.3%;"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FE TEX-I"></mjx-c></mjx-mi><mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-script style="vertical-align: 0.289em;"><mjx-mn class="mjx-n" style="font-size: 83.3%;"><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mi>O</mi><mo stretchy="false">~</mo></mover></mrow><mo stretchy="false">(</mo><mrow><mfrac><mrow><mi>S</mi><mi>A</mi></mrow><mrow><msup><mi>ϵ</mi><mn>4</mn></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>γ</mi><msup><mo stretchy="false">)</mo><mn>8</mn></msup></mrow></mfrac></mrow><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> in this setting achieved by delayed Q-learning (Strehlet al., 2006),, and matches the lower bound in terms of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="400" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ϵ</mi></math></mjx-assistive-mml></mjx-container> as well as <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="401" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>S</mi></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="402" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi></math></mjx-assistive-mml></mjx-container> up to logarithmic factors.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BkglSTNFDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJxWS64FwH" data-number="512">
      <h4>
        <a href="/forum?id=SJxWS64FwH">
            Deep Network Classification by Scattering and Homotopy Dictionary Learning
        </a>
      
        
          <a href="/pdf?id=SJxWS64FwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=john.zarka%40ens.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="john.zarka@ens.fr">John Zarka</a>, <a href="/profile?email=louis.thiry%40ens.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="louis.thiry@ens.fr">Louis Thiry</a>, <a href="/profile?email=tomas.angles%40ens.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="tomas.angles@ens.fr">Tomas Angles</a>, <a href="/profile?email=stephane.mallat%40ens.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="stephane.mallat@ens.fr">Stephane Mallat</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SJxWS64FwH-details-607" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJxWS64FwH-details-607"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A scattering transform followed by supervised dictionary learning reaches a higher accuracy than AlexNet on ImageNet.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We introduce a sparse scattering deep convolutional neural network, which provides a simple model to analyze properties of deep representation learning for classification. Learning a single dictionary matrix with a classifier yields a higher classification accuracy than AlexNet over the ImageNet 2012 dataset. The network first applies a scattering transform that linearizes variabilities due to geometric transformations such as translations and small deformations.
      A sparse <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="403" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>ℓ</mi><mn>1</mn></msup></math></mjx-assistive-mml></mjx-container> dictionary coding reduces intra-class variability while preserving class separation through projections over unions of linear spaces. It is implemented in a deep convolutional network with a homotopy algorithm having an exponential convergence. A convergence proof is given in a general framework that includes ALISTA. Classification results are analyzed on ImageNet.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">dictionary learning, scattering transform, sparse coding, imagenet</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJxWS64FwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1gmHaEKwB" data-number="517">
      <h4>
        <a href="/forum?id=H1gmHaEKwB">
            Data-Independent Neural Pruning via Coresets
        </a>
      
        
          <a href="/pdf?id=H1gmHaEKwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=bengordoncshaifa%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bengordoncshaifa@gmail.com">Ben Mussay</a>, <a href="/profile?email=rita%40cs.haifa.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="rita@cs.haifa.ac.il">Margarita Osadchy</a>, <a href="/profile?email=vova%40cs.jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vova@cs.jhu.edu">Vladimir Braverman</a>, <a href="/profile?email=samsonzhou%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="samsonzhou@gmail.com">Samson Zhou</a>, <a href="/profile?email=dannyf.post%40gmail.co" class="profile-link" data-toggle="tooltip" data-placement="top" title="dannyf.post@gmail.co">Dan Feldman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#H1gmHaEKwB-details-403" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1gmHaEKwB-details-403"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">coresets, neural pruning, network compression</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose an efficient, provable and data independent method for network compression via neural pruning using coresets of neurons -- a novel construction proposed in this paper.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Previous work showed empirically that large neural networks can be significantly reduced in size while preserving their accuracy. Model compression became a central research topic, as it is crucial for deployment of neural networks on devices with limited computational and memory resources. The majority of the compression methods are based on heuristics and offer no worst-case guarantees on the trade-off between the compression rate and the approximation error for an arbitrarily new sample.
      
      We propose the first efficient, data-independent neural pruning algorithm with a provable trade-off between its compression rate and the approximation error for any future test sample. Our method is based on the coreset framework, which finds a small weighted subset of points that provably approximates the original inputs. Specifically, we approximate the output of a layer of neurons by a coreset of neurons in the previous layer and discard the rest. We apply this framework in a layer-by-layer fashion from the top to the bottom. Unlike previous works, our coreset is data independent, meaning that it provably guarantees the accuracy of the function for any input <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="404" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c211D TEX-A"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.41em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mi>d</mi></msup></math></mjx-assistive-mml></mjx-container>, including an adversarial one. We demonstrate the effectiveness of our method on popular network architectures. In particular, our coresets yield 90% compression of the LeNet-300-100 architecture on MNIST while improving the accuracy.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/BenMussay/Data-Independent-Neural-Pruning-via-Coresets</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1gmHaEKwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkgXHTNtvS" data-number="518">
      <h4>
        <a href="/forum?id=BkgXHTNtvS">
            Bounds on Over-Parameterization for Guaranteed Existence of Descent Paths in Shallow ReLU Networks
        </a>
      
        
          <a href="/pdf?id=BkgXHTNtvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=a.sharifnassab%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.sharifnassab@gmail.com">Arsalan Sharifnassab</a>, <a href="/profile?email=saber.salehk%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="saber.salehk@gmail.com">Saber Salehkaleybar</a>, <a href="/profile?email=golestani%40sharif.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="golestani@sharif.edu">S. Jamaloddin Golestani</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="#BkgXHTNtvS-details-277" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkgXHTNtvS-details-277"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Spurious local minima, Loss landscape, Over-parameterization, Theory of deep learning, Optimization, Descent path</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study the landscape of squared loss in neural networks with one-hidden layer and ReLU activation functions.  Let <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="405" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45A TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>m</mi></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="406" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi></math></mjx-assistive-mml></mjx-container> be the widths of hidden and input layers, respectively. We show that there exist poor local minima with positive curvature for some training sets of size <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="407" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D45A TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≥</mo><mi>m</mi><mo>+</mo><mn>2</mn><mi>d</mi><mo>−</mo><mn>2</mn></math></mjx-assistive-mml></mjx-container>. By positive curvature of a local minimum, we mean that within a small neighborhood the loss function is strictly increasing in all directions. Consequently, for such training sets, there are initialization of weights from which there is no descent path to global optima. It is known that for <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="408" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2264"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D45A TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≤</mo><mi>m</mi></math></mjx-assistive-mml></mjx-container>, there always exist descent paths to global optima from all initial weights. In this perspective, our results provide a somewhat sharp characterization of the over-parameterization required for "existence of descent paths" in the loss landscape. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BkgXHTNtvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByeNra4FDB" data-number="520">
      <h4>
        <a href="/forum?id=ByeNra4FDB">
            Novelty Detection Via Blurring
        </a>
      
        
          <a href="/pdf?id=ByeNra4FDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=si_choi%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="si_choi@kaist.ac.kr">Sungik Choi</a>, <a href="/profile?email=schung%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="schung@kaist.ac.kr">Sae-Young Chung</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#ByeNra4FDB-details-938" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByeNra4FDB-details-938"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">novelty, anomaly, uncertainty</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a novel OOD detector that employ blurred images as adversarial examples . Our model achieve significant OOD detection performance in various domains.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value "> Conventional out-of-distribution (OOD) detection schemes based on variational autoencoder or Random Network Distillation (RND) are known to assign lower uncertainty to the OOD data than the target distribution. In this work, we discover that such conventional novelty detection schemes are also vulnerable to the blurred images. Based on the observation, we construct a novel RND-based OOD detector, SVD-RND, that utilizes blurred images during training. Our detector is simple, efficient in test time, and outperforms baseline OOD detectors in various domains. Further results show that SVD-RND learns a better target distribution representation than the baselines. Finally, SVD-RND combined with geometric transform achieves near-perfect detection accuracy in CelebA domain.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByeNra4FDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1x6BTEKwr" data-number="540">
      <h4>
        <a href="/forum?id=B1x6BTEKwr">
            Piecewise linear activations substantially shape the loss surfaces of neural networks
        </a>
      
        
          <a href="/pdf?id=B1x6BTEKwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=fengxiang.he%40sydney.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="fengxiang.he@sydney.edu.au">Fengxiang He</a>, <a href="/profile?email=bhwangfy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bhwangfy@gmail.com">Bohan Wang</a>, <a href="/profile?email=dacheng.tao%40sydney.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="dacheng.tao@sydney.edu.au">Dacheng Tao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 27 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>24 Replies</span>
        
        
      </div>
      
        <a href="#B1x6BTEKwr-details-680" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1x6BTEKwr-details-680"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper presents how the loss surfaces of nonlinear neural networks are substantially shaped by the nonlinearities in activations.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Understanding the loss surface of a neural network is fundamentally important to the understanding of deep learning. This paper presents how piecewise linear activation functions substantially shape the loss surfaces of neural networks. We first prove that {\it the loss surfaces of many neural networks have infinite spurious local minima} which are defined as the local minima with higher empirical risks than the global minima. Our result demonstrates that the networks with piecewise linear activations possess substantial differences to the well-studied linear neural networks. This result holds for any neural network with arbitrary depth and arbitrary piecewise linear activation functions (excluding linear functions) under most loss functions in practice. Essentially, the underlying assumptions are consistent with most practical circumstances where the output layer is narrower than any hidden layer. In addition, the loss surface of a neural network with piecewise linear activations is partitioned into multiple smooth and multilinear cells by nondifferentiable boundaries. The constructed spurious local minima are concentrated in one cell as a valley: they are connected with each other by a continuous path, on which empirical risk is invariant. Further for one-hidden-layer networks, we prove that all local minima in a cell constitute an equivalence class; they are concentrated in a valley; and they are all global minima in the cell.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">neural network, nonlinear activation, loss surface, spurious local minimum</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1x6BTEKwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1lGU64tDr" data-number="552">
      <h4>
        <a href="/forum?id=B1lGU64tDr">
            Relational State-Space Model for Stochastic Multi-Object Systems
        </a>
      
        
          <a href="/pdf?id=B1lGU64tDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=fanyang01%40zju.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="fanyang01@zju.edu.cn">Fan Yang</a>, <a href="/profile?email=lingchen%40cs.zju.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="lingchen@cs.zju.edu.cn">Ling Chen</a>, <a href="/profile?email=fanzhou%40zju.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="fanzhou@zju.edu.cn">Fan Zhou</a>, <a href="/profile?email=jianchuan.gys%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianchuan.gys@alibaba-inc.com">Yusong Gao</a>, <a href="/profile?email=mingsong.cw%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mingsong.cw@alibaba-inc.com">Wei Cao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 27 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#B1lGU64tDr-details-287" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1lGU64tDr-details-287"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">state-space model, time series, deep sequential model, graph neural network</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A deep hierarchical state-space model in which the state transitions of correlated objects are coordinated by graph neural networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Real-world dynamical systems often consist of multiple stochastic subsystems that interact with each other. Modeling and forecasting the behavior of such dynamics are generally not easy, due to the inherent hardness in understanding the complicated interactions and evolutions of their constituents. This paper introduces the relational state-space model (R-SSM), a sequential hierarchical latent variable model that makes use of graph neural networks (GNNs) to simulate the joint state transitions of multiple correlated objects. By letting GNNs cooperate with SSM, R-SSM provides a flexible way to incorporate relational information into the modeling of multi-object dynamics. We further suggest augmenting the model with normalizing flows instantiated for vertex-indexed random variables and propose two auxiliary contrastive objectives to facilitate the learning. The utility of R-SSM is empirically evaluated on synthetic and real time series datasets.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/fanyang01/relational-ssm</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1lGU64tDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJxX8T4Kvr" data-number="553">
      <h4>
        <a href="/forum?id=rJxX8T4Kvr">
            Learning Efficient Parameter Server Synchronization Policies for Distributed SGD
        </a>
      
        
          <a href="/pdf?id=rJxX8T4Kvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=red.zr%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="red.zr@alibaba-inc.com">Rong Zhu</a>, <a href="/profile?email=yangsheng%40hit.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yangsheng@hit.edu.cn">Sheng Yang</a>, <a href="/profile?email=andreaswernerrober%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="andreaswernerrober@alibaba-inc.com">Andreas Pfadler</a>, <a href="/profile?email=zhengping.qzp%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhengping.qzp@alibaba-inc.com">Zhengping Qian</a>, <a href="/profile?email=jingren.zhou%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jingren.zhou@alibaba-inc.com">Jingren Zhou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#rJxX8T4Kvr-details-633" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJxX8T4Kvr-details-633"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Distributed SGD, Paramter-Server, Synchronization Policy, Reinforcement Learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We apply a reinforcement learning based approach to learning optimal synchronization policies used for Parameter Server-based distributed training  of SGD.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We apply a reinforcement learning (RL) based approach to learning optimal synchronization policies used for Parameter Server-based distributed training of machine learning models with Stochastic Gradient Descent (SGD). Utilizing a formal synchronization policy description in the PS-setting, we are able to derive a suitable and compact description of states and actions, allowing us to efficiently use the standard off-the-shelf deep Q-learning algorithm. As a result, we are able to learn synchronization policies which generalize to different cluster environments, different training datasets and small model variations and (most importantly) lead to considerable decreases in training time when compared to standard policies such as bulk synchronous parallel (BSP), asynchronous parallel (ASP), or stale synchronous parallel (SSP). To support our claims we present extensive numerical results obtained from experiments performed in simulated cluster environments. In our experiments training time is reduced by 44 on average and learned policies generalize to multiple unseen circumstances.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJxX8T4Kvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryg48p4tPH" data-number="557">
      <h4>
        <a href="/forum?id=ryg48p4tPH">
            Action Semantics Network: Considering the Effects of Actions in Multiagent Systems
        </a>
      
        
          <a href="/pdf?id=ryg48p4tPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wxwang%40tju.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wxwang@tju.edu.cn">Weixun Wang</a>, <a href="/profile?email=tpyang%40tju.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="tpyang@tju.edu.cn">Tianpei Yang</a>, <a href="/profile?email=lucasliunju%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lucasliunju@gmail.com">Yong Liu</a>, <a href="/profile?email=jianye.hao%40tju.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianye.hao@tju.edu.cn">Jianye Hao</a>, <a href="/profile?email=xiaotianhao%40tju.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaotianhao@tju.edu.cn">Xiaotian Hao</a>, <a href="/profile?email=huyujing%40corp.netease.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="huyujing@corp.netease.com">Yujing Hu</a>, <a href="/profile?email=chenyingfeng1%40corp.netease.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenyingfeng1@corp.netease.com">Yingfeng Chen</a>, <a href="/profile?email=fanchangjie%40corp.netease.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fanchangjie@corp.netease.com">Changjie Fan</a>, <a href="/profile?email=gaoy%40nju.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="gaoy@nju.edu.cn">Yang Gao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#ryg48p4tPH-details-32" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryg48p4tPH-details-32"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">multiagent coordination, multiagent learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Our proposed ASN characterizes different actions' influence on other agents using neural networks based on the action semantics between them.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In multiagent systems (MASs), each agent makes individual decisions but all of them contribute globally to the system evolution. Learning in MASs is difficult since each agent's selection of actions must take place in the presence of other co-learning agents. Moreover, the environmental stochasticity and uncertainties increase exponentially with the increase in the number of agents. Previous works borrow various multiagent coordination mechanisms into deep learning architecture to facilitate multiagent coordination. However, none of them explicitly consider action semantics between agents that different actions have different influences on other agents. In this paper, we propose a novel network architecture, named Action Semantics Network (ASN), that explicitly represents such action semantics between agents. ASN characterizes different actions' influence on other agents using neural networks based on the action semantics between them. ASN can be easily combined with existing deep reinforcement learning (DRL) algorithms to boost their performance. Experimental results on StarCraft II micromanagement and Neural MMO show ASN significantly improves the performance of state-of-the-art DRL approaches compared with several network architectures.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/MAS-anony/ASN</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryg48p4tPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkxBUpEKwH" data-number="558">
      <h4>
        <a href="/forum?id=SkxBUpEKwH">
            Vid2Game: Controllable Characters Extracted from Real-World Videos
        </a>
      
        
          <a href="/pdf?id=SkxBUpEKwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=oran.gafni%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="oran.gafni@gmail.com">Oran Gafni</a>, <a href="/profile?email=wolf%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wolf@fb.com">Lior Wolf</a>, <a href="/profile?email=yaniv%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaniv@fb.com">Yaniv Taigman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SkxBUpEKwH-details-579" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkxBUpEKwH-details-579"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We extract a controllable model from a video of a person performing a certain activity. The model generates novel image sequences of that person, according to user-defined control signals, typically marking the displacement of the moving body. The generated video can have an arbitrary background, and effectively capture both the dynamics and appearance of the person. 
      
      The method is based on two networks. The first  maps a current pose, and a single-instance control signal to the next pose. The second maps the current pose, the new pose, and a given background, to an output frame. Both networks include multiple novelties that enable high-quality performance. This is demonstrated on multiple characters extracted from various videos of dancers and athletes.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkxBUpEKwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1l8L6EtDS" data-number="560">
      <h4>
        <a href="/forum?id=B1l8L6EtDS">
            Self-Adversarial Learning with Comparative Discrimination for Text Generation
        </a>
      
        
          <a href="/pdf?id=B1l8L6EtDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=v-waz%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="v-waz@microsoft.com">Wangchunshu Zhou</a>, <a href="/profile?email=tage%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tage@microsoft.com">Tao Ge</a>, <a href="/profile?email=kexu%40nlsde.buaa.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="kexu@nlsde.buaa.edu.cn">Ke Xu</a>, <a href="/profile?email=fuwei%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fuwei@microsoft.com">Furu Wei</a>, <a href="/profile?email=mingzhou%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mingzhou@microsoft.com">Ming Zhou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#B1l8L6EtDS-details-577" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1l8L6EtDS-details-577"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial learning, text generation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a self-adversarial learning (SAL) paradigm which improves the generator in a self-play fashion for improving GANs' performance in text generation.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Conventional Generative Adversarial Networks (GANs) for text generation tend to have issues of reward sparsity and mode collapse that affect the quality and diversity of generated samples. To address the issues, we propose a novel self-adversarial learning (SAL) paradigm for improving GANs' performance in text generation. In contrast to standard GANs that use a binary classifier as its discriminator to predict whether a sample is real or generated, SAL employs a comparative discriminator which is a pairwise classifier for comparing the text quality between a pair of samples. During training, SAL rewards the generator when its currently generated sentence is found to be better than its previously generated samples. This self-improvement reward mechanism allows the model to receive credits more easily and avoid collapsing towards the limited number of real samples, which not only helps alleviate the reward sparsity issue but also reduces the risk of mode collapse. Experiments on text generation benchmark datasets show that our proposed approach substantially improves both the quality and the diversity, and yields more stable performance compared to the previous GANs for text generation.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1l8L6EtDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxOUTVYDH" data-number="565">
      <h4>
        <a href="/forum?id=ryxOUTVYDH">
            Robust training with ensemble consensus
        </a>
      
        
          <a href="/pdf?id=ryxOUTVYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jisoolee%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jisoolee@kaist.ac.kr">Jisoo Lee</a>, <a href="/profile?email=schung%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="schung@kaist.ac.kr">Sae-Young Chung</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#ryxOUTVYDH-details-942" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxOUTVYDH-details-942"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Annotation noise, Noisy label, Robustness, Ensemble, Perturbation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This work presents a method of generating and using ensembles effectively to identify noisy examples in the presence of annotation noise. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Since deep neural networks are over-parameterized, they can memorize noisy examples. We address such memorizing issue in the presence of annotation noise. From the fact that deep neural networks cannot generalize neighborhoods of the features acquired via memorization, we hypothesize that noisy examples do not consistently incur small losses on the network under a certain perturbation. Based on this, we propose a novel training method called Learning with Ensemble Consensus (LEC) that prevents overfitting noisy examples by eliminating them using the consensus of an ensemble of perturbed networks. One of the proposed LECs, LTEC outperforms the current state-of-the-art methods on noisy MNIST, CIFAR-10, and CIFAR-100 in an efficient manner.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxOUTVYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SklOUpEYvB" data-number="566">
      <h4>
        <a href="/forum?id=SklOUpEYvB">
            Identifying through Flows for Recovering Latent Representations
        </a>
      
        
          <a href="/pdf?id=SklOUpEYvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=maths.shenli%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maths.shenli@gmail.com">Shen Li</a>, <a href="/profile?email=bhooi%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="bhooi@comp.nus.edu.sg">Bryan Hooi</a>, <a href="/profile?email=dcslgh%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="dcslgh@nus.edu.sg">Gim Hee Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="#SklOUpEYvB-details-192" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SklOUpEYvB-details-192"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Identifiability, or recovery of the true latent representations from which the observed data originates, is de facto a fundamental goal of representation learning. Yet, most deep generative models do not address the question of identifiability, and thus fail to deliver on the promise of the recovery of the true latent sources that generate the observations. Recent work proposed identifiable generative modelling using variational autoencoders (iVAE) with a theory of identifiability. Due to the intractablity of KL divergence between variational approximate posterior and the true posterior, however, iVAE has to maximize the evidence lower bound (ELBO) of the marginal likelihood, leading to suboptimal solutions in both theory and practice. In contrast, we propose an identifiable framework for estimating latent representations using a flow-based model (iFlow). Our approach directly maximizes the marginal likelihood, allowing for theoretical guarantees on identifiability, thereby dispensing with variational approximations. We derive its optimization objective in analytical form, making it possible to train iFlow in an end-to-end manner. Simulations on synthetic data validate the correctness and effectiveness of our proposed method and demonstrate its practical advantages over other existing methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Representation learning, identifiable generative models, nonlinear-ICA</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SklOUpEYvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkeWw6VFwr" data-number="585">
      <h4>
        <a href="/forum?id=BkeWw6VFwr">
            Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing
        </a>
      
        
          <a href="/pdf?id=BkeWw6VFwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jinyuan.jia%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jinyuan.jia@duke.edu">Jinyuan Jia</a>, <a href="/profile?email=xiaoyu.cao%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaoyu.cao@duke.edu">Xiaoyu Cao</a>, <a href="/profile?email=binghui.wang%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="binghui.wang@duke.edu">Binghui Wang</a>, <a href="/profile?email=neil.gong%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="neil.gong@duke.edu">Neil Zhenqiang Gong</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#BkeWw6VFwr-details-908" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkeWw6VFwr-details-908"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Certified Adversarial Robustness, Randomized Smoothing, Adversarial Examples</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">It is well-known that  classifiers are vulnerable to adversarial perturbations. To defend against adversarial perturbations, various certified robustness results have been derived. However, existing certified robustnesses are limited to top-1 predictions. In many real-world applications, top-<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="409" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container> predictions are more relevant. In this work, we aim to derive certified robustness for top-<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="410" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container> predictions. In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier. We derive a tight robustness in <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="411" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mn>2</mn></msub></math></mjx-assistive-mml></mjx-container> norm for top-<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="412" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container> predictions  when using randomized smoothing with Gaussian noise. We find that generalizing the certified robustness  from top-1 to top-<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="413" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container> predictions faces significant technical challenges. We also empirically evaluate our method on CIFAR10 and ImageNet. For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\% when the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="414" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mn>2</mn></msub></math></mjx-assistive-mml></mjx-container>-norms of the adversarial perturbations are less than 0.5 (=127/255). Our code is publicly available at: \url{https://github.com/jjy1994/Certify_Topk}. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/jjy1994/Certify_Topk</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BkeWw6VFwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1xGP6VYwH" data-number="588">
      <h4>
        <a href="/forum?id=r1xGP6VYwH">
            Optimistic Exploration even with a Pessimistic Initialisation
        </a>
      
        
          <a href="/pdf?id=r1xGP6VYwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tabish.rashid%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="tabish.rashid@cs.ox.ac.uk">Tabish Rashid</a>, <a href="/profile?email=bei.peng%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="bei.peng@cs.ox.ac.uk">Bei Peng</a>, <a href="/profile?email=wendelin.boehmer%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="wendelin.boehmer@cs.ox.ac.uk">Wendelin Boehmer</a>, <a href="/profile?email=shimon.whiteson%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="shimon.whiteson@cs.ox.ac.uk">Shimon Whiteson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#r1xGP6VYwH-details-689" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1xGP6VYwH-details-689"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement Learning, Exploration, Optimistic Initialisation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We augment the Q-value estimates with a count-based bonus that ensures optimism during action selection and bootstrapping, even if the Q-value estimates are pessimistic.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Optimistic initialisation is an effective strategy for efficient exploration in reinforcement learning (RL). In the tabular case, all provably efficient model-free algorithms rely on it. However, model-free deep RL algorithms do not use optimistic initialisation despite taking inspiration from these provably efficient tabular algorithms. In particular, in scenarios with only positive rewards, Q-values are initialised at their lowest possible values due to commonly used network initialisation schemes, a pessimistic initialisation. Merely initialising the network to output optimistic Q-values is not enough, since we cannot ensure that they remain optimistic for novel state-action pairs, which is crucial for exploration. We propose a simple count-based augmentation to pessimistically initialised Q-values that separates the source of optimism from the neural network. We show that this scheme is provably efficient in the tabular setting and extend it to the deep RL setting. Our algorithm, Optimistic Pessimistically Initialised Q-Learning (OPIQ), augments the Q-value estimates of a DQN-based agent with count-derived bonuses to ensure optimism during both action selection and bootstrapping. We show that OPIQ outperforms non-optimistic DQN variants that utilise a pseudocount-based intrinsic motivation in hard exploration tasks, and that it predicts optimistic estimates for novel state-action pairs.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1xGP6VYwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SygXPaEYvH" data-number="591">
      <h4>
        <a href="/forum?id=SygXPaEYvH">
            VL-BERT: Pre-training of Generic Visual-Linguistic Representations
        </a>
      
        
          <a href="/pdf?id=SygXPaEYvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jackroos%40mail.ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jackroos@mail.ustc.edu.cn">Weijie Su</a>, <a href="/profile?email=ezra0408%40mail.ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ezra0408@mail.ustc.edu.cn">Xizhou Zhu</a>, <a href="/profile?email=yuecao%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuecao@microsoft.com">Yue Cao</a>, <a href="/profile?email=binli%40ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="binli@ustc.edu.cn">Bin Li</a>, <a href="/profile?email=lewlu%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lewlu@microsoft.com">Lewei Lu</a>, <a href="/profile?email=fuwei%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fuwei@microsoft.com">Furu Wei</a>, <a href="/profile?email=jifdai%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jifdai@microsoft.com">Jifeng Dai</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SygXPaEYvH-details-746" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SygXPaEYvH-details-746"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Visual-Linguistic, Generic Representation, Pre-training</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">VL-BERT is a simple yet powerful pre-trainable generic representation for visual-linguistic tasks. It is pre-trained on the massive-scale caption dataset and text-only corpus, and can be finetuned for varies down-stream visual-linguistic tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We introduce a new pre-trainable generic representation for visual-linguistic tasks, called Visual-Linguistic BERT (VL-BERT for short). VL-BERT adopts the simple yet powerful Transformer model as the backbone, and extends it to take both visual and linguistic embedded features as input. In it, each element of the input is either of a word from the input sentence, or a region-of-interest (RoI) from the input image. It is designed to fit for most of the visual-linguistic downstream tasks. To better exploit the generic representation, we pre-train VL-BERT on the massive-scale Conceptual Captions dataset, together with text-only corpus. Extensive empirical analysis demonstrates that the pre-training procedure can better align the visual-linguistic clues and benefit the downstream tasks, such as visual commonsense reasoning, visual question answering and referring expression comprehension. It is worth noting that VL-BERT achieved the first place of single model on the leaderboard of the VCR benchmark.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/jackroos/VL-BERT</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SygXPaEYvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkxSv6VFvS" data-number="594">
      <h4>
        <a href="/forum?id=SkxSv6VFvS">
            Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation
        </a>
      
        
          <a href="/pdf?id=SkxSv6VFvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=hangg%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hangg@berkeley.edu">Hang Gao</a>, <a href="/profile?email=ezra0408%40mail.ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ezra0408@mail.ustc.edu.cn">Xizhou Zhu</a>, <a href="/profile?email=stevelin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="stevelin@microsoft.com">Stephen Lin</a>, <a href="/profile?email=jifdai%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jifdai@microsoft.com">Jifeng Dai</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SkxSv6VFvS-details-987" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkxSv6VFvS-details-987"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Effective Receptive Fields, Deformation Modeling, Dynamic Inference</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Don't deform your convolutions -- deform your kernels.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Convolutional networks are not aware of an object's geometric variations, which leads to inefficient utilization of model and data capacity. To overcome this issue, recent works on deformation modeling seek to spatially reconfigure the data towards a common arrangement such that semantic recognition suffers less from deformation. This is typically done by augmenting static operators with learned free-form sampling grids in the image space, dynamically tuned to the data and task for adapting the receptive field. Yet adapting the receptive field does not quite reach the actual goal -- what really matters to the network is the *effective* receptive field (ERF), which reflects how much each pixel contributes. It is thus natural to design other approaches to adapt the ERF directly during runtime. In this work, we instantiate one possible solution as Deformable Kernels (DKs), a family of novel and generic convolutional operators for handling object deformations by directly adapting the ERF while leaving the receptive field untouched. At the heart of our method is the ability to resample the original kernel space towards recovering the deformation of objects. This approach is justified with theoretical insights that the ERF is strictly determined by data sampling locations and kernel values. We implement DKs as generic drop-in replacements of rigid kernels and conduct a series of empirical studies whose results conform with our theories. Over several tasks and standard base models, our approach compares favorably against prior works that adapt during runtime. In addition, further experiments suggest a working mechanism orthogonal and complementary to previous works.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/hangg7/deformable-kernels/</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkxSv6VFvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BygSP6Vtvr" data-number="595">
      <h4>
        <a href="/forum?id=BygSP6Vtvr">
            Ensemble Distribution Distillation
        </a>
      
        
          <a href="/pdf?id=BygSP6Vtvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=am969%40yandex-team.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="am969@yandex-team.ru">Andrey Malinin</a>, <a href="/profile?email=bkm28%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="bkm28@cam.ac.uk">Bruno Mlodozeniec</a>, <a href="/profile?email=mjfg%40eng.cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="mjfg@eng.cam.ac.uk">Mark Gales</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#BygSP6Vtvr-details-802" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BygSP6Vtvr-details-802"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Ensemble Distillation, Knowledge Distillation, Uncertainty Estimation, Density Estimation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We distill an ensemble of models into a single model, capturing both the improved classification performance and information about the diversity of the ensemble, which is useful for uncertainty estimation.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Ensembles of models often yield improvements in system performance. These ensemble approaches have also been empirically shown to yield robust measures of uncertainty, and are capable of distinguishing between different forms of uncertainty. However, ensembles come at a computational and memory cost which may be prohibitive for many applications. There has been significant work done on the distillation of an ensemble into a single model. Such approaches decrease computational cost and allow a single model to achieve an accuracy comparable to that of an ensemble. However, information about the diversity of the ensemble, which can yield estimates of different forms of uncertainty, is lost. This work considers the novel task of Ensemble Distribution Distillation (EnD^2) - distilling the distribution of the predictions from an ensemble, rather than just the average prediction, into a single model. EnD^2 enables a single model to retain both the improved classification performance of ensemble distillation as well as information about the diversity of the ensemble, which is useful for uncertainty estimation. A solution for EnD^2 based on Prior Networks, a class of models which allow a single neural network to explicitly model a distribution over output distributions, is proposed in this work. The properties of EnD^2 are investigated on both an artificial dataset, and on the CIFAR-10, CIFAR-100 and TinyImageNet datasets, where it is shown that EnD^2 can approach the classification performance of an ensemble, and outperforms both standard DNNs and Ensemble Distillation on the tasks of misclassification and out-of-distribution input detection.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BygSP6Vtvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1lLw6EYwB" data-number="597">
      <h4>
        <a href="/forum?id=B1lLw6EYwB">
            Gap-Aware Mitigation of Gradient Staleness
        </a>
      
        
          <a href="/pdf?id=B1lLw6EYwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=saarbarkai%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="saarbarkai@gmail.com">Saar Barkai</a>, <a href="/profile?email=idohakimi%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="idohakimi@gmail.com">Ido Hakimi</a>, <a href="/profile?email=assaf%40cs.technion.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="assaf@cs.technion.ac.il">Assaf Schuster</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#B1lLw6EYwB-details-250" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1lLw6EYwB-details-250"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">distributed, asynchronous, large scale, gradient staleness, staleness penalization, sgd, deep learning, neural networks, optimization</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A new distributed, asynchronous, SGD-based algorithm, which achieves state-of-the-art accuracy on existing architectures using staleness penalization without having to re-tune the hyperparameters.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Cloud computing is becoming increasingly popular as a platform for distributed training of deep neural networks. Synchronous stochastic gradient descent (SSGD) suffers from substantial slowdowns due to stragglers if the environment is non-dedicated, as is common in cloud computing. Asynchronous SGD (ASGD) methods are immune to these slowdowns but are scarcely used due to gradient staleness, which encumbers the convergence process. Recent techniques have had limited success mitigating the gradient staleness when scaling up to many workers (computing nodes).  In this paper we define the Gap as a measure of gradient staleness and propose Gap-Aware (GA), a novel asynchronous-distributed method that penalizes stale gradients linearly to the Gap and performs well even when scaling to large numbers of workers. Our evaluation on the CIFAR, ImageNet, and WikiText-103 datasets shows that GA outperforms the currently acceptable gradient penalization method, in final test accuracy. We also provide convergence rate proof for GA. Despite prior beliefs, we show that if GA is applied, momentum becomes beneficial in asynchronous environments, even when the number of workers scales up.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/drive/folders/1z1e_GI-6FZyfROIftoLHqz1X7xvNczWs?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1lLw6EYwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJxDDpEKvH" data-number="600">
      <h4>
        <a href="/forum?id=SJxDDpEKvH">
            Counterfactuals uncover the modular structure of deep generative models
        </a>
      
        
          <a href="/pdf?id=SJxDDpEKvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=michel.besserve%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="michel.besserve@tuebingen.mpg.de">Michel Besserve</a>, <a href="/profile?email=mehrjou.arash%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mehrjou.arash@gmail.com">Arash Mehrjou</a>, <a href="/profile?email=remy.sun%40ens-rennes.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="remy.sun@ens-rennes.fr">Rémy Sun</a>, <a href="/profile?email=bs%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="bs@tuebingen.mpg.de">Bernhard Schölkopf</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 30 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SJxDDpEKvH-details-874" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJxDDpEKvH-details-874"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We develop a framework to find modular internal representations in generative models and manipulate then to generate counterfactual examples.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep generative models can emulate the perceptual properties of complex image datasets, providing a latent representation of the data. However, manipulating such representation to perform meaningful and controllable transformations in the data space remains challenging without some form of supervision. While previous work has focused on exploiting statistical independence to \textit{disentangle} latent factors, we argue that such requirement can be advantageously relaxed and propose instead a non-statistical framework that relies on identifying a modular organization of the network, based on counterfactual manipulations. Our experiments support that modularity between groups of channels is achieved to a certain degree on a variety of generative models. This allowed the design of targeted interventions on complex image datasets, opening the way to applications such as computationally efficient style transfer and the automated assessment of robustness to contextual changes in pattern recognition systems.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://www.dropbox.com/sh/4qnjictmh4a2soq/AAAa5brzPDlt69QOc9n2K4uOa?dl=0</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">generative models, causality, counterfactuals, representation learning, disentanglement, generalization, unsupervised learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJxDDpEKvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJeKwTNFvB" data-number="604">
      <h4>
        <a href="/forum?id=BJeKwTNFvB">
            Physics-as-Inverse-Graphics: Unsupervised Physical Parameter Estimation from Video
        </a>
      
        
          <a href="/pdf?id=BJeKwTNFvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=m.a.m.jaques%40sms.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.a.m.jaques@sms.ed.ac.uk">Miguel Jaques</a>, <a href="/profile?email=michael.burke%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael.burke@ed.ac.uk">Michael Burke</a>, <a href="/profile?email=t.hospedales%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="t.hospedales@ed.ac.uk">Timothy Hospedales</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#BJeKwTNFvB-details-9" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJeKwTNFvB-details-9"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a model that is able to perform physical parameter estimation of systems from video, where the differential equations governing the scene dynamics are known, but labeled states or objects are not available.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose a model that is able to perform physical parameter estimation of systems from video, where the differential equations governing the scene dynamics are known, but labeled states or objects are not available. Existing physical scene understanding methods require either object state supervision, or do not integrate with differentiable physics to learn interpretable system parameters and states. We address this problem through a \textit{physics-as-inverse-graphics} approach that brings together vision-as-inverse-graphics and differentiable physics engines, where objects and explicit state and velocity representations are discovered by the model. This framework allows us to perform long term extrapolative video prediction, as well as vision-based model-predictive control. Our approach significantly outperforms related unsupervised methods in long-term future frame prediction of systems with interacting objects (such as ball-spring or 3-body gravitational systems), due to its ability to build dynamics into the model as an inductive bias. We further show the value of this tight vision-physics integration by demonstrating data-efficient learning of vision-actuated model-based control for a pendulum system. We also show that the controller's interpretability provides unique capabilities in goal-driven control and physical reasoning for zero-data adaptation.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJeKwTNFvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJeiDpVFPr" data-number="608">
      <h4>
        <a href="/forum?id=HJeiDpVFPr">
            An Inductive Bias for Distances: Neural Nets that Respect the Triangle Inequality
        </a>
      
        
          <a href="/pdf?id=HJeiDpVFPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=spitis%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="spitis@cs.toronto.edu">Silviu Pitis</a>, <a href="/profile?email=hchan%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hchan@cs.toronto.edu">Harris Chan</a>, <a href="/profile?email=kiarash.jamali%40mail.utoronto.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="kiarash.jamali@mail.utoronto.ca">Kiarash Jamali</a>, <a href="/profile?email=jba%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jba@cs.toronto.edu">Jimmy Ba</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 07 Jul 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#HJeiDpVFPr-details-369" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJeiDpVFPr-details-369"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">metric learning, deep metric learning, neural network architectures, triangle inequality, graph distances</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose novel neural network architectures, guaranteed to satisfy the triangle inequality, for purposes of (asymmetric) metric learning and modeling graph distances. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Distances are pervasive in machine learning. They serve as similarity measures, loss functions, and learning targets; it is said that a good distance measure solves a task. When defining distances, the triangle inequality has proven to be a useful constraint, both theoretically---to prove convergence and optimality guarantees---and empirically---as an inductive bias. Deep metric learning architectures that respect the triangle inequality rely, almost exclusively, on Euclidean distance in the latent space. Though effective, this fails to model two broad classes of subadditive distances, common in graphs and reinforcement learning: asymmetric metrics, and metrics that cannot be embedded into Euclidean space. To address these problems, we introduce novel architectures that are guaranteed to satisfy the triangle inequality. We prove our architectures universally approximate norm-induced metrics on <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="415" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c211D TEX-A"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.41em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mi>n</mi></msup></math></mjx-assistive-mml></mjx-container>, and present a similar result for modified Input Convex Neural Networks. We show that our architectures outperform existing metric approaches when modeling graph distances and have a better inductive bias than non-metric approaches when training data is limited in the multi-goal reinforcement learning setting.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/spitis/deepnorms</span>
          </li>
          <li>
            <strong class="note-content-field">Slides:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJeiDpVFPr&amp;name=slides" class="attachment-download-link" title="Download Slides" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJeiDpVFPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryenvpEKDr" data-number="611">
      <h4>
        <a href="/forum?id=ryenvpEKDr">
            A Constructive Prediction of the Generalization Error Across Scales
        </a>
      
        
          <a href="/pdf?id=ryenvpEKDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jonsr%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonsr@mit.edu">Jonathan S. Rosenfeld</a>, <a href="/profile?email=amir%40eecs.yorku.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="amir@eecs.yorku.ca">Amir Rosenfeld</a>, <a href="/profile?email=belinkov%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="belinkov@mit.edu">Yonatan Belinkov</a>, <a href="/profile?email=shanir%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shanir@csail.mit.edu">Nir Shavit</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#ryenvpEKDr-details-413" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryenvpEKDr-details-413"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We predict the generalization error and specify the model which attains it across model/data scales.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The dependency of the generalization error of neural networks on model and dataset size is of critical importance both in practice and for understanding the theory of neural networks. Nevertheless, the functional form of this dependency remains elusive. In this work, we present a functional form which approximates well the generalization error in practice. Capitalizing on the successful concept of model scaling (e.g., width, depth), we are able to simultaneously construct such a form and specify the exact models which can attain it across model/data scales. Our construction follows insights obtained from observations conducted over a range of model/data scales, in various model types and datasets, in vision and language tasks. We show that the form both fits the observations well across scales, and provides accurate predictions from small- to large-scale models and data.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">neural networks, deep learning, generalization error, scaling, scalability, vision, language</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryenvpEKDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJlguT4YPr" data-number="619">
      <h4>
        <a href="/forum?id=BJlguT4YPr">
            Scalable Neural Methods for Reasoning With a Symbolic Knowledge   Base
        </a>
      
        
          <a href="/pdf?id=BJlguT4YPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wcohen%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wcohen@google.com">William W. Cohen</a>, <a href="/profile?email=haitiansun%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="haitiansun@google.com">Haitian Sun</a>, <a href="/profile?email=rofer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rofer@google.com">R. Alex Hofer</a>, <a href="/profile?email=msiegler%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="msiegler@google.com">Matthew Siegler</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#BJlguT4YPr-details-157" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJlguT4YPr-details-157"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A scalable differentiable neural module that implements reasoning on symbolic KBs.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We describe a novel way of representing a symbolic knowledge base (KB) called a sparse-matrix reified KB.  This representation enables neural modules that are fully differentiable, faithful to the original semantics of the KB, expressive enough to model multi-hop inferences, and scalable enough to use with realistically large KBs. The sparse-matrix reified KB can be distributed across multiple GPUs, can scale to tens of millions of entities and facts, and is orders of magnitude faster than naive sparse-matrix implementations.  The reified KB enables very simple end-to-end architectures to obtain competitive performance on several benchmarks representing two families of tasks: KB completion, and learning semantic parsers from denotations.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">question-answering, knowledge base completion, neuro-symbolic reasoning, multihop reasoning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJlguT4YPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJlfuTEtvB" data-number="623">
      <h4>
        <a href="/forum?id=HJlfuTEtvB">
            CLN2INV: Learning Loop Invariants with Continuous Logic Networks
        </a>
      
        
          <a href="/pdf?id=HJlfuTEtvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=gabe%40cs.columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gabe@cs.columbia.edu">Gabriel Ryan</a>, <a href="/profile?email=justin.wong%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="justin.wong@columbia.edu">Justin Wong</a>, <a href="/profile?email=jy3022%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jy3022@columbia.edu">Jianan Yao</a>, <a href="/profile?email=ronghui.gu%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ronghui.gu@columbia.edu">Ronghui Gu</a>, <a href="/profile?email=suman%40cs.columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="suman@cs.columbia.edu">Suman Jana</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#HJlfuTEtvB-details-116" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJlfuTEtvB-details-116"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce the Continuous Logic Network (CLN), a novel neural architecture for automatically learning loop invariants and general SMT formulas.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Program verification offers a framework for ensuring program correctness and therefore systematically eliminating different classes of bugs. Inferring loop invariants is one of the main challenges behind automated verification of real-world programs which often contain many loops. In this paper, we present the Continuous Logic Network (CLN), a novel neural architecture for automatically learning loop invariants directly from program execution traces. Unlike existing neural networks, CLNs can learn precise and explicit representations of formulas in Satisfiability Modulo Theories (SMT)  for loop invariants from program execution traces. We develop a new sound and complete semantic mapping for assigning SMT formulas to continuous truth values that allows CLNs to be trained efficiently. We use CLNs to implement a new inference system for loop invariants, CLN2INV, that significantly outperforms existing approaches on the popular Code2Inv dataset. CLN2INV is the first tool to solve all 124 theoretically solvable problems in the Code2Inv dataset. Moreover, CLN2INV takes only 1.1 second on average for each problem, which is 40 times faster than existing approaches. We further demonstrate that CLN2INV can even learn 12 significantly more complex loop invariants than the ones required for the Code2Inv dataset.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">loop invariants, deep learning, logic learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJlfuTEtvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HygrdpVKvr" data-number="630">
      <h4>
        <a href="/forum?id=HygrdpVKvr">
            NAS evaluation is frustratingly hard
        </a>
      
        
          <a href="/pdf?id=HygrdpVKvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=antoineyang3%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="antoineyang3@gmail.com">Antoine Yang</a>, <a href="/profile?email=pedro.esperanca%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pedro.esperanca@huawei.com">Pedro M. Esperança</a>, <a href="/profile?email=fabiom.carlucci%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fabiom.carlucci@gmail.com">Fabio M. Carlucci</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HygrdpVKvr-details-489" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HygrdpVKvr-details-489"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">neural architecture search, nas, benchmark, reproducibility, harking</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A study of how different components in the NAS pipeline contribute to the final accuracy. Also, a benchmark of 8 methods on 5 datasets.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Neural Architecture Search (NAS) is an exciting new field which promises to be as much as a game-changer as Convolutional Neural Networks were in 2012. Despite many great works leading to substantial improvements on a variety of tasks, comparison between different methods is still very much an open issue. While most algorithms are tested on the same datasets, there is no shared experimental protocol followed by all. As such, and due to the under-use of ablation studies, there is a lack of clarity regarding why certain methods are more effective than others. Our first contribution is a benchmark of 8 NAS methods on 5 datasets. To overcome the hurdle of comparing methods with different search spaces, we propose using a method’s relative improvement over the randomly sampled average architecture, which effectively removes advantages arising from expertly engineered search spaces or training protocols. Surprisingly, we find that many NAS techniques struggle to significantly beat the average architecture baseline. We perform further experiments with the commonly used DARTS search space in order to understand the contribution of each component in the NAS pipeline. These experiments highlight that: (i) the use of tricks in the evaluation protocol has a predominant impact on the reported performance of architectures; (ii) the cell-based search space has a very narrow accuracy range, such that the seed has a considerable impact on architecture rankings; (iii) the hand-designed macrostructure (cells) is more important than the searched micro-structure (operations); and (iv) the depth-gap is a real phenomenon, evidenced by the change in rankings between 8 and 20 cell architectures. To conclude, we suggest best practices, that we hope will prove useful for the community and help mitigate current NAS pitfalls, e.g. difficulties in reproducibility and comparison of search methods. The
      code used is available at https://github.com/antoyang/NAS-Benchmark.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/antoyang/NAS-Benchmark</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HygrdpVKvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1eY_pVYvB" data-number="639">
      <h4>
        <a href="/forum?id=B1eY_pVYvB">
            Efficient and Information-Preserving Future Frame Prediction and Beyond
        </a>
      
        
          <a href="/pdf?id=B1eY_pVYvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=gnosis%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gnosis@cs.toronto.edu">Wei Yu</a>, <a href="/profile?email=yichao%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yichao@cs.toronto.edu">Yichao Lu</a>, <a href="/profile?email=sme%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sme@cs.toronto.edu">Steve Easterbrook</a>, <a href="/profile?email=fidler%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fidler@cs.toronto.edu">Sanja Fidler</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#B1eY_pVYvB-details-693" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1eY_pVYvB-details-693"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Applying resolution-preserving blocks is a common practice to maximize information preservation in video prediction, yet their high memory consumption greatly limits their application scenarios. We propose CrevNet, a Conditionally Reversible Network that uses reversible architectures to build a bijective two-way autoencoder and its complementary recurrent predictor. Our model enjoys the theoretically guaranteed property of no information loss during the feature extraction, much lower memory consumption and computational efficiency. The lightweight nature of our model enables us to incorporate 3D convolutions without concern of memory bottleneck, enhancing the model's ability to capture both short-term and long-term temporal dependencies. Our proposed approach achieves state-of-the-art results on Moving MNIST, Traffic4cast and KITTI datasets. We further demonstrate the transferability of our self-supervised learning method by exploiting its learnt features for object detection on KITTI. Our competitive results indicate the potential of using CrevNet as a generative pre-training strategy to guide downstream tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">self-supervised learning, generative pre-training, video prediction, reversible architecture</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/file/d/1koVpH2RhkOl4_Xm_q8Iy1FuX3zQxC9gd/view?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1eY_pVYvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HygsuaNFwr" data-number="645">
      <h4>
        <a href="/forum?id=HygsuaNFwr">
            Order Learning and Its Application to Age Estimation
        </a>
      
        
          <a href="/pdf?id=HygsuaNFwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kslim%40mcl.korea.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="kslim@mcl.korea.ac.kr">Kyungsun Lim</a>, <a href="/profile?email=nhshin%40mcl.korea.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="nhshin@mcl.korea.ac.kr">Nyeong-Ho Shin</a>, <a href="/profile?email=yy77lee%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yy77lee@gmail.com">Young-Yoon Lee</a>, <a href="/profile?email=changsukim%40korea.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="changsukim@korea.ac.kr">Chang-Su Kim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HygsuaNFwr-details-149" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HygsuaNFwr-details-149"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Order learning, age estimation, aesthetic assessment</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">The notion of order learning is proposed and it is applied to regression problems in computer vision</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose order learning to determine the order graph of classes, representing ranks or priorities, and classify an object instance into one of the classes. To this end, we design a pairwise comparator to categorize the relationship between two instances into one of three cases: one instance is `greater than,' `similar to,' or `smaller than' the other. Then, by comparing an input instance with reference instances and maximizing the consistency among the comparison results, the class of the input can be estimated reliably. We apply order learning to develop a facial age estimator, which provides the state-of-the-art performance. Moreover, the performance is further improved when the order graph is divided into disjoint chains using gender and ethnic group information or even in an unsupervised manner.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/changsukim-ku/order-learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HygsuaNFwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJgJtT4tvB" data-number="655">
      <h4>
        <a href="/forum?id=HJgJtT4tvB">
            ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning
        </a>
      
        
          <a href="/pdf?id=HJgJtT4tvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=weihaoyu6%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="weihaoyu6@gmail.com">Weihao Yu</a>, <a href="/profile?email=jzihang%40u.nus.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jzihang@u.nus.edu">Zihang Jiang</a>, <a href="/profile?email=yanfei.dong43%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanfei.dong43@gmail.com">Yanfei Dong</a>, <a href="/profile?email=elefjia%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="elefjia@nus.edu.sg">Jiashi Feng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 22 Aug 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HJgJtT4tvB-details-76" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJgJtT4tvB-details-76"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce ReClor, a reading comprehension dataset requiring logical reasoning, and find that current state-of-the-art models struggle with real logical reasoning with poor performance near that of random guess.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recent powerful pre-trained language models have achieved remarkable performance on most of the popular datasets for reading comprehension. It is time to introduce more challenging datasets to push the development of this field towards more comprehensive reasoning of text. In this paper, we introduce a new Reading Comprehension dataset requiring logical reasoning (ReClor) extracted from standardized graduate admission examinations. As earlier studies suggest, human-annotated datasets usually contain biases, which are often exploited by models to achieve high accuracy without truly understanding the text. In order to comprehensively evaluate the logical reasoning ability of models on ReClor, we propose to identify biased data points and separate them into EASY set while the rest as HARD set. Empirical results show that state-of-the-art models have an outstanding ability to capture biases contained in the dataset with high accuracy on EASY set. However, they struggle on HARD set with poor performance near that of random guess, indicating more research is needed to essentially enhance the logical reasoning ability of current models. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reading comprehension, logical reasoning, natural language processing</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">http://whyu.me/reclor/</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJgJtT4tvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJgMK64Ywr" data-number="661">
      <h4>
        <a href="/forum?id=SJgMK64Ywr">
            AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures
        </a>
      
        
          <a href="/pdf?id=SJgMK64Ywr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mryoo%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mryoo@google.com">Michael S. Ryoo</a>, <a href="/profile?email=ajpiergi%40indiana.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ajpiergi@indiana.edu">AJ Piergiovanni</a>, <a href="/profile?email=tanmingxing%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tanmingxing@google.com">Mingxing Tan</a>, <a href="/profile?email=anelia%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anelia@google.com">Anelia Angelova</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SJgMK64Ywr-details-468" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJgMK64Ywr-details-468"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">video representation learning, video understanding, activity recognition, neural architecture search</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We search for multi-stream neural architectures with better connectivity and spatio-temporal interactions for video understanding.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Learning to represent videos is a very challenging task both algorithmically and computationally. Standard video CNN architectures have been designed by directly extending architectures devised for image understanding to include the time dimension, using modules such as 3D convolutions, or by using two-stream design to capture both appearance and motion in videos. We interpret a video CNN as a collection of multi-stream convolutional blocks connected to each other, and propose the approach of automatically finding neural architectures with better connectivity and spatio-temporal interactions for video understanding. This is done by evolving a population of overly-connected architectures guided by connection weight learning. 
      Architectures combining representations that abstract different input types (i.e., RGB and optical flow) at multiple temporal resolutions are searched for, allowing different types or sources of information to interact with each other. Our method, referred to as AssembleNet, outperforms prior approaches on public video datasets, in some cases by a great margin. We obtain 58.6% mAP on Charades and 34.27% accuracy on Moments-in-Time.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJgMK64Ywr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1gfFaEYDS" data-number="662">
      <h4>
        <a href="/forum?id=H1gfFaEYDS">
            Adversarially Robust Representations with Smooth Encoders
        </a>
      
        
          <a href="/pdf?id=H1gfFaEYDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=taylancemgil%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="taylancemgil@google.com">Taylan Cemgil</a>, <a href="/profile?email=sumedhg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sumedhg@google.com">Sumedh Ghaisas</a>, <a href="/profile?email=dvij%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dvij@google.com">Krishnamurthy (Dj) Dvijotham</a>, <a href="/profile?email=pushmeet%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pushmeet@google.com">Pushmeet Kohli</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#H1gfFaEYDS-details-876" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1gfFaEYDS-details-876"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a method for computing adversarially robust representations in an entirely unsupervised way.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper studies the undesired phenomena of over-sensitivity of representations learned by deep networks to semantically-irrelevant changes in data. We identify a cause for this shortcoming in the classical Variational Auto-encoder (VAE) objective, the evidence lower bound (ELBO). We show that the ELBO fails to control the behaviour of the encoder out of the support of the empirical data distribution and this behaviour of the VAE can lead to extreme errors in the learned representation. This is a key hurdle in the effective use of representations for data-efficient learning and transfer. To address this problem, we propose to augment the data with specifications that enforce insensitivity of the representation with respect to families of transformations. To incorporate these specifications, we propose a regularization method that is based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. For certain choices of parameters, our formulation naturally leads to the minimization of the entropy regularized Wasserstein distance between representations. We illustrate our approach on standard datasets and experimentally show that significant improvements in the downstream adversarial accuracy can be achieved by learning robust representations completely in an unsupervised manner, without a reference to a particular downstream task and without a costly supervised adversarial training procedure. 
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Adversarial Learning, Robust Representations, Variational AutoEncoder, Wasserstein Distance, Variational Inference</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1gfFaEYDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1g7tpEYDS" data-number="663">
      <h4>
        <a href="/forum?id=S1g7tpEYDS">
            From Variational to Deterministic Autoencoders
        </a>
      
        
          <a href="/pdf?id=S1g7tpEYDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=partha.ghosh%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="partha.ghosh@tuebingen.mpg.de">Partha Ghosh</a>, <a href="/profile?email=msajjadi%40tue.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="msajjadi@tue.mpg.de">Mehdi S. M. Sajjadi</a>, <a href="/profile?email=antonio.vergari%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="antonio.vergari@tuebingen.mpg.de">Antonio Vergari</a>, <a href="/profile?email=black%40tue.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="black@tue.mpg.de">Michael Black</a>, <a href="/profile?email=bs%40tue.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="bs@tue.mpg.de">Bernhard Scholkopf</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="#S1g7tpEYDS-details-692" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1g7tpEYDS-details-692"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Deterministic regularized autoencoders can learn a smooth, meaningful latent space as VAEs without having to force some arbitrarily chosen prior (i.e., Gaussian).</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value "> Variational Autoencoders (VAEs) provide a theoretically-backed and popular framework for deep generative models. However, learning a VAE from data poses still unanswered theoretical questions and considerable practical challenges. In this work, we propose an alternative framework for generative modeling that is simpler, easier to train, and deterministic, yet has many of the advantages of the VAE. We observe that sampling a stochastic encoder in a Gaussian VAE can be interpreted as simply injecting noise into the input of a deterministic decoder. We investigate how substituting this kind of stochasticity, with other explicit and implicit regularization schemes, can lead to an equally smooth and meaningful latent space without having to force it to conform to an arbitrarily chosen prior. To retrieve a generative mechanism to sample new data points, we introduce an ex-post density estimation step that can be readily applied to the proposed framework as well as existing VAEs, improving their sample quality. We show, in a rigorous empirical study, that the proposed regularized deterministic autoencoders are able to generate samples that are comparable to, or better than, those of VAEs and more powerful alternatives when applied to images as well as to structured data such as molecules. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Unsupervised learning, Generative Models, Variational Autoencoders, Regularization</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/ParthaEth/Regularized_autoencoders-RAE-</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1g7tpEYDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkxLFaNKwB" data-number="671">
      <h4>
        <a href="/forum?id=SkxLFaNKwB">
            Computation Reallocation for Object Detection
        </a>
      
        
          <a href="/pdf?id=SkxLFaNKwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=liangfeng%40sensetime.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liangfeng@sensetime.com">Feng Liang</a>, <a href="/profile?email=linchen%40sensetime.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="linchen@sensetime.com">Chen Lin</a>, <a href="/profile?email=guoronghao%40sensetime.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="guoronghao@sensetime.com">Ronghao Guo</a>, <a href="/profile?email=sunming1%40sensetime.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sunming1@sensetime.com">Ming Sun</a>, <a href="/profile?email=wuwei%40sensetime.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wuwei@sensetime.com">Wei Wu</a>, <a href="/profile?email=yanjunjie%40sensetime.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanjunjie@sensetime.com">Junjie Yan</a>, <a href="/profile?email=wanli.ouyang%40sydney.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanli.ouyang@sydney.edu.au">Wanli Ouyang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#SkxLFaNKwB-details-693" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkxLFaNKwB-details-693"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose CR-NAS to reallocate engaged  computation resources in different resolution and spatial position.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The allocation of computation resources in the backbone is a crucial issue in object detection. However, classification allocation pattern is usually adopted directly to object detector, which is proved to be sub-optimal. In order to reallocate the engaged computation resources in a more efficient way, we present CR-NAS (Computation Reallocation Neural Architecture Search) that can learn computation reallocation strategies across different feature resolution and spatial position diectly on the target detection dataset. A two-level reallocation space is proposed for both stage and spatial reallocation. A novel hierarchical search procedure is adopted to cope with the complex search space. We apply CR-NAS to multiple backbones and achieve consistent improvements. Our CR-ResNet50 and CR-MobileNetV2 outperforms the baseline by 1.9% and 1.7% COCO AP respectively without any additional computation budget. The models discovered by CR-NAS can be equiped to other powerful detection neck/head and be easily transferred to other dataset, e.g. PASCAL VOC, and other vision tasks, e.g. instance segmentation. Our CR-NAS can be used as a plugin to improve the performance of various networks, which is demanding.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Neural Architecture Search, Object Detection</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkxLFaNKwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylvYaNYDH" data-number="672">
      <h4>
        <a href="/forum?id=rylvYaNYDH">
            Finding and Visualizing Weaknesses of Deep Reinforcement Learning Agents
        </a>
      
        
          <a href="/pdf?id=rylvYaNYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=christian.rupprecht%40eng.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="christian.rupprecht@eng.ox.ac.uk">Christian Rupprecht</a>, <a href="/profile?email=cyril.ibrahim%40elementai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cyril.ibrahim@elementai.com">Cyril Ibrahim</a>, <a href="/profile?email=christopher.pal%40polymtl.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="christopher.pal@polymtl.ca">Christopher J. Pal</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rylvYaNYDH-details-764" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylvYaNYDH-details-764"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We generate critical states of a trained RL algorithms to visualize potential weaknesses. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">As deep reinforcement learning driven by visual perception becomes more widely used there is a growing need to better understand and probe the learned agents. Understanding the decision making process and its relationship to visual inputs can be very valuable to identify problems in learned behavior. However, this topic has been relatively under-explored in the research community. In this work we present a method for synthesizing visual inputs of interest for a trained agent. Such inputs or states could be situations in which specific actions are necessary. Further, critical states in which a very high or a very low reward can be achieved are often interesting to understand the situational awareness of the system as they can correspond to risky states. To this end, we learn a generative model over the state space of the environment and use its latent space to optimize a target function for the state of interest. In our experiments we show that this method can generate insights for a variety of environments and reinforcement learning methods. We explore results in the standard Atari benchmark games as well as in an autonomous driving simulator. Based on the efficiency with which we have been able to identify behavioural weaknesses with this technique, we believe this general approach could serve as an important tool for AI safety applications.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Visualization, Reinforcement Learning, Safety</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rylvYaNYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HygDF6NFPB" data-number="673">
      <h4>
        <a href="/forum?id=HygDF6NFPB">
            A Fair Comparison of Graph Neural Networks for Graph Classification
        </a>
      
        
          <a href="/pdf?id=HygDF6NFPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=federico.errica%40phd.unipi.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="federico.errica@phd.unipi.it">Federico Errica</a>, <a href="/profile?email=marco.podda%40di.unipi.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="marco.podda@di.unipi.it">Marco Podda</a>, <a href="/profile?email=bacciu%40di.unipi.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="bacciu@di.unipi.it">Davide Bacciu</a>, <a href="/profile?email=micheli%40di.unipi.it" class="profile-link" data-toggle="tooltip" data-placement="top" title="micheli@di.unipi.it">Alessio Micheli</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="#HygDF6NFPB-details-624" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HygDF6NFPB-details-624"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">graph neural networks, graph classification, reproducibility, graph representation learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We provide a rigorous comparison of different Graph Neural Networks for graph classification.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Experimental reproducibility and replicability are critical topics in machine learning. Authors have often raised concerns about their lack in scientific publications to improve the quality of the field. Recently, the graph representation learning field has attracted the attention of a wide research community, which resulted in a large stream of works.
      As such, several Graph Neural Network models have been developed to effectively tackle graph classification. However, experimental procedures often lack rigorousness and are hardly reproducible. Motivated by this, we provide an overview of common practices that should be avoided to fairly compare with the state of the art. To counter this troubling trend, we ran more than 47000 experiments in a controlled and uniform framework to re-evaluate five popular models across nine common benchmarks. Moreover, by comparing GNNs with structure-agnostic baselines we provide convincing evidence that, on some datasets, structural information has not been exploited yet. We believe that this work can contribute to the development of the graph learning field, by providing a much needed grounding for rigorous evaluations of graph classification models.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/diningphil/gnn-comparison</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HygDF6NFPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1e_FpNFDr" data-number="675">
      <h4>
        <a href="/forum?id=r1e_FpNFDr">
            Generalization bounds for deep convolutional neural networks
        </a>
      
        
          <a href="/pdf?id=r1e_FpNFDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=plong%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="plong@google.com">Philip M. Long</a>, <a href="/profile?email=hsedghi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hsedghi@google.com">Hanie Sedghi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 08 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#r1e_FpNFDr-details-258" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1e_FpNFDr-details-258"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">generalization, convolutional networks, statistical learning theory</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We prove generalization bounds for convolutional neural networks that take account of weight-tying</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We prove bounds on the generalization error of convolutional networks.
      The bounds are in terms of the training loss, the number of
      parameters, the Lipschitz constant of the loss and the distance from
      the weights to the initial weights.  They are independent of the
      number of pixels in the input, and the height and width of hidden
      feature maps.
      We present experiments using CIFAR-10 with varying
      hyperparameters of a deep convolutional network, comparing our bounds
      with practical generalization gaps.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1e_FpNFDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rye5YaEtPr" data-number="679">
      <h4>
        <a href="/forum?id=rye5YaEtPr">
            SAdam: A Variant of Adam for Strongly Convex Functions
        </a>
      
        
          <a href="/pdf?id=rye5YaEtPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=guhuwang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="guhuwang@gmail.com">Guanghui Wang</a>, <a href="/profile?email=lsy1116%40qq.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lsy1116@qq.com">Shiyin Lu</a>, <a href="/profile?email=chengquangm%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chengquangm@gmail.com">Quan Cheng</a>, <a href="/profile?email=tuwwcn%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tuwwcn@gmail.com">Wei-wei Tu</a>, <a href="/profile?email=zljzju%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zljzju@gmail.com">Lijun Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#rye5YaEtPr-details-188" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rye5YaEtPr-details-188"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Online convex optimization, Adaptive online learning, Adam</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A variant of Adam for strongly convex functions</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The Adam algorithm has become extremely popular for large-scale machine learning. Under convexity condition, it has been proved to enjoy a data-dependent <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="416" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.169em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msqrt><mi>T</mi></msqrt><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> regret bound where <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="417" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></mjx-assistive-mml></mjx-container> is the time horizon. However, whether strong convexity can be utilized to further improve the performance remains an open problem. In this paper, we give an affirmative answer by developing a variant of Adam (referred to as SAdam) which achieves a data-dependent <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="418" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-n"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mi>T</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> regret bound for strongly convex functions. The essential idea is to maintain a faster decaying yet under controlled step size for exploiting strong convexity. In addition, under a special configuration of hyperparameters, our SAdam reduces to SC-RMSprop, a recently proposed variant of RMSprop for strongly convex functions, for which we provide the first data-dependent logarithmic regret bound. Empirical results on optimizing strongly convex functions and training deep networks demonstrate the effectiveness of our method.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/SAdam-ICLR2020/codes</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rye5YaEtPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJlsFpVtDB" data-number="681">
      <h4>
        <a href="/forum?id=SJlsFpVtDB">
            Continual Learning with Bayesian Neural Networks for Non-Stationary Data
        </a>
      
        
          <a href="/pdf?id=SJlsFpVtDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=richard.kurle%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="richard.kurle@tum.de">Richard Kurle</a>, <a href="/profile?email=botond.cseke%40argmax.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="botond.cseke@argmax.ai">Botond Cseke</a>, <a href="/profile?email=a.klushyn%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.klushyn@tum.de">Alexej Klushyn</a>, <a href="/profile?email=smagt%40argmax.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="smagt@argmax.ai">Patrick van der Smagt</a>, <a href="/profile?email=guennemann%40in.tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="guennemann@in.tum.de">Stephan Günnemann</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#SJlsFpVtDB-details-904" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJlsFpVtDB-details-904"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Continual Learning, Online Variational Bayes, Non-Stationary Data, Bayesian Neural Networks, Variational Inference, Lifelong Learning, Concept Drift, Episodic Memory</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This work addresses continual learning for non-stationary data, using Bayesian neural networks and memory-based online variational Bayes.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This work addresses continual learning for non-stationary data, using Bayesian neural networks and memory-based online variational Bayes. We represent the posterior approximation of the network weights by a diagonal Gaussian distribution and a complementary memory of raw data. This raw data corresponds to likelihood terms that cannot be well approximated by the Gaussian. We introduce a novel method for sequentially updating both components of the posterior approximation. Furthermore, we propose Bayesian forgetting and a Gaussian diffusion process for adapting to non-stationary data. The experimental results show that our update method improves on existing approaches for streaming data. Additionally, the adaptation methods lead to better predictive performance for non-stationary data. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJlsFpVtDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylnK6VtDH" data-number="684">
      <h4>
        <a href="/forum?id=rylnK6VtDH">
            Multiplicative Interactions and Where to Find Them
        </a>
      
        
          <a href="/pdf?id=rylnK6VtDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sidmj%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sidmj@google.com">Siddhant M. Jayakumar</a>, <a href="/profile?email=lejlot%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lejlot@google.com">Wojciech M. Czarnecki</a>, <a href="/profile?email=jmenick%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jmenick@google.com">Jacob Menick</a>, <a href="/profile?email=schwarzjn%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="schwarzjn@google.com">Jonathan Schwarz</a>, <a href="/profile?email=jwrae%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jwrae@google.com">Jack Rae</a>, <a href="/profile?email=osindero%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="osindero@google.com">Simon Osindero</a>, <a href="/profile?email=ywteh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ywteh@google.com">Yee Whye Teh</a>, <a href="/profile?email=tharley%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tharley@google.com">Tim Harley</a>, <a href="/profile?email=razp%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="razp@google.com">Razvan Pascanu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rylnK6VtDH-details-293" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylnK6VtDH-details-293"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">multiplicative interactions, hypernetworks, attention</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We explore the role of multiplicative interaction as a unifying framework to describe a range of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions amongst others.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We explore the role of multiplicative interaction as a unifying framework to describe a range of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions amongst others.
      Multiplicative interaction layers as primitive operations have a long-established presence in the literature, though this often not emphasized and thus under-appreciated. We begin by showing that such layers strictly enrich the representable function classes of neural networks. We conjecture that multiplicative interactions offer a particularly powerful inductive bias when fusing multiple streams of information or when conditional computation is required. We therefore argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft-used concatenation operation. Finally, we back up our claims and demonstrate the potential of multiplicative interactions by applying them in large-scale complex RL and sequence modelling tasks, where their use allows us to deliver state-of-the-art results, and thereby provides new evidence in support of multiplicative interactions playing a more prominent role when designing new neural network architectures.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rylnK6VtDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bkeeca4Kvr" data-number="693">
      <h4>
        <a href="/forum?id=Bkeeca4Kvr">
            FEW-SHOT LEARNING ON GRAPHS VIA SUPER-CLASSES BASED ON GRAPH SPECTRAL MEASURES
        </a>
      
        
          <a href="/pdf?id=Bkeeca4Kvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=chauhanjatin100%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chauhanjatin100@gmail.com">Jatin Chauhan</a>, <a href="/profile?email=deepakn1019%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="deepakn1019@gmail.com">Deepak Nathani</a>, <a href="/profile?email=mkaul%40iith.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="mkaul@iith.ac.in">Manohar Kaul</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#Bkeeca4Kvr-details-379" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bkeeca4Kvr-details-379"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Few shot graph classification, graph spectral measures, super-classes</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose to study the problem of few-shot graph classification in graph neural networks (GNNs) to recognize unseen classes, given limited labeled graph examples. Despite several interesting GNN variants being proposed recently for node and graph classification tasks, when faced with scarce labeled examples in the few-shot setting, these GNNs exhibit significant loss in classification performance. Here, we present an approach where a probability measure is assigned to each graph based on the spectrum of the graph’s normalized Laplacian. This enables us to accordingly cluster the graph base-labels associated with each graph into super-classes, where the L^p Wasserstein distance serves as our underlying distance metric. Subsequently, a super-graph constructed based on the super-classes is then fed to our proposed GNN framework which exploits the latent inter-class relationships made explicit by the super-graph to achieve better class label separation among the graphs. We conduct exhaustive empirical evaluations of our proposed method and show that it outperforms both the adaptation of state-of-the-art graph classification methods to few-shot scenario and our naive baseline GNNs. Additionally, we also extend and study the behavior of our method to semi-supervised and active learning scenarios.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/chauhanjatin10/GraphsFewShot</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Bkeeca4Kvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJl-5pNKDB" data-number="696">
      <h4>
        <a href="/forum?id=BJl-5pNKDB">
            On Computation and Generalization of Generative Adversarial Imitation Learning
        </a>
      
        
          <a href="/pdf?id=BJl-5pNKDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mchen393%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mchen393@gatech.edu">Minshuo Chen</a>, <a href="/profile?email=wyzjack990122%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wyzjack990122@gmail.com">Yizhou Wang</a>, <a href="/profile?email=tianyiliu%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianyiliu@gatech.edu">Tianyi Liu</a>, <a href="/profile?email=zy6%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zy6@princeton.edu">Zhuoran Yang</a>, <a href="/profile?email=xingguol%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xingguol@princeton.edu">Xingguo Li</a>, <a href="/profile?email=zhaoran.wang%40northwestern.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaoran.wang@northwestern.edu">Zhaoran Wang</a>, <a href="/profile?email=tourzhao%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tourzhao@gatech.edu">Tuo Zhao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#BJl-5pNKDB-details-217" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJl-5pNKDB-details-217"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Generative Adversarial Imitation Learning (GAIL) is a powerful and practical approach for learning sequential decision-making policies. Different from Reinforcement Learning (RL), GAIL takes advantage of demonstration data by experts (e.g., human), and learns both the policy and reward function of the unknown environment. Despite the significant empirical progresses, the theory behind GAIL is still largely unknown. The major difficulty comes from the underlying temporal dependency of the demonstration data and the minimax computational formulation of GAIL without convex-concave structure. To bridge such a gap between theory and practice, this paper investigates the theoretical properties of GAIL. Specifically, we show: (1) For GAIL with general reward parameterization, the generalization can be guaranteed as long as the class of the reward functions is properly controlled; (2) For GAIL, where the reward is parameterized as a reproducing kernel function, GAIL can be efficiently solved by stochastic first order optimization algorithms, which attain sublinear convergence to a stationary solution. To the best of our knowledge, these are the first results on statistical and computational guarantees of imitation learning with reward/policy function ap- proximation. Numerical experiments are provided to support our analysis.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJl-5pNKDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BylVcTNtDS" data-number="702">
      <h4>
        <a href="/forum?id=BylVcTNtDS">
            A Target-Agnostic Attack on Deep Models: Exploiting Security Vulnerabilities of Transfer Learning
        </a>
      
        
          <a href="/pdf?id=BylVcTNtDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=srezaei%40ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="srezaei@ucdavis.edu">Shahbaz Rezaei</a>, <a href="/profile?email=xinliu%40ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xinliu@ucdavis.edu">Xin Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#BylVcTNtDS-details-13" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BylVcTNtDS-details-13"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Machine learning security, Transfer learning, deep learning security, Softmax Vulnerability, Transfer learning Security</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Due to insufficient training data and the high computational cost to train a deep neural network from scratch, transfer learning has been extensively used in many deep-neural-network-based applications. A commonly used transfer learning approach involves taking a part of a pre-trained model, adding a few layers at the end, and re-training the new layers with a small dataset. This approach, while efficient and widely used, imposes a security vulnerability because the pre-trained model used in transfer learning is usually publicly available, including to potential attackers. In this paper, we show that without any additional knowledge other than the pre-trained model, an attacker can launch an effective and efficient brute force attack that can craft instances of input to trigger each target class with high confidence. We assume that the attacker has no access to any target-specific information, including samples from target classes, re-trained model, and probabilities assigned by Softmax to each class, and thus making the attack target-agnostic. These assumptions render all previous attack models inapplicable, to the best of our knowledge. To evaluate the proposed attack, we perform a set of experiments on face recognition and speech recognition tasks and show the effectiveness of the attack. Our work reveals a fundamental security weakness of the Softmax layer when used in transfer learning settings.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/shrezaei/Target-Agnostic-Attack</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BylVcTNtDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJeIcTNtvS" data-number="707">
      <h4>
        <a href="/forum?id=rJeIcTNtvS">
            Low-Resource Knowledge-Grounded Dialogue Generation
        </a>
      
        
          <a href="/pdf?id=rJeIcTNtvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xl.zhao%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xl.zhao@pku.edu.cn">Xueliang Zhao</a>, <a href="/profile?email=wuwei%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wuwei@microsoft.com">Wei Wu</a>, <a href="/profile?email=chongyangtao%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="chongyangtao@pku.edu.cn">Chongyang Tao</a>, <a href="/profile?email=can.xu%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="can.xu@microsoft.com">Can Xu</a>, <a href="/profile?email=zhaody%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaody@pku.edu.cn">Dongyan Zhao</a>, <a href="/profile?email=ruiyan%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruiyan@pku.edu.cn">Rui Yan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rJeIcTNtvS-details-756" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJeIcTNtvS-details-756"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Responding with knowledge has been recognized as an important capability for an intelligent conversational agent. Yet knowledge-grounded dialogues, as training data for learning such a response generation model, are difficult to obtain. Motivated by the challenge in practice, we consider knowledge-grounded dialogue generation under a natural assumption that only limited training examples are available. In such a low-resource setting, we devise a disentangled response decoder in order to isolate parameters that depend on knowledge-grounded dialogues from the entire generation model. By this means, the major part of the model can be learned from a large number of ungrounded dialogues and unstructured documents, while the remaining small parameters can be well fitted using the limited training examples. Evaluation results on two benchmarks indicate that with only <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="419" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow><mo>/</mo></mrow><mn>8</mn></math></mjx-assistive-mml></mjx-container> training data, our model can achieve the state-of-the-art performance and generalize well on out-of-domain knowledge. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJeIcTNtvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1gF56VYPH" data-number="714">
      <h4>
        <a href="/forum?id=B1gF56VYPH">
            Deep 3D Pan via local adaptive "t-shaped" convolutions with global and local adaptive dilations
        </a>
      
        
          <a href="/pdf?id=B1gF56VYPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=juanluisgb%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="juanluisgb@kaist.ac.kr">Juan Luis Gonzalez Bello</a>, <a href="/profile?email=mkimee%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="mkimee@kaist.ac.kr">Munchurl Kim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 21 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#B1gF56VYPH-details-432" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1gF56VYPH-details-432"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep learning, Stereoscopic view synthesis, Monocular depth, Deep 3D Pan</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Novel architecture for stereoscopic view synthesis at arbitrary camera shifts utilizing adaptive t-shaped kernels with adaptive dilations.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recent advances in deep learning have shown promising results in many low-level vision tasks. However, solving the single-image-based view synthesis is still an open problem. In particular, the generation of new images at parallel camera views given a single input image is of great interest, as it enables 3D visualization of the 2D input scenery. We propose a novel network architecture to perform stereoscopic view synthesis at arbitrary camera positions along the X-axis, or “Deep 3D Pan”, with “t-shaped” adaptive kernels equipped with globally and locally adaptive dilations. Our proposed network architecture, the monster-net, is devised with a novel t-shaped adaptive kernel with globally and locally adaptive dilation, which can efficiently incorporate global camera shift into and handle local 3D geometries of the target image’s pixels for the synthesis of naturally looking 3D panned views when a 2-D input image is given. Extensive experiments were performed on the KITTI, CityScapes, and our VICLAB_STEREO indoors dataset to prove the efficacy of our method. Our monster-net significantly outperforms the state-of-the-art method (SOTA) by a large margin in all metrics of RMSE, PSNR, and SSIM. Our proposed monster-net is capable of reconstructing more reliable image structures in synthesized images with coherent geometry. Moreover, the disparity information that can be extracted from the “t-shaped” kernel is much more reliable than that of the SOTA for the unsupervised monocular depth estimation task, confirming the effectiveness of our method.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1gF56VYPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJxK5pEYvr" data-number="715">
      <h4>
        <a href="/forum?id=HJxK5pEYvr">
            Tree-Structured Attention with Hierarchical Accumulation
        </a>
      
        
          <a href="/pdf?id=HJxK5pEYvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=nxphi47%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nxphi47@gmail.com">Xuan-Phi Nguyen</a>, <a href="/profile?email=sjoty%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjoty@salesforce.com">Shafiq Joty</a>, Steven Hoi, Richard Socher
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="#HJxK5pEYvr-details-154" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJxK5pEYvr-details-154"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Tree, Constituency Tree, Hierarchical Accumulation, Machine Translation, NMT, WMT, IWSLT, Text Classification, Sentiment Analysis</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Incorporating hierarchical structures like constituency trees has been shown to be effective for various natural language processing (NLP) tasks. However, it is evident that state-of-the-art (SOTA) sequence-based models like the Transformer struggle to encode such structures inherently. On the other hand, dedicated models like the Tree-LSTM, while explicitly modeling hierarchical structures, do not perform as efficiently as the Transformer. In this paper, we attempt to bridge this gap with Hierarchical Accumulation to encode parse tree structures into self-attention at constant time complexity. Our approach outperforms SOTA methods in four IWSLT translation tasks and the WMT'14 English-German task. It also yields improvements over Transformer and Tree-LSTM on three text classification tasks. We further demonstrate that using hierarchical priors can compensate for data shortage, and that our model prefers phrase-level attentions over token-level attentions.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJxK5pEYvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkgscaNYPS" data-number="720">
      <h4>
        <a href="/forum?id=SkgscaNYPS">
            The asymptotic spectrum of the Hessian of DNN throughout training
        </a>
      
        
          <a href="/pdf?id=SkgscaNYPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=arthur.jacot%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="arthur.jacot@epfl.ch">Arthur Jacot</a>, <a href="/profile?email=franck.gabriel%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="franck.gabriel@epfl.ch">Franck Gabriel</a>, <a href="/profile?email=clement.hongler%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="clement.hongler@epfl.ch">Clement Hongler</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SkgscaNYPS-details-832" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkgscaNYPS-details-832"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">theory of deep learning, loss surface, training, fisher information matrix</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Description of the limiting spectrum of the Hesian of the loss surface of DNNs in the infinite-width limit.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The dynamics of DNNs during gradient descent is described by the so-called Neural Tangent Kernel (NTK). In this article, we show that the NTK allows one to gain precise insight into the Hessian of the cost of DNNs: we obtain a full characterization of the asymptotics of the spectrum of the Hessian, at initialization and during training. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkgscaNYPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1lhqpEYPr" data-number="722">
      <h4>
        <a href="/forum?id=H1lhqpEYPr">
            Actor-Critic Provably Finds Nash Equilibria of Linear-Quadratic Mean-Field Games
        </a>
      
        
          <a href="/pdf?id=H1lhqpEYPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zuyuefu2022%40u.northwestern.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zuyuefu2022@u.northwestern.edu">Zuyue Fu</a>, <a href="/profile?email=zy6%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zy6@princeton.edu">Zhuoran Yang</a>, <a href="/profile?email=yongchen%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yongchen@gatech.edu">Yongxin Chen</a>, <a href="/profile?email=zhaoranwang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaoranwang@gmail.com">Zhaoran Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>20 Replies</span>
        
        
      </div>
      
        <a href="#H1lhqpEYPr-details-646" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1lhqpEYPr-details-646"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Actor-Critic method with function approximation finds the Nash equilibrium pairs in mean-field games with theoretical guarantee. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study discrete-time mean-field Markov games with infinite numbers of agents where each agent aims to minimize its ergodic cost. We consider the setting where the agents have identical linear state transitions and quadratic cost func- tions, while the aggregated effect of the agents is captured by the population mean of their states, namely, the mean-field state. For such a game, based on the Nash certainty equivalence principle, we provide sufficient conditions for the existence and uniqueness of its Nash equilibrium. Moreover, to find the Nash equilibrium, we propose a mean-field actor-critic algorithm with linear function approxima- tion, which does not require knowing the model of dynamics. Specifically, at each iteration of our algorithm, we use the single-agent actor-critic algorithm to approximately obtain the optimal policy of the each agent given the current mean- field state, and then update the mean-field state. In particular, we prove that our algorithm converges to the Nash equilibrium at a linear rate. To the best of our knowledge, this is the first success of applying model-free reinforcement learn- ing with function approximation to discrete-time mean-field Markov games with provable non-asymptotic global convergence guarantees.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1lhqpEYPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJx-j64FDr" data-number="732">
      <h4>
        <a href="/forum?id=SJx-j64FDr">
            In Search for a SAT-friendly Binarized Neural Network Architecture
        </a>
      
        
          <a href="/pdf?id=SJx-j64FDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=n.narodytska%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="n.narodytska@gmail.com">Nina Narodytska</a>, <a href="/profile?email=hongcez%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hongcez@princeton.edu">Hongce Zhang</a>, <a href="/profile?email=aartig%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aartig@cs.princeton.edu">Aarti Gupta</a>, <a href="/profile?email=toby.walsh%40data61.csiro.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="toby.walsh@data61.csiro.au">Toby Walsh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#SJx-j64FDr-details-502" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJx-j64FDr-details-502"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Formal analysis of  Binarized Neural Networks </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Analyzing the behavior of neural networks is  one of the most pressing challenges in deep learning.  Binarized Neural Networks are an important class of networks that allow equivalent representation in Boolean logic and can be analyzed formally with logic-based reasoning tools like SAT solvers. Such tools can be used to answer existential and probabilistic queries about the network, perform explanation generation, etc. However, the main bottleneck for all methods is their ability to reason about large BNNs efficiently. In this work, we analyze architectural design choices of BNNs and discuss how they affect the performance of logic-based reasoners. We propose changes to the BNN architecture and the training procedure to get a simpler network for SAT solvers without sacrificing accuracy on the primary task. Our experimental results demonstrate that our approach scales to larger deep neural networks compared to existing work for existential and probabilistic queries, leading to significant speed ups on all tested datasets.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">verification, Boolean satisfiability, Binarized Neural Networks</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJx-j64FDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJg7spEYDS" data-number="737">
      <h4>
        <a href="/forum?id=SJg7spEYDS">
            Generative Ratio Matching Networks
        </a>
      
        
          <a href="/pdf?id=SJg7spEYDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=akash.srivastava%40me.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="akash.srivastava@me.com">Akash Srivastava</a>, <a href="/profile?email=kai.xu%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="kai.xu@ed.ac.uk">Kai Xu</a>, <a href="/profile?email=michael.gutmann%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael.gutmann@ed.ac.uk">Michael U. Gutmann</a>, <a href="/profile?email=charlessutton%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="charlessutton@google.com">Charles Sutton</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="#SJg7spEYDS-details-927" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJg7spEYDS-details-927"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep generative model, deep learning, maximum mean discrepancy, density ratio estimation</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep generative models can learn to generate realistic-looking images, but many of the most effective methods are adversarial and involve a saddlepoint optimization, which requires a careful balancing of training between a generator network and a critic network. Maximum mean discrepancy networks (MMD-nets) avoid this issue by using kernel as a fixed adversary, but unfortunately, they have not on their own been able to match the generative quality of adversarial training. In this work, we take their insight of using kernels as fixed adversaries further and present a novel method for training deep generative models that does not involve saddlepoint optimization. We call our method generative ratio matching or GRAM for short. In GRAM, the generator and the critic networks do not play a zero-sum game against each other, instead, they do so against a fixed kernel. Thus GRAM networks are not only stable to train like MMD-nets but they also match and beat the generative quality of adversarially trained generative networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/GRAM-nets</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">MMD-based, saddle-point optimisation free, stable-to-train generative model that beats GAN on generative quality without playing any  zero-sum games.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJg7spEYDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylHspEKPr" data-number="743">
      <h4>
        <a href="/forum?id=rylHspEKPr">
            Learning to Represent Programs with Property Signatures
        </a>
      
        
          <a href="/pdf?id=rylHspEKPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=augustusodena%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="augustusodena@google.com">Augustus Odena</a>, <a href="/profile?email=csutton%40inf.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="csutton@inf.ed.ac.uk">Charles Sutton</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#rylHspEKPr-details-560" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylHspEKPr-details-560"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Program Synthesis</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We represent a computer program using a set of simpler programs and use this representation to improve program synthesis techniques.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We introduce the notion of property signatures, a representation for programs and
      program specifications meant for consumption by machine learning algorithms.
      Given a function with input type τ_in and output type τ_out, a property is a function
      of type: (τ_in, τ_out) → Bool that (informally) describes some simple property
      of the function under consideration. For instance, if τ_in and τ_out are both lists
      of the same type, one property might ask ‘is the input list the same length as the
      output list?’. If we have a list of such properties, we can evaluate them all for our
      function to get a list of outputs that we will call the property signature. Crucially,
      we can ‘guess’ the property signature for a function given only a set of input/output
      pairs meant to specify that function. We discuss several potential applications of
      property signatures and show experimentally that they can be used to improve
      over a baseline synthesizer so that it emits twice as many programs in less than
      one-tenth of the time.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/brain-research/searcho</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rylHspEKPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJeLopEYDH" data-number="745">
      <h4>
        <a href="/forum?id=SJeLopEYDH">
            V4D: 4D Convolutional Neural Networks for Video-level Representation Learning
        </a>
      
        
          <a href="/pdf?id=SJeLopEYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=shizhang%40malong.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shizhang@malong.com">Shiwen Zhang</a>, <a href="/profile?email=sheng%40malong.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sheng@malong.com">Sheng Guo</a>, <a href="/profile?email=whuang%40malong.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="whuang@malong.com">Weilin Huang</a>, <a href="/profile?email=mscott%40malong.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mscott@malong.com">Matthew R. Scott</a>, <a href="/profile?email=07wanglimin%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="07wanglimin@gmail.com">Limin Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 17 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SJeLopEYDH-details-548" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJeLopEYDH-details-548"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A novel 4D CNN structure for video-level representation learning, surpassing  recent 3D CNNs.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Most existing 3D CNN structures for video representation learning are clip-based methods, and do not consider video-level temporal evolution of spatio-temporal features. In this paper, we propose Video-level 4D Convolutional Neural Networks, namely V4D, to model the evolution of long-range spatio-temporal representation with 4D convolutions, as well as preserving 3D spatio-temporal representations with residual connections. We further introduce the training and inference methods for the proposed V4D. Extensive experiments are conducted on three video recognition benchmarks, where V4D achieves excellent results, surpassing recent 3D CNNs by a large margin.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">video-level representation learning, video action recognition, 4D CNNs</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJeLopEYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1gqipNYwH" data-number="755">
      <h4>
        <a href="/forum?id=B1gqipNYwH">
            Option Discovery using Deep Skill Chaining
        </a>
      
        
          <a href="/pdf?id=B1gqipNYwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=akhil_bagaria%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="akhil_bagaria@brown.edu">Akhil Bagaria</a>, <a href="/profile?email=gdk%40cs.brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gdk@cs.brown.edu">George Konidaris</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#B1gqipNYwH-details-323" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1gqipNYwH-details-323"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Hierarchical Reinforcement Learning, Reinforcement Learning, Skill Discovery, Deep Learning, Deep Reinforcement Learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present a new hierarchical reinforcement learning algorithm which can solve high-dimensional goal-oriented tasks  more reliably than non-hierarchical agents and other state-of-the-art skill discovery techniques.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Autonomously discovering temporally extended actions, or skills, is a longstanding goal of hierarchical reinforcement learning. We propose a new algorithm that combines skill chaining with deep neural networks to autonomously discover skills in high-dimensional, continuous domains. The resulting algorithm, deep skill chaining, constructs skills with the property that executing one enables the agent to execute another. We demonstrate that deep skill chaining significantly outperforms both non-hierarchical agents and other state-of-the-art skill discovery techniques in challenging continuous control tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/deep-skill-chaining/deep-skill-chaining</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1gqipNYwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyxG3p4twS" data-number="772">
      <h4>
        <a href="/forum?id=HyxG3p4twS">
            Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations
        </a>
      
        
          <a href="/pdf?id=HyxG3p4twS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=pkorus%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pkorus@nyu.edu">Pawel Korus</a>, <a href="/profile?email=memon%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="memon@nyu.edu">Nasir Memon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#HyxG3p4twS-details-566" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyxG3p4twS-details-566"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">image forensics, photo manipulation detection, learned compression, lossy compression, image compression, entropy estimation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We learn an efficient lossy image codec that can be optimized to facilitate reliable photo manipulation detection at fractional cost in payload/quality and even at low bitrates.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Detection of photo manipulation relies on subtle statistical traces, notoriously removed by aggressive lossy compression employed online. We demonstrate that end-to-end modeling of complex photo dissemination channels allows for codec optimization with explicit provenance objectives. We design a lightweight trainable lossy image codec, that delivers competitive rate-distortion performance, on par with best hand-engineered alternatives, but has lower computational footprint on modern GPU-enabled platforms. Our results show that significant improvements in manipulation detection accuracy are possible at fractional costs in bandwidth/storage. Our codec improved the accuracy from 37% to 86% even at very low bit-rates, well below the practicality of JPEG (QF 20). </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/pkorus/neural-imaging</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HyxG3p4twS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgz2aEKDr" data-number="774">
      <h4>
        <a href="/forum?id=rkgz2aEKDr">
            On the Variance of the Adaptive Learning Rate and Beyond
        </a>
      
        
          <a href="/pdf?id=rkgz2aEKDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ll2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ll2@illinois.edu">Liyuan Liu</a>, <a href="/profile?email=jianghm%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianghm@gatech.edu">Haoming Jiang</a>, <a href="/profile?email=penhe%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="penhe@microsoft.com">Pengcheng He</a>, <a href="/profile?email=wzchen%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wzchen@microsoft.com">Weizhu Chen</a>, <a href="/profile?email=xiaodl%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaodl@microsoft.com">Xiaodong Liu</a>, <a href="/profile?email=jfgao%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jfgao@microsoft.com">Jianfeng Gao</a>, <a href="/profile?email=hanj%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanj@illinois.edu">Jiawei Han</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="#rkgz2aEKDr-details-744" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgz2aEKDr-details-744"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">warmup, adam, adaptive learning rate, variance</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">If warmup is the answer, what is the question?</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The learning rate warmup heuristic achieves remarkable success in stabilizing training, accelerating convergence and improving generalization for adaptive stochastic optimization algorithms like RMSprop and Adam. Pursuing the theory behind warmup, we identify a problem of the adaptive learning rate -- its variance is problematically large in the early stage, and presume warmup works as a variance reduction technique. We provide both empirical and theoretical evidence to verify our hypothesis. We further propose Rectified Adam (RAdam), a novel variant of Adam, by introducing a term to rectify the variance of the adaptive learning rate. Experimental results on image classification, language modeling, and neural machine translation verify our intuition and demonstrate the efficacy and robustness of RAdam. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/LiyuanLucasLiu/RAdam</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgz2aEKDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1lmhaVtvr" data-number="776">
      <h4>
        <a href="/forum?id=H1lmhaVtvr">
            Dynamical Distance Learning for Semi-Supervised and Unsupervised Skill Discovery
        </a>
      
        
          <a href="/pdf?id=H1lmhaVtvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kristian.hartikainen%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kristian.hartikainen@gmail.com">Kristian Hartikainen</a>, <a href="/profile?email=young.geng%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="young.geng@berkeley.edu">Xinyang Geng</a>, <a href="/profile?email=tuomash%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tuomash@google.com">Tuomas Haarnoja</a>, <a href="/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="#H1lmhaVtvr-details-191" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1lmhaVtvr-details-191"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We show how to automatically learn dynamical distances in reinforcement learning setting and use them to provide well-shaped reward functions for reaching new goals.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Reinforcement learning requires manual specification of a reward function to learn a task. While in principle this reward function only needs to specify the task goal, in practice reinforcement learning can be very time-consuming or even infeasible unless the reward function is shaped so as to provide a smooth gradient towards a successful outcome. This shaping is difficult to specify by hand, particularly when the task is learned from raw observations, such as images. In this paper, we study how we can automatically learn dynamical distances: a measure of the expected number of time steps to reach a given goal state from any other state. These dynamical distances can be used to provide well-shaped reward functions for reaching new goals, making it possible to learn complex tasks efficiently. We show that dynamical distances can be used in a semi-supervised regime, where unsupervised interaction with the environment is used to learn the dynamical distances, while a small amount of preference supervision is used to determine the task goal, without any manually engineered reward function or goal examples. We evaluate our method both on a real-world robot and in simulation. We show that our method can learn to turn a valve with a real-world 9-DoF hand, using raw image observations and just ten preference labels, without any other supervision. Videos of the learned skills can be found on the project website: https://sites.google.com/view/dynamical-distance-learning</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, semi-supervised learning, unsupervised learning, robotics, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1lmhaVtvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkgB2TNYPS" data-number="780">
      <h4>
        <a href="/forum?id=HkgB2TNYPS">
            A Theoretical Analysis of the Number of Shots in Few-Shot Learning
        </a>
      
        
          <a href="/pdf?id=HkgB2TNYPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tianshi.cao%40mail.utoronto.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianshi.cao@mail.utoronto.ca">Tianshi Cao</a>, <a href="/profile?email=law%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="law@cs.toronto.edu">Marc T Law</a>, <a href="/profile?email=fidler%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fidler@cs.toronto.edu">Sanja Fidler</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HkgB2TNYPS-details-242" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkgB2TNYPS-details-242"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">The paper analyzes the effect of shot number on prototypical networks and proposes a robust method when the shot number differs from meta-training to meta-testing time.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Few-shot classification is the task of predicting the category of an example from a set of few labeled examples. The number of labeled examples per category is called the number of shots (or shot number). Recent works tackle this task through meta-learning, where a meta-learner extracts information from observed tasks during meta-training to quickly adapt to new tasks during meta-testing. In this formulation, the number of shots exploited during meta-training has an impact on the recognition performance at meta-test time. Generally, the shot number used in meta-training should match the one used in meta-testing to obtain the best performance. We introduce a theoretical analysis of the impact of the shot number on Prototypical Networks, a state-of-the-art few-shot classification method. From our analysis, we propose a simple method that is robust to the choice of shot number used during meta-training, which is a crucial hyperparameter. The performance of our model trained for an arbitrary meta-training shot number shows great performance for different values of meta-testing shot numbers. We experimentally demonstrate our approach on different few-shot classification benchmarks.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Few shot learning, Meta Learning, Performance Bounds</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkgB2TNYPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyxL2TNtvr" data-number="783">
      <h4>
        <a href="/forum?id=SyxL2TNtvr">
            Unsupervised Model Selection for Variational Disentangled Representation Learning
        </a>
      
        
          <a href="/pdf?id=SyxL2TNtvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sunnyd%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sunnyd@google.com">Sunny Duan</a>, <a href="/profile?email=lmatthey%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lmatthey@google.com">Loic Matthey</a>, <a href="/profile?email=andresnds%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="andresnds@google.com">Andre Saraiva</a>, <a href="/profile?email=nwatters%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nwatters@google.com">Nick Watters</a>, <a href="/profile?email=cpburgess%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cpburgess@google.com">Chris Burgess</a>, <a href="/profile?email=lerchner%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lerchner@google.com">Alexander Lerchner</a>, <a href="/profile?email=irinah%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="irinah@google.com">Irina Higgins</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>22 Replies</span>
        
        
      </div>
      
        <a href="#SyxL2TNtvr-details-476" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyxL2TNtvr-details-476"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">unsupervised disentanglement metric, disentangling, representation learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce a method for unsupervised disentangled model selection for VAE-based disentangled representation learning approaches.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Disentangled representations have recently been shown to improve fairness, data efficiency and generalisation in simple supervised and reinforcement learning tasks. To extend the benefits of disentangled representations to more complex domains and practical applications, it is important to enable hyperparameter tuning and model selection of existing unsupervised approaches without requiring access to ground truth attribute labels, which are not available for most datasets. This paper addresses this problem by introducing a simple yet robust and reliable method for unsupervised disentangled model selection. We show that our approach performs comparably to the existing supervised alternatives across 5400 models from six state of the art unsupervised disentangled representation learning model classes. Furthermore, we show that the ranking produced by our approach correlates well with the final task performance on two different domains.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SyxL2TNtvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkgnhTEtDS" data-number="795">
      <h4>
        <a href="/forum?id=BkgnhTEtDS">
            Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection
        </a>
      
        
          <a href="/pdf?id=BkgnhTEtDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tsangm%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tsangm@usc.edu">Michael Tsang</a>, <a href="/profile?email=dehuacheng%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dehuacheng@fb.com">Dehua Cheng</a>, <a href="/profile?email=hanpengl%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanpengl@usc.edu">Hanpeng Liu</a>, <a href="/profile?email=xfeng%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xfeng@fb.com">Xue Feng</a>, <a href="/profile?email=hanningz%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanningz@fb.com">Eric Zhou</a>, <a href="/profile?email=yanliu.cs%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanliu.cs@usc.edu">Yan Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#BkgnhTEtDS-details-337" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkgnhTEtDS-details-337"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Feature Interaction, Interpretability, Black Box, AutoML</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Proposed methods to extract and leverage interpretations of feature interactions</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recommendation is a prevalent application of machine learning that affects many users; therefore, it is important for recommender models to be accurate and interpretable. In this work, we propose a method to both interpret and augment the predictions of black-box recommender systems. In particular, we propose to interpret feature interactions from a source recommender model and explicitly encode these interactions in a target recommender model, where both source and target models are black-boxes. By not assuming the structure of the recommender system, our approach can be used in general settings. In our experiments, we focus on a prominent use of machine learning recommendation: ad-click prediction. We found that our interaction interpretations are both informative and predictive, e.g., significantly outperforming existing recommender models. What's more, the same approach to interpret interactions can provide new insights into domains even beyond recommendation, such as text and image classification.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/mtsang/interaction_interpretability</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BkgnhTEtDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1x62TNtDS" data-number="799">
      <h4>
        <a href="/forum?id=B1x62TNtDS">
            Understanding the Limitations of Variational Mutual Information Estimators
        </a>
      
        
          <a href="/pdf?id=B1x62TNtDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jiaming.tsong%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiaming.tsong@gmail.com">Jiaming Song</a>, <a href="/profile?email=ermon%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ermon@cs.stanford.edu">Stefano Ermon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 24 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>4 Replies</span>
        
        
      </div>
      
        <a href="#B1x62TNtDS-details-393" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1x62TNtDS-details-393"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Variational approaches based on neural networks are showing promise for estimating mutual information (MI) between high dimensional variables. However, they can be difficult to use in practice due to poorly understood bias/variance tradeoffs. We theoretically show that, under some conditions, estimators such as MINE exhibit variance that could grow exponentially with the true  amount of underlying MI. We also empirically demonstrate that existing estimators fail to satisfy basic self-consistency properties of MI, such as data processing and additivity under independence. Based on a unified perspective of variational approaches, we develop a new estimator that focuses on variance reduction. Empirical results on standard benchmark tasks demonstrate that our proposed estimator exhibits improved bias-variance trade-offs on standard benchmark tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/ermongroup/smile-mi-estimator</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1x62TNtDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkxfaTVFwH" data-number="810">
      <h4>
        <a href="/forum?id=BkxfaTVFwH">
            GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations
        </a>
      
        
          <a href="/pdf?id=BkxfaTVFwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=martin%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="martin@robots.ox.ac.uk">Martin Engelcke</a>, <a href="/profile?email=adamk%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="adamk@robots.ox.ac.uk">Adam R. Kosiorek</a>, <a href="/profile?email=oiwi%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="oiwi@robots.ox.ac.uk">Oiwi Parker Jones</a>, <a href="/profile?email=ingmar%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="ingmar@robots.ox.ac.uk">Ingmar Posner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#BkxfaTVFwH-details-755" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkxfaTVFwH-details-755"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present the first object-centric generative model of 3D visual scenes capable of both decomposing and generating scenes.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Generative latent-variable models are emerging as promising tools in robotics and reinforcement learning. Yet, even though tasks in these domains typically involve distinct objects, most state-of-the-art generative models do not explicitly capture the compositional nature of visual scenes. Two recent exceptions, MONet and IODINE, decompose scenes into objects in an unsupervised fashion. Their underlying generative processes, however, do not account for component interactions. Hence, neither of them allows for principled sampling of novel scenes. Here we present GENESIS, the first  object-centric generative model of 3D visual scenes capable of both decomposing and generating scenes by capturing relationships between scene components. GENESIS parameterises a spatial GMM over images which is decoded from a set of object-centric latent variables that are either inferred sequentially in an amortised fashion or sampled from an autoregressive prior. We train GENESIS on several publicly available datasets and evaluate its performance on scene generation, decomposition, and semi-supervised learning.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Generative modelling, object-centric representations, scene generation, variational inference</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/applied-ai-lab/genesis</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BkxfaTVFwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJgza6VtPB" data-number="811">
      <h4>
        <a href="/forum?id=BJgza6VtPB">
            Language GANs Falling Short
        </a>
      
        
          <a href="/pdf?id=BJgza6VtPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=massimo.p.caccia%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="massimo.p.caccia@gmail.com">Massimo Caccia</a>, <a href="/profile?email=lucas.page-caccia%40mail.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="lucas.page-caccia@mail.mcgill.ca">Lucas Caccia</a>, <a href="/profile?email=liam.fedus%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liam.fedus@gmail.com">William Fedus</a>, <a href="/profile?email=hugolarochelle%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hugolarochelle@google.com">Hugo Larochelle</a>, <a href="/profile?email=jpineau%40cs.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="jpineau@cs.mcgill.ca">Joelle Pineau</a>, <a href="/profile?email=lcharlin%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lcharlin@gmail.com">Laurent Charlin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="#BJgza6VtPB-details-820" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJgza6VtPB-details-820"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">GANs have been applied to text generation and are believed SOTA. However, we propose a new evaluation protocol demonstrating that maximum-likelihood trained models are still better.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Traditional natural language generation  (NLG) models are trained using maximum likelihood estimation (MLE) which differs from the sample generation inference procedure. During training the ground truth tokens are passed to the model, however, during inference, the model instead reads its previously generated samples - a phenomenon coined exposure bias. Exposure bias was hypothesized to be a root cause of poor sample quality and thus many generative adversarial networks (GANs) were proposed as a remedy since they have identical training and inference.  However, many of the ensuing GAN variants validated sample quality improvements but ignored loss of sample diversity. This work reiterates the fallacy of quality-only metrics and clearly demonstrate that the well-established technique of reducing softmax temperature can outperform GANs on a quality-only metric. Further, we establish a definitive quality-diversity evaluation procedure using temperature tuning over local and global sample metrics. Under this, we find that MLE models consistently outperform the proposed GAN variants over the whole quality-diversity space.  Specifically, we find that 1) exposure bias appears to be less of an issue than the complications arising from non-differentiable, sequential GAN training;  2) MLE trained models provide a better quality/diversity trade-off compared to their GAN counterparts, all while being easier to train, easier to cross-validate, and less computationally expensive.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/pclucas14/GansFallingShort</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">NLP, GAN, MLE, adversarial, text generation, temperature</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJgza6VtPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1lSapVtwS" data-number="817">
      <h4>
        <a href="/forum?id=S1lSapVtwS">
            Stochastic Conditional Generative Networks with Basis Decomposition
        </a>
      
        
          <a href="/pdf?id=S1lSapVtwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ze.w%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ze.w@duke.edu">Ze Wang</a>, <a href="/profile?email=xiuyuan.cheng%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiuyuan.cheng@duke.edu">Xiuyuan Cheng</a>, <a href="/profile?email=guillermo.sapiro%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guillermo.sapiro@duke.edu">Guillermo Sapiro</a>, <a href="/profile?email=qiang.qiu%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qiang.qiu@duke.edu">Qiang Qiu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#S1lSapVtwS-details-402" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1lSapVtwS-details-402"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1lSapVtwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgO66VKDS" data-number="824">
      <h4>
        <a href="/forum?id=rkgO66VKDS">
            LEARNED STEP SIZE QUANTIZATION
        </a>
      
        
          <a href="/pdf?id=rkgO66VKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sesser%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sesser@us.ibm.com">Steven K. Esser</a>, <a href="/profile?email=jlmckins%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jlmckins@us.ibm.com">Jeffrey L. McKinstry</a>, <a href="/profile?email=deepika.bablani%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="deepika.bablani@ibm.com">Deepika Bablani</a>, <a href="/profile?email=rappusw%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rappusw@us.ibm.com">Rathinakumar Appuswamy</a>, <a href="/profile?email=dmodha%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dmodha@us.ibm.com">Dharmendra S. Modha</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rkgO66VKDS-details-40" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgO66VKDS-details-40"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, low precision, classification, quantization</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A method for learning quantization configuration for low precision networks that achieves state of the art performance for quantized networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep networks run with low precision operations at inference time offer power and space advantages over high precision alternatives, but need to overcome the challenge of maintaining high accuracy as precision decreases. Here, we present a method for training such networks, Learned Step Size Quantization, that achieves the highest accuracy to date on the ImageNet dataset when using models, from a variety of architectures, with weights and activations quantized to 2-, 3- or 4-bits of precision, and that can train 3-bit models that reach full precision baseline accuracy. Our approach builds upon existing methods for learning weights in quantized networks by improving how the quantizer itself is configured. Specifically, we introduce a novel means to estimate and scale the task loss gradient at each weight and activation layer's quantizer step size, such that it can be learned in conjunction with other network parameters. This approach works using different levels of precision as needed for a given system and requires only a simple modification of existing training code.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgO66VKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HylsTT4FvB" data-number="832">
      <h4>
        <a href="/forum?id=HylsTT4FvB">
            On the "steerability" of generative adversarial networks
        </a>
      
        
          <a href="/pdf?id=HylsTT4FvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jahanian%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jahanian@mit.edu">Ali Jahanian*</a>, <a href="/profile?email=lrchai%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lrchai@mit.edu">Lucy Chai*</a>, <a href="/profile?email=phillipi%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="phillipi@mit.edu">Phillip Isola</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HylsTT4FvB-details-487" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HylsTT4FvB-details-487"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">An open secret in contemporary machine learning is that many models work beautifully on standard benchmarks but fail to generalize outside the lab. This has been attributed to biased training data, which provide poor coverage over real world events. Generative models are no exception, but recent advances in generative adversarial networks (GANs) suggest otherwise -- these models can now synthesize strikingly realistic and diverse images. Is generative modeling of photos a solved problem? We show that although current GANs can fit standard datasets very well, they still fall short of being comprehensive models of the visual manifold. In particular, we study their ability to fit simple transformations such as camera movements and color changes. We find that the models reflect the biases of the datasets on which they are trained (e.g., centered objects), but that they also exhibit some capacity for generalization: by "steering" in latent space, we can shift the distribution while still creating realistic images. We hypothesize that the degree of distributional shift is related to the breadth of the training data distribution. Thus, we conduct experiments to quantify the limits of GAN transformations and introduce techniques to mitigate the problem.   Code is released on our project page: https://ali-design.github.io/gan_steerability/</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">generative adversarial network, latent space interpolation, dataset bias, model generalization</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Interpolations in the latent space demonstrate generalization capacity of GANs and the effect of dataset biases.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HylsTT4FvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkgC6TNFvr" data-number="839">
      <h4>
        <a href="/forum?id=SkgC6TNFvr">
            Reinforced active learning for image segmentation
        </a>
      
        
          <a href="/pdf?id=SkgC6TNFvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=arantxa.casanova-paga%40polymtl.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="arantxa.casanova-paga@polymtl.ca">Arantxa Casanova</a>, <a href="/profile?email=pedro%40opinheiro.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pedro@opinheiro.com">Pedro O. Pinheiro</a>, <a href="/profile?email=negar%40elementai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="negar@elementai.com">Negar Rostamzadeh</a>, <a href="/profile?email=chris.j.pal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chris.j.pal@gmail.com">Christopher J. Pal</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SkgC6TNFvr-details-195" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkgC6TNFvr-details-195"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">semantic segmentation, active learning, reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Learning a labeling policy with reinforcement learning to reduce labeling effort for the task of semantic segmentation</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Learning-based approaches for semantic segmentation have two inherent challenges. First, acquiring pixel-wise labels is expensive and time-consuming. Second, realistic segmentation datasets are highly unbalanced: some categories are much more abundant than others, biasing the performance to the most represented ones. In this paper, we are interested in focusing human labelling effort on a small subset of a larger pool of data, minimizing this effort while maximizing performance of a segmentation model on a hold-out set. We present a new active learning strategy for semantic segmentation based on deep reinforcement learning (RL). An agent learns a policy to select a subset of small informative image regions -- opposed to entire images -- to be labeled, from a pool of unlabeled data. The region selection decision is made based on predictions and uncertainties of the segmentation model being trained. Our method proposes a new modification of the deep Q-network (DQN) formulation for active learning, adapting it to the large-scale nature of semantic segmentation problems. We test the proof of concept in CamVid and provide results in the large-scale dataset Cityscapes. On Cityscapes, our deep RL region-based DQN approach requires roughly 30% less additional labeled data than our most competitive baseline to reach the same performance. Moreover, we find that our method asks for more labels of under-represented categories compared to the baselines, improving their performance and helping to mitigate class imbalance.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkgC6TNFvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SygW0TEFwH" data-number="844">
      <h4>
        <a href="/forum?id=SygW0TEFwH">
            Sign Bits Are All You Need for Black-Box Attacks
        </a>
      
        
          <a href="/pdf?id=SygW0TEFwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ash.aldujaili%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ash.aldujaili@gmail.com">Abdullah Al-Dujaili</a>, <a href="/profile?email=unamay%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="unamay@csail.mit.edu">Una-May O'Reilly</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#SygW0TEFwH-details-748" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SygW0TEFwH-details-748"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Black-box adversarial attack models, Deep Nets, Adversarial Examples, Black-Box Optimization, Zeroth-Order Optimization</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present a sign-based, rather than magnitude-based, gradient estimation approach that shifts gradient estimation from continuous to binary black-box optimization.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present a novel black-box adversarial attack algorithm with state-of-the-art model evasion rates for query efficiency under <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="420" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-n" size="s"><mjx-c class="mjx-c221E"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mi mathvariant="normal">∞</mi></msub></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="421" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mn>2</mn></msub></math></mjx-assistive-mml></mjx-container> metrics. It exploits a \textit{sign-based}, rather than magnitude-based, gradient estimation approach that shifts the gradient estimation from continuous to binary black-box optimization. It adaptively constructs queries to estimate the gradient, one query relying upon the previous, rather than re-estimating the gradient each step with random query construction. Its reliance on sign bits yields  a smaller memory footprint and it requires neither hyperparameter tuning or dimensionality reduction. Further, its theoretical performance is guaranteed and it can characterize  adversarial subspaces better than white-box gradient-aligned subspaces. On two public black-box attack challenges and a model robustly trained against transfer attacks, the algorithm's evasion rates surpass all submitted attacks. For a suite of published models,  the algorithm is <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="422" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>3.8</mn><mo>×</mo></math></mjx-assistive-mml></mjx-container> less failure-prone while spending <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="423" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2.5</mn><mo>×</mo></math></mjx-assistive-mml></mjx-container>  fewer queries versus the best combination of state of art algorithms. For example, it evades a standard MNIST model using just <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="424" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>12</mn></math></mjx-assistive-mml></mjx-container> queries on average. Similar performance is observed on a standard IMAGENET model with an average of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="425" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c37"></mjx-c><mjx-c class="mjx-c39"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>579</mn></math></mjx-assistive-mml></mjx-container> queries.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/ash-aldujaili/blackbox-adv-examples-signhunter</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SygW0TEFwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkgH0TEYwH" data-number="854">
      <h4>
        <a href="/forum?id=HkgH0TEYwH">
            Deep Semi-Supervised Anomaly Detection
        </a>
      
        
          <a href="/pdf?id=HkgH0TEYwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=contact%40lukasruff.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="contact@lukasruff.com">Lukas Ruff</a>, <a href="/profile?email=vandermeulen%40cs.uni-kl.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="vandermeulen@cs.uni-kl.de">Robert A. Vandermeulen</a>, <a href="/profile?email=nico.goernitz%40tu-berlin.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="nico.goernitz@tu-berlin.de">Nico Görnitz</a>, <a href="/profile?email=alexander_binder%40sutd.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexander_binder@sutd.edu.sg">Alexander Binder</a>, <a href="/profile?email=mueller%40bit.uni-bonn.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="mueller@bit.uni-bonn.de">Emmanuel Müller</a>, <a href="/profile?email=klaus-robert.mueller%40tu-berlin.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="klaus-robert.mueller@tu-berlin.de">Klaus-Robert Müller</a>, <a href="/profile?email=kloft%40cs.uni-kl.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="kloft@cs.uni-kl.de">Marius Kloft</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HkgH0TEYwH-details-66" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkgH0TEYwH-details-66"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/lukasruff/Deep-SAD-PyTorch</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">anomaly detection, deep learning, semi-supervised learning, unsupervised learning, outlier detection, one-class classification, deep anomaly detection, deep one-class classification</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkgH0TEYwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyxLRTVKPH" data-number="856">
      <h4>
        <a href="/forum?id=HyxLRTVKPH">
            Budgeted Training: Rethinking Deep Neural Network Training Under Resource Constraints
        </a>
      
        
          <a href="/pdf?id=HyxLRTVKPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mtli%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mtli@cs.cmu.edu">Mengtian Li</a>, <a href="/profile?email=meyumer%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="meyumer@gmail.com">Ersin Yumer</a>, <a href="/profile?email=deva%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="deva@cs.cmu.edu">Deva Ramanan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HyxLRTVKPH-details-469" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyxLRTVKPH-details-469"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Introduce a formal setting for budgeted training and propose a budget-aware linear learning rate schedule</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In most practical settings and theoretical analyses, one assumes that a model can be trained until convergence. However, the growing complexity of machine learning datasets and models may violate such assumptions. Indeed, current approaches for hyper-parameter tuning and neural architecture search tend to be limited by practical resource constraints. Therefore, we introduce a formal setting for studying training under the non-asymptotic, resource-constrained regime, i.e., budgeted training. We analyze the following problem: "given a dataset, algorithm, and fixed resource budget, what is the best achievable performance?" We focus on the number of optimization iterations as the representative resource. Under such a setting, we show that it is critical to adjust the learning rate schedule according to the given budget. Among budget-aware learning schedules, we find simple linear decay to be both robust and high-performing. We support our claim through extensive experiments with state-of-the-art models on ImageNet (image classification), Kinetics (video classification), MS COCO (object detection and instance segmentation), and Cityscapes (semantic segmentation). We also analyze our results and find that the key to a good schedule is budgeted convergence, a phenomenon whereby the gradient vanishes at the end of each allowed budget. We also revisit existing approaches for fast convergence and show that budget-aware learning schedules readily outperform such approaches under (the practical but under-explored) budgeted training setting.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">budgeted training, learning rate schedule, linear schedule, annealing, learning rate decay</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HyxLRTVKPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SygpC6Ntvr" data-number="873">
      <h4>
        <a href="/forum?id=SygpC6Ntvr">
            Minimizing FLOPs to Learn Efficient Sparse Representations
        </a>
      
        
          <a href="/pdf?id=SygpC6Ntvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=bparia%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bparia@cs.cmu.edu">Biswajit Paria</a>, <a href="/profile?email=cjyeh%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cjyeh@cs.cmu.edu">Chih-Kuan Yeh</a>, <a href="/profile?email=a061105%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="a061105@gmail.com">Ian E.H. Yen</a>, <a href="/profile?email=ningxu01%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ningxu01@gmail.com">Ning Xu</a>, <a href="/profile?email=pradeepr%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pradeepr@cs.cmu.edu">Pradeep Ravikumar</a>, <a href="/profile?email=bapoczos%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bapoczos@cs.cmu.edu">Barnabás Póczos</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 13 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#SygpC6Ntvr-details-694" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SygpC6Ntvr-details-694"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">sparse embeddings, deep representations, metric learning, regularization</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose an approach to learn sparse high dimensional representations that are fast to search, by incorporating a surrogate of the number of operations directly into the loss function.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep representation learning has become one of the most widely adopted approaches for visual search, recommendation, and identification. Retrieval of such  representations from a large database is however computationally challenging. Approximate methods based on learning compact representations, have been widely explored for this problem, such as locality sensitive hashing, product quantization, and PCA. In this work, in contrast to learning compact representations, we propose to learn high dimensional and sparse representations that have similar representational capacity as dense embeddings while being more efficient due to sparse matrix multiplication operations which can be much faster than dense multiplication. Following the key insight that the number of operations decreases quadratically with the sparsity of embeddings provided the non-zero entries are distributed uniformly across dimensions, we propose a novel approach to learn such distributed sparse embeddings via the use of a carefully constructed regularization function that directly minimizes a continuous relaxation of the number of floating-point operations (FLOPs) incurred during retrieval. Our experiments show that our approach is competitive to the other baselines and yields a similar or better speed-vs-accuracy tradeoff on practical datasets.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/biswajitsc/sparse-embed</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SygpC6Ntvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1ly10EKDS" data-number="877">
      <h4>
        <a href="/forum?id=S1ly10EKDS">
            Reanalysis of Variance Reduced Temporal Difference Learning
        </a>
      
        
          <a href="/pdf?id=S1ly10EKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xu.3260%40osu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xu.3260@osu.edu">Tengyu Xu</a>, <a href="/profile?email=wang.10982%40osu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wang.10982@osu.edu">Zhe Wang</a>, <a href="/profile?email=yi.zhou%40utah.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yi.zhou@utah.edu">Yi Zhou</a>, <a href="/profile?email=liang.889%40osu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liang.889@osu.edu">Yingbin Liang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#S1ly10EKDS-details-81" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1ly10EKDS-details-81"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper provides a rigorous study of the variance reduced TD learning and characterizes its advantage over vanilla TD learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Temporal difference (TD) learning is a popular algorithm for policy evaluation in reinforcement learning, but the vanilla TD can substantially suffer from the inherent optimization variance. A variance reduced TD (VRTD) algorithm was proposed by \cite{korda2015td}, which applies the variance reduction technique directly to the online TD learning with Markovian samples. In this work, we first point out the technical errors in the analysis of VRTD in \cite{korda2015td}, and then provide a mathematically solid analysis of the non-asymptotic convergence of VRTD and its variance reduction performance. We show that VRTD is guaranteed to converge to a neighborhood of the fixed-point solution of TD at a linear convergence rate. Furthermore, the variance error (for both i.i.d.\ and Markovian sampling) and the bias error (for Markovian sampling) of VRTD are significantly reduced by the batch size of variance reduction in comparison to those of vanilla TD. As a result, the overall computational complexity of VRTD to attain a given accurate solution outperforms that of TD under Markov sampling and outperforms that of TD under i.i.d.\ sampling for a sufficiently small conditional number.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement Learning, TD learning, Markovian sample, Variance Reduction</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1ly10EKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hyg-JC4FDr" data-number="882">
      <h4>
        <a href="/forum?id=Hyg-JC4FDr">
            Imitation Learning via Off-Policy Distribution Matching
        </a>
      
        
          <a href="/pdf?id=Hyg-JC4FDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kostrikov%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kostrikov@cs.nyu.edu">Ilya Kostrikov</a>, <a href="/profile?email=ofirnachum%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ofirnachum@google.com">Ofir Nachum</a>, <a href="/profile?email=tompson%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tompson@google.com">Jonathan Tompson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#Hyg-JC4FDr-details-77" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hyg-JC4FDr-details-77"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, deep learning, imitation learning, adversarial learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">When performing imitation learning from expert demonstrations, distribution matching is a popular approach, in which one alternates between estimating distribution ratios and then using these ratios as rewards in a standard reinforcement learning (RL) algorithm. Traditionally, estimation of the distribution ratio requires on-policy data, which has caused previous work to either be exorbitantly data- inefficient or alter the original objective in a manner that can drastically change its optimum. In this work, we show how the original distribution ratio estimation objective may be transformed in a principled manner to yield a completely off-policy objective. In addition to the data-efficiency that this provides, we are able to show that this objective also renders the use of a separate RL optimization unnecessary. Rather, an imitation policy may be learned directly from this objective without the use of explicit rewards. We call the resulting algorithm ValueDICE and evaluate it on a suite of popular imitation learning benchmarks, finding that it can achieve state-of-the-art sample efficiency and performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hyg-JC4FDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgMkCEtPB" data-number="884">
      <h4>
        <a href="/forum?id=rkgMkCEtPB">
            Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML
        </a>
      
        
          <a href="/pdf?id=rkgMkCEtPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=aniruddhraghu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aniruddhraghu@gmail.com">Aniruddh Raghu</a>, <a href="/profile?email=maithrar%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maithrar@gmail.com">Maithra Raghu</a>, <a href="/profile?email=bengio%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bengio@google.com">Samy Bengio</a>, <a href="/profile?email=vinyals%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vinyals@google.com">Oriol Vinyals</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#rkgMkCEtPB-details-644" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgMkCEtPB-details-644"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning analysis, representation learning, meta-learning, few-shot learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">The success of MAML relies on feature reuse from the meta-initialization, which also yields a natural simplification of the algorithm, with the inner loop removed for the network body, as well as other insights on the head and body.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">An important research direction in machine learning has centered around developing meta-learning algorithms to tackle few-shot learning. An especially successful algorithm has been Model Agnostic Meta-Learning (MAML), a method that consists of two optimization loops, with the outer loop finding a meta-initialization, from which the inner loop can efficiently learn new tasks. Despite MAML's popularity, a fundamental open question remains -- is the effectiveness of MAML due to the meta-initialization being primed for rapid learning (large, efficient changes in the representations) or due to feature reuse,  with the meta initialization already containing high quality features? We investigate this question, via ablation studies and analysis of the latent representations, finding that feature reuse is the dominant factor. This leads to the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where we remove the inner loop for all but the (task-specific) head of the underlying neural network. ANIL matches MAML's performance on benchmark few-shot image classification and RL and offers computational improvements over MAML. We further study the precise contributions of the head and body of the network, showing that performance on the test tasks is entirely determined by the quality of the learned features, and we can remove even the head of the network (the NIL algorithm). We conclude with a discussion of the rapid learning vs feature reuse question for meta-learning algorithms more broadly.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgMkCEtPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1lmyRNFvr" data-number="888">
      <h4>
        <a href="/forum?id=H1lmyRNFvr">
            Augmenting Genetic Algorithms with Deep Neural Networks for Exploring the Chemical Space
        </a>
      
        
          <a href="/pdf?id=H1lmyRNFvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=akshat.nigam%40mail.utoronto.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="akshat.nigam@mail.utoronto.ca">AkshatKumar Nigam</a>, <a href="/profile?email=pascal.friederich%40utoronto.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="pascal.friederich@utoronto.ca">Pascal Friederich</a>, <a href="/profile?email=mario.krenn%40utoronto.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="mario.krenn@utoronto.ca">Mario Krenn</a>, <a href="/profile?email=alan%40aspuru.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alan@aspuru.com">Alan Aspuru-Guzik</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#H1lmyRNFvr-details-841" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1lmyRNFvr-details-841"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Generative model, Chemical Space, Inverse Molecular Design</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Tackling inverse design via genetic algorithms augmented with deep neural networks. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Challenges in natural sciences can often be phrased as optimization problems. Machine learning techniques have recently been applied to solve such problems. One example in chemistry is the design of tailor-made organic materials and molecules, which requires efficient methods to explore the chemical space. We present a genetic algorithm (GA) that is enhanced with a neural network (DNN) based discriminator model to improve the diversity of generated molecules and at the same time steer the GA. We show that our algorithm outperforms other generative models in optimization tasks. We furthermore present a way to increase interpretability of genetic algorithms, which helped us to derive design principles</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/aspuru-guzik-group/GA</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1lmyRNFvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJe_yR4Fwr" data-number="898">
      <h4>
        <a href="/forum?id=HJe_yR4Fwr">
            Improved Sample Complexities for Deep Neural Networks and Robust Classification via an All-Layer Margin
        </a>
      
        
          <a href="/pdf?id=HJe_yR4Fwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=colinwei%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="colinwei@stanford.edu">Colin Wei</a>, <a href="/profile?email=tengyuma%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tengyuma@cs.stanford.edu">Tengyu Ma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#HJe_yR4Fwr-details-337" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJe_yR4Fwr-details-337"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a new notion of margin that has a direct relationship with neural net generalization, and obtain improved generalization bounds for neural nets and robust classification by analyzing this margin.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">For linear classifiers, the relationship between (normalized) output margin and generalization is captured in a clear and simple bound – a large output margin implies good generalization. Unfortunately, for deep models, this relationship is less clear: existing analyses of the output margin give complicated bounds which sometimes depend exponentially on depth. In this work, we propose to instead analyze a new notion of margin, which we call the “all-layer margin.” Our analysis reveals that the all-layer margin has a clear and direct relationship with generalization for deep models. This enables the following concrete applications of the all-layer margin: 1) by analyzing the all-layer margin, we obtain tighter generalization bounds for neural nets which depend on Jacobian and hidden layer norms and remove the exponential dependency on depth 2) our neural net results easily translate to the adversarially robust setting, giving the first direct analysis of robust test error for deep networks, and 3) we present a theoretically inspired training algorithm for increasing the all-layer margin. Our algorithm improves both clean and adversarially robust test performance over strong baselines in practice.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning theory, generalization bounds, adversarially robust generalization, data-dependent generalization bounds</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJe_yR4Fwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1l6y0VFPr" data-number="909">
      <h4>
        <a href="/forum?id=B1l6y0VFPr">
            Identity Crisis: Memorization and Generalization Under Extreme Overparameterization
        </a>
      
        
          <a href="/pdf?id=B1l6y0VFPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=pluskid%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pluskid@gmail.com">Chiyuan Zhang</a>, <a href="/profile?email=bengio%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bengio@google.com">Samy Bengio</a>, <a href="/profile?email=moritzhardt%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="moritzhardt@gmail.com">Moritz Hardt</a>, <a href="/profile?email=mcmozer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mcmozer@google.com">Michael C. Mozer</a>, <a href="/profile?email=y.s%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="y.s@cs.princeton.edu">Yoram Singer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#B1l6y0VFPr-details-804" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1l6y0VFPr-details-804"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Generalization, Memorization, Understanding, Inductive Bias</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study the interplay between memorization and generalization of
      overparameterized networks in the extreme case of a single training example and an identity-mapping task. We examine fully-connected and convolutional networks (FCN and CNN), both linear and nonlinear, initialized randomly and then trained to minimize the reconstruction error. The trained networks stereotypically take one of two forms: the constant function (memorization) and the identity function (generalization).
      We formally characterize generalization in single-layer FCNs and CNNs.
      We show empirically that different architectures exhibit strikingly different inductive biases.
      For example, CNNs of up to 10 layers are able to generalize
      from a single example, whereas FCNs cannot learn the identity function reliably from 60k examples. Deeper CNNs often fail, but nonetheless do astonishing work to memorize the training output: because CNN biases are location invariant, the model must progressively grow an output pattern from the image boundaries via the coordination of many layers. Our work helps to quantify and visualize the sensitivity of inductive biases to architectural choices such as depth, kernel width, and number of channels.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1l6y0VFPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HklkeR4KPB" data-number="914">
      <h4>
        <a href="/forum?id=HklkeR4KPB">
            ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring
        </a>
      
        
          <a href="/pdf?id=HklkeR4KPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=dberth%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dberth@google.com">David Berthelot</a>, <a href="/profile?email=ncarlini%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ncarlini@google.com">Nicholas Carlini</a>, <a href="/profile?email=cubuk%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cubuk@google.com">Ekin D. Cubuk</a>, <a href="/profile?email=kurakin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kurakin@google.com">Alex Kurakin</a>, <a href="/profile?email=kihyuks%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kihyuks@google.com">Kihyuk Sohn</a>, <a href="/profile?email=zhanghan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhanghan@google.com">Han Zhang</a>, <a href="/profile?email=craffel%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="craffel@google.com">Colin Raffel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#HklkeR4KPB-details-981" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HklkeR4KPB-details-981"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">semi-supervised learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce Distribution Matching and Augmentation Anchoring, two improvements to MixMatch which produce state-of-the-art results and enable surprisingly strong performance with only 40 labels on CIFAR-10 and SVHN.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We improve the recently-proposed ``MixMatch semi-supervised learning algorithm by introducing two new techniques: distribution alignment and augmentation anchoring.
      - Distribution alignment encourages the marginal distribution of predictions on unlabeled data to be close to the marginal distribution of ground-truth labels.
      - Augmentation anchoring} feeds multiple strongly augmented versions of an input into the model and encourages each output to be close to the prediction for a weakly-augmented version of the same input.
      To produce strong augmentations, we propose a variant of AutoAugment which learns the augmentation policy while the model is being trained.
      
      Our new algorithm, dubbed ReMixMatch, is significantly more data-efficient than prior work, requiring between 5 times and 16 times less data to reach the same accuracy. For example, on CIFAR-10 with 250 labeled examples we reach 93.73% accuracy (compared to MixMatch's accuracy of 93.58% with 4000 examples) and a median accuracy of 84.92% with just four labels per class.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/google-research/remixmatch</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HklkeR4KPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJxWx0NYPr" data-number="918">
      <h4>
        <a href="/forum?id=BJxWx0NYPr">
            Adaptive Structural Fingerprints for Graph Attention Networks
        </a>
      
        
          <a href="/pdf?id=BJxWx0NYPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kzhang980%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kzhang980@gmail.com">Kai Zhang</a>, <a href="/profile?email=52184501026%40stu.ecnu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="52184501026@stu.ecnu.edu.cn">Yaokang Zhu</a>, <a href="/profile?email=wongjun%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wongjun@gmail.com">Jun Wang</a>, <a href="/profile?email=jzhang080%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jzhang080@gmail.com">Jie Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#BJxWx0NYPr-details-926" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJxWx0NYPr-details-926"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Exploiting rich strucural details in graph-structued data via adaptive "strucutral fingerprints''</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Graph attention network (GAT) is a promising framework to perform convolution and massage passing on graphs. Yet, how to fully exploit rich structural information in the attention mechanism remains a challenge. In the current version, GAT calculates attention scores mainly using node features and among one-hop neighbors, while increasing the attention range to higher-order neighbors can negatively affect its performance, reflecting the over-smoothing risk of GAT (or graph neural networks in general), and the ineffectiveness in exploiting graph structural details. In this paper, we propose an ``"adaptive structural fingerprint" (ADSF) model to fully exploit graph topological details in graph attention network. The key idea is to contextualize each node with a weighted, learnable receptive field  encoding rich and diverse local graph structures. By doing this, structural interactions between the nodes can  be inferred accurately, thus significantly improving subsequent attention layer as well as the convergence of learning. Furthermore, our model provides a useful platform  for different subspaces of node features and various scales of graph structures to ``cross-talk'' with each other through the learning of multi-head attention, being particularly useful in handling complex real-world data. Empirical results demonstrate the power of our approach in exploiting rich structural information in GAT and in alleviating  the intrinsic oversmoothing problem in graph neural networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">http://github.com/AvigdorZ</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Graph attention networks, graph neural networks, node classification</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJxWx0NYPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkxXe0Etwr" data-number="923">
      <h4>
        <a href="/forum?id=BkxXe0Etwr">
            CAQL: Continuous Action Q-Learning
        </a>
      
        
          <a href="/pdf?id=BkxXe0Etwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mkryu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mkryu@google.com">Moonkyung Ryu</a>, <a href="/profile?email=yinlamchow%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yinlamchow@google.com">Yinlam Chow</a>, <a href="/profile?email=rander%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rander@google.com">Ross Anderson</a>, <a href="/profile?email=ctjandra%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ctjandra@google.com">Christian Tjandraatmadja</a>, <a href="/profile?email=cboutilier%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cboutilier@google.com">Craig Boutilier</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#BkxXe0Etwr-details-655" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkxXe0Etwr-details-655"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement learning (RL), DQN, Continuous control, Mixed-Integer Programming (MIP)</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A general framework of value-based reinforcement learning for continuous control</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Reinforcement learning (RL) with value-based methods (e.g., Q-learning) has shown success in a variety of domains such as
      games and recommender systems (RSs). When the action space is finite, these algorithms implicitly finds a policy by learning the optimal value function, which are often very efficient. 
      However, one major challenge of extending Q-learning to tackle continuous-action RL problems is that obtaining optimal Bellman backup requires solving a continuous action-maximization (max-Q) problem. While it is common to restrict the parameterization of the Q-function to be concave in actions to simplify the max-Q problem, such a restriction might lead to performance degradation. Alternatively, when the Q-function is parameterized with a generic feed-forward neural network (NN), the max-Q problem can be NP-hard. In this work, we propose the CAQL method which minimizes the Bellman residual using Q-learning with one of several plug-and-play action optimizers. In particular, leveraging the strides of optimization theories in deep NN, we show that max-Q problem can be solved optimally with mixed-integer programming (MIP)---when the Q-function has sufficient representation power, this MIP-based optimization induces better policies and is more robust than counterparts, e.g., CEM or GA, that approximate the max-Q solution. To speed up training of CAQL, we develop three techniques, namely (i) dynamic tolerance, (ii) dual filtering, and (iii) clustering.
      To speed up inference of CAQL, we introduce the action function that concurrently learns the optimal policy.
      To demonstrate the efficiency of CAQL we compare it with state-of-the-art RL algorithms on benchmark continuous control problems that have different degrees of action constraints and show that CAQL significantly outperforms policy-based methods in heavily constrained environments.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BkxXe0Etwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJluxREKDB" data-number="933">
      <h4>
        <a href="/forum?id=BJluxREKDB">
            Learning Heuristics for Quantified Boolean Formulas through Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=BJluxREKDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=gilled%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gilled@berkeley.edu">Gil Lederman</a>, <a href="/profile?email=mrabe%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mrabe@google.com">Markus Rabe</a>, <a href="/profile?email=sshesia%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sshesia@eecs.berkeley.edu">Sanjit Seshia</a>, <a href="/profile?email=eal%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="eal@eecs.berkeley.edu">Edward A. Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#BJluxREKDB-details-592" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJluxREKDB-details-592"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Logic, QBF, Logical Reasoning, SAT, Graph, Reinforcement Learning, GNN</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We use RL to automatically learn branching heuristic within a state of the art QBF solver, on industrial problems.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We demonstrate how to learn efficient heuristics for automated reasoning algorithms for quantified Boolean formulas through deep reinforcement learning. We focus on a backtracking search algorithm, which can already solve formulas of impressive size - up to hundreds of thousands of variables. The main challenge is to find a representation of these formulas that lends itself to making predictions in a scalable way. For a family of challenging problems, we learned a heuristic that solves significantly more formulas compared to the existing handwritten heuristics.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJluxREKDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgOlCVYvB" data-number="935">
      <h4>
        <a href="/forum?id=rkgOlCVYvB">
            Pure and Spurious Critical Points: a Geometric Study of Linear Networks
        </a>
      
        
          <a href="/pdf?id=rkgOlCVYvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=matthew.trager%40cims.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthew.trager@cims.nyu.edu">Matthew Trager</a>, <a href="/profile?email=kathlen.korn%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kathlen.korn@gmail.com">Kathlén Kohn</a>, <a href="/profile?email=bruna%40cims.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bruna@cims.nyu.edu">Joan Bruna</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#rkgOlCVYvB-details-304" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgOlCVYvB-details-304"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The critical locus of the loss function of a neural network is determined by the geometry of the functional space and by the parameterization of this space by the network's weights. We introduce a natural distinction between pure critical points, which only depend on the functional space, and spurious critical points, which arise from the parameterization. We apply this perspective to revisit and extend the literature on the loss function of linear neural networks. For this type of network, the functional space is either the set of all linear maps from input to output space, or a determinantal variety, i.e., a set of linear maps with bounded rank. We use geometric properties of determinantal varieties to derive new results on the landscape of linear networks with different loss functions and different parameterizations. Our analysis clearly illustrates that the absence of "bad" local minima in the loss landscape of linear networks is due to two distinct phenomena that apply in different settings: it is true for arbitrary smooth convex losses in the case of architectures that can express all linear maps ("filling architectures") but it holds only for the quadratic loss when the functional space is a determinantal variety ("non-filling architectures"). Without any assumption on the architecture, smooth convex losses may lead to landscapes with many bad minima.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/file/d/1eSU6mwgmowSAyQY3b1jXPzvbymNv338z/view?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Loss landscape, linear networks, algebraic geometry</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgOlCVYvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJeYe0NtvH" data-number="936">
      <h4>
        <a href="/forum?id=SJeYe0NtvH">
            Neural Text Generation With Unlikelihood Training
        </a>
      
        
          <a href="/pdf?id=SJeYe0NtvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wellecks%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wellecks@nyu.edu">Sean Welleck</a>, <a href="/profile?email=kulikov%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kulikov@cs.nyu.edu">Ilia Kulikov</a>, <a href="/profile?email=roller%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="roller@fb.com">Stephen Roller</a>, <a href="/profile?email=edinan%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="edinan@fb.com">Emily Dinan</a>, <a href="/profile?email=kyunghyun.cho%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kyunghyun.cho@nyu.edu">Kyunghyun Cho</a>, <a href="/profile?email=jase%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jase@fb.com">Jason Weston</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SJeYe0NtvH-details-254" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJeYe0NtvH-details-254"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">language modeling, machine learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Neural text generation is a key tool in natural language applications, but it is well known there are major problems at its core. In particular, standard likelihood training and decoding leads to dull and repetitive outputs. While some post-hoc fixes have been proposed, in particular top-k and nucleus sampling, they do not address the fact that the token-level probabilities predicted by the model are poor. In this paper we show that the likelihood objective itself is at fault, resulting in a model that assigns too much probability to sequences containing repeats and frequent words, unlike those from the human training distribution. We propose a new objective, unlikelihood training, which forces unlikely generations to be assigned lower probability by the model. We show that both token and sequence level unlikelihood training give less repetitive, less dull text while maintaining perplexity, giving superior generations using standard greedy or beam search. According to human evaluations, our approach with standard beam search also outperforms the currently popular decoding methods of nucleus sampling or beam blocking, thus providing a strong alternative to existing techniques.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/open?id=1rTksP8hubiXcYzJ8RBl83R8Ent5EtLOj</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJeYe0NtvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJeqeCEtvH" data-number="939">
      <h4>
        <a href="/forum?id=rJeqeCEtvH">
            Semi-Supervised Generative Modeling for Controllable Speech Synthesis
        </a>
      
        
          <a href="/pdf?id=rJeqeCEtvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=raza.habib%40cs.ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="raza.habib@cs.ucl.ac.uk">Raza Habib</a>, <a href="/profile?email=soroosh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="soroosh@google.com">Soroosh Mariooryad</a>, <a href="/profile?email=mattshannon%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mattshannon@google.com">Matt Shannon</a>, <a href="/profile?email=ebattenberg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ebattenberg@google.com">Eric Battenberg</a>, <a href="/profile?email=rjryan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rjryan@google.com">RJ Skerry-Ryan</a>, <a href="/profile?email=daisy%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daisy@google.com">Daisy Stanton</a>, <a href="/profile?email=davidkao%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="davidkao@google.com">David Kao</a>, <a href="/profile?email=tombagby%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tombagby@google.com">Tom Bagby</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#rJeqeCEtvH-details-344" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJeqeCEtvH-details-344"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">TTS, Speech Synthesis, Semi-supervised Models, VAE, disentanglement</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present a novel generative model that combines state-of-the-art neural text- to-speech (TTS) with semi-supervised probabilistic latent variable models. By providing partial supervision to some of the latent variables, we are able to force them to take on consistent and interpretable purposes, which previously hasn’t been possible with purely unsupervised methods. We demonstrate that our model is able to reliably discover and control important but rarely labelled attributes of speech, such as affect and speaking rate, with as little as 1% (30 minutes) supervision. Even at such low supervision levels we do not observe a degradation of synthesis quality compared to a state-of-the-art baseline. We will release audio samples at https://google.github.io/tacotron/publications/semisupervised_generative_modeling_for_controllable_speech_synthesis/.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJeqeCEtvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkxybANtDB" data-number="950">
      <h4>
        <a href="/forum?id=SkxybANtDB">
            Dynamic Time Lag Regression: Predicting What &amp; When
        </a>
      
        
          <a href="/pdf?id=SkxybANtDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mandar.chandorkar%40cwi.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="mandar.chandorkar@cwi.nl">Mandar Chandorkar</a>, <a href="/profile?email=furtlehn%40lri.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="furtlehn@lri.fr">Cyril Furtlehner</a>, <a href="/profile?email=bala.poduval%40unh.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bala.poduval@unh.edu">Bala Poduval</a>, <a href="/profile?email=e.camporeale%40cwi.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="e.camporeale@cwi.nl">Enrico Camporeale</a>, <a href="/profile?email=michele.sebag%40lri.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="michele.sebag@lri.fr">Michele Sebag</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SkxybANtDB-details-113" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkxybANtDB-details-113"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Dynamic Time-Lag Regression, Time Delay, Regression, Time Series</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a new regression framework for temporal phenomena having non-stationary time-lag dependencies.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper tackles a new regression problem, called Dynamic Time-Lag Regression (DTLR), where a cause signal drives an effect signal with an unknown time delay.
      The motivating application, pertaining to space weather modelling, aims to predict the near-Earth solar wind speed based on estimates of the Sun's  coronal magnetic field. 
      DTLR differs from mainstream regression and from sequence-to-sequence learning in two respects: firstly, no ground truth (e.g., pairs of associated sub-sequences) is available; secondly, the cause signal contains much information irrelevant to the effect signal (the solar magnetic field governs the solar wind propagation in the heliosphere, of which the Earth's magnetosphere is but a minuscule region). 
      
      A Bayesian approach is presented to tackle the specifics of the DTLR problem, with theoretical justifications based on linear stability analysis. A proof of concept on synthetic problems is presented. Finally, the empirical results on the solar wind modelling task improve on the state of the art in solar wind forecasting.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/transcendent-ai-labs/PlasmaML</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkxybANtDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkgxW0EYDS" data-number="952">
      <h4>
        <a href="/forum?id=HkgxW0EYDS">
            Scalable Model Compression by Entropy Penalized Reparameterization
        </a>
      
        
          <a href="/pdf?id=HkgxW0EYDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=doktay%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="doktay@princeton.edu">Deniz Oktay</a>, <a href="/profile?email=jballe%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jballe@google.com">Johannes Ballé</a>, <a href="/profile?email=saurabhsingh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="saurabhsingh@google.com">Saurabh Singh</a>, <a href="/profile?email=abhinav%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhinav@cs.umd.edu">Abhinav Shrivastava</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HkgxW0EYDS-details-4" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkgxW0EYDS-details-4"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, model compression, computer vision, information theory</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">An end-to-end trainable model compression method optimizing accuracy jointly with the expected model size.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We describe a simple and general neural network weight compression approach, in which the network parameters (weights and biases) are represented in a “latent” space, amounting to a reparameterization. This space is equipped with a learned probability model, which is used to impose an entropy penalty on the parameter representation during training, and to compress the representation using a simple arithmetic coder after training. Classification accuracy and model compressibility is maximized jointly, with the bitrate–accuracy trade-off specified by a hyperparameter. We evaluate the method on the MNIST, CIFAR-10 and ImageNet classification benchmarks using six distinct model architectures. Our results show that state-of-the-art model compression can be achieved in a scalable and general way without requiring complex procedures such as multi-stage training.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkgxW0EYDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bkl7bREtDr" data-number="959">
      <h4>
        <a href="/forum?id=Bkl7bREtDr">
            AMRL: Aggregated Memory For Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=Bkl7bREtDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jacob_beck%40alumni.brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jacob_beck@alumni.brown.edu">Jacob Beck</a>, <a href="/profile?email=kamil.ciosek%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kamil.ciosek@microsoft.com">Kamil Ciosek</a>, <a href="/profile?email=sam.devlin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sam.devlin@microsoft.com">Sam Devlin</a>, <a href="/profile?email=sebastian.tschiatschek%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastian.tschiatschek@microsoft.com">Sebastian Tschiatschek</a>, <a href="/profile?email=cheng.zhang%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cheng.zhang@microsoft.com">Cheng Zhang</a>, <a href="/profile?email=katja.hofmann%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="katja.hofmann@microsoft.com">Katja Hofmann</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#Bkl7bREtDr-details-613" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bkl7bREtDr-details-613"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">In Deep RL, order-invariant functions can be used in conjunction with standard memory modules to improve gradient decay and resilience to noise.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In many partially observable scenarios, Reinforcement Learning (RL) agents must rely on long-term memory in order to learn an optimal policy. We demonstrate that using techniques from NLP and supervised learning fails at RL tasks due to stochasticity from the environment and from exploration. Utilizing our insights on the limitations of traditional memory methods in RL, we propose AMRL, a class of models that can learn better policies with greater sample efficiency and are resilient to noisy inputs. Specifically, our models use a standard memory module to summarize short-term context, and then aggregate all prior states from the standard model without respect to order. We show that this provides advantages both in terms of gradient decay and signal-to-noise ratio over time. Evaluating in Minecraft and maze environments that test long-term memory, we find that our model improves average return by 19% over a baseline that has the same number of parameters and by 9% over a stronger baseline that has far more parameters.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, reinforcement learning, rl, memory, noise, machine learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Bkl7bREtDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJxV-ANKDH" data-number="962">
      <h4>
        <a href="/forum?id=HJxV-ANKDH">
            Efficient Riemannian Optimization on the Stiefel Manifold via the Cayley Transform
        </a>
      
        
          <a href="/pdf?id=HJxV-ANKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=liju2%40oregonstate.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="liju2@oregonstate.edu">Jun Li</a>, <a href="/profile?email=fuxin.li%40oregonstate.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fuxin.li@oregonstate.edu">Fuxin Li</a>, <a href="/profile?email=sinisa%40oregonstate.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sinisa@oregonstate.edu">Sinisa Todorovic</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="#HJxV-ANKDH-details-114" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJxV-ANKDH-details-114"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Strictly enforcing orthonormality constraints on parameter matrices has been shown advantageous in deep learning. This amounts to Riemannian optimization on the Stiefel manifold, which, however, is computationally expensive. To address this challenge, we present two main contributions: (1) A new efficient retraction map based on an iterative Cayley transform for optimization updates, and (2) An implicit vector transport mechanism based on the combination of a projection of the momentum and the Cayley transform on the Stiefel manifold. We specify two new optimization algorithms: Cayley SGD with momentum, and Cayley ADAM on the Stiefel manifold. Convergence of Cayley SGD is theoretically analyzed. Our experiments for CNN training demonstrate that both algorithms: (a) Use less running time per iteration relative to existing approaches that enforce orthonormality of CNN parameters; and (b) Achieve faster convergence rates than the baseline SGD and ADAM algorithms without compromising the performance of the CNN. Cayley SGD and Cayley ADAM are also shown to reduce the training time for optimizing the unitary transition matrices in RNNs.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Orthonormality, Efficient Riemannian Optimization, the Stiefel manifold.</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper is about efficient Riemannian optimization on the Stiefel manifold that enforces the parameter matrices orthonormal.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJxV-ANKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkgrZ0EYwB" data-number="963">
      <h4>
        <a href="/forum?id=HkgrZ0EYwB">
            Unpaired Point Cloud Completion on Real Scans using Adversarial Training
        </a>
      
        
          <a href="/pdf?id=HkgrZ0EYwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xuelin.chen.sdu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xuelin.chen.sdu@gmail.com">Xuelin Chen</a>, <a href="/profile?email=baoquan.chen%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="baoquan.chen@gmail.com">Baoquan Chen</a>, <a href="/profile?email=n.mitra%40cs.ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="n.mitra@cs.ucl.ac.uk">Niloy J. Mitra</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HkgrZ0EYwB-details-176" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkgrZ0EYwB-details-176"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">As 3D scanning solutions become increasingly popular, several deep learning setups have been developed for the task of scan completion, i.e., plausibly filling in regions that were missed in the raw scans. These methods, however, largely rely on supervision in the form of paired training data, i.e., partial scans with corresponding desired completed scans. While these methods have been successfully demonstrated on synthetic data, the approaches cannot be directly used on real scans in absence of suitable paired training data. We develop a first approach that works directly on input point clouds, does not require paired training data,  and hence can directly be applied to real scans for scan completion. We evaluate the approach qualitatively on several real-world datasets (ScanNet, Matterport3D, KITTI), quantitatively on 3D-EPN shape completion benchmark dataset, and demonstrate realistic completions under varying levels of incompleteness.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">point cloud completion, generative adversarial network, real scans</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/xuelin-chen/pcl2pcl-gan-pub</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkgrZ0EYwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJe_Z04Yvr" data-number="970">
      <h4>
        <a href="/forum?id=HJe_Z04Yvr">
            Adjustable Real-time Style Transfer
        </a>
      
        
          <a href="/pdf?id=HJe_Z04Yvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mb2%40uiuc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mb2@uiuc.edu">Mohammad Babaeizadeh</a>, <a href="/profile?email=golnazg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="golnazg@google.com">Golnaz Ghiasi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#HJe_Z04Yvr-details-230" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJe_Z04Yvr-details-230"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Image Style Transfer, Deep Learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Stochastic style transfer with adjustable features. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Artistic style transfer is the problem of synthesizing an image with content similar to a given image and style similar to another. Although recent feed-forward neural networks can generate stylized images in real-time, these models produce a single stylization given a pair of style/content images, and the user doesn't have control over the synthesized output. Moreover, the style transfer depends on the hyper-parameters of the model with varying ``optimum" for different input images. Therefore, if the stylized output is not appealing to the user, she/he has to try multiple models or retrain one with different hyper-parameters to get a favorite stylization. In this paper, we address these issues by proposing a novel method which allows adjustment of crucial hyper-parameters, after the training and in real-time, through a set of manually adjustable parameters. These parameters enable the user to modify the synthesized outputs from the same pair of style/content images, in search of a favorite stylized image. Our quantitative and qualitative experiments indicate how adjusting these parameters is comparable to retraining the model with different hyper-parameters. We also demonstrate how these parameters can be randomized to generate results which are diverse but still very similar in style and content.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://goo.gl/PVWQ9K</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJe_Z04Yvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rygFWAEFwS" data-number="974">
      <h4>
        <a href="/forum?id=rygFWAEFwS">
            Stochastic Weight Averaging in Parallel: Large-Batch Training That Generalizes Well
        </a>
      
        
          <a href="/pdf?id=rygFWAEFwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=vipul_gupta%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vipul_gupta@berkeley.edu">Vipul Gupta</a>, <a href="/profile?email=sakle%40apple.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sakle@apple.com">Santiago Akle Serrano</a>, <a href="/profile?email=ddecoste%40apple.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ddecoste@apple.com">Dennis DeCoste</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#rygFWAEFwS-details-468" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rygFWAEFwS-details-468"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Large batch training, Distributed neural network training, Stochastic Weight Averaging</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose SWAP, a distributed algorithm for large-batch training of neural networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose Stochastic Weight Averaging in Parallel (SWAP), an algorithm to accelerate DNN training. Our algorithm uses large mini-batches to compute an approximate solution quickly and then refines it by averaging the weights of multiple models computed independently and in parallel. The resulting models generalize equally well as those trained with small mini-batches but are produced in a substantially shorter time. We demonstrate the reduction in training time and the good generalization performance of the resulting models on the computer vision datasets CIFAR10, CIFAR100, and ImageNet.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rygFWAEFwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byg5ZANtvH" data-number="976">
      <h4>
        <a href="/forum?id=Byg5ZANtvH">
            Short and Sparse Deconvolution --- A Geometric Approach
        </a>
      
        
          <a href="/pdf?id=Byg5ZANtvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=y.lau%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="y.lau@columbia.edu">Yenson Lau</a>, <a href="/profile?email=qq213%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qq213@nyu.edu">Qing Qu</a>, <a href="/profile?email=hk2673%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hk2673@columbia.edu">Han-Wen Kuo</a>, <a href="/profile?email=pz2230%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pz2230@columbia.edu">Pengcheng Zhou</a>, <a href="/profile?email=yz2557%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yz2557@cornell.edu">Yuqian Zhang</a>, <a href="/profile?email=jw2966%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jw2966@columbia.edu">John Wright</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="#Byg5ZANtvH-details-318" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byg5ZANtvH-details-318"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Short-and-sparse deconvolution (SaSD) is the problem of extracting localized, recurring motifs in signals with spatial or temporal structure. Variants of this problem arise in applications such as image deblurring, microscopy, neural spike sorting, and more. The problem is challenging in both theory and practice, as natural optimization formulations are nonconvex. Moreover, practical deconvolution problems involve smooth motifs (kernels) whose spectra decay rapidly, resulting in poor conditioning and numerical challenges. This paper is motivated by recent theoretical advances \citep{zhang2017global,kuo2019geometry}, which characterize the optimization landscape of a particular nonconvex formulation of SaSD. This is used to derive a provable algorithm that exactly solves certain non-practical instances of the SaSD problem. We leverage the key ideas from this theory (sphere constraints, data-driven initialization) to develop a practical algorithm, which performs well on data arising from a range of application areas. We highlight key additional challenges posed by the ill-conditioning of real SaSD problems and suggest heuristics (acceleration, continuation, reweighting) to mitigate them. Experiments demonstrate the performance and generality of the proposed method.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/qingqu06/sparse_deconvolution</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Byg5ZANtvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJg2b0VYDr" data-number="979">
      <h4>
        <a href="/forum?id=HJg2b0VYDr">
            Selection via Proxy: Efficient Data Selection for Deep Learning
        </a>
      
        
          <a href="/pdf?id=HJg2b0VYDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=cody%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cody@cs.stanford.edu">Cody Coleman</a>, <a href="/profile?email=chrisyeh%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chrisyeh@stanford.edu">Christopher Yeh</a>, <a href="/profile?email=mussmann%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mussmann@stanford.edu">Stephen Mussmann</a>, <a href="/profile?email=baharanm%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="baharanm@stanford.edu">Baharan Mirzasoleiman</a>, <a href="/profile?email=pbailis%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pbailis@cs.stanford.edu">Peter Bailis</a>, <a href="/profile?email=pliang%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pliang@cs.stanford.edu">Percy Liang</a>, <a href="/profile?email=jure%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jure@cs.stanford.edu">Jure Leskovec</a>, <a href="/profile?email=matei%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="matei@cs.stanford.edu">Matei Zaharia</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 27 Oct 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#HJg2b0VYDr-details-145" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJg2b0VYDr-details-145"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">we can significantly improve the computational efficiency of data selection in deep learning by using a much smaller proxy model to perform data selection.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Data selection methods, such as active learning and core-set selection, are useful tools for machine learning on large datasets. However, they can be prohibitively expensive to apply in deep learning because they depend on feature representations that need to be learned. In this work, we show that we can greatly improve the computational efficiency by using a small proxy model to perform data selection (e.g., selecting data points to label for active learning). By removing hidden layers from the target model, using smaller architectures, and training for fewer epochs, we create proxies that are an order of magnitude faster to train. Although these small proxy models have higher error rates, we find that they empirically provide useful signals for data selection. We evaluate this "selection via proxy" (SVP) approach on several data selection tasks across five datasets: CIFAR10, CIFAR100, ImageNet, Amazon Review Polarity, and Amazon Review Full. For active learning, applying SVP can give an order of magnitude improvement in data selection runtime (i.e., the time it takes to repeatedly train and select points) without significantly increasing the final error (often within 0.1%). For core-set selection on CIFAR10, proxies that are over 10× faster to train than their larger, more accurate targets can remove up to 50% of the data without harming the final accuracy of the target, leading to a 1.6× end-to-end training time improvement.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">data selection, active-learning, core-set selection, deep learning, uncertainty sampling</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/stanford-futuredata/selection-via-proxy</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJg2b0VYDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1lnbRNtwr" data-number="981">
      <h4>
        <a href="/forum?id=B1lnbRNtwr">
            Global Relational Models of Source Code
        </a>
      
        
          <a href="/pdf?id=B1lnbRNtwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=vjhellendoorn%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vjhellendoorn@gmail.com">Vincent J. Hellendoorn</a>, <a href="/profile?email=charlessutton%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="charlessutton@google.com">Charles Sutton</a>, <a href="/profile?email=rising%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rising@google.com">Rishabh Singh</a>, <a href="/profile?email=maniatis%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maniatis@google.com">Petros Maniatis</a>, <a href="/profile?email=dbieber%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dbieber@google.com">David Bieber</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="#B1lnbRNtwr-details-359" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1lnbRNtwr-details-359"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Models of source code that combine global and structural features learn more powerful representations of programs.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Models of code can learn distributed representations of a program's syntax and semantics to predict many non-trivial properties of a program. Recent state-of-the-art models leverage highly structured representations of programs, such as trees, graphs and paths therein (e.g. data-flow relations), which are precise and abundantly available for code. This provides a strong inductive bias towards semantically meaningful relations, yielding more generalizable representations than classical sequence-based models. Unfortunately, these models primarily rely on graph-based message passing to represent relations in code, which makes them de facto local due to the high cost of message-passing steps, quite in contrast to modern, global sequence-based models, such as the Transformer. In this work, we bridge this divide between global and structured models by introducing two new hybrid model families that are both global and incorporate structural bias: Graph Sandwiches, which wrap traditional (gated) graph message-passing layers in sequential message-passing layers; and Graph Relational Embedding Attention Transformers (GREAT for short), which bias traditional Transformers with relational information from graph edge types. By studying a popular, non-trivial program repair task, variable-misuse identification, we explore the relative merits of traditional and hybrid model families for code representation. Starting with a  graph-based model that already improves upon the prior state-of-the-art for this task by 20%, we show that our proposed hybrid models improve an additional 10-15%, while training both faster and using fewer parameters.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Models of Source Code, Graph Neural Networks, Structured Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1lnbRNtwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJl6bANtwH" data-number="983">
      <h4>
        <a href="/forum?id=BJl6bANtwH">
            Detecting Extrapolation with Local Ensembles
        </a>
      
        
          <a href="/pdf?id=BJl6bANtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=david.madras%40mail.utoronto.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.madras@mail.utoronto.ca">David Madras</a>, <a href="/profile?email=atwoodj%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="atwoodj@google.com">James Atwood</a>, <a href="/profile?email=alexdamour%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexdamour@google.com">Alexander D'Amour</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#BJl6bANtwH-details-800" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJl6bANtwH-details-800"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">extrapolation, reliability, influence functions, laplace approximation, ensembles, Rashomon set</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present local ensembles, a method for detecting extrapolation in trained models, which approximates the variance of an ensemble using local-second order information.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present local ensembles, a method for detecting extrapolation at test time in a pre-trained model. We focus on underdetermination as a key component of extrapolation: we aim to detect when many possible predictions are consistent with the training data and model class. Our method uses local second-order information to approximate the variance of predictions across an ensemble of models from the same class. We compute this approximation by estimating the norm of the component of a test point's gradient that aligns with the low-curvature directions of the Hessian, and provide a tractable method for estimating this quantity. Experimentally, we show that our method is capable of detecting when a pre-trained model is extrapolating on test data, with applications to out-of-distribution detection, detecting spurious correlates, and active learning.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/dmadras/local-ensembles</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJl6bANtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1eRbANtDB" data-number="985">
      <h4>
        <a href="/forum?id=S1eRbANtDB">
            Learning to Link
        </a>
      
        
          <a href="/pdf?id=S1eRbANtDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ninamf%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ninamf@cs.cmu.edu">Maria-Florina Balcan</a>, <a href="/profile?email=tdick%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tdick@ttic.edu">Travis Dick</a>, <a href="/profile?email=manuel.lang%40student.kit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="manuel.lang@student.kit.edu">Manuel Lang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#S1eRbANtDB-details-603" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1eRbANtDB-details-603"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Data-driven Algorithm Configuration, Metric Learning, Linkage Clustering, Learning Algorithms</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We show how to use data to automatically learn low-loss linkage procedures and metrics for specific clustering applications.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Clustering is an important part of many modern data analysis pipelines, including network analysis and data retrieval. There are many different clustering algorithms developed by various communities, and it is often not clear which algorithm will give the best performance on a specific clustering task. Similarly, we often have multiple ways to measure distances between data points, and the best clustering performance might require a non-trivial combination of those metrics. In this work, we study data-driven algorithm selection and metric learning for clustering problems, where the goal is to simultaneously learn the best algorithm and metric for a specific application. The family of clustering algorithms we consider is parameterized linkage based procedures that includes single and complete linkage. The family of distance functions we learn over are convex combinations of base distance functions. We design efficient learning algorithms which receive samples from an application-specific distribution over clustering instances and learn a near-optimal distance and clustering algorithm from these classes. We also carry out a comprehensive empirical evaluation of our techniques showing that they can lead to significantly improved clustering performance on real-world datasets.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1eRbANtDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryebG04YvB" data-number="992">
      <h4>
        <a href="/forum?id=ryebG04YvB">
            Adversarially robust transfer learning
        </a>
      
        
          <a href="/pdf?id=ryebG04YvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ashafahi%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ashafahi@cs.umd.edu">Ali Shafahi</a>, <a href="/profile?email=parsa%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="parsa@cs.umd.edu">Parsa Saadatpanah</a>, <a href="/profile?email=chenzhu%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenzhu@cs.umd.edu">Chen Zhu</a>, <a href="/profile?email=amin%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="amin@cs.umd.edu">Amin Ghiasi</a>, <a href="/profile?email=studer%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="studer@cornell.edu">Christoph Studer</a>, <a href="/profile?email=djacobs%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="djacobs@cs.umd.edu">David Jacobs</a>, <a href="/profile?email=tomg%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tomg@cs.umd.edu">Tom Goldstein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#ryebG04YvB-details-75" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryebG04YvB-details-75"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Robust models have robust feature extractors which can be useful for transferring robustness to other domains</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Transfer learning, in which a network is trained on one task and re-purposed on another, is often used to produce neural network classifiers when data is scarce or full-scale training is too costly.  When the goal is to produce a model that is not only accurate but also adversarially robust, data scarcity and computational limitations become even more cumbersome.
      We consider robust transfer learning, in which we transfer not only performance but also robustness from a source model to a target domain.  We start by observing that robust networks contain robust feature extractors. By training classifiers on top of these feature extractors, we produce new models that inherit the robustness of their parent networks. We then consider the case of "fine tuning" a network by re-training end-to-end in the target domain. When using lifelong learning strategies, this process preserves the robustness of the source network while achieving high accuracy. By using such strategies, it is possible to produce accurate and robust models with little data, and without the cost of adversarial training. Additionally, we can improve the generalization of adversarially trained models, while maintaining their robustness.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryebG04YvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJeNz04tDS" data-number="999">
      <h4>
        <a href="/forum?id=SJeNz04tDS">
            Overlearning Reveals Sensitive Attributes
        </a>
      
        
          <a href="/pdf?id=SJeNz04tDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=cs2296%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cs2296@cornell.edu">Congzheng Song</a>, <a href="/profile?email=shmat%40cs.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shmat@cs.cornell.edu">Vitaly Shmatikov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SJeNz04tDS-details-214" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJeNz04tDS-details-214"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">privacy, censoring representation, transfer learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Overlearning means that a model trained for a seemingly simple objective implicitly learns to recognize attributes and concepts that are (1) not part of the learning objective, and (2) sensitive from a privacy or bias perspective.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">``"Overlearning'' means that a model trained for a seemingly simple
      objective implicitly learns to recognize attributes and concepts that are
      (1) not part of the learning objective, and (2) sensitive from a privacy
      or bias perspective.  For example, a binary gender classifier of facial
      images also learns to recognize races, even races that are
      not represented in the training data, and identities.
      
      We demonstrate overlearning in several vision and NLP models and analyze
      its harmful consequences.  First, inference-time representations of an
      overlearned model reveal sensitive attributes of the input, breaking
      privacy protections such as model partitioning.  Second, an overlearned
      model can be "`re-purposed'' for a different, privacy-violating task
      even in the absence of the original training data.
      
      We show that overlearning is intrinsic for some tasks and cannot be
      prevented by censoring unwanted attributes.  Finally, we investigate
      where, when, and why overlearning happens during model training.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/file/d/1hu0PhN3pWXe6LobxiPFeYBm8L-vQX2zJ/view?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJeNz04tDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJgwzCEKwH" data-number="1004">
      <h4>
        <a href="/forum?id=SJgwzCEKwH">
            Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness
        </a>
      
        
          <a href="/pdf?id=SJgwzCEKwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zhao.pu%40husky.neu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhao.pu@husky.neu.edu">Pu Zhao</a>, <a href="/profile?email=pin-yu.chen%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pin-yu.chen@ibm.com">Pin-Yu Chen</a>, <a href="/profile?email=daspa%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daspa@us.ibm.com">Payel Das</a>, <a href="/profile?email=knatesa%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="knatesa@us.ibm.com">Karthikeyan Natesan Ramamurthy</a>, <a href="/profile?email=xue.lin%40northeastern.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xue.lin@northeastern.edu">Xue Lin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 29 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SJgwzCEKwH-details-863" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJgwzCEKwH-details-863"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A novel approach using mode connectivity in loss landscapes to mitigate adversarial effects, repair tampered models, and evaluate adversarial robustness</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Mode connectivity provides novel geometric insights on analyzing loss landscapes and enables building high-accuracy pathways between well-trained neural networks. In this work, we propose to employ mode connectivity in loss landscapes to study the adversarial robustness of deep neural networks, and provide novel methods for improving this robustness.  Our experiments cover various types of adversarial attacks applied to different network architectures and datasets. When network models are tampered with backdoor or error-injection attacks, our results demonstrate that the path connection learned using limited amount of bonafide data can effectively mitigate adversarial effects while maintaining the original accuracy on clean data. Therefore, mode connectivity provides users with the power to repair backdoored or error-injected models.  We also use mode connectivity to investigate the loss landscapes of regular and robust models against evasion attacks. Experiments show that there exists a barrier in adversarial robustness loss on the path connecting regular and adversarially-trained models.  A high correlation is observed between the adversarial robustness loss and the largest eigenvalue of the input Hessian matrix, for which theoretical justifications are provided.  Our results suggest that mode connectivity offers a holistic tool and practical means for evaluating and improving adversarial robustness.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">mode connectivity, adversarial robustness, backdoor attack, error-injection attack, evasion attacks, loss landscapes</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJgwzCEKwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJgqMRVYvr" data-number="1010">
      <h4>
        <a href="/forum?id=rJgqMRVYvr">
            Differentially Private Meta-Learning
        </a>
      
        
          <a href="/pdf?id=rJgqMRVYvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jwl3%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jwl3@andrew.cmu.edu">Jeffrey Li</a>, <a href="/profile?email=khodak%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="khodak@cs.cmu.edu">Mikhail Khodak</a>, <a href="/profile?email=scaldas%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="scaldas@cs.cmu.edu">Sebastian Caldas</a>, <a href="/profile?email=talwalkar%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="talwalkar@cmu.edu">Ameet Talwalkar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rJgqMRVYvr-details-414" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJgqMRVYvr-details-414"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Parameter-transfer is a well-known and versatile approach for meta-learning, with applications including few-shot learning, federated learning, with personalization, and reinforcement learning. However, parameter-transfer algorithms often require sharing models that have been trained on the samples from specific tasks, thus leaving the task-owners susceptible to breaches of privacy. We conduct the first formal study of privacy in this setting and formalize the notion of task-global differential privacy as a practical relaxation of more commonly studied threat models. We then propose a new differentially private algorithm for gradient-based parameter transfer that not only satisfies this privacy requirement but also retains provable transfer learning guarantees in convex settings. Empirically, we apply our analysis to the problems of federated learning with personalization and few-shot classification, showing that allowing the relaxation to task-global privacy from the more commonly studied notion of local privacy leads to dramatically increased performance in recurrent neural language modeling and image classification.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Differential Privacy, Meta-Learning, Federated Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJgqMRVYvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1e9GCNKvH" data-number="1011">
      <h4>
        <a href="/forum?id=r1e9GCNKvH">
            One-Shot Pruning of Recurrent Neural Networks by Jacobian Spectrum Evaluation
        </a>
      
        
          <a href="/pdf?id=r1e9GCNKvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=matthew.zhang%40mail.utoronto.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthew.zhang@mail.utoronto.ca">Shunshi Zhang</a>, <a href="/profile?email=bstadie%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bstadie@berkeley.edu">Bradly C. Stadie</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#r1e9GCNKvH-details-687" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1e9GCNKvH-details-687"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Pruning, RNNs, Sparsity</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">New Objective for One-Shot Pruning Recurrent Neural Networks</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">  Recent advances in the sparse neural network literature have made it possible to prune many large feed forward and convolutional networks with only a small quantity of data. Yet, these same techniques often falter when applied to the problem of recovering sparse recurrent networks. These failures are quantitative: when pruned with recent techniques, RNNs typically obtain worse performance than they do under a simple random pruning scheme. The failures are also qualitative: the distribution of active weights in a pruned LSTM or GRU network tend to be concentrated in specific neurons and gates, and not well dispersed across the entire architecture. We seek to rectify both the quantitative and qualitative issues with recurrent network pruning by introducing a new recurrent pruning objective derived from the spectrum of the recurrent Jacobian. Our objective is data efficient (requiring only 64 data points to prune the network), easy to implement, and produces 95 % sparse GRUs that significantly improve on existing baselines. We evaluate on sequential MNIST, Billion Words, and Wikitext. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1e9GCNKvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgAGAVKPr" data-number="1019">
      <h4>
        <a href="/forum?id=rkgAGAVKPr">
            Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples
        </a>
      
        
          <a href="/pdf?id=rkgAGAVKPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=eleni%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="eleni@cs.toronto.edu">Eleni Triantafillou</a>, <a href="/profile?email=tylerzhu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tylerzhu@google.com">Tyler Zhu</a>, <a href="/profile?email=vdumoulin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vdumoulin@google.com">Vincent Dumoulin</a>, <a href="/profile?email=lamblinp%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lamblinp@google.com">Pascal Lamblin</a>, <a href="/profile?email=evcu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="evcu@google.com">Utku Evci</a>, <a href="/profile?email=kelvinxu%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kelvinxu@berkeley.edu">Kelvin Xu</a>, <a href="/profile?email=goroshin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="goroshin@google.com">Ross Goroshin</a>, <a href="/profile?email=cgel%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cgel@google.com">Carles Gelada</a>, <a href="/profile?email=kswersky%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kswersky@google.com">Kevin Swersky</a>, <a href="/profile?email=manzagop%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="manzagop@google.com">Pierre-Antoine Manzagol</a>, <a href="/profile?email=hugolarochelle%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hugolarochelle@google.com">Hugo Larochelle</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 08 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rkgAGAVKPr-details-731" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgAGAVKPr-details-731"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a new large-scale diverse environment for few-shot learning, and evaluate popular models' performance on it, revealing important research challenges.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Few-shot classification refers to learning a classifier for new classes given only a few examples. While a plethora of models have emerged to tackle it, we find the procedure and datasets that are used to assess their progress lacking. To address this limitation, we propose Meta-Dataset: a new benchmark for training and evaluating models that is large-scale, consists of diverse datasets, and presents more realistic tasks. We experiment with popular baselines and meta-learners on Meta-Dataset, along with a competitive method that we propose. We analyze performance as a function of various characteristics of test tasks and examine the models’ ability to leverage diverse training sources for improving their generalization. We also propose a new set of baselines for quantifying the benefit of meta-learning in Meta-Dataset. Our extensive experimentation has uncovered important research challenges and we hope to inspire work in these directions.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://storage.googleapis.com/meta-dataset-source-code/meta-dataset-iclr2020.tar.gz</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">few-shot learning, meta-learning, few-shot classification</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgAGAVKPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByxRM0Ntvr" data-number="1020">
      <h4>
        <a href="/forum?id=ByxRM0Ntvr">
            Are Transformers universal approximators of sequence-to-sequence functions?
        </a>
      
        
          <a href="/pdf?id=ByxRM0Ntvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=chulheey%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chulheey@mit.edu">Chulhee Yun</a>, <a href="/profile?email=bsrinadh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bsrinadh@google.com">Srinadh Bhojanapalli</a>, <a href="/profile?email=ankitsrawat%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ankitsrawat@google.com">Ankit Singh Rawat</a>, <a href="/profile?email=sashank%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sashank@google.com">Sashank Reddi</a>, <a href="/profile?email=sanjivk%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanjivk@google.com">Sanjiv Kumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#ByxRM0Ntvr-details-87" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByxRM0Ntvr-details-87"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We prove that Transformer networks are universal approximators of sequence-to-sequence functions.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Despite the widespread adoption of Transformer models for NLP tasks, the expressive power of these models is not well-understood. In this paper, we establish that Transformer models are universal approximators of continuous permutation equivariant sequence-to-sequence functions with compact support, which is quite surprising given the amount of shared parameters in these models. Furthermore, using positional encodings, we circumvent the restriction of permutation equivariance, and show that Transformer models can universally approximate arbitrary continuous sequence-to-sequence functions on a compact domain. Interestingly, our proof techniques clearly highlight the different roles of the self-attention and the feed-forward layers in Transformers. In particular, we prove that fixed width self-attention layers can compute contextual mappings of the input sequences, playing a key role in the universal approximation property of Transformers. Based on this insight from our analysis, we consider other simpler alternatives to self-attention layers and empirically evaluate them.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Transformer, universal approximation, contextual mapping, expressive power, permutation equivariance</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByxRM0Ntvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkg-mA4FDr" data-number="1027">
      <h4>
        <a href="/forum?id=rkg-mA4FDr">
            Pre-training Tasks for Embedding-based Large-scale Retrieval
        </a>
      
        
          <a href="/pdf?id=rkg-mA4FDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wchang2%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wchang2@cs.cmu.edu">Wei-Cheng Chang</a>, <a href="/profile?email=felixyu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="felixyu@google.com">Felix X. Yu</a>, <a href="/profile?email=yinwen%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yinwen@google.com">Yin-Wen Chang</a>, <a href="/profile?email=yiming%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yiming@cs.cmu.edu">Yiming Yang</a>, <a href="/profile?email=sanjivk%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanjivk@google.com">Sanjiv Kumar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#rkg-mA4FDr-details-18" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkg-mA4FDr-details-18"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We consider large-scale retrieval problems such as question answering retrieval and present a comprehensive study of how different sentence level pre-training improving the BERT-style token-level pre-training for two-tower Transformer models.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We consider the large-scale query-document retrieval problem: given a query (e.g., a question), return the set of relevant documents (e.g., paragraphs containing the answer) from a large document corpus. This problem is often solved in two steps. The retrieval phase first reduces the solution space, returning a subset of candidate documents. The scoring phase then re-ranks the documents. Critically, the retrieval algorithm not only desires high recall but also requires to be highly efficient, returning candidates in time sublinear to the number of documents. Unlike the scoring phase witnessing significant advances recently due to the BERT-style pre-training tasks on cross-attention models, the retrieval phase remains less well studied. Most previous works rely on classic Information Retrieval (IR) methods such as BM-25 (token matching + TF-IDF weights). These models only accept sparse handcrafted features and can not be optimized for different downstream tasks of interest. In this paper, we conduct a comprehensive study on the embedding-based retrieval models. We show that the key ingredient of learning a strong embedding-based Transformer model is the set of pre-training tasks. With adequately designed paragraph-level pre-training tasks, the Transformer models can remarkably improve over the widely-used BM-25 as well as embedding models without Transformers. The paragraph-level pre-training tasks we studied are Inverse Cloze Task (ICT), Body First Selection (BFS), Wiki Link Prediction (WLP), and the combination of all three.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">natural language processing, large-scale retrieval, unsupervised representation learning, paragraph-level pre-training, two-tower Transformer models</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkg-mA4FDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skl4mRNYDr" data-number="1034">
      <h4>
        <a href="/forum?id=Skl4mRNYDr">
            Deep Imitative Models for Flexible Inference, Planning, and Control
        </a>
      
        
          <a href="/pdf?id=Skl4mRNYDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=nrhineha%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nrhineha@cs.cmu.edu">Nicholas Rhinehart</a>, <a href="/profile?email=rmcallister%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rmcallister@berkeley.edu">Rowan McAllister</a>, <a href="/profile?email=svlevine%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="svlevine@eecs.berkeley.edu">Sergey Levine</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#Skl4mRNYDr-details-666" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skl4mRNYDr-details-666"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">In this paper, we propose Imitative Models to combine the benefits of IL and goal-directed planning: probabilistic predictive models of desirable behavior able to plan interpretable expert-like trajectories to achieve specified goals.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Imitation Learning (IL) is an appealing approach to learn desirable autonomous behavior. However, directing IL to achieve arbitrary goals is difficult. In contrast, planning-based algorithms use dynamics models and reward functions to achieve goals. Yet, reward functions that evoke desirable behavior are often difficult to specify. In this paper, we propose "Imitative Models" to combine the benefits of IL and goal-directed planning. Imitative Models are probabilistic predictive models of desirable behavior able to plan interpretable expert-like trajectories to achieve specified goals. We derive families of flexible goal objectives, including constrained goal regions, unconstrained goal sets, and energy-based goals. We show that our method can use these objectives to successfully direct behavior. Our method substantially outperforms six IL approaches and a planning-based approach in a dynamic simulated autonomous driving task, and is efficiently learned from expert demonstrations without online data collection.  We also show our approach is robust to poorly-specified goals, such as goals on the wrong side of the road.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">imitation learning, planning, autonomous driving</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Skl4mRNYDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1lEX04tPr" data-number="1035">
      <h4>
        <a href="/forum?id=S1lEX04tPr">
            CM3: Cooperative Multi-goal Multi-stage Multi-agent Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=S1lEX04tPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yjiachen%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yjiachen@gmail.com">Jiachen Yang</a>, <a href="/profile?email=anakhaei%40honda-ri.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anakhaei@honda-ri.com">Alireza Nakhaei</a>, <a href="/profile?email=disele%40honda-ri.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="disele@honda-ri.com">David Isele</a>, <a href="/profile?email=kfujimura%40honda-ri.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kfujimura@honda-ri.com">Kikuo Fujimura</a>, <a href="/profile?email=zha%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zha@cc.gatech.edu">Hongyuan Zha</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#S1lEX04tPr-details-496" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1lEX04tPr-details-496"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">multi-agent reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A modular method for fully cooperative multi-goal multi-agent reinforcement learning, based on curriculum learning for efficient exploration and credit assignment for action-goal interactions.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">A variety of cooperative multi-agent control problems require agents to achieve individual goals while contributing to collective success. This multi-goal multi-agent setting poses difficulties for recent algorithms, which primarily target settings with a single global reward, due to two new challenges: efficient exploration for learning both individual goal attainment and cooperation for others' success, and credit-assignment for interactions between actions and goals of different agents. To address both challenges, we restructure the problem into a novel two-stage curriculum, in which single-agent goal attainment is learned prior to learning multi-agent cooperation, and we derive a new multi-goal multi-agent policy gradient with a credit function for localized credit assignment. We use a function augmentation scheme to bridge value and policy functions across the curriculum. The complete architecture, called CM3, learns significantly faster than direct adaptations of existing algorithms on three challenging multi-goal multi-agent problems: cooperative navigation in difficult formations, negotiating multi-vehicle lane changes in the SUMO traffic simulator, and strategic cooperation in a Checkers environment.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1lEX04tPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJlSmC4FPS" data-number="1036">
      <h4>
        <a href="/forum?id=HJlSmC4FPS">
            Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks
        </a>
      
        
          <a href="/pdf?id=HJlSmC4FPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sm7582%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sm7582@nyu.edu">Sreyas Mohan</a>, <a href="/profile?email=zk388%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zk388@nyu.edu">Zahra Kadkhodaie</a>, <a href="/profile?email=eero.simoncelli%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="eero.simoncelli@nyu.edu">Eero P. Simoncelli</a>, <a href="/profile?email=cfgranda%40cims.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cfgranda@cims.nyu.edu">Carlos Fernandez-Granda</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HJlSmC4FPS-details-732" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJlSmC4FPS-details-732"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">denoising, overfitting, generalization, robustness, interpretability, analysis of neural networks</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study the generalization properties of deep convolutional neural networks for image denoising in the presence of varying noise levels. We provide extensive empirical evidence that current state-of-the-art architectures systematically overfit to the noise levels in the training set, performing very poorly at new noise levels. We show that strong generalization can be achieved through a simple architectural modification: removing all additive constants. The resulting "bias-free" networks attain state-of-the-art performance over a broad range of noise levels, even when trained over a limited range. They are also locally linear, which enables direct analysis with linear-algebraic tools.  We show that the denoising map can be visualized locally as a filter that adapts to both image structure and noise level. In addition, our analysis reveals that deep networks implicitly perform a projection onto an adaptively-selected low-dimensional subspace, with dimensionality inversely proportional to noise level, that captures features of natural images. </span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We show that removing constant terms from CNN architectures ensures strong generalization across noise levels, and also provides interpretability of the denoising method via linear-algebra techniques.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJlSmC4FPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJxIm0VtwH" data-number="1038">
      <h4>
        <a href="/forum?id=SJxIm0VtwH">
            Towards Better Understanding of Adaptive Gradient Algorithms in Generative Adversarial Nets
        </a>
      
        
          <a href="/pdf?id=SJxIm0VtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mingrui-liu%40uiowa.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mingrui-liu@uiowa.edu">Mingrui Liu</a>, <a href="/profile?email=mroueh%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mroueh@us.ibm.com">Youssef Mroueh</a>, <a href="/profile?email=rossja%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rossja@us.ibm.com">Jerret Ross</a>, <a href="/profile?email=weiz%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="weiz@us.ibm.com">Wei Zhang</a>, <a href="/profile?email=cuix%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cuix@us.ibm.com">Xiaodong Cui</a>, <a href="/profile?email=daspa%40us.ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daspa@us.ibm.com">Payel Das</a>, <a href="/profile?email=tianbao-yang%40uiowa.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianbao-yang@uiowa.edu">Tianbao Yang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 16 Jun 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#SJxIm0VtwH-details-865" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJxIm0VtwH-details-865"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Generative Adversarial Nets, Adaptive Gradient Algorithms</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper provides novel analysis of adaptive gradient algorithms for solving non-convex non-concave min-max problems as GANs, and explains the reason why adaptive gradient methods outperform its non-adaptive counterparts by empirical studies.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Adaptive gradient algorithms perform gradient-based updates using the history of gradients and are ubiquitous in training deep neural networks. While adaptive gradient methods theory is well understood for minimization problems, the underlying factors driving their empirical success in min-max problems such as GANs remain unclear. In this paper, we aim at bridging  this gap from both theoretical and empirical perspectives. First, we analyze a variant of Optimistic Stochastic Gradient (OSG) proposed in~\citep{daskalakis2017training} for solving a class of non-convex non-concave min-max problem and establish <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="426" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msup><mi>ϵ</mi><mrow><mo>−</mo><mn>4</mn></mrow></msup><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> complexity for finding <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="427" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ϵ</mi></math></mjx-assistive-mml></mjx-container>-first-order stationary point, in which the algorithm only requires invoking one stochastic first-order oracle while enjoying state-of-the-art iteration complexity achieved by stochastic extragradient method by~\citep{iusem2017extragradient}. Then we propose an adaptive variant of OSG named Optimistic Adagrad (OAdagrad) and reveal an \emph{improved} adaptive complexity <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="428" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.06em; padding-left: 0.187em; margin-bottom: -0.597em;"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c2DC TEX-S1"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom><mjx-mrow><mjx-mo class="mjx-lop"><mjx-c class="mjx-c28 TEX-S2"></mjx-c></mjx-mo><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.438em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn class="mjx-n" style="font-size: 83.3%;"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow style="font-size: 83.3%;"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FC TEX-I"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-lop"><mjx-c class="mjx-c29 TEX-S2"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mi>O</mi><mo>~</mo></mover></mrow><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><msup><mi>ϵ</mi><mrow><mo>−</mo><mfrac><mn>2</mn><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow></mfrac></mrow></msup><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>~\footnote{Here <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="429" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.06em; padding-left: 0.187em; margin-bottom: -0.597em;"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c2DC TEX-S1"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mi>O</mi><mo>~</mo></mover></mrow><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> compresses a logarithmic factor of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="430" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ϵ</mi></math></mjx-assistive-mml></mjx-container>.}, where <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="431" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FC TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>α</mi></math></mjx-assistive-mml></mjx-container> characterizes the growth rate of the cumulative stochastic gradient and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="432" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2264"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D6FC TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2264"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>0</mn><mo>≤</mo><mi>α</mi><mo>≤</mo><mn>1</mn><mrow><mo>/</mo></mrow><mn>2</mn></math></mjx-assistive-mml></mjx-container>. To the best of our knowledge, this is the first work for establishing adaptive complexity in non-convex non-concave min-max optimization. Empirically, our experiments show that indeed adaptive gradient algorithms outperform their non-adaptive counterparts in GAN training. Moreover, this observation can be explained by the slow growth rate of the cumulative stochastic gradient, as observed empirically.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJxIm0VtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJeO7RNKPr" data-number="1043">
      <h4>
        <a href="/forum?id=HJeO7RNKPr">
            DeepV2D: Video to Depth with Differentiable Structure from Motion
        </a>
      
        
          <a href="/pdf?id=HJeO7RNKPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zteed%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zteed@princeton.edu">Zachary Teed</a>, <a href="/profile?email=jiadeng%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiadeng@princeton.edu">Jia Deng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HJeO7RNKPr-details-138" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJeO7RNKPr-details-138"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">DeepV2D predicts depth from a video clip by composing elements of classical SfM into a fully differentiable network.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose DeepV2D, an end-to-end deep learning architecture for predicting depth from video.  DeepV2D combines the representation ability of neural networks with the geometric principles governing image formation. We compose a collection of classical geometric algorithms, which are converted into trainable modules and combined into an end-to-end differentiable architecture. DeepV2D interleaves two stages: motion estimation and depth estimation. During inference, motion and depth estimation are alternated and converge to accurate depth. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Structure-from-Motion, Video to Depth, Dense Depth Estimation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJeO7RNKPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkenmREFDr" data-number="1052">
      <h4>
        <a href="/forum?id=rkenmREFDr">
            Learning Space Partitions for Nearest Neighbor Search
        </a>
      
        
          <a href="/pdf?id=rkenmREFDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yihedong%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yihedong@gmail.com">Yihe Dong</a>, <a href="/profile?email=indyk%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="indyk@mit.edu">Piotr Indyk</a>, <a href="/profile?email=ilyaraz%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilyaraz@microsoft.com">Ilya Razenshteyn</a>, <a href="/profile?email=tal.wagner%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tal.wagner@gmail.com">Tal Wagner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rkenmREFDr-details-233" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkenmREFDr-details-233"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">space partition, lsh, locality sensitive hashing, nearest neighbor search</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We use supervised learning (and in particular deep learning) to produce better space partitions for fast nearest neighbor search.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Space partitions of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="433" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c211D TEX-A"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.41em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mi>d</mi></msup></math></mjx-assistive-mml></mjx-container> underlie a vast and important
      class of fast nearest neighbor search (NNS) algorithms. Inspired by recent theoretical work on NNS for general metric spaces (Andoni et al. 2018b,c), we develop a new framework for building space partitions reducing the problem to balanced graph partitioning followed by supervised classification.
      We instantiate this general approach with the KaHIP graph partitioner (Sanders and Schulz 2013) and neural networks, respectively, to obtain a new partitioning procedure called Neural Locality-Sensitive Hashing (Neural LSH). On several standard benchmarks for NNS (Aumuller et al. 2017), our experiments show that the partitions obtained by Neural LSH consistently outperform partitions found by quantization-based and tree-based methods as well as classic, data-oblivious LSH.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://anonymous.4open.science/r/cdd789a8-818c-4675-98fd-39f8da656129/</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkenmREFDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1xnXRVFwH" data-number="1053">
      <h4>
        <a href="/forum?id=S1xnXRVFwH">
            Playing the lottery with rewards and multiple languages: lottery tickets in RL and NLP
        </a>
      
        
          <a href="/pdf?id=S1xnXRVFwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=haonanu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="haonanu@gmail.com">Haonan Yu</a>, <a href="/profile?email=edunov%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="edunov@fb.com">Sergey Edunov</a>, <a href="/profile?email=yuandong%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuandong@fb.com">Yuandong Tian</a>, <a href="/profile?email=arimorcos%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="arimorcos@gmail.com">Ari S. Morcos</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#S1xnXRVFwH-details-12" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1xnXRVFwH-details-12"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">lottery tickets, nlp, transformer, rl, reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We find that the lottery ticket phenomenon is present in both NLP and RL, and find that it can be used to train compressed Transformers to high performance</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The lottery ticket hypothesis proposes that over-parameterization of deep neural networks (DNNs) aids training by increasing the probability of a “lucky” sub-network initialization being present rather than by helping the optimization process (Frankle&amp; Carbin, 2019). Intriguingly, this phenomenon suggests that initialization strategies for DNNs can be improved substantially, but the lottery ticket hypothesis has only previously been tested in the context of supervised learning for natural image tasks. Here, we evaluate whether “winning ticket” initializations exist in two different domains: natural language processing (NLP) and reinforcement learning (RL).For NLP, we examined both recurrent LSTM models and large-scale Transformer models (Vaswani et al., 2017). For RL, we analyzed a number of discrete-action space tasks, including both classic control and pixel control. Consistent with workin supervised image classification, we confirm that winning ticket initializations generally outperform parameter-matched random initializations, even at extreme pruning rates for both NLP and RL. Notably, we are able to find winning ticket initializations for Transformers which enable models one-third the size to achieve nearly equivalent performance. Together, these results suggest that the lottery ticket hypothesis is not restricted to supervised learning of natural images, but rather represents a broader phenomenon in DNNs.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1xnXRVFwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SklTQCNtvS" data-number="1054">
      <h4>
        <a href="/forum?id=SklTQCNtvS">
            Sign-OPT: A Query-Efficient Hard-label Adversarial Attack
        </a>
      
        
          <a href="/pdf?id=SklTQCNtvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mhcheng%40ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mhcheng@ucla.edu">Minhao Cheng</a>, <a href="/profile?email=simranjit%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="simranjit@cs.ucla.edu">Simranjit Singh</a>, <a href="/profile?email=patrickchen%40ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="patrickchen@ucla.edu">Patrick H. Chen</a>, <a href="/profile?email=pin-yu.chen%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pin-yu.chen@ibm.com">Pin-Yu Chen</a>, <a href="/profile?email=sijia.liu%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sijia.liu@ibm.com">Sijia Liu</a>, <a href="/profile?email=chohsieh%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chohsieh@cs.ucla.edu">Cho-Jui Hsieh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="#SklTQCNtvS-details-812" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SklTQCNtvS-details-812"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study the most practical problem setup for evaluating adversarial robustness of a machine learning system with limited access:  the hard-label black-box attack setting for generating adversarial examples, where limited model queries are allowed and only the decision is provided to a queried data input. Several algorithms have been proposed for this problem but they typically require huge amount (&gt;20,000) of queries for attacking one example. Among them, one of the state-of-the-art approaches (Cheng et al., 2019) showed that hard-label attack can be modeled as an optimization problem where the objective function can be evaluated by binary search with additional model queries, thereby a zeroth order optimization algorithm can be applied. In this paper, we adopt the same optimization formulation but  propose to directly estimate the sign of gradient at any direction instead of the gradient itself, which enjoys the benefit of single query. 
      Using this single query oracle for retrieving sign of directional derivative, we develop a novel query-efficient Sign-OPT approach for hard-label black-box attack. We provide a convergence analysis of the new algorithm and conduct experiments on several models on MNIST, CIFAR-10 and ImageNet. 
      We find that Sign-OPT attack consistently requires 5X to 10X fewer queries when compared to the current state-of-the-art approaches, and usually converges to an adversarial example with smaller perturbation. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/cmhcbb/attackbox</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SklTQCNtvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJxR7R4FvS" data-number="1058">
      <h4>
        <a href="/forum?id=HJxR7R4FvS">
            RaCT: Toward Amortized Ranking-Critical Training For Collaborative Filtering 
        </a>
      
        
          <a href="/pdf?id=HJxR7R4FvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=samuel_lobel%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="samuel_lobel@brown.edu">Sam Lobel*</a>, <a href="/profile?email=chunyuan.li%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chunyuan.li@microsoft.com">Chunyuan Li*</a>, <a href="/profile?email=jfgao%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jfgao@microsoft.com">Jianfeng Gao</a>, <a href="/profile?email=lcarin%40duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lcarin@duke.edu">Lawrence Carin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#HJxR7R4FvS-details-25" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJxR7R4FvS-details-25"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Collaborative Filtering, Recommender Systems, Actor-Critic, Learned Metrics</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We apply the actor-critic methodology from reinforcement learning to collaborative filtering, resulting in improved performance across a variety of latent-variable models</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We investigate new methods for training collaborative filtering models based on actor-critic reinforcement learning, to more directly maximize ranking-based objective functions. Specifically, we train a critic network to approximate ranking-based metrics, and then update the actor network to directly optimize against the learned metrics. In contrast to traditional learning-to-rank methods that require re-running the optimization procedure for new lists, our critic-based method amortizes the scoring process with a neural network, and can directly provide the (approximate) ranking scores for new lists.
      
      We demonstrate the actor-critic's ability to significantly improve the performance of a variety of prediction models, and achieve better or comparable performance to a variety of strong baselines on three large-scale datasets.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/samlobel/RaCT_CF</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJxR7R4FvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJleNCNtDH" data-number="1063">
      <h4>
        <a href="/forum?id=SJleNCNtDH">
            Intrinsic Motivation for Encouraging Synergistic Behavior
        </a>
      
        
          <a href="/pdf?id=SJleNCNtDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ronuchit%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ronuchit@mit.edu">Rohan Chitnis</a>, <a href="/profile?email=shubhtuls%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shubhtuls@fb.com">Shubham Tulsiani</a>, <a href="/profile?email=saurabhg%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="saurabhg@illinois.edu">Saurabh Gupta</a>, <a href="/profile?email=abhinavg%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhinavg@cs.cmu.edu">Abhinav Gupta</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SJleNCNtDH-details-171" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJleNCNtDH-details-171"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a formulation of intrinsic motivation that is suitable as an exploration bias in synergistic multi-agent tasks, by encouraging agents to affect the world in ways that would not be achieved if they were acting individually.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study the role of intrinsic motivation as an exploration bias for reinforcement learning in sparse-reward synergistic tasks, which are tasks where multiple agents must work together to achieve a goal they could not individually. Our key idea is that a good guiding principle for intrinsic motivation in synergistic tasks is to take actions which affect the world in ways that would not be achieved if the agents were acting on their own. Thus, we propose to incentivize agents to take (joint) actions whose effects cannot be predicted via a composition of the predicted effect for each individual agent. We study two instantiations of this idea, one based on the true states encountered, and another based on a dynamics model trained concurrently with the policy. While the former is simpler, the latter has the benefit of being analytically differentiable with respect to the action taken. We validate our approach in robotic bimanual manipulation and multi-agent locomotion tasks with sparse rewards; we find that our approach yields more efficient learning than both 1) training with only the sparse reward and 2) using the typical surprise-based formulation of intrinsic motivation, which does not bias toward synergistic behavior. Videos are available on the project webpage: https://sites.google.com/view/iclr2020-synergistic.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, intrinsic motivation, synergistic, robot manipulation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJleNCNtDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rygG4AVFvH" data-number="1067">
      <h4>
        <a href="/forum?id=rygG4AVFvH">
            Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation
        </a>
      
        
          <a href="/pdf?id=rygG4AVFvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=bhahn%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bhahn@eng.ucsd.edu">Byung Hoon Ahn</a>, <a href="/profile?email=ppilligu%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ppilligu@eng.ucsd.edu">Prannoy Pilligundla</a>, <a href="/profile?email=ayazdan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ayazdan@google.com">Amir Yazdanbakhsh</a>, <a href="/profile?email=hadi%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hadi@eng.ucsd.edu">Hadi Esmaeilzadeh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 12 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rygG4AVFvH-details-857" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rygG4AVFvH-details-857"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement Learning, Learning to Optimize, Combinatorial Optimization, Compilers, Code Optimization, Neural Networks, ML for Systems, Learning for Systems</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Reinforcement Learning and Adaptive Sampling for Optimized Compilation of Deep Neural Networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Achieving faster execution with shorter compilation time can foster further diversity and innovation in neural networks. However, the current paradigm of executing neural networks either relies on hand-optimized libraries, traditional compilation heuristics, or very recently genetic algorithms and other stochastic methods. These methods suffer from frequent costly hardware measurements rendering them not only too time consuming but also suboptimal. As such, we devise a solution that can learn to quickly adapt to a previously unseen design space for code optimization, both accelerating the search and improving the output performance. This solution dubbed Chameleon leverages reinforcement learning whose solution takes fewer steps to converge, and develops an adaptive sampling algorithm that not only focuses on the costly samples (real hardware measurements) on representative points but also uses a domain-knowledge inspired logic to improve the samples itself. Experimentation with real hardware shows that Chameleon provides 4.45x speed up in optimization time over AutoTVM, while also improving inference time of the modern deep networks by 5.6%.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rygG4AVFvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1gB4RVKvB" data-number="1074">
      <h4>
        <a href="/forum?id=H1gB4RVKvB">
            Recurrent neural circuits for contour detection
        </a>
      
        
          <a href="/pdf?id=H1gB4RVKvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=drew_linsley%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="drew_linsley@brown.edu">Drew Linsley*</a>, <a href="/profile?email=junkyung_kim%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="junkyung_kim@brown.edu">Junkyung Kim*</a>, <a href="/profile?email=alekh_karkada_ashok%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="alekh_karkada_ashok@brown.edu">Alekh Ashok</a>, <a href="/profile?email=thomas_serre%40brown.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas_serre@brown.edu">Thomas Serre</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#H1gB4RVKvB-details-39" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1gB4RVKvB-details-39"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Contextual illusions, visual cortex, recurrent feedback, neural circuits</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Contextual illusions are a feature, not a bug, of neural routines optimized for contour detection.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We introduce a deep recurrent neural network architecture that approximates visual cortical circuits (Mély et al., 2018). We show that this architecture, which we refer to as the 𝜸-net, learns to solve contour detection tasks with better sample efficiency than state-of-the-art feedforward networks, while also exhibiting a classic perceptual illusion, known as the orientation-tilt illusion. Correcting this illusion significantly reduces \gnetw contour detection accuracy by driving it to prefer low-level edges over high-level object boundary contours. Overall, our study suggests that the orientation-tilt illusion is a byproduct of neural circuits that help biological visual systems achieve robust and efficient contour detection, and that incorporating these circuits in artificial neural networks can improve computer vision.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://mega.nz/#F!DrA12KCT!4BC_rfjqN5pXBbCl9Ay1DA</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1gB4RVKvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hye_V0NKwr" data-number="1080">
      <h4>
        <a href="/forum?id=Hye_V0NKwr">
            Locality and Compositionality in Zero-Shot Learning
        </a>
      
        
          <a href="/pdf?id=Hye_V0NKwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tristan.sylvain%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tristan.sylvain@gmail.com">Tristan Sylvain</a>, <a href="/profile?email=lindapetrini%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lindapetrini@gmail.com">Linda Petrini</a>, <a href="/profile?email=devon.hjelm%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="devon.hjelm@microsoft.com">Devon Hjelm</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#Hye_V0NKwr-details-748" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hye_V0NKwr-details-748"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">An analysis of the effects of compositionality and locality on representation learning for zero-shot learning.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In this work we study locality and compositionality in the context of learning representations for Zero Shot Learning (ZSL). 
      In order to well-isolate the importance of these properties in learned representations, we impose the additional constraint that, differently from most recent work in ZSL, no pre-training on different datasets (e.g. ImageNet) is performed.
      The results of our experiment show how locality, in terms of small parts of the input, and compositionality, i.e. how well can the learned representations be expressed as a function of a smaller vocabulary, are both deeply related to generalization and motivate the focus on more local-aware models in future research directions for representation learning.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Zero-shot learning, Compositionality, Locality, Deep Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hye_V0NKwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BygFVAEKDH" data-number="1083">
      <h4>
        <a href="/forum?id=BygFVAEKDH">
            Understanding Knowledge Distillation in Non-autoregressive Machine Translation
        </a>
      
        
          <a href="/pdf?id=BygFVAEKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=chuntinz%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chuntinz@andrew.cmu.edu">Chunting Zhou</a>, <a href="/profile?email=jgu%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jgu@fb.com">Jiatao Gu</a>, <a href="/profile?email=gneubig%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gneubig@cs.cmu.edu">Graham Neubig</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="#BygFVAEKDH-details-355" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BygFVAEKDH-details-355"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We systematically examine why knowledge distillation is crucial to the training of non-autoregressive translation (NAT) models, and propose methods to further improve the distilled data to best match the capacity of an NAT model.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Non-autoregressive machine translation (NAT) systems predict a sequence of output tokens in parallel, achieving substantial improvements in generation speed compared to autoregressive models. Existing NAT models usually rely on the technique of knowledge distillation, which creates the training data from a pretrained autoregressive model for better performance. Knowledge distillation is empirically useful, leading to large gains in accuracy for NAT models, but the reason for this success has, as of yet, been unclear. In this paper, we first design systematic experiments to investigate why knowledge distillation is crucial to NAT training. We find that knowledge distillation can reduce the complexity of data sets and help NAT to model the variations in the output data. Furthermore, a strong correlation is observed between the capacity of an NAT model and the optimal complexity of the distilled data for the best translation quality. Based on these findings, we further propose several approaches that can alter the complexity of data sets to improve the performance of NAT models. We achieve the state-of-the-art performance for the NAT-based models, and close the gap with the autoregressive baseline on WMT14 En-De benchmark.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">knowledge distillation, non-autoregressive neural machine translation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BygFVAEKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byl5NREFDr" data-number="1084">
      <h4>
        <a href="/forum?id=Byl5NREFDr">
            Thieves on Sesame Street! Model Extraction of BERT-based APIs
        </a>
      
        
          <a href="/pdf?id=Byl5NREFDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kalpesh%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kalpesh@cs.umass.edu">Kalpesh Krishna</a>, <a href="/profile?email=gtomar%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gtomar@google.com">Gaurav Singh Tomar</a>, <a href="/profile?email=aparikh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aparikh@google.com">Ankur P. Parikh</a>, <a href="/profile?email=papernot%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="papernot@google.com">Nicolas Papernot</a>, <a href="/profile?email=miyyer%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="miyyer@cs.umass.edu">Mohit Iyyer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#Byl5NREFDr-details-14" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byl5NREFDr-details-14"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">model extraction, BERT, natural language processing, pretraining language models, model stealing, deep learning security</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Outputs of modern NLP APIs on nonsensical text provide strong signals about model internals, allowing adversaries to steal the APIs.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al., 2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction—membership classification and API watermarking—which while successful against some adversaries can also be circumvented by more clever ones.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/google-research/language/tree/master/language/bert_extraction</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Byl5NREFDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJx040EFvH" data-number="1095">
      <h4>
        <a href="/forum?id=BJx040EFvH">
            Fast is better than free: Revisiting adversarial training
        </a>
      
        
          <a href="/pdf?id=BJx040EFvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ericwong%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ericwong@cs.cmu.edu">Eric Wong</a>, <a href="/profile?email=larice%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="larice@cs.cmu.edu">Leslie Rice</a>, <a href="/profile?email=zkolter%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zkolter@cs.cmu.edu">J. Zico Kolter</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>51 Replies</span>
        
        
      </div>
      
        <a href="#BJx040EFvH-details-744" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJx040EFvH-details-744"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">FGSM-based adversarial training, with randomization, works just as well as PGD-based adversarial training: we can use this to train a robust classifier in 6 minutes on CIFAR10, and 12 hours on ImageNet, on a single machine.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Adversarial training, a method for learning robust deep networks, is typically assumed to be more expensive than traditional training due to the necessity of constructing adversarial examples via a first-order method like projected gradient decent (PGD).  In this paper, we make the surprising discovery that it is possible to train empirically robust models using a much weaker and cheaper adversary, an approach that was previously believed to be ineffective, rendering the method no more costly than standard training in practice.  Specifically, we show that adversarial training with the fast gradient sign method (FGSM), when combined with random initialization, is as effective as PGD-based training but has significantly lower cost.  Furthermore we show that FGSM adversarial training can be further accelerated by using standard techniques for efficient training of deep networks, allowing us to learn a robust CIFAR10 classifier with 45% robust accuracy at epsilon=8/255 in 6 minutes, and a robust ImageNet classifier with 43% robust accuracy at epsilon=2/255 in 12 hours, in comparison to past work based on ``free'' adversarial training which took 10 and 50 hours to reach the same respective thresholds. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/anonymous-sushi-armadillo</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial examples, adversarial training, fast gradient sign method</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJx040EFvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgyS0VFvr" data-number="1097">
      <h4>
        <a href="/forum?id=rkgyS0VFvr">
            DBA: Distributed Backdoor Attacks against Federated Learning
        </a>
      
        
          <a href="/pdf?id=rkgyS0VFvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=chulinxie%40zju.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="chulinxie@zju.edu.cn">Chulin Xie</a>, <a href="/profile?email=nick_cooper%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="nick_cooper@sjtu.edu.cn">Keli Huang</a>, <a href="/profile?email=pin-yu.chen%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pin-yu.chen@ibm.com">Pin-Yu Chen</a>, <a href="/profile?email=lbo%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lbo@illinois.edu">Bo Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 03 May 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rkgyS0VFvr-details-88" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgyS0VFvr-details-88"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We proposed a novel distributed backdoor attack on federated learning and show that it is not only more effective compared with standard centralized attacks, but also harder to be defended by existing robust FL methods</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Backdoor attacks aim to manipulate a subset of training data by injecting adversarial triggers such that machine learning models trained on the tampered dataset will make arbitrarily (targeted) incorrect prediction on the testset with the same trigger embedded. While federated learning (FL) is capable of aggregating information provided by different parties for training a better model, its distributed learning methodology and inherently heterogeneous data distribution across parties may bring new vulnerabilities. In addition to recent centralized backdoor attacks on FL where each party embeds the same global trigger during training, we propose the distributed backdoor attack (DBA) --- a novel threat assessment framework developed by fully exploiting the distributed nature of FL. DBA decomposes a global trigger pattern into separate local patterns and embed them into the training set of different adversarial parties respectively. Compared to standard centralized backdoors, we show that DBA is substantially more persistent and stealthy against FL on diverse datasets such as finance and image data. We conduct extensive experiments to show that the attack success rate of DBA is significantly higher than centralized backdoors under different settings. Moreover, we find that distributed attacks are indeed more insidious, as DBA can evade two state-of-the-art robust FL algorithms against centralized backdoors. We also provide explanations for the effectiveness of DBA via feature visual interpretation and feature importance ranking.
      To further explore the properties of DBA, we test the attack performance by varying different trigger factors, including local trigger variations (size, gap, and location), scaling factor in FL, data distribution, and poison ratio and interval. Our proposed DBA and thorough evaluation results shed lights on characterizing the robustness of FL.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">distributed backdoor attack, federated learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgyS0VFvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJeXS04FPH" data-number="1105">
      <h4>
        <a href="/forum?id=rJeXS04FPH">
            DeFINE: Deep Factorized Input Token Embeddings for Neural Sequence Modeling
        </a>
      
        
          <a href="/pdf?id=rJeXS04FPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sacmehta%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sacmehta@uw.edu">Sachin Mehta</a>, <a href="/profile?email=kedzior%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kedzior@uw.edu">Rik Koncel-Kedziorski</a>, <a href="/profile?email=mohammadr%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="mohammadr@allenai.org">Mohammad Rastegari</a>, <a href="/profile?email=hannaneh%40washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hannaneh@washington.edu">Hannaneh Hajishirzi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="#rJeXS04FPH-details-255" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJeXS04FPH-details-255"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">sequence modeling, input representations, language modeling, word embedding</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">DeFINE uses a deep, hierarchical, sparse network with new skip connections to learn better word embeddings efficiently. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">For sequence models with large vocabularies, a majority of network parameters lie in the input and output layers. In this work, we describe a new method, DeFINE, for learning deep token representations efficiently. Our architecture uses a hierarchical structure with novel skip-connections which allows for the use of low dimensional input and output layers, reducing total parameters and training time while delivering similar or better performance versus existing methods. DeFINE can be incorporated easily in new or existing sequence models. Compared to state-of-the-art methods including adaptive input representations, this technique results in a 6% to 20% drop in perplexity. On WikiText-103, DeFINE reduces the total parameters of Transformer-XL by half with minimal impact on performance. On the Penn Treebank, DeFINE improves AWD-LSTM by 4 points with a 17% reduction in parameters, achieving comparable performance to state-of-the-art methods with fewer parameters. For machine translation, DeFINE improves the efficiency of the Transformer model by about 1.4 times while delivering similar performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJeXS04FPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylVHR4FPB" data-number="1108">
      <h4>
        <a href="/forum?id=rylVHR4FPB">
            Sampling-Free Learning of Bayesian Quantized Neural Networks
        </a>
      
        
          <a href="/pdf?id=rylVHR4FPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jiahaosu%40terpmail.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiahaosu@terpmail.umd.edu">Jiahao Su</a>, <a href="/profile?email=mcvitkov%40caltech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mcvitkov@caltech.edu">Milan Cvitkovic</a>, <a href="/profile?email=furongh%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="furongh@cs.umd.edu">Furong Huang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rylVHR4FPB-details-378" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylVHR4FPB-details-378"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose Bayesian quantized networks, for which we learn a posterior distribution over their quantized parameters.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Bayesian learning of model parameters in neural networks is important in scenarios where estimates with well-calibrated uncertainty are important. In this paper, we propose Bayesian quantized networks (BQNs), quantized neural networks (QNNs) for which we learn a posterior distribution over their discrete parameters. We provide a set of efficient algorithms for learning and prediction in BQNs without the need to sample from their parameters or activations, which not only allows for differentiable learning in quantized models but also reduces the variance in gradients estimation. We evaluate BQNs on MNIST, Fashion-MNIST and KMNIST classification datasets compared against bootstrap ensemble of QNNs (E-QNN). We demonstrate BQNs achieve both lower predictive errors and better-calibrated uncertainties than E-QNN (with less than 20% of the negative log-likelihood).</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Bayesian neural networks, Quantized neural networks</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rylVHR4FPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByeUBANtvB" data-number="1112">
      <h4>
        <a href="/forum?id=ByeUBANtvB">
            Learning to solve the credit assignment problem
        </a>
      
        
          <a href="/pdf?id=ByeUBANtvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ben.lansdell%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ben.lansdell@gmail.com">Benjamin James Lansdell</a>, <a href="/profile?email=prprak%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="prprak@seas.upenn.edu">Prashanth Ravi Prakash</a>, <a href="/profile?email=koerding%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="koerding@gmail.com">Konrad Paul Kording</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#ByeUBANtvB-details-154" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByeUBANtvB-details-154"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">biologically plausible deep learning, node perturbation, REINFORCE, synthetic gradients, feedback alignment</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Perturbations can be used to train feedback weights to learn in fully connected and convolutional neural networks</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Backpropagation is driving today's artificial neural networks (ANNs). However, despite extensive research, it remains unclear if the brain implements this algorithm. Among neuroscientists, reinforcement learning (RL) algorithms are often seen as a realistic alternative: neurons can randomly introduce change, and use unspecific feedback signals to observe their effect on the cost and thus approximate their gradient. However, the convergence rate of such learning scales poorly with the number of involved neurons. Here we propose a hybrid learning approach. Each neuron uses an RL-type strategy to learn how to approximate the gradients that backpropagation would provide. We provide proof that our approach converges to the true gradient for certain classes of networks. In both feedforward and convolutional networks, we empirically show that our approach learns to approximate the gradient, and can match the performance of gradient-based learning. Learning feedback weights provides a biologically plausible mechanism of achieving good performance, without the need for precise, pre-specified learning rules.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/benlansdell/synthfeedback</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByeUBANtvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJx8HANFDH" data-number="1113">
      <h4>
        <a href="/forum?id=HJx8HANFDH">
            Four Things Everyone Should Know to Improve Batch Normalization
        </a>
      
        
          <a href="/pdf?id=HJx8HANFDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ceciliasummers07%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ceciliasummers07@gmail.com">Cecilia Summers</a>, <a href="/profile?email=mjd%40cs.auckland.ac.nz" class="profile-link" data-toggle="tooltip" data-placement="top" title="mjd@cs.auckland.ac.nz">Michael J. Dinneen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#HJx8HANFDH-details-572" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJx8HANFDH-details-572"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">batch normalization</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Four things that improve batch normalization across all batch sizes</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">A key component of most neural network architectures is the use of normalization layers, such as Batch Normalization. Despite its common use and large utility in optimizing deep architectures, it has been challenging both to generically improve upon Batch Normalization and to understand the circumstances that lend themselves to other enhancements. In this paper, we identify four improvements to the generic form of Batch Normalization and the circumstances under which they work, yielding performance gains across all batch sizes while requiring no additional computation during training. These contributions include proposing a method for reasoning about the current example in inference normalization statistics, fixing a training vs. inference discrepancy; recognizing and validating the powerful regularization effect of Ghost Batch Normalization for small and medium batch sizes; examining the effect of weight decay regularization on the scaling and shifting parameters γ and β; and identifying a new normalization algorithm for very small batch sizes by combining the strengths of Batch and Group Normalization. We validate our results empirically on six datasets: CIFAR-100, SVHN, Caltech-256, Oxford Flowers-102, CUB-2011, and ImageNet.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/ceciliaresearch/four_things_batch_norm</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJx8HANFDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJedHRVtPB" data-number="1117">
      <h4>
        <a href="/forum?id=BJedHRVtPB">
            Pseudo-LiDAR++: Accurate Depth for 3D Object Detection in Autonomous Driving
        </a>
      
        
          <a href="/pdf?id=BJedHRVtPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yy785%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yy785@cornell.edu">Yurong You</a>, <a href="/profile?email=yw763%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yw763@cornell.edu">Yan Wang</a>, <a href="/profile?email=weilunchao760414%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="weilunchao760414@gmail.com">Wei-Lun Chao</a>, <a href="/profile?email=dg595%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dg595@cornell.edu">Divyansh Garg</a>, <a href="/profile?email=gp346%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gp346@cornell.edu">Geoff Pleiss</a>, <a href="/profile?email=bharathh%40cs.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bharathh@cs.cornell.edu">Bharath Hariharan</a>, <a href="/profile?email=mc288%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mc288@cornell.edu">Mark Campbell</a>, <a href="/profile?email=kqw4%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kqw4@cornell.edu">Kilian Q. Weinberger</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 20 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#BJedHRVtPB-details-280" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJedHRVtPB-details-280"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Detecting objects such as cars and pedestrians in 3D plays an indispensable role in autonomous driving. Existing approaches largely rely on expensive LiDAR sensors for accurate depth information. While recently pseudo-LiDAR has been introduced as a promising alternative, at a much lower cost based solely on stereo images, there is still a notable performance gap. 
      In this paper we provide substantial advances to the pseudo-LiDAR framework through improvements in stereo depth estimation. Concretely, we adapt the stereo network architecture and loss function to be more aligned with accurate depth estimation of faraway objects --- currently the primary weakness of pseudo-LiDAR. Further, we explore the idea to leverage cheaper but extremely sparse LiDAR sensors, which alone provide insufficient information for 3D detection, to de-bias our depth estimation. We propose a depth-propagation algorithm, guided by the initial depth estimates, to diffuse these few exact measurements across the entire depth map. We show on the KITTI object detection benchmark that our combined approach yields substantial improvements in depth estimation and stereo-based 3D object detection --- outperforming the previous state-of-the-art detection accuracy for faraway objects by 40%. Our code is available at https://github.com/mileyan/Pseudo_Lidar_V2.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">pseudo-LiDAR, 3D-object detection, stereo depth estimation, autonomous driving</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/mileyan/Pseudo_Lidar_V2</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJedHRVtPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkxJ8REYPH" data-number="1123">
      <h4>
        <a href="/forum?id=SkxJ8REYPH">
            SlowMo: Improving Communication-Efficient Distributed SGD with Slow Momentum
        </a>
      
        
          <a href="/pdf?id=SkxJ8REYPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jianyuw1%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianyuw1@andrew.cmu.edu">Jianyu Wang</a>, <a href="/profile?email=tantia%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tantia@fb.com">Vinayak Tantia</a>, <a href="/profile?email=ballasn%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ballasn@fb.com">Nicolas Ballas</a>, <a href="/profile?email=mikerabbat%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mikerabbat@fb.com">Michael Rabbat</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SkxJ8REYPH-details-535" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkxJ8REYPH-details-535"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">SlowMo improves the optimization and generalization performance of communication-efficient decentralized algorithms without sacrificing speed.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Distributed optimization is essential for training large models on large datasets. Multiple approaches have been proposed to reduce the communication overhead in distributed training, such as synchronizing only after performing multiple local SGD steps, and decentralized methods (e.g., using gossip algorithms) to decouple communications among workers. Although these methods run faster than AllReduce-based methods, which use blocking communication before every update, the resulting models may be less accurate after the same number of updates. Inspired by the BMUF method of Chen &amp; Huo (2016), we propose a slow momentum (SlowMo) framework, where workers periodically synchronize and perform a momentum update, after multiple iterations of a base optimization algorithm. Experiments on image classification and machine translation tasks demonstrate that SlowMo consistently yields improvements in optimization and generalization performance relative to the base optimizer, even when the additional overhead is amortized over many updates so that the SlowMo runtime is on par with that of the base optimizer. We provide theoretical convergence guarantees showing that SlowMo converges to a stationary point of smooth non-convex losses. Since BMUF can be expressed through the SlowMo framework, our results also correspond to the first theoretical convergence guarantees for BMUF.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">distributed optimization, decentralized training methods, communication-efficient distributed training with momentum, large-scale parallel SGD</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkxJ8REYPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJx1URNKwH" data-number="1124">
      <h4>
        <a href="/forum?id=SJx1URNKwH">
            MetaPix: Few-Shot Video Retargeting
        </a>
      
        
          <a href="/pdf?id=SJx1URNKwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jl5%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jl5@cs.cmu.edu">Jessica Lee</a>, <a href="/profile?email=deva%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="deva@cs.cmu.edu">Deva Ramanan</a>, <a href="/profile?email=rgirdhar%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rgirdhar@cs.cmu.edu">Rohit Girdhar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SJx1URNKwH-details-659" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJx1URNKwH-details-659"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Meta-learning, Few-shot Learning, Generative Adversarial Networks, Video Retargeting</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Video retargeting typically requires large amount of target data to be effective, which may not always be available; we propose a metalearning approach that improves over popular baselines while producing temporally coherent frames.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We address the task of unsupervised retargeting of human actions from one video to another. We consider the challenging setting where only a few frames of the target is available. The core of our approach is a conditional generative model that can transcode input skeletal poses (automatically extracted with an off-the-shelf pose estimator) to output target frames. However, it is challenging to build a universal transcoder because humans can appear wildly different due to clothing and background scene geometry. Instead, we learn to adapt – or personalize – a universal generator to the particular human and background in the target. To do so, we make use of meta-learning to discover effective strategies for on-the-fly personalization. One significant benefit of meta-learning is that the personalized transcoder naturally enforces temporal coherence across its generated frames; all frames contain consistent clothing and background geometry of the target. We experiment on in-the-wild internet videos and images and show our approach improves over widely-used baselines for the task.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJx1URNKwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxz8CVYDH" data-number="1130">
      <h4>
        <a href="/forum?id=ryxz8CVYDH">
            Learning to Learn by Zeroth-Order Oracle
        </a>
      
        
          <a href="/pdf?id=ryxz8CVYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ruanyj3107%40zju.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruanyj3107@zju.edu.cn">Yangjun Ruan</a>, <a href="/profile?email=yhxiong%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yhxiong@cs.ucla.edu">Yuanhao Xiong</a>, <a href="/profile?email=sashank%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sashank@google.com">Sashank Reddi</a>, <a href="/profile?email=sanjivk%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanjivk@google.com">Sanjiv Kumar</a>, <a href="/profile?email=chohsieh%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chohsieh@cs.ucla.edu">Cho-Jui Hsieh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 27 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#ryxz8CVYDH-details-104" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxz8CVYDH-details-104"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">learning to learn, zeroth-order optimization, black-box adversarial attack</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Novel variant of learning to learn framework for zeroth-order optimization that learns both the update rule and the Gaussian sampling rule.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In the learning to learn (L2L) framework, we cast the design of optimization algorithms as a machine learning problem and use deep neural networks to learn the update rules. In this paper, we extend the L2L framework to zeroth-order (ZO) optimization setting, where no explicit gradient information is available. Our learned optimizer, modeled as recurrent neural network (RNN), first approximates gradient by ZO gradient estimator and then produces parameter update utilizing the knowledge of previous iterations. To reduce high variance effect due to ZO gradient estimator, we further introduce another RNN to learn the Gaussian sampling rule and dynamically guide the query direction sampling. Our learned optimizer outperforms hand-designed algorithms in terms of convergence rate and final solution on both synthetic and practical ZO optimization tasks (in particular, the black-box adversarial attack task, which is one of the most widely used tasks of ZO optimization). We finally conduct extensive analytical experiments to demonstrate the effectiveness of our proposed optimizer.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/RYoungJ/ZO-L2L</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxz8CVYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1gX8C4YPr" data-number="1132">
      <h4>
        <a href="/forum?id=H1gX8C4YPr">
            DD-PPO: Learning Near-Perfect PointGoal Navigators from 2.5 Billion Frames
        </a>
      
        
          <a href="/pdf?id=H1gX8C4YPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=etw%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="etw@gatech.edu">Erik Wijmans</a>, <a href="/profile?email=akadian%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="akadian@fb.com">Abhishek Kadian</a>, <a href="/profile?email=arimorcos%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="arimorcos@gmail.com">Ari Morcos</a>, <a href="/profile?email=leestef%40oregonstate.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="leestef@oregonstate.edu">Stefan Lee</a>, <a href="/profile?email=irfan%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="irfan@gatech.edu">Irfan Essa</a>, <a href="/profile?email=parikh%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="parikh@gatech.edu">Devi Parikh</a>, <a href="/profile?email=msavva%40sfu.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="msavva@sfu.ca">Manolis Savva</a>, <a href="/profile?email=dbatra%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dbatra@gatech.edu">Dhruv Batra</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#H1gX8C4YPr-details-388" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1gX8C4YPr-details-388"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">autonomous navigation, habitat, embodied AI, pointgoal navigation, reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present Decentralized Distributed Proximal Policy Optimization (DD-PPO), a method for distributed reinforcement learning in resource-intensive simulated environments. DD-PPO is distributed (uses multiple machines), decentralized (lacks a centralized server), and synchronous (no computation is ever "stale"), making it conceptually simple and easy to implement. In our experiments on training virtual robots to navigate in Habitat-Sim, DD-PPO exhibits near-linear scaling -- achieving a speedup of 107x on 128 GPUs over a serial implementation. We leverage this scaling to train an agent for 2.5 Billion steps of experience (the equivalent of 80 years of human experience) -- over 6 months of GPU-time training in under 3 days of wall-clock time with 64 GPUs. 
      
      This massive-scale training not only sets the state of art on Habitat Autonomous Navigation Challenge 2019, but essentially "solves" the task -- near-perfect autonomous navigation in an unseen environment without access to a map, directly from an RGB-D camera and a GPS+Compass sensor.  Fortuitously, error vs computation exhibits a power-law-like distribution; thus, 90% of peak performance is obtained relatively early (at 100 million steps) and relatively cheaply (under 1 day with 8 GPUs). Finally, we show that the scene understanding and navigation policies learned can be transferred to other navigation tasks -- the analog of "ImageNet pre-training + task-specific fine-tuning" for embodied AI. Our model outperforms ImageNet pre-trained CNNs on these transfer tasks and can serve as a universal resource (all models and code are publicly available). </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/facebookresearch/habitat-api</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1gX8C4YPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJxVI04YvB" data-number="1134">
      <h4>
        <a href="/forum?id=BJxVI04YvB">
            PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction
        </a>
      
        
          <a href="/pdf?id=BJxVI04YvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sangdonp%40cis.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sangdonp@cis.upenn.edu">Sangdon Park</a>, <a href="/profile?email=obastani%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="obastani@seas.upenn.edu">Osbert Bastani</a>, <a href="/profile?email=nmatni%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nmatni@seas.upenn.edu">Nikolai Matni</a>, <a href="/profile?email=lee%40cis.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lee@cis.upenn.edu">Insup Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#BJxVI04YvB-details-795" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJxVI04YvB-details-795"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose an algorithm combining calibrated prediction and generalization bounds from learning theory to construct confidence sets for deep neural networks with PAC guarantees---i.e., the confidence set for a given input contains the true label with high probability. We demonstrate how our approach can be used to construct PAC confidence sets on ResNet for ImageNet, a visual object tracking model, and a dynamics model for the half-cheetah reinforcement learning problem.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">PAC, confidence sets, classification, regression, reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/sangdon/PAC-confidence-set</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJxVI04YvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJgVU0EKwS" data-number="1135">
      <h4>
        <a href="/forum?id=SJgVU0EKwS">
            Precision Gating: Improving Neural Network Efficiency with Dynamic Dual-Precision Activations
        </a>
      
        
          <a href="/pdf?id=SJgVU0EKwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yz2499%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yz2499@cornell.edu">Yichi Zhang</a>, <a href="/profile?email=rz252%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rz252@cornell.edu">Ritchie Zhao</a>, <a href="/profile?email=wh399%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wh399@cornell.edu">Weizhe Hua</a>, <a href="/profile?email=nx38%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nx38@cornell.edu">Nayun Xu</a>, <a href="/profile?email=edward.suh%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="edward.suh@cornell.edu">G. Edward Suh</a>, <a href="/profile?email=zhiruz%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhiruz@cornell.edu">Zhiru Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#SJgVU0EKwS-details-719" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJgVU0EKwS-details-719"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose precision gating (PG), an end-to-end trainable dynamic dual-precision quantization technique for deep neural networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose precision gating (PG), an end-to-end trainable dynamic dual-precision quantization technique for deep neural networks.  PG computes most features in a low precision and only a small proportion of important features in a higher precision to preserve accuracy.  The proposed approach is applicable to a variety of DNN architectures and significantly reduces the computational cost of DNN execution with almost no accuracy loss.  Our experiments indicate that PG achieves excellent results on CNNs, including statically compressed mobile-friendly networks such as ShuffleNet. Compared to the state-of-the-art prediction-based quantization schemes, PG achieves the same or higher accuracy with 2.4× less compute on ImageNet. PG furthermore applies to RNNs. Compared to 8-bit uniform quantization, PG obtains a 1.2% improvement in perplexity per word with 2.7× computational cost reduction on LSTM on the Penn Tree Bank dataset.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/cornell-zhang/dnn-gating</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, neural network, dynamic quantization, dual precision, efficient gating</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJgVU0EKwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bke8UR4FPB" data-number="1139">
      <h4>
        <a href="/forum?id=Bke8UR4FPB">
            Oblique Decision Trees from Derivatives of ReLU Networks
        </a>
      
        
          <a href="/pdf?id=Bke8UR4FPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=guanghe%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guanghe@csail.mit.edu">Guang-He Lee</a>, <a href="/profile?email=tommi%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tommi@csail.mit.edu">Tommi S. Jaakkola</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 04 May 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#Bke8UR4FPB-details-471" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bke8UR4FPB-details-471"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A novel neural architecture which implicitly realizes (oblique) decision trees.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We show how neural models can be used to realize piece-wise constant functions such as decision trees. The proposed architecture, which we call locally constant networks, builds on ReLU networks that are piece-wise linear and hence their associated gradients with respect to the inputs are locally constant. We formally establish the equivalence between the classes of locally constant networks and decision trees. Moreover, we highlight several advantageous properties of locally constant networks, including how they realize decision trees with parameter sharing across branching / leaves. Indeed, only <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="434" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi></math></mjx-assistive-mml></mjx-container> neurons suffice to implicitly model an oblique decision tree with <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="435" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.363em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>2</mn><mi>M</mi></msup></math></mjx-assistive-mml></mjx-container> leaf nodes. The neural representation also enables us to adopt many tools developed for deep networks (e.g., DropConnect (Wan et al., 2013)) while implicitly training decision trees. We demonstrate that our method outperforms alternative techniques for training oblique decision trees in the context of molecular property classification and regression tasks. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">oblique decision trees, ReLU networks</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/guanghelee/iclr20-lcn</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Bke8UR4FPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1guLAVFDB" data-number="1145">
      <h4>
        <a href="/forum?id=B1guLAVFDB">
            Span Recovery for Deep Neural Networks with Applications to Input Obfuscation
        </a>
      
        
          <a href="/pdf?id=B1guLAVFDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=rkjayara%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rkjayara@cs.cmu.edu">Rajesh Jayaram</a>, <a href="/profile?email=dwoodruf%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dwoodruf@andrew.cmu.edu">David P. Woodruff</a>, <a href="/profile?email=qiuyiz%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qiuyiz@google.com">Qiuyi Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#B1guLAVFDB-details-319" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1guLAVFDB-details-319"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Span recovery, low rank neural networks, adversarial attack</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We provably recover the span of a deep multi-layered neural network with latent structure and empirically apply efficient span recovery algorithms to attack networks by obfuscating inputs.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The tremendous success of deep neural networks has motivated the need to better understand the fundamental properties of these networks, but many of the theoretical results proposed have only been for shallow networks. In this paper, we study an important primitive for understanding the meaningful input space of a deep network: span recovery. For <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="436" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>&lt;</mo><mi>n</mi></math></mjx-assistive-mml></mjx-container>, let <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="437" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D400 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c211D TEX-A"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.41em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold">A</mi></mrow><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>k</mi><mo>×</mo><mi>n</mi></mrow></msup></math></mjx-assistive-mml></mjx-container> be the innermost weight matrix of an arbitrary feed forward neural network <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="438" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3A"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c211D TEX-A"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.41em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c211D TEX-A"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi><mo>:</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mi>n</mi></msup><mo accent="false" stretchy="false">→</mo><mrow><mi mathvariant="double-struck">R</mi></mrow></math></mjx-assistive-mml></mjx-container>, so <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="439" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> can be written as <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="440" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D70E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D400 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="bold">A</mi></mrow><mi>x</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>, for some network <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="441" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D70E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3A"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c211D TEX-A"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.41em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c211D TEX-A"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>σ</mi><mo>:</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mi>k</mi></msup><mo accent="false" stretchy="false">→</mo><mrow><mi mathvariant="double-struck">R</mi></mrow></math></mjx-assistive-mml></mjx-container>. The goal is then to recover the row span of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="442" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D400 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold">A</mi></mrow></math></mjx-assistive-mml></mjx-container> given only oracle access to the value of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="443" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>. We show that if <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="444" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi></math></mjx-assistive-mml></mjx-container> is a multi-layered network with ReLU activation functions, then partial recovery is possible: namely, we can provably recover <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="445" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mrow><mo>/</mo></mrow><mn>2</mn></math></mjx-assistive-mml></mjx-container> linearly independent vectors in the row span of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="446" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D400 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold">A</mi></mrow></math></mjx-assistive-mml></mjx-container> using poly<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="447" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> non-adaptive queries to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="448" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>.  Furthermore, if <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="449" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi></math></mjx-assistive-mml></mjx-container> has differentiable activation functions, we demonstrate that \textit{full} span recovery is possible even when the output is first passed through a sign or <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="450" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>0</mn><mrow><mo>/</mo></mrow><mn>1</mn></math></mjx-assistive-mml></mjx-container> thresholding function; in this case our algorithm is adaptive. Empirically, we confirm that full span recovery is not always possible, but only for unrealistically thin layers. For reasonably wide networks, we obtain full span recovery on both random networks and networks trained on MNIST data. Furthermore, we demonstrate the utility of span recovery as an attack by inducing neural networks to misclassify data obfuscated by controlled random noise as sensical inputs. 
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/open?id=1-vPO5g52w8oON4neivTTmrL53Lnj4bdR  https://drive.google.com/open?id=1qXHG90ypdzfYt_sGqRtyQZ5pFgt3KllP</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1guLAVFDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByxY8CNtvr" data-number="1146">
      <h4>
        <a href="/forum?id=ByxY8CNtvr">
            Improving Neural Language Generation with Spectrum Control
        </a>
      
        
          <a href="/pdf?id=ByxY8CNtvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=lingxw%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lingxw@cs.ucla.edu">Lingxiao Wang</a>, <a href="/profile?email=jing.huang%40jd.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jing.huang@jd.com">Jing Huang</a>, <a href="/profile?email=kevin.huang3%40jd.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kevin.huang3@jd.com">Kevin Huang</a>, <a href="/profile?email=bull%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bull@cs.ucla.edu">Ziniu Hu</a>, <a href="/profile?email=guangtao.wang%40jd.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="guangtao.wang@jd.com">Guangtao Wang</a>, <a href="/profile?email=qgu%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qgu@cs.ucla.edu">Quanquan Gu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#ByxY8CNtvr-details-113" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByxY8CNtvr-details-113"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recent Transformer-based models such as Transformer-XL and BERT have achieved huge success on various natural language processing tasks. However, contextualized embeddings at the output layer of these powerful models tend to degenerate and occupy an anisotropic cone in the vector space, which is called the representation degeneration problem. In this paper, we propose a novel spectrum control approach to address this degeneration problem. The core idea of our method is to directly guide the spectra training of the output embedding matrix with a slow-decaying singular value prior distribution through a reparameterization framework. We show that our proposed method encourages isotropy of the learned word representations while maintains the modeling power of these contextual neural models. We further provide a theoretical analysis and insight on the benefit of modeling singular value distribution. We demonstrate that our spectrum control method outperforms the state-of-the-art Transformer-XL modeling for language model, and various Transformer-based models for machine translation, on common benchmark datasets for these tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByxY8CNtvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJlh8CEYDB" data-number="1153">
      <h4>
        <a href="/forum?id=SJlh8CEYDB">
            Learn to Explain Efficiently via Neural Logic Inductive Learning
        </a>
      
        
          <a href="/pdf?id=SJlh8CEYDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yyang754%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yyang754@gatech.edu">Yuan Yang</a>, <a href="/profile?email=lsong%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lsong@cc.gatech.edu">Le Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="#SJlh8CEYDB-details-227" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJlh8CEYDB-details-227"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">An efficient differentiable ILP model that learns first-order logic rules that can explain the data.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The capability of making interpretable and self-explanatory decisions is essential for developing responsible machine learning systems. In this work, we study the learning to explain the problem in the scope of inductive logic programming (ILP). We propose Neural Logic Inductive Learning (NLIL), an efficient differentiable ILP framework that learns first-order logic rules that can explain the patterns in the data. In experiments, compared with the state-of-the-art models, we find NLIL is able to search for rules that are x10 times longer while remaining x3 times faster. We also show that NLIL can scale to large image datasets, i.e. Visual Genome, with 1M entities.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">inductive logic programming, interpretability, attention</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/gblackout/NLIL</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJlh8CEYDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryx1wRNFvB" data-number="1160">
      <h4>
        <a href="/forum?id=ryx1wRNFvB">
            Improved memory in recurrent neural networks with sequential non-normal dynamics
        </a>
      
        
          <a href="/pdf?id=ryx1wRNFvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=aeminorhan%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aeminorhan@gmail.com">Emin Orhan</a>, <a href="/profile?email=xaq%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xaq@rice.edu">Xaq Pitkow</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#ryx1wRNFvB-details-86" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryx1wRNFvB-details-86"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">a feedforward, chain-like motif (1-&gt;2-&gt;3-&gt;...) is proposed as a useful inductive bias for better memory in RNNs.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Training recurrent neural networks (RNNs) is a hard problem due to degeneracies in the optimization landscape, a problem also known as vanishing/exploding gradients. Short of designing new RNN architectures, previous methods for dealing with this problem usually boil down to orthogonalization of the recurrent dynamics, either at initialization or during the entire training period. The basic motivation behind these methods is that orthogonal transformations are isometries of the Euclidean space, hence they preserve (Euclidean) norms and effectively deal with vanishing/exploding gradients. However, this ignores the crucial effects of non-linearity and noise. In the presence of a non-linearity, orthogonal transformations no longer preserve norms, suggesting that alternative transformations might be better suited to non-linear networks. Moreover, in the presence of noise, norm preservation itself ceases to be the ideal objective. A more sensible objective is maximizing the signal-to-noise ratio (SNR) of the propagated signal instead. Previous work has shown that in the linear case, recurrent networks that maximize the SNR display strongly non-normal, sequential dynamics and orthogonal networks are highly suboptimal by this measure. Motivated by this finding, here we investigate the potential of non-normal RNNs, i.e. RNNs with a non-normal recurrent connectivity matrix, in sequential processing tasks. Our experimental results show that non-normal RNNs outperform their orthogonal counterparts in a diverse range of benchmarks. We also find evidence for increased non-normality and hidden chain-like feedforward motifs in trained RNNs initialized with orthogonal recurrent connectivity matrices. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">recurrent neural networks, memory, non-normal dynamics</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/eminorhan/nonnormal-init</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryx1wRNFvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SygWvAVFPr" data-number="1164">
      <h4>
        <a href="/forum?id=SygWvAVFPr">
            Neural Module Networks for Reasoning over Text
        </a>
      
        
          <a href="/pdf?id=SygWvAVFPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=gnnitish%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gnnitish@gmail.com">Nitish Gupta</a>, <a href="/profile?email=kevinlin%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kevinlin@eecs.berkeley.edu">Kevin Lin</a>, <a href="/profile?email=danroth%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="danroth@seas.upenn.edu">Dan Roth</a>, <a href="/profile?email=sameer%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sameer@uci.edu">Sameer Singh</a>, <a href="/profile?email=mattg%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="mattg@allenai.org">Matt Gardner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SygWvAVFPr-details-711" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SygWvAVFPr-details-711"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">question answering, compositionality, neural module networks, multi-step reasoning, reading comprehension</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper extends neural module networks to answer compositional questions against text by introducing differentiable modules that perform reasoning over text and symbols in a probabilistic manner.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Answering compositional questions that require multiple steps of reasoning against text is challenging, especially when they involve discrete, symbolic operations. Neural module networks (NMNs) learn to parse such questions as executable programs composed of learnable modules, performing well on synthetic visual QA domains. However, we find that it is challenging to learn these models for non-synthetic questions on open-domain text, where a model needs to deal with the diversity of natural language and perform a broader range of reasoning. We extend NMNs by: (a) introducing modules that reason over a paragraph of text, performing symbolic reasoning (such as arithmetic, sorting, counting) over numbers and dates in a probabilistic and differentiable manner; and (b) proposing an unsupervised auxiliary loss to help extract arguments associated with the events in text. Additionally, we show that a limited amount of heuristically-obtained question program and intermediate module output supervision provides sufficient inductive bias for accurate learning. Our proposed model significantly outperforms state-of-the-art models on a subset of the DROP dataset that poses a variety of reasoning challenges that are covered by our modules.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://nitishgupta.github.io/nmn-drop/</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SygWvAVFPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJgfDREKDB" data-number="1166">
      <h4>
        <a href="/forum?id=HJgfDREKDB">
            Higher-Order Function Networks for Learning Composable 3D Object Representations
        </a>
      
        
          <a href="/pdf?id=HJgfDREKDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=eric.anthony.mitchell95%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="eric.anthony.mitchell95@gmail.com">Eric Mitchell</a>, <a href="/profile?email=engin003%40umn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="engin003@umn.edu">Selim Engin</a>, <a href="/profile?email=isler%40umn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="isler@umn.edu">Volkan Isler</a>, <a href="/profile?email=ddlee%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ddlee@seas.upenn.edu">Daniel D Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HJgfDREKDB-details-218" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJgfDREKDB-details-218"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Neural nets can encode complex 3D objects into the parameters of other (surprisingly small) neural nets</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present a new approach to 3D object representation where a neural network encodes the geometry of an object directly into the weights and biases of a second 'mapping' network. This mapping network can be used to reconstruct an object by applying its encoded transformation to points randomly sampled from a simple geometric space, such as the unit sphere. We study the effectiveness of our method through various experiments on subsets of the ShapeNet dataset. We find that the proposed approach can reconstruct encoded objects with accuracy equal to or exceeding state-of-the-art methods with orders of magnitude fewer parameters. Our smallest mapping network has only about 7000 parameters and shows reconstruction quality on par with state-of-the-art object decoder architectures with millions of parameters. Further experiments on feature mixing through the composition of learned functions show that the encoding captures a meaningful subspace of objects.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">computer vision, 3d reconstruction, deep learning, representation learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJgfDREKDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1x5wRVtvS" data-number="1185">
      <h4>
        <a href="/forum?id=H1x5wRVtvS">
            Variational Hetero-Encoder Randomized GANs for Joint Image-Text Modeling
        </a>
      
        
          <a href="/pdf?id=H1x5wRVtvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zhanghao_xidian%40163.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhanghao_xidian@163.com">Hao Zhang</a>, <a href="/profile?email=bchen%40mail.xidian.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="bchen@mail.xidian.edu.cn">Bo Chen</a>, <a href="/profile?email=tianlong_xidian%40163.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianlong_xidian@163.com">Long Tian</a>, <a href="/profile?email=zhengjuewang%40163.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhengjuewang@163.com">Zhengjue Wang</a>, <a href="/profile?email=mingyuan.zhou%40mccombs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mingyuan.zhou@mccombs.utexas.edu">Mingyuan Zhou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#H1x5wRVtvS-details-373" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1x5wRVtvS-details-373"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep topic model, image generation, text generation, raster-scan-GAN, zero-shot learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A novel Bayesian deep learning framework that captures and relates hierarchical semantic and visual concepts, performing well on a variety of image and text modeling and generation tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">For bidirectional joint image-text modeling, we develop variational hetero-encoder (VHE) randomized generative adversarial network (GAN), a versatile deep generative model that integrates a probabilistic text decoder, probabilistic image encoder, and GAN into a coherent end-to-end multi-modality learning framework. VHE randomized GAN (VHE-GAN) encodes an image to decode its associated text, and feeds the variational posterior as the source of randomness into the GAN image generator. We plug three off-the-shelf modules, including a deep topic model, a ladder-structured image encoder, and StackGAN++, into VHE-GAN, which already achieves competitive performance. This further motivates the development of VHE-raster-scan-GAN that generates photo-realistic images in not only a multi-scale low-to-high-resolution manner, but also a hierarchical-semantic coarse-to-fine fashion. By capturing and relating hierarchical semantic and visual concepts with end-to-end training, VHE-raster-scan-GAN achieves state-of-the-art performance in a wide variety of image-text multi-modality learning and generation tasks. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/BoChenGroup/VHE-GAN</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1x5wRVtvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1eowANFvr" data-number="1188">
      <h4>
        <a href="/forum?id=r1eowANFvr">
            Towards Fast Adaptation of Neural Architectures with Meta Learning
        </a>
      
        
          <a href="/pdf?id=r1eowANFvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=liandz%40shanghaitech.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="liandz@shanghaitech.edu.cn">Dongze Lian</a>, <a href="/profile?email=yzheng3xg%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yzheng3xg@gmail.com">Yin Zheng</a>, <a href="/profile?email=xuyt%40shanghaitech.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xuyt@shanghaitech.edu.cn">Yintao Xu</a>, <a href="/profile?email=alanlu%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alanlu@tencent.com">Yanxiong Lu</a>, <a href="/profile?email=goshawklin%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="goshawklin@tencent.com">Leyu Lin</a>, <a href="/profile?email=masonzhao%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="masonzhao@tencent.com">Peilin Zhao</a>, <a href="/profile?email=jzhuang%40uta.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jzhuang@uta.edu">Junzhou Huang</a>, <a href="/profile?email=gaoshh%40shanghaitech.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="gaoshh@shanghaitech.edu.cn">Shenghua Gao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 24 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#r1eowANFvr-details-154" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1eowANFvr-details-154"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Fast adaptation, Meta learning, NAS</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recently, Neural Architecture Search (NAS) has been successfully applied to multiple artificial intelligence areas and shows better performance compared with hand-designed networks. However, the existing NAS methods only target a specific task. Most of them usually do well in searching an architecture for single task but are troublesome for multiple datasets or multiple tasks. Generally, the architecture for a new task is either searched from scratch, which is neither efficient nor flexible enough for practical application scenarios, or borrowed from the ones searched on other tasks, which might be not optimal. In order to tackle the transferability of NAS and conduct fast adaptation of neural architectures, we propose a novel Transferable Neural Architecture Search method based on meta-learning in this paper, which is termed as T-NAS. T-NAS learns a meta-architecture that is able to adapt to a new task quickly through a few gradient steps, which makes the transferred architecture suitable for the specific task. Extensive experiments show that T-NAS achieves state-of-the-art performance in few-shot learning and comparable performance in supervised learning but with 50x less searching cost, which demonstrates the effectiveness of our method.</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A meta-learning method for fast adaptation of neural architectures.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1eowANFvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1x6w0EtwH" data-number="1192">
      <h4>
        <a href="/forum?id=B1x6w0EtwH">
            Graph Constrained Reinforcement Learning for Natural Language Action Spaces
        </a>
      
        
          <a href="/pdf?id=B1x6w0EtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=raj.ammanabrolu%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="raj.ammanabrolu@gatech.edu">Prithviraj Ammanabrolu</a>, <a href="/profile?email=matthew.hausknecht%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthew.hausknecht@microsoft.com">Matthew Hausknecht</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#B1x6w0EtwH-details-949" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1x6w0EtwH-details-949"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">natural language generation, deep reinforcement learning, knowledge graphs, interactive fiction</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present KG-A2C, a reinforcement learning agent that builds a dynamic knowledge graph while exploring and generates natural language using a template-based action space - outperforming all current agents on a wide set of text-based games.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Interactive Fiction games are text-based simulations in which an agent interacts with the world purely through natural language. They are ideal environments for studying how to extend reinforcement learning agents to meet the challenges of natural language understanding, partial observability, and action generation in combinatorially-large text-based action spaces. We present KG-A2C, an agent that builds a dynamic knowledge graph while exploring and generates actions using a template-based action space. We contend that the dual uses of the knowledge graph to reason about game state and to constrain natural language generation are the keys to scalable exploration of combinatorially large natural language actions. Results across a wide variety of IF games show that KG-A2C outperforms current IF agents despite the exponential increase in action space size.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/rajammanabrolu/KG-A2C</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1x6w0EtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJxG_0EtDS" data-number="1204">
      <h4>
        <a href="/forum?id=BJxG_0EtDS">
            Prediction, Consistency, Curvature: Representation Learning for Locally-Linear Control
        </a>
      
        
          <a href="/pdf?id=BJxG_0EtDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=nirlevine%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nirlevine@google.com">Nir Levine</a>, <a href="/profile?email=yinlamchow%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yinlamchow@google.com">Yinlam Chow</a>, <a href="/profile?email=ruishu%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruishu@stanford.edu">Rui Shu</a>, <a href="/profile?email=anglili%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anglili@google.com">Ang Li</a>, <a href="/profile?email=mgh%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mgh@fb.com">Mohammad Ghavamzadeh</a>, <a href="/profile?email=v.hungbh1%40vinai.io" class="profile-link" data-toggle="tooltip" data-placement="top" title="v.hungbh1@vinai.io">Hung Bui</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#BJxG_0EtDS-details-808" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJxG_0EtDS-details-808"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Embed-to-Control, Representation Learning, Stochastic Optimal Control, VAE, iLQR</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Learning embedding for control with high-dimensional observations</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Many real-world sequential decision-making problems can be formulated as optimal control with high-dimensional observations and unknown dynamics. A promising approach is to embed the high-dimensional observations into a lower-dimensional latent representation space, estimate the latent dynamics model, then utilize this model for control in the latent space. An important open question is how to learn a representation that is amenable to existing control algorithms? In this paper, we focus on learning representations for locally-linear control algorithms, such as iterative LQR (iLQR). By formulating and analyzing the representation learning problem from an optimal control perspective, we establish three underlying principles that the learned representation should comprise: 1) accurate prediction in the observation space, 2) consistency between latent and observation space dynamics, and 3) low curvature in the latent space transitions. These principles naturally correspond to a loss function that consists of three terms: prediction, consistency, and curvature (PCC). Crucially, to make PCC tractable, we derive an amortized variational bound for the PCC loss function. Extensive experiments on benchmark domains demonstrate that the new variational-PCC learning algorithm benefits from significantly more stable and reproducible training, and leads to superior control performance.  Further ablation studies give support to the importance of all three PCC components for learning a good latent space for control.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJxG_0EtDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxQuANKPB" data-number="1206">
      <h4>
        <a href="/forum?id=ryxQuANKPB">
            Augmenting Non-Collaborative Dialog Systems with Explicit Semantic and Strategic Dialog History
        </a>
      
        
          <a href="/pdf?id=ryxQuANKPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yihengz1%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yihengz1@cs.cmu.edu">Yiheng Zhou</a>, <a href="/profile?email=ytsvetko%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ytsvetko@cs.cmu.edu">Yulia Tsvetkov</a>, <a href="/profile?email=awb%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="awb@cs.cmu.edu">Alan W Black</a>, <a href="/profile?email=joyu%40ucdavis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="joyu@ucdavis.edu">Zhou Yu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#ryxQuANKPB-details-576" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxQuANKPB-details-576"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">dialog systems, history tracking</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study non-collaborative dialogs, where two agents have a conflict of interest but must strategically communicate to reach an agreement (e.g., negotiation). This setting poses new challenges for modeling dialog history because the dialog's outcome relies not only on the semantic intent, but also on tactics that convey the intent.  We propose to model both semantic and tactic history using finite state transducers (FSTs). Unlike RNN, FSTs can explicitly represent dialog history through all the states traversed, facilitating interpretability of dialog structure. We train FSTs on a set of strategies and tactics used in negotiation dialogs. The trained FSTs show plausible tactic structure and can be generalized to other non-collaborative domains (e.g., persuasion). We evaluate the FSTs by incorporating them in an automated negotiating system that attempts to sell products and a persuasion system that persuades people to donate to a charity. Experiments show that explicitly modeling both semantic and tactic history is an effective way to improve both dialog policy planning and generation performance. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxQuANKPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkeHuCVFDr" data-number="1210">
      <h4>
        <a href="/forum?id=SkeHuCVFDr">
            BERTScore: Evaluating Text Generation with BERT
        </a>
      
        
          <a href="/pdf?id=SkeHuCVFDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zty27x%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zty27x@gmail.com">Tianyi Zhang*</a>, <a href="/profile?email=vk352%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vk352@cornell.edu">Varsha Kishore*</a>, <a href="/profile?email=fw245%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fw245@cornell.edu">Felix Wu*</a>, <a href="/profile?email=kqw4%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kqw4@cornell.edu">Kilian Q. Weinberger</a>, <a href="/profile?email=yoav%40cs.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoav@cs.cornell.edu">Yoav Artzi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SkeHuCVFDr-details-794" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkeHuCVFDr-details-794"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose BERTScore, an automatic evaluation metric for text generation, which correlates better with human judgments and provides stronger model selection performance than existing metrics.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose BERTScore, an automatic evaluation metric for text generation. Analogously to common metrics, BERTScore computes a similarity score for each token in the candidate sentence with each token in the reference sentence. However, instead of exact matches, we compute token similarity using contextual embeddings. We evaluate using the outputs of 363 machine translation and image captioning systems. BERTScore correlates better with human judgments and provides stronger model selection performance than existing metrics. Finally, we use an adversarial paraphrase detection task and show that BERTScore is more robust to challenging examples compared to existing metrics. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Metric, Evaluation, Contextual Embedding, Text Generation</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/Tiiiger/bert_score</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkeHuCVFDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkgKO0EtvS" data-number="1218">
      <h4>
        <a href="/forum?id=SkgKO0EtvS">
            Neural Execution of Graph Algorithms
        </a>
      
        
          <a href="/pdf?id=SkgKO0EtvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=petarv%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="petarv@google.com">Petar Veličković</a>, <a href="/profile?email=rexying%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rexying@stanford.edu">Rex Ying</a>, <a href="/profile?email=mp861%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="mp861@cam.ac.uk">Matilde Padovano</a>, <a href="/profile?email=raia%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="raia@google.com">Raia Hadsell</a>, <a href="/profile?email=cblundell%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cblundell@google.com">Charles Blundell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SkgKO0EtvS-details-1" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkgKO0EtvS-details-1"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We supervise graph neural networks to imitate intermediate and step-wise outputs of classical graph algorithms, recovering highly favourable insights.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Graph Neural Networks (GNNs) are a powerful representational tool for solving problems on graph-structured inputs. In almost all cases so far, however, they have been applied to directly recovering a final solution from raw inputs, without explicit guidance on how to structure their problem-solving. Here, instead, we focus on learning in the space of algorithms: we train several state-of-the-art GNN architectures to imitate individual steps of classical graph algorithms, parallel (breadth-first search, Bellman-Ford) as well as sequential (Prim's algorithm). As graph algorithms usually rely on making discrete decisions within neighbourhoods, we hypothesise that maximisation-based message passing neural networks are best-suited for such objectives, and validate this claim empirically. We also demonstrate how learning in the space of algorithms can yield new opportunities for positive transfer between tasks---showing how learning a shortest-path algorithm can be substantially improved when simultaneously learning a reachability algorithm.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Graph Neural Networks, Graph Algorithms, Learning to Execute, Program Synthesis, Message Passing Neural Networks, Deep Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkgKO0EtvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1lF_CEYwS" data-number="1219">
      <h4>
        <a href="/forum?id=r1lF_CEYwS">
            On the Need for Topology-Aware Generative Models for Manifold-Based Defenses
        </a>
      
        
          <a href="/pdf?id=r1lF_CEYwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wjang%40cs.wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wjang@cs.wisc.edu">Uyeong Jang</a>, <a href="/profile?email=susmit.jha%40sri.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="susmit.jha@sri.com">Susmit Jha</a>, <a href="/profile?email=jha%40cs.wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jha@cs.wisc.edu">Somesh Jha</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#r1lF_CEYwS-details-747" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1lF_CEYwS-details-747"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Manifold-based Defense, Robust Learning, Adversarial Attacks</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">ML algorithms or models, especially deep neural networks (DNNs), have shown significant promise in several areas. However, recently researchers have demonstrated that ML algorithms, especially DNNs, are vulnerable to adversarial examples (slightly perturbed samples that cause mis-classification). Existence of adversarial examples has hindered deployment of ML algorithms in safety-critical sectors, such as security. Several defenses for adversarial examples exist in the literature. One of the important classes of defenses are manifold-based defenses, where a sample is "pulled back" into the data manifold before classifying. These defenses rely on the manifold assumption (data lie in a manifold of lower dimension than the input space). These defenses use a generative model to approximate the input distribution. This paper asks the following question: do the generative models used in manifold-based defenses need to be topology-aware? Our paper suggests the answer is yes. We provide theoretical and empirical evidence to support our claim.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1lF_CEYwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1xtORNFwH" data-number="1220">
      <h4>
        <a href="/forum?id=S1xtORNFwH">
            FSNet: Compression of Deep Convolutional Neural Networks by Filter Summary
        </a>
      
        
          <a href="/pdf?id=S1xtORNFwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=superyyzg%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="superyyzg@gmail.com">Yingzhen Yang</a>, <a href="/profile?email=jyu79%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jyu79@illinois.edu">Jiahui Yu</a>, <a href="/profile?email=jojic%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jojic@microsoft.com">Nebojsa Jojic</a>, <a href="/profile?email=lukehuan%40shenshangtech.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukehuan@shenshangtech.com">Jun Huan</a>, <a href="/profile?email=t-huang1%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="t-huang1@illinois.edu">Thomas S. Huang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="#S1xtORNFwH-details-196" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1xtORNFwH-details-196"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Compression of Convolutional Neural Networks, Filter Summary CNNs, Weight Sharing</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present a novel method of compression of deep Convolutional Neural Networks (CNNs) by weight sharing through a new representation of convolutional filters.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present a novel method of compression of deep Convolutional Neural Networks (CNNs) by weight sharing through a new representation of convolutional filters. The proposed method reduces the number of parameters of each convolutional layer by learning a <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="451" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn></math></mjx-assistive-mml></mjx-container>D vector termed Filter Summary (FS). The convolutional filters are located in FS as overlapping <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="452" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn></math></mjx-assistive-mml></mjx-container>D segments, and nearby filters in FS share weights in their overlapping regions in a natural way. The resultant neural network based on such weight sharing scheme, termed Filter Summary CNNs or FSNet, has a FS in each convolution layer instead of a set of independent filters in the conventional convolution layer. FSNet has the same architecture as that of the baseline CNN to be compressed, and each convolution layer of FSNet has the same number of filters from FS as that of the basline CNN in the forward process. With compelling computational acceleration ratio, the parameter space of FSNet is much smaller than that of the baseline CNN. In addition, FSNet is quantization friendly. FSNet with weight quantization leads to even higher compression ratio without noticeable performance loss. We further propose Differentiable FSNet where the way filters share weights is learned in a differentiable and end-to-end manner. Experiments demonstrate the effectiveness of FSNet in compression of CNNs for computer vision tasks including image classification and object detection, and the effectiveness of DFSNet is evidenced by the task of Neural Architecture Search.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1xtORNFwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJe6uANtwH" data-number="1229">
      <h4>
        <a href="/forum?id=HJe6uANtwH">
            Capsules with Inverted Dot-Product Attention Routing
        </a>
      
        
          <a href="/pdf?id=HJe6uANtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yaohungt%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaohungt@cs.cmu.edu">Yao-Hung Hubert Tsai</a>, <a href="/profile?email=nitish_srivastava%40apple.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nitish_srivastava@apple.com">Nitish Srivastava</a>, <a href="/profile?email=hanlin%40apple.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanlin@apple.com">Hanlin Goh</a>, <a href="/profile?email=rsalakhutdinov%40apple.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsalakhutdinov@apple.com">Ruslan Salakhutdinov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HJe6uANtwH-details-261" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJe6uANtwH-details-261"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">capsule networks, routing, attention</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present a new routing method for Capsule networks, and it performs at-par with ResNet-18 on CIFAR-10/ CIFAR-100.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We introduce a new routing algorithm for capsule networks, in which a child capsule is routed to a parent based only on agreement between the parent's state and the child's vote. 
      The new mechanism 1) designs routing via inverted dot-product attention; 2) imposes Layer Normalization as normalization; and 3) replaces sequential iterative routing with concurrent iterative routing.
      When compared to previously proposed routing algorithms, our method improves performance on benchmark datasets such as CIFAR-10 and CIFAR-100, and it performs at-par with a powerful CNN (ResNet-18) with 4x fewer parameters.
      On a different task of recognizing digits from overlayed digit images, the proposed capsule model performs favorably against CNNs given the same number of layers and neurons per layer.  We believe that our work raises the possibility of applying capsule networks to complex real-world tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/apple/ml-capsules-inverted-attention-routing</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJe6uANtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BylA_C4tPr" data-number="1230">
      <h4>
        <a href="/forum?id=BylA_C4tPr">
            Composition-based Multi-Relational Graph Convolutional Networks
        </a>
      
        
          <a href="/pdf?id=BylA_C4tPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=shikhar%40iisc.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="shikhar@iisc.ac.in">Shikhar Vashishth</a>, <a href="/profile?email=sanyal.soumya8%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanyal.soumya8@gmail.com">Soumya Sanyal</a>, <a href="/profile?email=vikram.nitin%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="vikram.nitin@columbia.edu">Vikram Nitin</a>, <a href="/profile?email=ppt%40iisc.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="ppt@iisc.ac.in">Partha Talukdar</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#BylA_C4tPr-details-426" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BylA_C4tPr-details-426"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Graph Convolutional Networks, Multi-relational Graphs, Knowledge Graph Embeddings, Link Prediction</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A Composition-based Graph Convolutional framework for multi-relational graphs.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Graph Convolutional Networks (GCNs) have recently been shown to be quite successful in modeling graph-structured data. However, the primary focus has been on handling simple undirected graphs. Multi-relational graphs are a more general and prevalent form of graphs where each edge has a label and direction associated with it. Most of the existing approaches to handle such graphs suffer from over-parameterization and are restricted to learning representations of nodes only. In this paper, we propose CompGCN, a novel Graph Convolutional framework which jointly embeds both nodes and relations in a relational graph. CompGCN leverages a variety of entity-relation composition operations from Knowledge Graph Embedding techniques and scales with the number of relations. It also generalizes several of the existing multi-relational GCN methods. We evaluate our proposed method on multiple tasks such as node classification, link prediction, and graph classification, and achieve demonstrably superior results. We make the source code of CompGCN available to foster reproducible research.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/malllabiisc/CompGCN</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BylA_C4tPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rklbKA4YDS" data-number="1237">
      <h4>
        <a href="/forum?id=rklbKA4YDS">
            Gradient-Based Neural DAG Learning
        </a>
      
        
          <a href="/pdf?id=rklbKA4YDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sebastien.lachapelle%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastien.lachapelle@umontreal.ca">Sébastien Lachapelle</a>, <a href="/profile?email=philippebrouillard%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="philippebrouillard@gmail.com">Philippe Brouillard</a>, <a href="/profile?email=tristan.deleu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tristan.deleu@gmail.com">Tristan Deleu</a>, <a href="/profile?email=slacoste%40iro.umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="slacoste@iro.umontreal.ca">Simon Lacoste-Julien</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#rklbKA4YDS-details-118" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rklbKA4YDS-details-118"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We are proposing a new score-based approach to structure/causal learning leveraging neural networks and a recent continuous constrained formulation to this problem</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose a novel score-based approach to learning a directed acyclic graph (DAG) from observational data. We adapt a recently proposed continuous constrained optimization formulation to allow for nonlinear relationships between variables using neural networks. This extension allows to model complex interactions while avoiding the combinatorial nature of the problem. In addition to comparing our method to existing continuous optimization methods, we provide missing empirical comparisons to nonlinear greedy search methods. On both synthetic and real-world data sets, this new method outperforms current continuous methods on most tasks while being competitive with existing greedy search methods on important metrics for causal inference.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/kurowasan/GraN-DAG</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Structure Learning, Causality, Density estimation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rklbKA4YDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJxMYANtPH" data-number="1238">
      <h4>
        <a href="/forum?id=HJxMYANtPH">
            The Local Elasticity of Neural Networks
        </a>
      
        
          <a href="/pdf?id=HJxMYANtPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=hangfeng%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hangfeng@seas.upenn.edu">Hangfeng He</a>, <a href="/profile?email=suw%40wharton.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="suw@wharton.upenn.edu">Weijie Su</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HJxMYANtPH-details-913" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJxMYANtPH-details-913"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper presents a phenomenon in neural networks that we refer to as local elasticity. Roughly speaking, a classifier is said to be locally elastic if its prediction at a feature vector x' is not significantly perturbed, after the classifier is updated via stochastic gradient descent at a (labeled) feature vector x that is dissimilar to x' in a certain sense. This phenomenon is shown to persist for neural networks with nonlinear activation functions through extensive simulations on real-life and synthetic datasets, whereas this is not observed in linear classifiers. In addition, we offer a geometric interpretation of local elasticity using the neural tangent kernel (Jacot et al., 2018). Building on top of local elasticity, we obtain pairwise similarity measures between feature vectors, which can be used for clustering in conjunction with K-means. The effectiveness of the clustering algorithm on the MNIST and CIFAR-10 datasets in turn corroborates the hypothesis of local elasticity of neural networks on real-life data. Finally, we discuss some implications of local elasticity to shed light on several intriguing aspects of deep neural networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJxMYANtPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1ezFREtwH" data-number="1239">
      <h4>
        <a href="/forum?id=H1ezFREtwH">
            Composing Task-Agnostic Policies with Deep Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=H1ezFREtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=a1qureshi%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="a1qureshi@ucsd.edu">Ahmed H. Qureshi</a>, <a href="/profile?email=jjj025%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jjj025@eng.ucsd.edu">Jacob J. Johnson</a>, <a href="/profile?email=y1qin%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="y1qin@eng.ucsd.edu">Yuzhe Qin</a>, <a href="/profile?email=tjwest%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tjwest@ucsd.edu">Taylor Henderson</a>, <a href="/profile?email=bboots%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bboots@cs.washington.edu">Byron Boots</a>, <a href="/profile?email=yip%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yip@ucsd.edu">Michael C. Yip</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="#H1ezFREtwH-details-570" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1ezFREtwH-details-570"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">composition, transfer learning, deep reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a novel reinforcement learning-based skill transfer and composition method that takes the agent's primitive policies to solve unseen tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The composition of elementary behaviors to solve challenging transfer learning problems is one of the key elements in building intelligent machines. To date, there has been plenty of work on learning task-specific policies or skills but almost no focus on composing necessary, task-agnostic skills to find a solution to new problems. In this paper, we propose a novel deep reinforcement learning-based skill transfer and composition method that takes the agent's primitive policies to solve unseen tasks. We evaluate our method in difficult cases where training policy through standard reinforcement learning (RL) or even hierarchical RL is either not feasible or exhibits high sample complexity. We show that our method not only transfers skills to new problem settings but also solves the challenging environments requiring both task planning and motion control with high data efficiency.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/file/d/1pbF9vMy5E3NLdOE5Id5zqzKlUesgStym/view?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1ezFREtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJlVY04FwH" data-number="1243">
      <h4>
        <a href="/forum?id=SJlVY04FwH">
            Convergence of Gradient Methods on Bilinear Zero-Sum Games
        </a>
      
        
          <a href="/pdf?id=SJlVY04FwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=guojun.zhang%40uwaterloo.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="guojun.zhang@uwaterloo.ca">Guojun Zhang</a>, <a href="/profile?email=yaoliang.yu%40uwaterloo.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaoliang.yu@uwaterloo.ca">Yaoliang Yu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SJlVY04FwH-details-897" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJlVY04FwH-details-897"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We systematically analyze the convergence of popular gradient algorithms for solving bilinear games, with both simultaneous and alternating updates.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Min-max formulations have attracted great attention in the ML community due to the rise of deep generative models and adversarial methods, while understanding the dynamics of gradient algorithms for solving such formulations has remained a grand challenge. As a first step, we restrict to bilinear zero-sum games and give a systematic analysis of popular gradient updates, for both simultaneous and alternating versions. We provide exact conditions for their convergence and find the optimal parameter setup and convergence rates. In particular, our results offer formal evidence that alternating updates converge "better" than simultaneous ones.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/Gordon-Guojun-Zhang/ICLR-2020</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">GAN, gradient algorithm, convergence, min-max optimization, bilinear game</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJlVY04FwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgHY0NYwr" data-number="1246">
      <h4>
        <a href="/forum?id=rkgHY0NYwr">
            Discovering Motor Programs by Recomposing Demonstrations
        </a>
      
        
          <a href="/pdf?id=rkgHY0NYwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tanmayshankar%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tanmayshankar@fb.com">Tanmay Shankar</a>, <a href="/profile?email=shubhtuls%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shubhtuls@fb.com">Shubham Tulsiani</a>, <a href="/profile?email=lerrel.pinto%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lerrel.pinto@gmail.com">Lerrel Pinto</a>, <a href="/profile?email=abhinavg%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhinavg@cs.cmu.edu">Abhinav Gupta</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#rkgHY0NYwr-details-463" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgHY0NYwr-details-463"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Learning from Demonstration, Imitation Learning, Motor Primitives</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We learn a space of motor primitives from unannotated robot demonstrations, and show these primitives are semantically meaningful and can be composed for new robot tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In this paper, we present an approach to learn recomposable motor primitives across large-scale and diverse manipulation demonstrations. Current approaches to decomposing demonstrations into primitives often assume manually defined primitives and bypass the difficulty of discovering these primitives. On the other hand, approaches in primitive discovery put restrictive assumptions on the complexity of a primitive, which limit applicability to narrow tasks. Our approach attempts to circumvent these challenges by jointly learning both the underlying motor primitives and recomposing these primitives to form the original demonstration. Through constraints on both the parsimony of primitive decomposition and the simplicity of a given primitive, we are able to learn a diverse set of motor primitives, as well as a coherent latent representation for these primitives. We demonstrate both qualitatively and quantitatively, that our learned primitives capture semantically meaningful aspects of a demonstration. This allows us to compose these primitives in a hierarchical reinforcement learning setup to efficiently solve robotic manipulation tasks like reaching and pushing. Our results may be viewed at https://sites.google.com/view/discovering-motor-programs. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgHY0NYwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJlUt0EYwS" data-number="1248">
      <h4>
        <a href="/forum?id=rJlUt0EYwS">
            Learning from Explanations with Neural Execution Tree
        </a>
      
        
          <a href="/pdf?id=rJlUt0EYwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ziqi-wan16%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ziqi-wan16@mails.tsinghua.edu.cn">Ziqi Wang*</a>, <a href="/profile?email=qinyj16%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="qinyj16@mails.tsinghua.edu.cn">Yujia Qin*</a>, <a href="/profile?email=zhouwenx%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhouwenx@usc.edu">Wenxuan Zhou</a>, <a href="/profile?email=yanjun%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanjun@usc.edu">Jun Yan</a>, <a href="/profile?email=qinyuany%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qinyuany@usc.edu">Qinyuan Ye</a>, <a href="/profile?email=lneves%40snap.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lneves@snap.com">Leonardo Neves</a>, <a href="/profile?email=liuzy%40tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="liuzy@tsinghua.edu.cn">Zhiyuan Liu</a>, <a href="/profile?email=xiangren%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiangren@usc.edu">Xiang Ren</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rJlUt0EYwS-details-683" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJlUt0EYwS-details-683"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">While deep neural networks have achieved impressive performance on a range of NLP tasks, these data-hungry models heavily rely on labeled data, which restricts their applications in scenarios where data annotation is expensive. Natural language (NL) explanations have been demonstrated very useful additional supervision, which can provide sufficient domain knowledge for generating more labeled data over new instances, while the annotation time only doubles. However, directly applying them for augmenting model learning encounters two challenges: (1) NL explanations are unstructured and inherently compositional, which asks for a modularized model to represent their semantics, (2) NL explanations often have large numbers of linguistic variants, resulting in low recall and limited generalization ability. In this paper, we propose a novel Neural Execution Tree (NExT) framework to augment training data for text classification using NL explanations. After transforming NL explanations into executable logical forms by semantic parsing, NExT generalizes different types of actions specified by the logical forms for labeling data instances, which substantially increases the coverage of each NL explanation. Experiments on two NLP tasks (relation extraction and sentiment analysis) demonstrate its superiority over baseline methods. Its extension to multi-hop question answering achieves performance gain with light annotation effort.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://www.dropbox.com/sh/zkp19yr44yr8idt/AABpjFN3r2COIOub33L7DtfLa?dl=0</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJlUt0EYwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byx_YAVYPH" data-number="1252">
      <h4>
        <a href="/forum?id=Byx_YAVYPH">
            Jelly Bean World: A Testbed for Never-Ending Learning
        </a>
      
        
          <a href="/pdf?id=Byx_YAVYPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=e.a.platanios%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="e.a.platanios@cs.cmu.edu">Emmanouil Antonios Platanios</a>, <a href="/profile?email=asaparov%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="asaparov@cs.cmu.edu">Abulhair Saparov</a>, <a href="/profile?email=tom.mitchell%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tom.mitchell@cs.cmu.edu">Tom Mitchell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#Byx_YAVYPH-details-867" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byx_YAVYPH-details-867"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Machine learning has shown growing success in recent years. However, current machine learning systems are highly specialized, trained for particular problems or domains, and typically on a single narrow dataset. Human learning, on the other hand, is highly general and adaptable. Never-ending learning is a machine learning paradigm that aims to bridge this gap, with the goal of encouraging researchers to design machine learning systems that can learn to perform a wider variety of inter-related tasks in more complex environments. To date, there is no environment or testbed to facilitate the development and evaluation of never-ending learning systems. To this end, we propose the Jelly Bean World testbed. The Jelly Bean World allows experimentation over two-dimensional grid worlds which are filled with items and in which agents can navigate. This testbed provides environments that are sufficiently complex and where more generally intelligent algorithms ought to perform better than current state-of-the-art reinforcement learning approaches. It does so by producing non-stationary environments and facilitating experimentation with multi-task, multi-agent, multi-modal, and curriculum learning settings. We hope that this new freely-available software will prompt new research and interest in the development and evaluation of never-ending learning systems and more broadly, general intelligence systems.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Byx_YAVYPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryeFY0EFwS" data-number="1256">
      <h4>
        <a href="/forum?id=ryeFY0EFwS">
            Coherent Gradients: An Approach to Understanding Generalization in Gradient Descent-based Optimization
        </a>
      
        
          <a href="/pdf?id=ryeFY0EFwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=satrajit%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="satrajit@gmail.com">Satrajit Chatterjee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>26 Replies</span>
        
        
      </div>
      
        <a href="#ryeFY0EFwS-details-902" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryeFY0EFwS-details-902"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">generalization, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a hypothesis for why gradient descent generalizes based on how per-example gradients interact with each other.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">An open question in the Deep Learning community is why neural networks trained with Gradient Descent generalize well on real datasets even though they are capable of fitting random data. We propose an approach to answering this question based on a hypothesis about the dynamics of gradient descent that we call Coherent Gradients: Gradients from similar examples are similar and so the overall gradient is stronger in certain directions where these reinforce each other. Thus changes to the network parameters during training are biased towards those that (locally) simultaneously benefit many examples when such similarity exists. We support this hypothesis with heuristic arguments and perturbative experiments and outline how this can explain several common empirical observations about Deep Learning. Furthermore, our analysis is not just descriptive, but prescriptive. It suggests a natural modification to gradient descent that can greatly reduce overfitting.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryeFY0EFwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJgCF0VFwr" data-number="1267">
      <h4>
        <a href="/forum?id=HJgCF0VFwr">
            Probabilistic Connection Importance Inference and Lossless Compression of Deep Neural Networks
        </a>
      
        
          <a href="/pdf?id=HJgCF0VFwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xin_xing%40fas.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xin_xing@fas.harvard.edu">Xin Xing</a>, <a href="/profile?email=longsha%40brandeis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="longsha@brandeis.edu">Long Sha</a>, <a href="/profile?email=hongpeng%40brandeis.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hongpeng@brandeis.edu">Pengyu Hong</a>, <a href="/profile?email=zuofeng.shang%40njit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zuofeng.shang@njit.edu">Zuofeng Shang</a>, <a href="/profile?email=jliu%40stat.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jliu@stat.harvard.edu">Jun S. Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="#HJgCF0VFwr-details-504" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJgCF0VFwr-details-504"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep neural networks (DNNs) can be huge in size, requiring a considerable a mount of energy and computational resources to operate, which limits their applications in numerous scenarios. It is thus of interest to compress DNNs while maintaining their performance levels.  We here propose a probabilistic importance inference approach for pruning DNNs. Specifically, we test the significance of the relevance of a connection in a DNN to the DNN’s outputs using a nonparemtric scoring testand keep only those significant ones. Experimental results show that the proposed approach achieves better lossless compression rates than existing techniques</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJgCF0VFwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJxlc0EtDr" data-number="1270">
      <h4>
        <a href="/forum?id=rJxlc0EtDr">
            MEMO: A Deep Network for Flexible Combination of Episodic Memories
        </a>
      
        
          <a href="/pdf?id=rJxlc0EtDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=abanino%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="abanino@google.com">Andrea Banino</a>, <a href="/profile?email=adriap%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adriap@google.com">Adrià Puigdomènech Badia</a>, <a href="/profile?email=rkoster%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rkoster@google.com">Raphael Köster</a>, <a href="/profile?email=mjchadwick%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mjchadwick@google.com">Martin J. Chadwick</a>, <a href="/profile?email=vzambaldi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vzambaldi@google.com">Vinicius Zambaldi</a>, <a href="/profile?email=dhteam%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dhteam@google.com">Demis Hassabis</a>, <a href="/profile?email=caswell.barry%40ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="caswell.barry@ucl.ac.uk">Caswell Barry</a>, <a href="/profile?email=botvinick%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="botvinick@google.com">Matthew Botvinick</a>, <a href="/profile?email=dkumaran%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dkumaran@google.com">Dharshan Kumaran</a>, <a href="/profile?email=cblundell%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cblundell@google.com">Charles Blundell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="#rJxlc0EtDr-details-295" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJxlc0EtDr-details-295"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Memory Augmented Neural Networks, Deep Learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A memory architecture that support inferential reasoning.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recent research developing neural network architectures with external memory have often used the benchmark bAbI question and answering dataset which provides a challenging number of tasks requiring reasoning. Here we employed a classic associative inference task from the human neuroscience literature in order to more carefully probe the reasoning capacity of existing memory-augmented architectures. This task is thought to capture the essence of reasoning -- the appreciation of distant relationships among elements distributed across multiple facts or memories. Surprisingly, we found that current architectures struggle to reason over long distance associations. Similar results were obtained on a more complex task involving finding the shortest path between nodes in a path. We therefore developed a novel architecture, MEMO, endowed with the capacity to reason over longer distances. This was accomplished with the addition of two novel components. First, it introduces a separation between memories/facts stored in external memory and the items that comprise these facts in external memory. Second, it makes use of an adaptive retrieval mechanism, allowing a variable number of ‘memory hops’ before the answer is produced. MEMO is capable of solving our novel reasoning tasks, as well as all 20 tasks in bAbI.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJxlc0EtDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyxV9ANFDH" data-number="1279">
      <h4>
        <a href="/forum?id=SyxV9ANFDH">
            Economy Statistical Recurrent Units For Inferring Nonlinear Granger Causality
        </a>
      
        
          <a href="/pdf?id=SyxV9ANFDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=elesaur%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="elesaur@nus.edu.sg">Saurabh Khanna</a>, <a href="/profile?email=vtan%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="vtan@nus.edu.sg">Vincent Y. F. Tan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SyxV9ANFDH-details-328" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyxV9ANFDH-details-328"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Recurrent neural networks, Granger causality, Causal inference, Statistical Recurrent Unit</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A new recurrent neural network architecture for detecting pairwise Granger causality between nonlinearly interacting time series. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Granger causality is a widely-used criterion for analyzing interactions in large-scale networks. As most physical interactions are inherently nonlinear, we consider the problem of inferring the existence of pairwise Granger causality between nonlinearly interacting stochastic processes from their time series measurements. Our proposed approach relies on modeling the embedded nonlinearities in the measurements using a component-wise time series prediction model based on Statistical Recurrent Units (SRUs). We make a case that the network topology of Granger causal relations is directly inferrable from a structured sparse estimate of the internal parameters of the SRU networks trained to predict the processes’ time series measurements. We propose a variant of SRU, called economy-SRU, which, by design has considerably fewer trainable parameters, and therefore less prone to overfitting. The economy-SRU computes a low-dimensional sketch of its high-dimensional hidden state in the form of random projections to generate the feedback for its recurrent processing. Additionally, the internal weight parameters of the economy-SRU are strategically regularized in a group-wise manner to facilitate the proposed network in extracting meaningful predictive features that are highly time-localized to mimic real-world causal events. Extensive experiments are carried out to demonstrate that the proposed economy-SRU based time series prediction model outperforms the MLP, LSTM and attention-gated CNN-based time series models considered previously for inferring Granger causality. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/sakhanna/SRU_for_GCI</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SyxV9ANFDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bkxv90EKPB" data-number="1285">
      <h4>
        <a href="/forum?id=Bkxv90EKPB">
            Bayesian Meta Sampling for Fast Uncertainty Adaptation
        </a>
      
        
          <a href="/pdf?id=Bkxv90EKPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zhenyiwa%40buffalo.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhenyiwa@buffalo.edu">Zhenyi Wang</a>, <a href="/profile?email=yzhao63%40buffalo.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yzhao63@buffalo.edu">Yang Zhao</a>, <a href="/profile?email=pingyu%40buffalo.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pingyu@buffalo.edu">Ping Yu</a>, <a href="/profile?email=ryzhang%40cs.duke.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ryzhang@cs.duke.edu">Ruiyi Zhang</a>, <a href="/profile?email=changyou%40buffalo.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="changyou@buffalo.edu">Changyou Chen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#Bkxv90EKPB-details-17" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bkxv90EKPB-details-17"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We proposed a Bayesian meta sampling method for adapting the model uncertainty in meta learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Meta learning has been making impressive progress for fast model adaptation. However, limited work has been done on learning fast uncertainty adaption for Bayesian modeling. In this paper, we propose to achieve the goal by placing meta learning on the space of probability measures, inducing the concept of meta sampling for fast uncertainty adaption. Specifically, we propose a Bayesian meta sampling framework consisting of two main components: a meta sampler and a sample adapter. The meta sampler is constructed by adopting a neural-inverse-autoregressive-flow (NIAF) structure, a variant of the recently proposed neural autoregressive flows, to efficiently generate meta samples to be adapted. The sample adapter moves meta samples to task-specific samples, based on a newly proposed and general Bayesian sampling technique, called optimal-transport Bayesian sampling. The combination of the two components allows a simple learning procedure for the
      meta sampler to be developed, which can be efficiently optimized via standard back-propagation. Extensive experimental results demonstrate the efficiency and effectiveness of the proposed framework, obtaining better sample quality and faster
      uncertainty adaption compared to related methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Bayesian Sampling, Uncertainty Adaptation, Meta Learning, Variational Inference</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Bkxv90EKPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1e_cC4twS" data-number="1288">
      <h4>
        <a href="/forum?id=H1e_cC4twS">
            Non-Autoregressive Dialog State Tracking
        </a>
      
        
          <a href="/pdf?id=H1e_cC4twS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=l.hung1610%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="l.hung1610@gmail.com">Hung Le</a>, <a href="/profile?email=rsocher%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsocher@salesforce.com">Richard Socher</a>, <a href="/profile?email=shoi%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shoi@salesforce.com">Steven C.H. Hoi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#H1e_cC4twS-details-522" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1e_cC4twS-details-522"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">task-oriented, dialogues, dialogue state tracking, non-autoregressive</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose the first non-autoregressive neural model for Dialogue State Tracking (DST), achieving the SOTA accuracy (49.04%) on MultiWOZ2.1 benchmark, and reducing inference latency by an order of magnitude.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recent efforts in Dialogue State Tracking (DST) for task-oriented dialogues have progressed toward open-vocabulary or generation-based approaches where the models can generate slot value candidates from the dialogue history itself. These approaches have shown good performance gain, especially in complicated dialogue domains with dynamic slot values. However, they fall short in two aspects: (1) they do not allow models to explicitly learn signals across domains and slots to detect potential dependencies among \textit{(domain, slot)} pairs; and (2) existing models follow auto-regressive approaches which incur high time cost when the dialogue evolves over multiple domains and multiple turns. In this paper, we propose a novel framework of Non-Autoregressive Dialog State Tracking (NADST) which can factor in potential dependencies among domains and slots to optimize the models towards better prediction of dialogue states as a complete set rather than separate slots. In particular, the non-autoregressive nature of our method not only enables decoding in parallel to significantly reduce the latency of DST for real-time dialogue response generation, but also detect dependencies among slots at token level in addition to slot and domain level. Our empirical results show that our model achieves the state-of-the-art joint accuracy across all domains on the MultiWOZ 2.1 corpus, and the latency of our model is an order of magnitude lower than the previous state of the art as the dialogue history extends over time. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/henryhungle/NADST</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1e_cC4twS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SklKcRNYDH" data-number="1291">
      <h4>
        <a href="/forum?id=SklKcRNYDH">
            Extreme Tensoring for Low-Memory Preconditioning 
        </a>
      
        
          <a href="/pdf?id=SklKcRNYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xinyic%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xinyic@google.com">Xinyi Chen</a>, <a href="/profile?email=namanagarwal%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="namanagarwal@google.com">Naman Agarwal</a>, <a href="/profile?email=ehazan%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ehazan@cs.princeton.edu">Elad Hazan</a>, <a href="/profile?email=cyril.zhang%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cyril.zhang@cs.princeton.edu">Cyril Zhang</a>, <a href="/profile?email=y.zhang%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="y.zhang@cs.princeton.edu">Yi Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SklKcRNYDH-details-473" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SklKcRNYDH-details-473"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">optimization, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">State-of-the-art models are now trained with billions of parameters, reaching hardware limits in terms of memory consumption. This has created a recent demand for memory-efficient optimizers. To this end, we investigate the limits and performance tradeoffs of memory-efficient adaptively preconditioned gradient methods. We propose \emph{extreme tensoring} for high-dimensional stochastic optimization, showing that an optimizer needs very little memory to benefit from adaptive preconditioning. Our technique applies to arbitrary models (not necessarily with tensor-shaped parameters), and is accompanied by regret and convergence guarantees, which shed light on the tradeoffs between preconditioner quality and expressivity. On a large-scale NLP model, we reduce the optimizer memory overhead by three orders of magnitude, without degrading performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SklKcRNYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HylpqA4FwS" data-number="1298">
      <h4>
        <a href="/forum?id=HylpqA4FwS">
            RNNs Incrementally Evolving on an Equilibrium Manifold: A Panacea for Vanishing and Exploding Gradients?
        </a>
      
        
          <a href="/pdf?id=HylpqA4FwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=anilkag%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="anilkag@bu.edu">Anil Kag</a>, <a href="/profile?email=zzhang%40merl.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zzhang@merl.com">Ziming Zhang</a>, <a href="/profile?email=srv%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="srv@bu.edu">Venkatesh Saligrama</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HylpqA4FwS-details-979" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HylpqA4FwS-details-979"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">novel recurrent neural architectures, learning representations of outputs or states</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Incremental-RNNs resolves exploding/vanishing gradient problem by updating state vectors based on difference between previous state and that predicted by an ODE.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recurrent neural networks (RNNs) are particularly well-suited for modeling long-term dependencies in sequential data, but are notoriously hard to train because the error backpropagated in time either vanishes or explodes at an exponential rate. While a number of works attempt to mitigate this effect through gated recurrent units, skip-connections, parametric constraints and design choices, we propose a novel incremental RNN (iRNN), where hidden state vectors keep track of incremental changes, and as such approximate state-vector increments of Rosenblatt's (1962) continuous-time RNNs. iRNN exhibits identity gradients and is able to account for long-term dependencies (LTD). We show that our method is computationally efficient overcoming overheads of many existing methods that attempt to improve RNN training, while suffering no performance degradation. We demonstrate the utility of our approach with extensive experiments and show competitive performance against standard LSTMs on LTD and other non-LTD tasks.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HylpqA4FwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkl1iRNFwS" data-number="1303">
      <h4>
        <a href="/forum?id=Hkl1iRNFwS">
            The Early Phase of Neural Network Training
        </a>
      
        
          <a href="/pdf?id=Hkl1iRNFwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jfrankle%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jfrankle@mit.edu">Jonathan Frankle</a>, <a href="/profile?email=dschwab%40gc.cuny.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dschwab@gc.cuny.edu">David J. Schwab</a>, <a href="/profile?email=arimorcos%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="arimorcos@gmail.com">Ari S. Morcos</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#Hkl1iRNFwS-details-125" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkl1iRNFwS-details-125"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">empirical, learning dynamics, lottery tickets, critical periods, early</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We thoroughly investigate neural network learning dynamics over the early phase of training, finding that these changes are crucial and difficult to approximate, though extended pretraining can recover them.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recent studies have shown that many important aspects of neural network learning take place within the very earliest iterations or epochs of training. For example, sparse, trainable sub-networks emerge (Frankle et al., 2019), gradient descent moves into a small subspace (Gur-Ari et al., 2018), and the network undergoes a critical period (Achille et al., 2019). Here we examine the changes that deep neural networks undergo during this early phase of training. We perform extensive measurements of the network state and its updates during these early iterations of training, and leverage the framework of Frankle et al. (2019) to quantitatively probe the weight distribution and its reliance on various aspects of the dataset. We find that, within this framework, deep networks are not robust to reinitializing with random weights while maintaining signs, and that weight distributions are highly non-independent even after only a few hundred iterations. Despite this, pre-training with blurred inputs or an auxiliary self-supervised task can approximate the changes in supervised networks, suggesting that these changes are label-agnostic, though labels significantly accelerate this process. Together, these results help to elucidate the network changes occurring during this pivotal initial period of learning.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hkl1iRNFwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxgsCVYPr" data-number="1307">
      <h4>
        <a href="/forum?id=ryxgsCVYPr">
            NeurQuRI: Neural Question Requirement Inspector for Answerability Prediction in Machine Reading Comprehension
        </a>
      
        
          <a href="/pdf?id=ryxgsCVYPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=scv.back%40samsung.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="scv.back@samsung.com">Seohyun Back</a>, <a href="/profile?email=sai.chetan%40samsung.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sai.chetan@samsung.com">Sai Chetan Chinthakindi</a>, <a href="/profile?email=akhil.kedia%40samsung.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="akhil.kedia@samsung.com">Akhil Kedia</a>, <a href="/profile?email=haejun82.lee%40samsung.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="haejun82.lee@samsung.com">Haejun Lee</a>, <a href="/profile?email=jchoo%40korea.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jchoo@korea.ac.kr">Jaegul Choo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#ryxgsCVYPr-details-758" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxgsCVYPr-details-758"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a neural question requirement inspection model called NeurQuRI that extracts a list of conditions from the question, each of which should be satisfied by the candidate answer generated by an MRC model.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Real-world question answering systems often retrieve potentially relevant documents to a given question through a keyword search, followed by a machine reading comprehension (MRC) step to find the exact answer from them. In this process, it is essential to properly determine whether an answer to the question exists in a given document. This task often becomes complicated when the question involves multiple different conditions or requirements which are to be met in the answer. For example, in a question "What was the projection of sea level increases in the fourth assessment report?", the answer should properly satisfy several conditions, such as "increases" (but not decreases) and "fourth" (but not third). To address this, we propose a neural question requirement inspection model called NeurQuRI that extracts a list of conditions from the question, each of which should be satisfied by the candidate answer generated by an MRC model. To check whether each condition is met, we propose a novel, attention-based loss function. We evaluate our approach on SQuAD 2.0 dataset by integrating the proposed module with various MRC models, demonstrating the consistent performance improvements across a wide range of state-of-the-art methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Question Answering, Machine Reading Comprehension, Answerability Prediction, Neural Checklist</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxgsCVYPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkgGjRVKDS" data-number="1310">
      <h4>
        <a href="/forum?id=SkgGjRVKDS">
            Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization
        </a>
      
        
          <a href="/pdf?id=SkgGjRVKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jjyan17%40fudan.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jjyan17@fudan.edu.cn">Junjie Yan</a>, <a href="/profile?email=wanruosi%40megvii.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanruosi@megvii.com">Ruosi Wan</a>, <a href="/profile?email=zhangxiangyu%40megvii.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhangxiangyu@megvii.com">Xiangyu Zhang</a>, <a href="/profile?email=weizh%40fudan.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="weizh@fudan.edu.cn">Wei Zhang</a>, <a href="/profile?email=weiyichen%40megvii.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="weiyichen@megvii.com">Yichen Wei</a>, <a href="/profile?email=sunjian%40megvii.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sunjian@megvii.com">Jian Sun</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 08 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SkgGjRVKDS-details-729" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkgGjRVKDS-details-729"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a novel normalization method to handle small batch size cases.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Batch Normalization (BN) is one of the most widely used techniques in Deep Learning field. But its performance can awfully degrade with insufficient batch size. This weakness limits the usage of BN on many computer vision tasks like detection or segmentation, where batch size is usually small due to the constraint of memory consumption. Therefore many modified normalization techniques have been proposed, which either fail to restore the performance of BN completely, or have to introduce additional nonlinear operations in inference procedure and increase huge consumption. In this paper, we reveal that there are two extra batch statistics involved in backward propagation of BN, on which has never been well discussed before. The extra batch statistics associated with gradients also can severely affect the training of deep neural network. Based on our analysis, we propose a novel normalization method, named Moving Average Batch Normalization (MABN). MABN can completely restore the performance of vanilla BN in small batch cases, without introducing any additional nonlinear operations in inference procedure. We prove the benefits of MABN by both theoretical analysis and experiments. Our experiments demonstrate the effectiveness of MABN in multiple computer vision tasks including ImageNet and COCO. The code has been released in https://github.com/megvii-model/MABN.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">batch normalization, small batch size, backward propagation</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/megvii-model/MABN</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkgGjRVKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJeQoCNYDS" data-number="1312">
      <h4>
        <a href="/forum?id=rJeQoCNYDS">
            Single Episode Policy Transfer in Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=rJeQoCNYDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yjiachen%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yjiachen@gmail.com">Jiachen Yang</a>, <a href="/profile?email=petersen33%40llnl.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="petersen33@llnl.gov">Brenden Petersen</a>, <a href="/profile?email=zha%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zha@cc.gatech.edu">Hongyuan Zha</a>, <a href="/profile?email=faissol1%40llnl.gov" class="profile-link" data-toggle="tooltip" data-placement="top" title="faissol1@llnl.gov">Daniel Faissol</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#rJeQoCNYDS-details-526" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJeQoCNYDS-details-526"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">transfer learning, reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Single episode policy transfer in a family of environments with related dynamics, via optimized probing for rapid inference of latent variables and immediate execution of a universal policy.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Transfer and adaptation to new unknown environmental dynamics is a key challenge for reinforcement learning (RL). An even greater challenge is performing near-optimally in a single attempt at test time, possibly without access to dense rewards, which is not addressed by current methods that require multiple experience rollouts for adaptation. To achieve single episode transfer in a family of environments with related dynamics, we propose a general algorithm that optimizes a probe and an inference model to rapidly estimate underlying latent variables of test dynamics, which are then immediately used as input to a universal control policy. This modular approach enables integration of state-of-the-art algorithms for variational inference or RL. Moreover, our approach does not require access to rewards at test time, allowing it to perform in settings where existing adaptive approaches cannot. In diverse experimental domains with a single episode test constraint, our method significantly outperforms existing adaptive approaches and shows favorable performance against baselines for robust transfer.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJeQoCNYDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HklBjCEKvH" data-number="1318">
      <h4>
        <a href="/forum?id=HklBjCEKvH">
            Generalization through Memorization: Nearest Neighbor Language Models
        </a>
      
        
          <a href="/pdf?id=HklBjCEKvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=urvashik%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="urvashik@stanford.edu">Urvashi Khandelwal</a>, <a href="/profile?email=omerlevy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="omerlevy@gmail.com">Omer Levy</a>, <a href="/profile?email=jurafsky%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jurafsky@stanford.edu">Dan Jurafsky</a>, <a href="/profile?email=lsz%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lsz@fb.com">Luke Zettlemoyer</a>, <a href="/profile?email=mikelewis%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mikelewis@fb.com">Mike Lewis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="#HklBjCEKvH-details-609" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HklBjCEKvH-details-609"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">language models, k-nearest neighbors</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We extend a pre-trained neural language model by linearly interpolating it with a k-nearest neighbors model, achieving new state-of-the-art results on Wikitext-103 with no additional training.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We introduce <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="453" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container>NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="454" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container>-nearest neighbors (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="455" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container>NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this transformation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="456" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></mjx-assistive-mml></mjx-container>NN-LM achieves a new state-of-the-art perplexity of 15.79 -- a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/urvashik/knnlm</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HklBjCEKvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1eIiCNYwS" data-number="1320">
      <h4>
        <a href="/forum?id=r1eIiCNYwS">
            Transformer-XH: Multi-Evidence Reasoning with eXtra Hop Attention
        </a>
      
        
          <a href="/pdf?id=r1eIiCNYwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=chenz%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenz@cs.umd.edu">Chen Zhao</a>, <a href="/profile?email=chenyan.xiong%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenyan.xiong@microsoft.com">Chenyan Xiong</a>, <a href="/profile?email=corbin.rosset%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="corbin.rosset@microsoft.com">Corby Rosset</a>, <a href="/profile?email=xiaso%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaso@microsoft.com">Xia Song</a>, <a href="/profile?email=paul.n.bennett%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="paul.n.bennett@microsoft.com">Paul Bennett</a>, <a href="/profile?email=satiwary%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="satiwary@microsoft.com">Saurabh Tiwary</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#r1eIiCNYwS-details-299" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1eIiCNYwS-details-299"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Transformer-XH, multi-hop QA, fact verification, extra hop attention, structured modeling</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present Transformer-XH, which upgrades Transformer with eXtra Hop attentions to intrinsically model structured texts in a data driven way. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Transformers have achieved new heights modeling natural language as a sequence of text tokens. However, in many real world scenarios, textual data inherently exhibits structures beyond a linear sequence such as trees and graphs; many tasks require reasoning with evidence scattered across multiple pieces of texts. This paper presents Transformer-XH, which uses eXtra Hop attention to enable intrinsic modeling of structured texts in a fully data-driven way. Its new attention mechanism naturally “hops” across the connected text sequences in addition to attending over tokens within each sequence. Thus, Transformer-XH better conducts joint multi-evidence reasoning by propagating information between documents and constructing global contextualized representations. On multi-hop question answering, Transformer-XH leads to a simpler multi-hop QA system which outperforms previous state-of-the-art on the HotpotQA FullWiki setting. On FEVER fact verification, applying Transformer-XH provides state-of-the-art accuracy and excels on claims whose verification requires multiple evidence.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/file/d/1-CwjDwSvGzLKHMXNapzTin8Vw6SVYD9b/view?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1eIiCNYwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1l8oANFDH" data-number="1321">
      <h4>
        <a href="/forum?id=S1l8oANFDH">
            Synthesizing Programmatic Policies that Inductively Generalize
        </a>
      
        
          <a href="/pdf?id=S1l8oANFDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jinala%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jinala@csail.mit.edu">Jeevana Priya Inala</a>, <a href="/profile?email=obastani%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="obastani@seas.upenn.edu">Osbert Bastani</a>, <a href="/profile?email=zenna%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zenna@mit.edu">Zenna Tavares</a>, <a href="/profile?email=asolar%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="asolar@csail.mit.edu">Armando Solar-Lezama</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="#S1l8oANFDH-details-930" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1l8oANFDH-details-930"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">An approach to learn program policies for control tasks that inductively generalize. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep reinforcement learning has successfully solved a number of challenging control tasks. However, learned policies typically have difficulty generalizing to novel environments. We propose an algorithm for learning programmatic state machine policies that can capture repeating behaviors. By doing so, they have the ability to generalize to instances requiring an arbitrary number of repetitions, a property we call inductive generalization. However, state machine policies are hard to learn since they consist of a combination of continuous and discrete structures. We propose a learning framework called adaptive teaching, which learns a state machine policy by imitating a teacher; in contrast to traditional imitation learning, our teacher adaptively updates itself based on the structure of the student. We show that our algorithm can be used to learn policies that inductively generalize to novel environments, whereas traditional neural network policies fail to do so. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Program synthesis, reinforcement learning, inductive generalization</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1l8oANFDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HklOo0VFDH" data-number="1325">
      <h4>
        <a href="/forum?id=HklOo0VFDH">
            Decoding As Dynamic Programming For Recurrent Autoregressive Models
        </a>
      
        
          <a href="/pdf?id=HklOo0VFDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=syed.zaidi1%40monash.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="syed.zaidi1@monash.edu">Najam Zaidi</a>, <a href="/profile?email=t.cohn%40unimelb.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="t.cohn@unimelb.edu.au">Trevor Cohn</a>, <a href="/profile?email=reza.haffari%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="reza.haffari@gmail.com">Gholamreza Haffari</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HklOo0VFDH-details-559" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HklOo0VFDH-details-559"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Approximate inference using dynamic programming for Autoregressive models.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Decoding in autoregressive models (ARMs) consists of searching for a high scoring output sequence under the trained model.  Standard decoding methods, based on unidirectional greedy algorithm or beam search, are suboptimal due to error propagation and myopic decisions which do not account for future steps in the generation process. In this paper we present a novel decoding approach based on the method of auxiliary coordinates (Carreira-Perpinan &amp; Wang, 2014) to address the aforementioned shortcomings.  Our method introduces discrete variables for output tokens,  and auxiliary continuous variables representing the states of the underlying ARM. The auxiliary variables lead to a factor graph approximation of the ARM, whose maximum a posteriori (MAP) inference is found exactly using dynamic programming. The MAP inference is then used to recreate an improved factor graph approximation of the ARM via updated auxiliary variables. We then extend our approach to decode in an ensemble of ARMs, possibly with different generation orders,  which is out of reach for the standard unidirectional decoding algorithms. Experiments on the text infilling task over SWAG and Daily Dialogue datasets show that our decoding method is superior to strong unidirectional decoding baselines.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Decoding</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HklOo0VFDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1g5sA4twr" data-number="1329">
      <h4>
        <a href="/forum?id=B1g5sA4twr">
            Deep Double Descent: Where Bigger Models and More Data Hurt
        </a>
      
        
          <a href="/pdf?id=B1g5sA4twr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=preetum%40cs.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="preetum@cs.harvard.edu">Preetum Nakkiran</a>, <a href="/profile?email=galkaplun%40g.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="galkaplun@g.harvard.edu">Gal Kaplun</a>, <a href="/profile?email=ybansal%40g.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ybansal@g.harvard.edu">Yamini Bansal</a>, <a href="/profile?email=tristanyang%40college.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tristanyang@college.harvard.edu">Tristan Yang</a>, <a href="/profile?email=b%40boazbarak.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="b@boazbarak.org">Boaz Barak</a>, <a href="/profile?email=ilyasu%40openai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilyasu@openai.com">Ilya Sutskever</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#B1g5sA4twr-details-33" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1g5sA4twr-details-33"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We demonstrate, and characterize, realistic settings where bigger models are worse, and more data hurts.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We show that a variety of modern deep learning tasks exhibit a "double-descent" phenomenon where, as we increase model size, performance first gets worse and then gets  better.  Moreover, we show that double descent occurs not just as a function of model size, but also as a function of the number of training epochs. We unify the above phenomena by defining a new complexity measure we call the effective model complexity, and conjecture a generalized double descent with respect to this measure. Furthermore, our notion of model complexity allows us to identify certain regimes where increasing (even quadrupling) the number of train samples actually hurts test performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, double descent, optimization, SGD, complexity</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1g5sA4twr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyxJhCEFDS" data-number="1341">
      <h4>
        <a href="/forum?id=HyxJhCEFDS">
            Intriguing Properties of Adversarial Training at Scale
        </a>
      
        
          <a href="/pdf?id=HyxJhCEFDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=cihangxie306%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cihangxie306@gmail.com">Cihang Xie</a>, <a href="/profile?email=alan.l.yuille%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alan.l.yuille@gmail.com">Alan Yuille</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HyxJhCEFDS-details-809" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyxJhCEFDS-details-809"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial defense, adversarial machine learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">The first rigor diagnose of large-scale adversarial training on ImageNet</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Adversarial training is one of the main defenses against adversarial attacks. In this paper, we provide the first rigorous study on diagnosing elements of large-scale adversarial training on ImageNet, which reveals two intriguing properties. 
      
      First, we study the role of normalization. Batch normalization (BN) is a crucial element for achieving state-of-the-art performance on many vision tasks, but we show it may prevent networks from obtaining strong robustness in adversarial training. One unexpected observation is that, for models trained with BN, simply removing clean images from training data largely boosts adversarial robustness, i.e., 18.3%. We relate this phenomenon to the hypothesis that clean images and adversarial images are drawn from two different domains. This two-domain hypothesis may explain the issue of BN when training with a mixture of clean and adversarial images, as estimating normalization statistics of this mixture distribution is challenging. Guided by this two-domain hypothesis, we show disentangling the mixture distribution for normalization, i.e., applying separate BNs to clean and adversarial images for statistics estimation, achieves much stronger robustness. Additionally, we find that enforcing BNs to behave consistently at training and testing can further enhance robustness.
      
      Second, we study the role of network capacity. We find our so-called "deep" networks are still shallow for the task of adversarial learning. Unlike traditional classification tasks where accuracy is only marginally improved by adding more layers to "deep" networks (e.g., ResNet-152), adversarial training exhibits a much stronger demand on deeper networks to achieve higher adversarial robustness. This robustness improvement can be observed substantially and consistently even by pushing the network capacity to an unprecedented scale, i.e., ResNet-638.  </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HyxJhCEFDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bkxe2AVtPS" data-number="1343">
      <h4>
        <a href="/forum?id=Bkxe2AVtPS">
            Shifted and Squeezed 8-bit Floating Point format for Low-Precision Training of Deep Neural Networks
        </a>
      
        
          <a href="/pdf?id=Bkxe2AVtPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=lcambier%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lcambier@stanford.edu">Leopold Cambier</a>, <a href="/profile?email=anahita.bhiwandiwalla%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anahita.bhiwandiwalla@intel.com">Anahita Bhiwandiwalla</a>, <a href="/profile?email=ting.gong%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ting.gong@intel.com">Ting Gong</a>, <a href="/profile?email=oguz.h.elibol%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="oguz.h.elibol@intel.com">Oguz H. Elibol</a>, <a href="/profile?email=mehran.nekuii%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mehran.nekuii@intel.com">Mehran Nekuii</a>, <a href="/profile?email=hanlin.tang%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanlin.tang@intel.com">Hanlin Tang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#Bkxe2AVtPS-details-99" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bkxe2AVtPS-details-99"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Low-precision training, numerics, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a novel 8-bit format that eliminates the need for loss scaling, stochastic rounding, and other low precision techniques</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Training with larger number of parameters while keeping fast iterations is an increasingly
      adopted strategy and trend for developing better performing Deep Neural
      Network (DNN) models. This necessitates increased memory footprint and
      computational requirements for training. Here we introduce a novel methodology
      for training deep neural networks using 8-bit floating point (FP8) numbers.
      Reduced bit precision allows for a larger effective memory and increased computational
      speed. We name this method Shifted and Squeezed FP8 (S2FP8). We
      show that, unlike previous 8-bit precision training methods, the proposed method
      works out of the box for representative models: ResNet50, Transformer and NCF.
      The method can maintain model accuracy without requiring fine-tuning loss scaling
      parameters or keeping certain layers in single precision. We introduce two
      learnable statistics of the DNN tensors - shifted and squeezed factors that are used
      to optimally adjust the range of the tensors in 8-bits, thus minimizing the loss in
      information due to quantization.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Bkxe2AVtPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJxZnR4YvB" data-number="1345">
      <h4>
        <a href="/forum?id=SJxZnR4YvB">
            Distributed Bandit Learning: Near-Optimal Regret with Efficient Communication
        </a>
      
        
          <a href="/pdf?id=SJxZnR4YvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yuanhao-16%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuanhao-16@mails.tsinghua.edu.cn">Yuanhao Wang</a>, <a href="/profile?email=nickh%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="nickh@pku.edu.cn">Jiachen Hu</a>, <a href="/profile?email=cxy30%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="cxy30@pku.edu.cn">Xiaoyu Chen</a>, <a href="/profile?email=wanglw%40cis.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanglw@cis.pku.edu.cn">Liwei Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SJxZnR4YvB-details-930" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJxZnR4YvB-details-930"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Theory, Bandit Algorithms, Communication Efficiency</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study the problem of regret minimization for distributed bandits learning, in which <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="457" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi></math></mjx-assistive-mml></mjx-container> agents work collaboratively to minimize their total regret under the coordination of a central server. Our goal is to design communication protocols with near-optimal regret and little communication cost, which is measured by the total amount of transmitted data. For distributed multi-armed bandits, we propose a protocol with near-optimal regret and only <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="458" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-n" space="2"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>M</mi><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mo stretchy="false">(</mo><mi>M</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> communication cost, where <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="459" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43E TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></mjx-assistive-mml></mjx-container> is the number of arms. The communication cost is independent of the time horizon <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="460" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></mjx-assistive-mml></mjx-container>, has only logarithmic dependence on the number of arms, and matches the lower bound except for a logarithmic factor. For distributed <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="461" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi></math></mjx-assistive-mml></mjx-container>-dimensional linear bandits, we propose a protocol that achieves near-optimal regret and has communication cost of order <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="462" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-n" space="2"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mi class="mjx-n" space="2"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mi class="mjx-n" space="2"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>M</mi><mi>d</mi><mo>+</mo><mi>d</mi><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mi>d</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mi>T</mi><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container>, which has only logarithmic dependence on <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="463" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></mjx-assistive-mml></mjx-container>.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJxZnR4YvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1xGnA4Kvr" data-number="1347">
      <h4>
        <a href="/forum?id=r1xGnA4Kvr">
            Biologically inspired sleep algorithm for increased generalization and adversarial robustness in deep neural networks
        </a>
      
        
          <a href="/pdf?id=r1xGnA4Kvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tttadros%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tttadros@ucsd.edu">Timothy Tadros</a>, <a href="/profile?email=gkrishnan%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gkrishnan@ucsd.edu">Giri Krishnan</a>, <a href="/profile?email=ramyaa.ramyaa%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ramyaa.ramyaa@gmail.com">Ramyaa Ramyaa</a>, <a href="/profile?email=mbazhenov%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mbazhenov@ucsd.edu">Maxim Bazhenov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>6 Replies</span>
        
        
      </div>
      
        <a href="#r1xGnA4Kvr-details-56" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1xGnA4Kvr-details-56"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Adversarial Robustness, Generalization, Neural Computing, Deep Learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We describe a biologically inspired sleep algorithm for increasing an artificial neural network's ability to extract the gist of a training set and exhibit increased robustness to adversarial attacks and general distortions.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Current artificial neural networks (ANNs) can perform and excel at a variety of tasks ranging from image classification to spam detection through training on large datasets of labeled data. While the trained network may perform well on similar testing data, inputs that differ even slightly from the training data may trigger unpredictable behavior. Due to this limitation, it is possible to design inputs with very small perturbations that can result in misclassification. These adversarial attacks present a security risk to deployed ANNs and indicate a divergence between how ANNs and humans perform classification. Humans are robust at behaving in the presence of noise and are capable of correctly classifying objects that are noisy, blurred, or otherwise distorted.  It has been hypothesized that sleep promotes generalization of knowledge and improves robustness against noise in animals and humans. In this work, we utilize a biologically inspired sleep phase in ANNs and demonstrate the benefit of sleep on defending against adversarial attacks as well as in increasing ANN classification robustness. We compare the sleep algorithm's performance on various robustness tasks with two previously proposed adversarial defenses - defensive distillation and fine-tuning. We report an increase in robustness after sleep phase to adversarial attacks as well as to general image distortions for three datasets: MNIST, CUB200, and a toy dataset. Overall, these results demonstrate the potential for biologically inspired solutions to solve existing problems in ANNs and guide the development of more robust, human-like ANNs.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1xGnA4Kvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJeVnCEKwH" data-number="1352">
      <h4>
        <a href="/forum?id=HJeVnCEKwH">
            A Closer Look at the Optimization Landscapes of Generative Adversarial Networks
        </a>
      
        
          <a href="/pdf?id=HJeVnCEKwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=berard.hugo%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="berard.hugo@gmail.com">Hugo Berard</a>, <a href="/profile?email=gauthier.gidel%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="gauthier.gidel@umontreal.ca">Gauthier Gidel</a>, <a href="/profile?email=amjadmahayri%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="amjadmahayri@gmail.com">Amjad Almahairi</a>, <a href="/profile?email=vincentp%40iro.umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="vincentp@iro.umontreal.ca">Pascal Vincent</a>, <a href="/profile?email=slacoste%40iro.umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="slacoste@iro.umontreal.ca">Simon Lacoste-Julien</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#HJeVnCEKwH-details-946" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJeVnCEKwH-details-946"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">By proposing new visualization techniques we give better insights on GANs optimization in practical settings, we show that GANs on challenging datasets exhibit rotational behavior and do not converge to Nash-Equilibria</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Generative adversarial networks have been very successful in generative modeling, however they remain relatively challenging to train compared to standard deep neural networks. In this paper, we propose new visualization techniques for the optimization landscapes of GANs that enable us to study the game vector field resulting from the concatenation of the gradient of both players.   Using these visualization techniques we try to bridge the gap between theory and practice by showing empirically that the training of GANs exhibits significant rotations around LSSP, similar to the one predicted by theory on toy examples. Moreover, we provide empirical evidence that GAN training seems to converge to a stable stationary point which is a saddle point for the generator loss, not a minimum, while still achieving excellent performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://anonymous.4open.science/repository/a93c04c6-a0b9-49ff-9c14-f817fd405fda/README.md</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep Learning, Generative models, GANs, Optimization, Visualization</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJeVnCEKwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJxEhREKDH" data-number="1353">
      <h4>
        <a href="/forum?id=HJxEhREKDH">
            On the Global Convergence  of Training Deep Linear ResNets
        </a>
      
        
          <a href="/pdf?id=HJxEhREKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=knowzou%40ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="knowzou@ucla.edu">Difan Zou</a>, <a href="/profile?email=plong%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="plong@google.com">Philip M. Long</a>, <a href="/profile?email=qgu%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qgu@cs.ucla.edu">Quanquan Gu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#HJxEhREKDH-details-76" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJxEhREKDH-details-76"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Under certain condition on the input and output linear transformations, both GD and SGD can achieve global convergence for training deep linear ResNets.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study the convergence of gradient descent (GD) and stochastic gradient descent (SGD) for training <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="464" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi></math></mjx-assistive-mml></mjx-container>-hidden-layer linear residual networks (ResNets). We prove that for training deep residual networks with certain linear transformations at input and output layers, which are fixed throughout training, both GD and SGD with zero initialization on all hidden weights can converge to the global minimum of the training loss. Moreover, when specializing to appropriate Gaussian random linear transformations, GD and SGD provably optimize wide enough deep linear ResNets. Compared with the global convergence result of GD for training standard deep linear networks \citep{du2019width}, our condition on the neural network width is sharper by a factor of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="465" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>κ</mi><mi>L</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>, where <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="466" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>κ</mi></math></mjx-assistive-mml></mjx-container> denotes the condition number of the covariance matrix of the training data. We further propose a modified identity input and output transformations, and show that a <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="467" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2B"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mi>d</mi><mo>+</mo><mi>k</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>-wide neural network is sufficient to guarantee the global convergence of GD/SGD, where <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="468" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi><mo>,</mo><mi>k</mi></math></mjx-assistive-mml></mjx-container> are the input and output dimensions respectively.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJxEhREKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hklr204Fvr" data-number="1355">
      <h4>
        <a href="/forum?id=Hklr204Fvr">
            Towards a Deep Network Architecture for Structured Smoothness
        </a>
      
        
          <a href="/pdf?id=Hklr204Fvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=haroun7%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="haroun7@gmail.com">Haroun Habeeb</a>, <a href="/profile?email=sanmi%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sanmi@illinois.edu">Oluwasanmi Koyejo</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="#Hklr204Fvr-details-815" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hklr204Fvr-details-815"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A feedforward layer to incorporate structured smoothness into a deep learning model</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose the Fixed Grouping Layer (FGL); a novel feedforward layer designed to incorporate the inductive bias of structured smoothness into a deep learning model. FGL achieves this goal by connecting nodes across layers based on spatial similarity. The use of structured smoothness, as implemented by FGL, is motivated by applications to structured spatial data, which is, in turn, motivated by domain knowledge. The proposed model architecture outperforms conventional neural network architectures across a variety of simulated and real datasets with structured smoothness. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hklr204Fvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJgdnAVKDH" data-number="1362">
      <h4>
        <a href="/forum?id=SJgdnAVKDH">
            Revisiting Self-Training for Neural Sequence Generation
        </a>
      
        
          <a href="/pdf?id=SJgdnAVKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=junxianh%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="junxianh@cs.cmu.edu">Junxian He</a>, <a href="/profile?email=thomagram%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomagram@gmail.com">Jiatao Gu</a>, <a href="/profile?email=jiajunshen%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiajunshen@fb.com">Jiajun Shen</a>, <a href="/profile?email=ranzato%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ranzato@fb.com">Marc'Aurelio Ranzato</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SJgdnAVKDH-details-405" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJgdnAVKDH-details-405"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">self-training, semi-supervised learning, neural sequence generatioin</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We revisit self-training as a semi-supervised learning method for neural sequence generation problem, and show that self-training can be quite successful with injected noise.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Self-training is one of the earliest and simplest semi-supervised methods. The key idea is to augment the original labeled dataset with unlabeled data paired with the model's prediction (i.e. the pseudo-parallel data). While self-training has been extensively studied on classification problems, in complex sequence generation tasks (e.g. machine translation) it is still unclear how self-training works due to the compositionality of the target space. In this work, we first empirically show that self-training is able to decently improve the supervised baseline on neural sequence generation tasks. Through careful examination of the performance gains, we find that the perturbation on the hidden states (i.e. dropout) is critical for self-training to benefit from the pseudo-parallel data, which acts as a regularizer and forces the model to yield close predictions for similar unlabeled inputs. Such effect helps the model correct some incorrect predictions on unlabeled data. To further encourage this mechanism, we propose to inject noise to the input space, resulting in a noisy version of self-training. Empirical study on standard machine translation and text summarization benchmarks shows that noisy self-training is able to effectively utilize unlabeled data and improve the performance of the supervised baseline by a large margin.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJgdnAVKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJeqhA4YDS" data-number="1366">
      <h4>
        <a href="/forum?id=HJeqhA4YDS">
            Denoising and Regularization via Exploiting the Structural Bias of Convolutional Generators
        </a>
      
        
          <a href="/pdf?id=HJeqhA4YDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=reinhard.heckel%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="reinhard.heckel@tum.de">Reinhard Heckel and Mahdi Soltanolkotabi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HJeqhA4YDS-details-777" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJeqhA4YDS-details-777"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Convolutional Neural Networks (CNNs) have emerged as highly successful tools for image generation, recovery, and restoration. A major contributing factor to this success is that convolutional networks impose strong prior assumptions about natural images. A surprising experiment that highlights this architectural bias towards natural images is that one can remove noise and corruptions from a natural image without using any training data, by simply fitting (via gradient descent) a randomly initialized, over-parameterized convolutional generator to the corrupted image. While this over-parameterized network can fit the corrupted image perfectly, surprisingly after a few iterations of gradient descent it generates an almost uncorrupted image. This intriguing phenomenon enables state-of-the-art CNN-based denoising and regularization of other inverse problems. In this paper, we attribute this effect to a particular architectural choice of convolutional networks, namely convolutions with fixed interpolating filters. We then formally characterize the dynamics of fitting a two-layer convolutional generator to a noisy signal and prove that early-stopped gradient descent denoises/regularizes. Our proof relies on showing that convolutional generators fit the structured part of an image significantly faster than the corrupted portion. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">theory for deep learning, convolutional network, deep image prior, deep decoder, dynamics of gradient descent, overparameterization</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/MLI-lab/overparameterized_convolutional_generators</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJeqhA4YDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1lj20NFDS" data-number="1368">
      <h4>
        <a href="/forum?id=B1lj20NFDS">
            Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities
        </a>
      
        
          <a href="/pdf?id=B1lj20NFDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ybcmath%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ybcmath@gmail.com">Baichuan Yuan</a>, <a href="/profile?email=daemon.wxw%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daemon.wxw@alibaba-inc.com">Xiaowei Wang</a>, <a href="/profile?email=majx13fromthu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="majx13fromthu@gmail.com">Jianxin Ma</a>, <a href="/profile?email=ericzhou.zc%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ericzhou.zc@alibaba-inc.com">Chang Zhou</a>, <a href="/profile?email=bertozzi%40math.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bertozzi@math.ucla.edu">Andrea L. Bertozzi</a>, <a href="/profile?email=yang.yhx%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yang.yhx@alibaba-inc.com">Hongxia Yang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#B1lj20NFDS-details-845" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1lj20NFDS-details-845"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">VAE, collaborative filtering, recommender systems, spatial point process</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Multivariate spatial point process models can describe heterotopic data over space. However, highly multivariate intensities are computationally challenging due to the curse of dimensionality. To bridge this gap, we introduce a declustering based hidden variable model that leads to an efficient inference procedure via a variational autoencoder (VAE). We also prove that this model is a generalization of the VAE-based model for collaborative filtering. This leads to an interesting application of spatial point process models to recommender systems. Experimental results show the method's utility on both synthetic data and real-world data sets.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1lj20NFDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skln2A4YDB" data-number="1371">
      <h4>
        <a href="/forum?id=Skln2A4YDB">
            Model-Augmented Actor-Critic: Backpropagating through Paths
        </a>
      
        
          <a href="/pdf?id=Skln2A4YDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=iclavera%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="iclavera@berkeley.edu">Ignasi Clavera</a>, <a href="/profile?email=violetfuyao%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="violetfuyao@berkeley.edu">Yao Fu</a>, <a href="/profile?email=pabbeel%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@cs.berkeley.edu">Pieter Abbeel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#Skln2A4YDB-details-151" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skln2A4YDB-details-151"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, model-based, actor-critic, pathwise</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Policy gradient through backpropagation through time using learned models and Q-functions. SOTA results in reinforcement learning benchmark environments.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Current model-based reinforcement learning approaches use the model simply as a learned black-box simulator to augment the data for policy optimization or value function learning. In this paper, we show how to make more effective use of the model by exploiting its differentiability. We construct a policy optimization algorithm that uses the pathwise derivative of the learned model and policy across future timesteps. Instabilities of learning across many timesteps are prevented by using a terminal value function, learning the policy in an actor-critic fashion. Furthermore, we present a derivation on the monotonic improvement of our objective in terms of the gradient error in the model and value function. We show that our approach (i) is consistently more sample efficient than existing state-of-the-art model-based algorithms, (ii) matches the asymptotic performance of model-free algorithms, and (iii) scales to long horizons, a regime where typically past model-based approaches have struggled.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Skln2A4YDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkx6hANtwH" data-number="1373">
      <h4>
        <a href="/forum?id=Hkx6hANtwH">
            LambdaNet: Probabilistic Type Inference using Graph Neural Networks
        </a>
      
        
          <a href="/pdf?id=Hkx6hANtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jiayi%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiayi@cs.utexas.edu">Jiayi Wei</a>, <a href="/profile?email=maruth%40utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="maruth@utexas.edu">Maruth Goyal</a>, <a href="/profile?email=gdurrett%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gdurrett@cs.utexas.edu">Greg Durrett</a>, <a href="/profile?email=isil%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="isil@cs.utexas.edu">Isil Dillig</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#Hkx6hANtwH-details-26" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkx6hANtwH-details-26"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">As gradual typing becomes increasingly popular in languages like Python and TypeScript, there is a growing need to infer type annotations automatically. While type annotations help with tasks like code completion and static error catching, these annotations cannot be fully inferred by compilers and are tedious to annotate by hand. This paper proposes a probabilistic type inference scheme for TypeScript based on a graph neural network. Our approach first uses lightweight source code analysis to generate a program abstraction called a type dependency graph, which links type variables with logical constraints as well as name and usage information. Given this program abstraction, we then use a graph neural network to propagate information between related type variables and eventually make type predictions. Our neural architecture can predict both standard types, like number or string, as well as user-defined types that have not been encountered during training. Our experimental results show that our approach outperforms prior work in this space by 14% (absolute) on library types, while having the ability to make type predictions that are out of scope for existing techniques. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Type inference, Graph neural network, Programming languages, Pointer network</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We have presented LambdaNet, a neural architecture for type inference that combines the strength of explicit program analysis with graph neural networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/MrVPlusOne/LambdaNet</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hkx6hANtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1guaREYPr" data-number="1399">
      <h4>
        <a href="/forum?id=H1guaREYPr">
            From Inference to Generation: End-to-end Fully Self-supervised Generation of Human Face from Speech
        </a>
      
        
          <a href="/pdf?id=H1guaREYPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kekepa15%40snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="kekepa15@snu.ac.kr">Hyeong-Seok Choi</a>, <a href="/profile?email=cdpark%40connect.ust.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="cdpark@connect.ust.hk">Changdae Park</a>, <a href="/profile?email=kglee%40snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="kglee@snu.ac.kr">Kyogu Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#H1guaREYPr-details-84" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1guaREYPr-details-84"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper proposes a method of end-to-end multi-modal generation of human face from speech based on a self-supervised learning framework.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This work seeks the possibility of generating the human face from voice solely based on the audio-visual data without any human-labeled annotations. To this end, we propose a multi-modal learning framework that links the inference stage and generation stage. First, the inference networks are trained to match the speaker identity between the two different modalities. Then the pre-trained inference networks cooperate with the generation network by giving conditional information about the voice. The proposed method exploits the recent development of GANs techniques and generates the human face directly from the speech waveform making our system fully end-to-end. We analyze the extent to which the network can naturally disentangle two latent factors that contribute to the generation of a face image one that comes directly from a speech signal and the other that is not related to it and explore whether the network can learn to generate natural human face image distribution by modeling these factors. Experimental results show that the proposed network can not only match the relationship between the human face and speech, but can also generate the high-quality human face sample conditioned on its speech. Finally, the correlation between the generated face and the corresponding speech is quantitatively measured to analyze the relationship between the two modalities.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Multi-modal learning, Self-supervised learning, Voice profiling, Conditional GANs</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1guaREYPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJxt60VtPr" data-number="1401">
      <h4>
        <a href="/forum?id=BJxt60VtPr">
            Learning from Unlabelled Videos Using Contrastive Predictive Neural 3D Mapping
        </a>
      
        
          <a href="/pdf?id=BJxt60VtPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=aharley%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aharley@cmu.edu">Adam W. Harley</a>, <a href="/profile?email=kowshika%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kowshika@cmu.edu">Shrinidhi K. Lakshmikanth</a>, <a href="/profile?email=fangyul%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fangyul@cmu.edu">Fangyu Li</a>, <a href="/profile?email=zhouxian%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhouxian@cmu.edu">Xian Zhou</a>, <a href="/profile?email=htung%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="htung@cs.cmu.edu">Hsiao-Yu Fish Tung</a>, <a href="/profile?email=katef%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="katef@cs.cmu.edu">Katerina Fragkiadaki</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#BJxt60VtPr-details-750" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJxt60VtPr-details-750"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We show that with the right loss and architecture, view-predictive learning improves 3D object detection</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Predictive coding theories suggest that the brain learns by predicting observations at various levels of abstraction. One of the most basic prediction tasks is view prediction: how would a given scene look from an alternative viewpoint? Humans excel at this task. Our ability to imagine and fill in missing information is tightly coupled with perception: we feel as if we see the world in 3 dimensions, while in fact, information from only the front surface of the world hits our retinas. This paper explores the role of view prediction in the development of 3D visual recognition. We propose neural 3D mapping networks, which take as input 2.5D (color and depth) video streams captured by a moving camera, and lift them to stable 3D feature maps of the scene, by disentangling the scene content from the motion of the camera. The model also projects its 3D feature maps to novel viewpoints, to predict and match against target views. We propose contrastive prediction losses to replace the standard color regression loss, and show that this leads to better performance on complex photorealistic data. We show that the proposed model learns visual representations useful for (1) semi-supervised learning of 3D object detectors, and (2) unsupervised learning of 3D moving object detectors, by estimating the motion of the inferred 3D feature maps in videos of dynamic scenes. To the best of our knowledge, this is the first work that empirically shows view prediction to be a scalable self-supervised task beneficial to 3D object detection. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">3D feature learning, unsupervised learning, inverse graphics, object discovery</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/aharley/neural_3d_mapping</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJxt60VtPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1gRTCVFvB" data-number="1412">
      <h4>
        <a href="/forum?id=r1gRTCVFvB">
            Decoupling Representation and Classifier for Long-Tailed Recognition
        </a>
      
        
          <a href="/pdf?id=r1gRTCVFvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kang%40u.nus.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kang@u.nus.edu">Bingyi Kang</a>, <a href="/profile?email=xiesaining%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiesaining@gmail.com">Saining Xie</a>, <a href="/profile?email=maroffm%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maroffm@gmail.com">Marcus Rohrbach</a>, <a href="/profile?email=zhicheng.yan%40live.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhicheng.yan@live.com">Zhicheng Yan</a>, <a href="/profile?email=albert.gordo.s%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="albert.gordo.s@gmail.com">Albert Gordo</a>, <a href="/profile?email=elefjia%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="elefjia@nus.edu.sg">Jiashi Feng</a>, <a href="/profile?email=ykalant%40image.ntua.gr" class="profile-link" data-toggle="tooltip" data-placement="top" title="ykalant@image.ntua.gr">Yannis Kalantidis</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#r1gRTCVFvB-details-148" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1gRTCVFvB-details-148"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The long-tail distribution of the visual world poses great challenges for deep learning based classification models on how to handle the class imbalance problem. Existing solutions usually involve class-balancing strategies, e.g., by loss re-weighting, data re-sampling, or transfer learning from head- to tail-classes, but most of them adhere to the scheme of jointly learning representations and classifiers. In this work, we decouple the learning procedure into representation learning and classification, and systematically explore how different balancing strategies affect them for long-tailed recognition. The findings are surprising: (1) data imbalance might not be an issue in learning high-quality representations; (2) with representations learned with the simplest instance-balanced (natural) sampling, it is also possible to achieve strong long-tailed recognition ability by adjusting only the classifier. We conduct extensive experiments and set new state-of-the-art performance on common long-tailed benchmarks like ImageNet-LT, Places-LT and iNaturalist, showing that it is possible to outperform carefully designed losses, sampling strategies, even complex modules with memory, by using a straightforward approach that decouples representation and classification. Our code is available at https://github.com/facebookresearch/classifier-balancing.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">long-tailed recognition, classification</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1gRTCVFvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJgC60EtwB" data-number="1413">
      <h4>
        <a href="/forum?id=HJgC60EtwB">
            Robust Reinforcement Learning for Continuous Control with Model Misspecification
        </a>
      
        
          <a href="/pdf?id=HJgC60EtwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=dmankowitz%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dmankowitz@google.com">Daniel J. Mankowitz</a>, <a href="/profile?email=nirlevine%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nirlevine@google.com">Nir Levine</a>, <a href="/profile?email=raejeong%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="raejeong@google.com">Rae Jeong</a>, <a href="/profile?email=aabdolmaleki%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aabdolmaleki@google.com">Abbas Abdolmaleki</a>, <a href="/profile?email=springenberg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="springenberg@google.com">Jost Tobias Springenberg</a>, <a href="/profile?email=yyshi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yyshi@google.com">Yuanyuan Shi</a>, <a href="/profile?email=kayj%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kayj@google.com">Jackie Kay</a>, <a href="/profile?email=toddhester%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="toddhester@google.com">Todd Hester</a>, <a href="/profile?email=timothymann%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="timothymann@google.com">Timothy Mann</a>, <a href="/profile?email=riedmiller%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="riedmiller@google.com">Martin Riedmiller</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#HJgC60EtwB-details-16" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJgC60EtwB-details-16"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A framework for incorporating robustness to model misspecification into continuous control Reinforcement Learning algorithms.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We provide a framework for incorporating robustness -- to perturbations in the transition dynamics which we refer to as model misspecification -- into continuous control Reinforcement Learning (RL) algorithms. We specifically focus on incorporating robustness into a state-of-the-art continuous control RL algorithm called Maximum a-posteriori Policy Optimization (MPO). We achieve this by learning a policy that optimizes for a worst case, entropy-regularized, expected return objective and derive a corresponding robust entropy-regularized Bellman contraction operator. In addition, we introduce a less conservative, soft-robust, entropy-regularized objective with a corresponding Bellman operator. We show that both, robust and soft-robust policies, outperform their non-robust counterparts in nine Mujoco domains with environment perturbations. In addition, we show improved robust performance on a challenging, simulated, dexterous robotic hand. Finally, we present multiple investigative experiments that provide a deeper insight into the robustness framework; including an adaptation to another continuous control RL algorithm. Performance videos can be found online at https://sites.google.com/view/robust-rl.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, robustness</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJgC60EtwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1l-C0NtwS" data-number="1420">
      <h4>
        <a href="/forum?id=S1l-C0NtwS">
            Cross-lingual Alignment vs Joint Training: A Comparative Study and A Simple Unified Framework
        </a>
      
        
          <a href="/pdf?id=S1l-C0NtwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ziruiw%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ziruiw@cs.cmu.edu">Zirui Wang*</a>, <a href="/profile?email=jiatengx%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiatengx@cs.cmu.edu">Jiateng Xie*</a>, <a href="/profile?email=ruochenx%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruochenx@cs.cmu.edu">Ruochen Xu</a>, <a href="/profile?email=yiming%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yiming@cs.cmu.edu">Yiming Yang</a>, <a href="/profile?email=gneubig%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gneubig@cs.cmu.edu">Graham Neubig</a>, <a href="/profile?email=jgc%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jgc@cs.cmu.edu">Jaime G. Carbonell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="#S1l-C0NtwS-details-859" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1l-C0NtwS-details-859"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We conduct a comparative study of cross-lingual alignment vs joint training methods and unify these two previously exclusive paradigms in a new framework. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Learning multilingual representations of text has proven a successful method for many cross-lingual transfer learning tasks. There are two main paradigms for learning such representations: (1) alignment, which maps different independently trained monolingual representations into a shared space, and (2) joint training, which directly learns unified multilingual representations using monolingual and cross-lingual objectives jointly. In this paper, we first conduct direct comparisons of representations learned using both of these methods across diverse cross-lingual tasks. Our empirical results reveal a set of pros and cons for both methods, and show that the relative performance of alignment versus joint training is task-dependent. Stemming from this analysis, we propose a simple and novel framework that combines these two previously mutually-exclusive approaches. Extensive experiments demonstrate that our proposed framework alleviates limitations of both approaches, and outperforms existing methods on the MUSE bilingual lexicon induction (BLI) benchmark. We further show that this framework can generalize to contextualized representations such as Multilingual BERT, and produces state-of-the-art results on the CoNLL cross-lingual NER benchmark.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Cross-lingual Representation</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/thespectrewithin/joint-align</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1l-C0NtwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJgmR0NKPr" data-number="1425">
      <h4>
        <a href="/forum?id=SJgmR0NKPr">
            Training Recurrent Neural Networks Online by Learning Explicit State Variables
        </a>
      
        
          <a href="/pdf?id=SJgmR0NKPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=somjit%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="somjit@ualberta.ca">Somjit Nath</a>, <a href="/profile?email=vliu1%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="vliu1@ualberta.ca">Vincent Liu</a>, <a href="/profile?email=achan4%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="achan4@ualberta.ca">Alan Chan</a>, <a href="/profile?email=xzli%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="xzli@ualberta.ca">Xin Li</a>, <a href="/profile?email=amw8%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="amw8@ualberta.ca">Adam White</a>, <a href="/profile?email=whitem%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="whitem@ualberta.ca">Martha White</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#SJgmR0NKPr-details-565" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJgmR0NKPr-details-565"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recurrent neural networks (RNNs) allow an agent to construct a state-representation from a stream of experience, which is essential in partially observable problems. However, there are two primary issues one must overcome when training an RNN: the sensitivity of the learning algorithm's performance to truncation length and and long training times. There are variety of strategies to improve training in RNNs, the mostly notably Backprop Through Time (BPTT) and by Real-Time Recurrent Learning. These strategies, however, are typically computationally expensive and focus computation on computing gradients back in time. In this work, we reformulate the RNN training objective to explicitly learn state vectors; this breaks the dependence across time and so avoids the need to estimate gradients far back in time. We show that for a fixed buffer of data, our algorithm---called Fixed Point Propagation (FPP)---is sound: it converges to a stationary point of the new objective. We investigate the empirical performance of our online FPP algorithm, particularly in terms of computation compared to truncated BPTT with varying truncation levels. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Recurrent Neural Network, Partial Observability, Online Prediction, Incremental Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJgmR0NKPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HklUCCVKDB" data-number="1432">
      <h4>
        <a href="/forum?id=HklUCCVKDB">
            Uncertainty-guided Continual Learning with Bayesian Neural Networks
        </a>
      
        
          <a href="/pdf?id=HklUCCVKDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sayna%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sayna@berkeley.edu">Sayna Ebrahimi</a>, <a href="/profile?email=mohamed.elhoseiny%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mohamed.elhoseiny@gmail.com">Mohamed Elhoseiny</a>, <a href="/profile?email=trevor%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="trevor@eecs.berkeley.edu">Trevor Darrell</a>, <a href="/profile?email=maroffm%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maroffm@gmail.com">Marcus Rohrbach</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HklUCCVKDB-details-723" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HklUCCVKDB-details-723"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">continual learning, catastrophic forgetting</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A regularization-based approach for continual learning using Bayesian neural networks to predict parameters' importance</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Continual learning aims to learn new tasks without forgetting previously learned ones. This is especially challenging when one cannot access data from previous tasks and when the model has a fixed capacity. Current regularization-based continual learning algorithms  need an external representation and extra computation to measure the parameters' \textit{importance}. In contrast, we propose Uncertainty-guided Continual Bayesian Neural Networks (UCB), where the learning rate adapts according to the uncertainty defined in the probability distribution of the weights in  networks. Uncertainty is a natural way to identify \textit{what to remember} and \textit{what to change} as we continually learn,  and thus mitigate catastrophic forgetting. We also show a variant of our model, which uses uncertainty for weight pruning 
      and retains task performance after pruning by saving binary masks per tasks. We evaluate our UCB approach extensively on diverse object classification datasets with short and long sequences of tasks and report superior or on-par performance compared to existing approaches. Additionally, we show that our model does not necessarily need task information at test time, i.e. it does not presume knowledge of which task a sample belongs to.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/SaynaEbrahimi/UCB</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HklUCCVKDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgt0REKwS" data-number="1438">
      <h4>
        <a href="/forum?id=rkgt0REKwS">
            Curriculum Loss: Robust Learning and Generalization  against Label Corruption
        </a>
      
        
          <a href="/pdf?id=rkgt0REKwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=lv_yueming%40outlook.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lv_yueming@outlook.com">Yueming Lyu</a>, <a href="/profile?email=ivor.tsang%40uts.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="ivor.tsang@uts.edu.au">Ivor W. Tsang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rkgt0REKwS-details-212" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgt0REKwS-details-212"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Curriculum Learning, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A novel loss bridges curriculum learning and robust learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep neural networks (DNNs) have great expressive power, which can even memorize samples with wrong labels. It is vitally important to reiterate robustness and generalization in DNNs against label corruption. To this end, this paper studies the 0-1 loss, which has a monotonic relationship between empirical adversary (reweighted) risk (Hu et al. 2018). Although the 0-1 loss is robust to outliers, it is also difficult to optimize.   To efficiently optimize the 0-1 loss while keeping its robust properties, we propose a very simple and efficient loss, i.e. curriculum loss (CL). Our CL  is a tighter upper bound of the 0-1 loss compared with conventional summation based surrogate losses.  Moreover, CL can adaptively select samples for stagewise training. As a result, our loss can be deemed as a novel perspective of curriculum sample selection strategy, which bridges a connection between curriculum learning and robust learning.     Experimental results on noisy MNIST, CIFAR10 and CIFAR100 dataset validate the robustness of the proposed loss.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgt0REKwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkgsACVKPH" data-number="1443">
      <h4>
        <a href="/forum?id=SkgsACVKPH">
            Picking Winning Tickets Before Training by Preserving Gradient Flow
        </a>
      
        
          <a href="/pdf?id=SkgsACVKPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=cqwang%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cqwang@cs.toronto.edu">Chaoqi Wang</a>, <a href="/profile?email=gdzhang%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gdzhang@cs.toronto.edu">Guodong Zhang</a>, <a href="/profile?email=rgrosse%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rgrosse@cs.toronto.edu">Roger Grosse</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="#SkgsACVKPH-details-993" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkgsACVKPH-details-993"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">neural network, pruning before training, weight pruning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduced a pruning criterion for pruning networks before training by preserving gradient flow.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Overparameterization has been shown to benefit both the optimization and generalization of neural networks, but large networks are resource hungry at both training and test time.  Network pruning can reduce test-time resource requirements, but is typically applied to trained networks and therefore cannot avoid the expensive training process. We aim to prune networks at initialization, thereby saving resources at training time as well. Specifically, we argue that efficient training requires preserving the gradient flow through the network. This leads to a simple but effective pruning criterion we term Gradient Signal Preservation (GraSP). We empirically investigate the effectiveness of the proposed method with extensive experiments on CIFAR-10, CIFAR-100, Tiny-ImageNet and ImageNet, using VGGNet and ResNet architectures. Our method can prune 80% of the weights of a VGG-16 network on ImageNet at initialization, with only a 1.6% drop in top-1 accuracy. Moreover, our method achieves significantly better performance than the baseline at extreme sparsity levels. Our code is made public
      at: https://github.com/alecwangcq/GraSP.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkgsACVKPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJgaRA4FPH" data-number="1448">
      <h4>
        <a href="/forum?id=SJgaRA4FPH">
            Generative Models for Effective ML on Private, Decentralized Datasets
        </a>
      
        
          <a href="/pdf?id=SJgaRA4FPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=saugenst%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="saugenst@google.com">Sean Augenstein</a>, <a href="/profile?email=mcmahan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mcmahan@google.com">H. Brendan McMahan</a>, <a href="/profile?email=dramage%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dramage@google.com">Daniel Ramage</a>, <a href="/profile?email=swaroopram%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="swaroopram@google.com">Swaroop Ramaswamy</a>, <a href="/profile?email=kairouz%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kairouz@google.com">Peter Kairouz</a>, <a href="/profile?email=mingqing%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mingqing@google.com">Mingqing Chen</a>, <a href="/profile?email=mathews%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mathews@google.com">Rajiv Mathews</a>, <a href="/profile?email=blaisea%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="blaisea@google.com">Blaise Aguera y Arcas</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SJgaRA4FPH-details-365" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJgaRA4FPH-details-365"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Generative Models + Federated Learning + Differential Privacy gives data scientists a way to analyze private, decentralized data (e.g., on mobile devices) where direct inspection is prohibited.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">To improve real-world applications of machine learning, experienced modelers develop intuition about their datasets, their models, and how the two interact. Manual inspection of raw data—of representative samples, of outliers, of misclassifications—is an essential tool in a) identifying and fixing problems in the data, b) generating new modeling hypotheses,
      and c) assigning or refining human-provided labels. However, manual data inspection is risky for privacy-sensitive datasets, such as those representing the behavior of real-world individuals. Furthermore, manual data inspection is impossible in the increasingly important setting of federated learning, where raw examples are stored at the edge and the modeler may only access aggregated outputs such as metrics or model parameters. This paper demonstrates that generative models—trained using federated methods and with formal differential privacy guarantees—can be used effectively to debug data issues even
      when the data cannot be directly inspected. We explore these methods in applications to text with differentially private federated RNNs and to images using a novel algorithm for differentially private federated GANs.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/tensorflow/federated/tree/master/tensorflow_federated/python/research/gans</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">generative models, federated learning, decentralized learning, differential privacy, privacy, security, GAN</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJgaRA4FPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJeW1yHYwH" data-number="1457">
      <h4>
        <a href="/forum?id=rJeW1yHYwH">
            Inductive representation learning on temporal graphs
        </a>
      
        
          <a href="/pdf?id=rJeW1yHYwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=da.xu%40walmartlabs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="da.xu@walmartlabs.com">da Xu</a>, <a href="/profile?email=ruanchuanwei%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruanchuanwei@gmail.com">chuanwei ruan</a>, <a href="/profile?email=ekorpeoglu%40walmart.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ekorpeoglu@walmart.com">evren korpeoglu</a>, <a href="/profile?email=skumar4%40walmartlabs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="skumar4@walmartlabs.com">sushant kumar</a>, <a href="/profile?email=kachan%40walmartlabs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kachan@walmartlabs.com">kannan achan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#rJeW1yHYwH-details-388" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJeW1yHYwH-details-388"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">temporal graph, inductive representation learning, functional time encoding, self-attention</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Inductive representation learning on temporal graphs is an important step toward salable machine learning on real-world dynamic networks. The evolving nature of temporal dynamic graphs requires handling new nodes as well as capturing temporal patterns. The node embeddings, which are now functions of time, should represent both the static node features and the evolving topological structures. Moreover, node and topological features can be temporal as well, whose patterns the node embeddings should also capture. We propose the temporal graph attention (TGAT) layer to efficiently aggregate temporal-topological neighborhood features to learn the time-feature interactions. For TGAT, we use the self-attention mechanism as building block and develop a novel functional time encoding technique based on the classical Bochner's theorem from harmonic analysis. By stacking TGAT layers, the network recognizes the node embeddings as functions of time and is able to inductively infer embeddings for both new and observed nodes as the graph evolves. The proposed approach handles both node classification and link prediction task, and can be naturally extended to include the temporal edge features. We evaluate our method with transductive and inductive tasks under temporal settings with two benchmark and one industrial dataset. Our TGAT model compares favorably to state-of-the-art baselines as well as the previous temporal graph embedding approaches.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/drive/folders/1GaH8vusCXJj4ucayfO-PyHpnNsJRkB78?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJeW1yHYwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sklf1yrYDr" data-number="1459">
      <h4>
        <a href="/forum?id=Sklf1yrYDr">
            BatchEnsemble: an Alternative Approach to Efficient Ensemble and Lifelong Learning
        </a>
      
        
          <a href="/pdf?id=Sklf1yrYDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ywen%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ywen@cs.toronto.edu">Yeming Wen</a>, <a href="/profile?email=trandustin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="trandustin@google.com">Dustin Tran</a>, <a href="/profile?email=jba%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jba@cs.toronto.edu">Jimmy Ba</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="#Sklf1yrYDr-details-915" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sklf1yrYDr-details-915"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, ensembles</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduced BatchEnsemble, an efficient method for ensembling and lifelong learning which can be used to improve the accuracy and uncertainty of any neural network like typical ensemble methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">
      Ensembles, where multiple neural networks are trained individually and their predictions are averaged, have been shown to be widely successful for improving both the accuracy and predictive uncertainty of single neural networks. However, an ensemble’s cost for both training and testing increases linearly with the number of networks, which quickly becomes untenable.
      In this paper, we propose BatchEnsemble, an ensemble method whose computational and memory costs are significantly lower than typical ensembles. BatchEnsemble achieves this by defining each weight matrix to be the Hadamard product of a shared weight among all ensemble members and a rank-one matrix per member. Unlike ensembles, BatchEnsemble is not only parallelizable across devices, where one device trains one member, but also parallelizable within a device, where multiple ensemble members are updated simultaneously for a given mini-batch. Across CIFAR-10, CIFAR-100, WMT14 EN-DE/EN-FR translation, and out-of-distribution tasks, BatchEnsemble yields competitive accuracy and uncertainties as typical ensembles; the speedup at test time is 3X and memory reduction is 3X at an ensemble of size 4. We also apply BatchEnsemble to lifelong learning, where on Split-CIFAR-100, BatchEnsemble yields comparable performance to progressive neural networks while having a much lower computational and memory costs. We further show that BatchEnsemble can easily scale up to lifelong learning on Split-ImageNet which involves 100 sequential learning tasks</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/google/edward2</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Sklf1yrYDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByxGkySKwH" data-number="1460">
      <h4>
        <a href="/forum?id=ByxGkySKwH">
            Towards neural networks that provably know when they don't know
        </a>
      
        
          <a href="/pdf?id=ByxGkySKwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=alexander.meinke%40uni-tuebingen.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexander.meinke@uni-tuebingen.de">Alexander Meinke</a>, <a href="/profile?email=matthias.hein%40uni-tuebingen.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthias.hein@uni-tuebingen.de">Matthias Hein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#ByxGkySKwH-details-301" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByxGkySKwH-details-301"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">It has recently been shown that ReLU networks produce arbitrarily over-confident predictions far away from the 
      training data. Thus, ReLU networks do not know when they don't know. However, this is a highly important property in safety
      critical applications. In the context of out-of-distribution detection (OOD) there have been a number of proposals to mitigate this problem but none of them are able to make any mathematical guarantees. In this paper we propose a new approach to OOD which overcomes both problems. Our approach can be used with ReLU networks and provides provably low confidence predictions far away from the training data as well as the first certificates for low confidence predictions in a neighborhood of an out-distribution point. In the experiments we show that state-of-the-art methods fail in this worst-case setting whereas our model can guarantee its performance while retaining state-of-the-art OOD performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByxGkySKwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJx81ySKwr" data-number="1469">
      <h4>
        <a href="/forum?id=HJx81ySKwr">
            Iterative energy-based projection on a normal data manifold for anomaly localization
        </a>
      
        
          <a href="/pdf?id=HJx81ySKwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=david%40anotherbrain.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="david@anotherbrain.ai">David Dehaene</a>, <a href="/profile?email=oriel%40anotherbrain.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="oriel@anotherbrain.ai">Oriel Frigo</a>, <a href="/profile?email=sebastien%40anotherbrain.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastien@anotherbrain.ai">Sébastien Combrexelle</a>, <a href="/profile?email=pierre%40anotherbrain.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="pierre@anotherbrain.ai">Pierre Eline</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HJx81ySKwr-details-302" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJx81ySKwr-details-302"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, visual inspection, unsupervised anomaly detection, anomaly localization, autoencoder, variational autoencoder, gradient descent, inpainting</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We use gradient descent on a regularized autoencoder loss to correct anomalous images.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Autoencoder reconstructions are widely used for the task of unsupervised anomaly localization. Indeed, an autoencoder trained on normal data is expected to only be able to reconstruct normal features of the data, allowing the segmentation of anomalous pixels in an image via a simple comparison between the image and its autoencoder reconstruction. In practice however, local defects added to a normal image can deteriorate the whole reconstruction, making this segmentation challenging. To tackle the issue, we propose in this paper a new approach for projecting anomalous data on a autoencoder-learned normal data manifold, by using gradient descent on an energy derived from the autoencoder's loss function. This energy can be augmented with regularization terms that model priors on what constitutes the user-defined optimal projection. By iteratively updating the input of the autoencoder, we bypass the loss of high-frequency information caused by the autoencoder bottleneck. This allows to produce images of higher quality than classic reconstructions. Our method achieves state-of-the-art results on various anomaly localization datasets. It also shows promising results at an inpainting task on the CelebA dataset.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJx81ySKwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skxuk1rFwB" data-number="1473">
      <h4>
        <a href="/forum?id=Skxuk1rFwB">
            Towards Stable and Efficient Training of Verifiably Robust Neural Networks
        </a>
      
        
          <a href="/pdf?id=Skxuk1rFwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=huan%40huan-zhang.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="huan@huan-zhang.com">Huan Zhang</a>, <a href="/profile?email=chenhg%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenhg@mit.edu">Hongge Chen</a>, <a href="/profile?email=xiaocw%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaocw@umich.edu">Chaowei Xiao</a>, <a href="/profile?email=sgowal%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sgowal@google.com">Sven Gowal</a>, <a href="/profile?email=stanforth%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="stanforth@google.com">Robert Stanforth</a>, <a href="/profile?email=lbo%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lbo@illinois.edu">Bo Li</a>, <a href="/profile?email=boning%40mtl.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="boning@mtl.mit.edu">Duane Boning</a>, <a href="/profile?email=chohsieh%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chohsieh@cs.ucla.edu">Cho-Jui Hsieh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="#Skxuk1rFwB-details-807" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skxuk1rFwB-details-807"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a new certified adversarial training method, CROWN-IBP, that achieves state-of-the-art robustness for L_inf norm adversarial perturbations.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Training neural networks with verifiable robustness guarantees is challenging. Several existing approaches utilize linear relaxation based neural network output bounds under perturbation, but they can slow down training by a factor of hundreds depending on the underlying network architectures. Meanwhile, interval bound propagation (IBP) based training is efficient and significantly outperforms linear relaxation based methods on many tasks, yet it may suffer from stability issues since the bounds are much looser especially at the beginning of training. In this paper, we propose a new certified adversarial training method, CROWN-IBP, by combining the fast IBP bounds in a forward bounding pass and a tight linear relaxation based bound, CROWN, in a backward bounding pass. CROWN-IBP is computationally efficient and consistently outperforms IBP baselines on training verifiably robust neural networks. We conduct large scale experiments on MNIST and CIFAR datasets, and outperform all previous linear relaxation and bound propagation based certified defenses in L_inf robustness.
      Notably, we achieve 7.02% verified test error on MNIST at epsilon=0.3, and 66.94% on CIFAR-10 with epsilon=8/255.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Robust Neural Networks, Verifiable Training, Certified Adversarial Defense</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/huanzhang12/CROWN-IBP</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Skxuk1rFwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1gskyStwr" data-number="1480">
      <h4>
        <a href="/forum?id=B1gskyStwr">
            Frequency-based Search-control in Dyna
        </a>
      
        
          <a href="/pdf?id=B1gskyStwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=pan6%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="pan6@ualberta.ca">Yangchen Pan</a>, <a href="/profile?email=jmei2%40ualberta.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="jmei2@ualberta.ca">Jincheng Mei</a>, <a href="/profile?email=farahmand%40vectorinstitute.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="farahmand@vectorinstitute.ai">Amir-massoud Farahmand</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#B1gskyStwr-details-877" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1gskyStwr-details-877"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Acquire states from high frequency region for search-control in Dyna.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Model-based reinforcement learning has been empirically demonstrated as a successful strategy to improve sample efficiency. In particular, Dyna is an elegant model-based architecture integrating learning and planning that provides huge flexibility of using a model. One of the most important components in Dyna is called search-control, which refers to the process of generating state or state-action pairs from which we query the model to acquire simulated experiences. Search-control is critical in improving learning efficiency. In this work, we propose a simple and novel search-control strategy by searching high frequency regions of the value function. Our main intuition is built on Shannon sampling theorem from signal processing, which indicates that a high frequency signal requires more samples to reconstruct. We empirically show that a high frequency function is more difficult to approximate. This suggests a search-control strategy: we should use states from high frequency regions of the value function to query the model to acquire more samples. We develop a simple strategy to locally measure the frequency of a function by gradient and hessian norms, and provide theoretical justification for this approach. We then apply our strategy to search-control in Dyna, and conduct experiments to show its property and effectiveness on benchmark domains.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Model-based reinforcement learning, search-control, Dyna, frequency of a signal</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1gskyStwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bke61krFvS" data-number="1486">
      <h4>
        <a href="/forum?id=Bke61krFvS">
            Learning representations for binary-classification without backpropagation
        </a>
      
        
          <a href="/pdf?id=Bke61krFvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mathias.lechner%40ist.ac.at" class="profile-link" data-toggle="tooltip" data-placement="top" title="mathias.lechner@ist.ac.at">Mathias Lechner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#Bke61krFvS-details-210" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bke61krFvS-details-210"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">feedback alignment, alternatives to backpropagation, biologically motivated learning algorithms</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">First feedback alignment algorithm with provable learning guarantees for networks with single output neuron</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The family of feedback alignment (FA) algorithms aims to provide a more biologically motivated alternative to backpropagation (BP), by substituting the computations that are unrealistic to be implemented in physical brains.
      While FA algorithms have been shown to work well in practice, there is a lack of rigorous theory proofing their learning capabilities.		
      Here we introduce the first feedback alignment algorithm with provable learning guarantees. In contrast to existing work, we do not require any assumption about the size or depth of the network except that it has a single output neuron, i.e., such as for binary classification tasks.
      We show that our FA algorithm can deliver its theoretical promises in practice, surpassing the learning performance of existing FA methods and matching backpropagation in binary classification tasks.
      Finally, we demonstrate the limits of our FA variant when the number of output neurons grows beyond a certain quantity.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/mlech26l/iclr_paper_mdfa</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Bke61krFvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HygegyrYwH" data-number="1492">
      <h4>
        <a href="/forum?id=HygegyrYwH">
            Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks
        </a>
      
        
          <a href="/pdf?id=HygegyrYwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ziweiji2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ziweiji2@illinois.edu">Ziwei Ji</a>, <a href="/profile?email=mjt%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mjt@illinois.edu">Matus Telgarsky</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="#HygegyrYwH-details-53" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HygegyrYwH-details-53"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">neural tangent kernel, polylogarithmic width, test error, gradient descent, classification</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recent theoretical work has guaranteed that overparameterized networks trained by gradient descent achieve arbitrarily low training error, and sometimes even low test error.
      The required width, however, is always polynomial in at least one of the sample size <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="469" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container>, the (inverse) target error <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="470" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow><mo>/</mo></mrow><mi>ϵ</mi></math></mjx-assistive-mml></mjx-container>, and the (inverse) failure probability <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="471" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FF TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow><mo>/</mo></mrow><mi>δ</mi></math></mjx-assistive-mml></mjx-container>. 
      This work shows that <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="472" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.06em; padding-left: 0.111em; margin-bottom: -0.597em;"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c2DC TEX-S1"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-n"><mjx-c class="mjx-c398"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mi mathvariant="normal">Θ</mi><mo>~</mo></mover></mrow><mo stretchy="false">(</mo><mn>1</mn><mrow><mo>/</mo></mrow><mi>ϵ</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> iterations of gradient descent with <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="473" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.06em; padding-left: 0.083em; margin-bottom: -0.597em;"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c2DC TEX-S1"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-n"><mjx-c class="mjx-c3A9"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mi mathvariant="normal">Ω</mi><mo>~</mo></mover></mrow><mo stretchy="false">(</mo><mn>1</mn><mrow><mo>/</mo></mrow><msup><mi>ϵ</mi><mn>2</mn></msup><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> training examples on two-layer ReLU networks of any width exceeding <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="474" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c79"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mtext></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="2"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="2"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FF TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mtext>polylog</mtext></mrow><mo stretchy="false">(</mo><mi>n</mi><mo>,</mo><mn>1</mn><mrow><mo>/</mo></mrow><mi>ϵ</mi><mo>,</mo><mn>1</mn><mrow><mo>/</mo></mrow><mi>δ</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> suffice to achieve a test misclassification error of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="475" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ϵ</mi></math></mjx-assistive-mml></mjx-container>. 
      We also prove that stochastic gradient descent can achieve <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="476" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ϵ</mi></math></mjx-assistive-mml></mjx-container> test error with polylogarithmic width and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="477" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.06em; padding-left: 0.111em; margin-bottom: -0.597em;"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c2DC TEX-S1"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-n"><mjx-c class="mjx-c398"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mi mathvariant="normal">Θ</mi><mo>~</mo></mover></mrow><mo stretchy="false">(</mo><mn>1</mn><mrow><mo>/</mo></mrow><mi>ϵ</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> samples. 
      The analysis relies upon the separation margin of the limiting kernel, which is guaranteed positive, can distinguish between true labels and random labels, and can give a tight sample-complexity analysis in the infinite-width setting.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HygegyrYwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1gelyrtwH" data-number="1493">
      <h4>
        <a href="/forum?id=r1gelyrtwH">
            Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics
        </a>
      
        
          <a href="/pdf?id=r1gelyrtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sungyons%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sungyons@usc.edu">Sungyong Seo*</a>, <a href="/profile?email=chuizhem%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chuizhem@usc.edu">Chuizheng Meng*</a>, <a href="/profile?email=yanliu.cs%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanliu.cs@usc.edu">Yan Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#r1gelyrtwH-details-48" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1gelyrtwH-details-48"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">physics-aware learning, spatial difference operators, sparsely-observed dynamics</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose physics-aware difference graph networks designed to effectively learn spatial differences to modeling sparsely-observed dynamics.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Sparsely available data points cause numerical error on finite differences which hinders us from modeling the dynamics of physical systems. The discretization error becomes even larger when the sparse data are irregularly distributed or defined on an unstructured grid, making it hard to build deep learning models to handle physics-governing observations on the unstructured grid. In this paper, we propose a novel architecture, Physics-aware Difference Graph Networks (PA-DGN), which exploits neighboring information to learn finite differences inspired by physics equations. PA-DGN leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. We demonstrate the superiority of PA-DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real-world climate observations from weather stations.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/USC-Melady/ICLR2020-PADGN</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1gelyrtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1lZgyBYwS" data-number="1496">
      <h4>
        <a href="/forum?id=r1lZgyBYwS">
            HiLLoC: lossless image compression with hierarchical latent variable models
        </a>
      
        
          <a href="/pdf?id=r1lZgyBYwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=james.townsend%40cs.ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="james.townsend@cs.ucl.ac.uk">James Townsend</a>, <a href="/profile?email=thomas.bird%40cs.ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.bird@cs.ucl.ac.uk">Thomas Bird</a>, <a href="/profile?email=julius.kunze%40cs.ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="julius.kunze@cs.ucl.ac.uk">Julius Kunze</a>, <a href="/profile?email=david.barber%40ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.barber@ucl.ac.uk">David Barber</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#r1lZgyBYwS-details-387" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1lZgyBYwS-details-387"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">compression, variational inference, lossless compression, deep latent variable models</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We scale up lossless compression with latent variables, achieving state of the art on full-size ImageNet images.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We make the following striking observation: fully convolutional VAE models trained on 32x32 ImageNet can generalize well, not just to 64x64 but also to far larger photographs, with no changes to the model. We use this property, applying fully convolutional models to lossless compression, demonstrating a method to scale the VAE-based 'Bits-Back with ANS' algorithm for lossless compression to large color photographs, and achieving state of the art for compression of full size ImageNet images. We release Craystack, an open source library for convenient prototyping of lossless compression using probabilistic models, along with full implementations of all of our compression results.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/hilloc-submission/hilloc</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1lZgyBYwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJeGlJStPr" data-number="1498">
      <h4>
        <a href="/forum?id=BJeGlJStPr">
            IMPACT: Importance Weighted Asynchronous Architectures with Clipped Target Networks
        </a>
      
        
          <a href="/pdf?id=BJeGlJStPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=michael.luo%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael.luo@berkeley.edu">Michael Luo</a>, <a href="/profile?email=jiahaoyao%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiahaoyao@berkeley.edu">Jiahao Yao</a>, <a href="/profile?email=rliaw%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rliaw@berkeley.edu">Richard Liaw</a>, <a href="/profile?email=ekhliang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ekhliang@gmail.com">Eric Liang</a>, <a href="/profile?email=istoica%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="istoica@berkeley.edu">Ion Stoica</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#BJeGlJStPr-details-382" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJeGlJStPr-details-382"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">IMPACT helps RL agents train faster by decreasing training wall-clock time and increasing sample efficiency simultaneously.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The practical usage of reinforcement learning agents is often bottlenecked by the duration of training time. To accelerate training, practitioners often turn to distributed reinforcement learning architectures to parallelize and accelerate the training process. However, modern methods for scalable reinforcement learning (RL) often tradeoff between the throughput of samples that an RL agent can learn from (sample throughput) and the quality of learning from each sample (sample efficiency). In these scalable RL architectures, as one increases sample throughput (i.e. increasing parallelization in IMPALA (Espeholt et al., 2018)), sample efficiency drops significantly. To address this, we propose a new distributed reinforcement learning algorithm, IMPACT. IMPACT extends PPO with three changes: a target network for stabilizing the surrogate objective, a circular buffer, and truncated importance sampling. In discrete action-space environments, we show that IMPACT attains higher reward and, simultaneously, achieves up to 30% decrease in training wall-time than that of IMPALA. For continuous control environments, IMPACT trains faster than existing scalable agents while preserving the sample efficiency of synchronous PPO.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement Learning, Artificial Intelligence, Distributed Computing, Neural Networks</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJeGlJStPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJewlyStDr" data-number="1510">
      <h4>
        <a href="/forum?id=BJewlyStDr">
            On Bonus Based Exploration Methods In The Arcade Learning Environment
        </a>
      
        
          <a href="/pdf?id=BJewlyStDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=adrien.alitaiga%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adrien.alitaiga@gmail.com">Adrien Ali Taiga</a>, <a href="/profile?email=liamfedus%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liamfedus@google.com">William Fedus</a>, <a href="/profile?email=marlosm%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="marlosm@google.com">Marlos C. Machado</a>, <a href="/profile?email=aaron.courville%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aaron.courville@gmail.com">Aaron Courville</a>, <a href="/profile?email=bellemare%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bellemare@google.com">Marc G. Bellemare</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="#BJewlyStDr-details-618" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJewlyStDr-details-618"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We find that existing bonus-based exploration methods have not been able to address the exploration-exploitation trade-off in the Arcade Learning Environment. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Research on exploration in reinforcement learning, as applied to Atari 2600 game-playing, has emphasized tackling difficult exploration problems such as Montezuma's Revenge (Bellemare et al., 2016). Recently, bonus-based exploration methods, which explore by augmenting the environment reward, have reached above-human average performance on such domains. In this paper we reassess popular bonus-based exploration methods within a common evaluation framework. We combine Rainbow (Hessel et al., 2018) with different exploration bonuses and evaluate its performance on Montezuma's Revenge, Bellemare et al.'s set of hard of exploration games with sparse rewards, and the whole Atari 2600 suite. We find that while exploration bonuses lead to higher score on Montezuma's Revenge they do not provide meaningful gains over the simpler epsilon-greedy scheme. In fact, we find that methods that perform best on that game often underperform epsilon-greedy on easy exploration Atari 2600 games. We find that our conclusions remain valid even when hyperparameters are tuned for these easy-exploration games. Finally, we find that none of the methods surveyed benefit from additional training samples (1 billion frames, versus Rainbow's 200 million) on Bellemare et al.'s hard exploration games. Our results suggest that recent gains in Montezuma's Revenge may be better attributed to architecture change, rather than better exploration schemes; and that the real pace of progress in exploration research for Atari 2600 games may have been obfuscated by good results on a single domain.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">exploration, arcade learning environment, bonus-based methods</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJewlyStDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1lOgyrKDS" data-number="1511">
      <h4>
        <a href="/forum?id=r1lOgyrKDS">
            Adaptive Correlated Monte Carlo for Contextual Categorical Sequence Generation
        </a>
      
        
          <a href="/pdf?id=r1lOgyrKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xfan%40utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xfan@utexas.edu">Xinjie Fan</a>, <a href="/profile?email=yizhe.zhang%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yizhe.zhang@microsoft.com">Yizhe Zhang</a>, <a href="/profile?email=zw2533%40columbia.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zw2533@columbia.edu">Zhendong Wang</a>, <a href="/profile?email=mingyuan.zhou%40mccombs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mingyuan.zhou@mccombs.utexas.edu">Mingyuan Zhou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#r1lOgyrKDS-details-498" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1lOgyrKDS-details-498"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Sequence generation models are commonly refined with reinforcement learning over user-defined metrics. However, high gradient variance hinders the practical use of this method. To stabilize this method, we adapt to contextual generation of categorical sequences a policy gradient estimator, which evaluates a set of correlated Monte Carlo (MC) rollouts for variance control. Due to the correlation, the number of unique rollouts is random and adaptive to model uncertainty; those rollouts naturally become baselines for each other, and hence are combined to effectively reduce gradient variance. We also demonstrate the use of correlated MC rollouts for binary-tree softmax models, which reduce the high generation cost in large vocabulary scenarios by decomposing each categorical action into a sequence of binary actions. We evaluate our methods on both neural program synthesis and image captioning. The proposed methods yield lower gradient variance and consistent improvement over related baselines. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/xinjiefan/ACMC_ICLR</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">binary softmax, discrete variables, policy gradient, pseudo actions, reinforcement learning, variance reduction</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1lOgyrKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJeOekHKwr" data-number="1512">
      <h4>
        <a href="/forum?id=HJeOekHKwr">
            Smoothness and Stability in GANs
        </a>
      
        
          <a href="/pdf?id=HJeOekHKwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=caseychu%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="caseychu@stanford.edu">Casey Chu</a>, <a href="/profile?email=minami%40preferred.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="minami@preferred.jp">Kentaro Minami</a>, <a href="/profile?email=fukumizu%40ism.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="fukumizu@ism.ac.jp">Kenji Fukumizu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HJeOekHKwr-details-791" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJeOekHKwr-details-791"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We develop a principled theoretical framework for understanding and enforcing the stability of various types of GANs</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Generative adversarial networks, or GANs, commonly display unstable behavior during training. In this work, we develop a principled theoretical framework for understanding the stability of various types of GANs. In particular, we derive conditions that guarantee eventual stationarity of the generator when it is trained with gradient descent, conditions that must be satisfied by the divergence that is minimized by the GAN and the generator's architecture. We find that existing GAN variants satisfy some, but not all, of these conditions. Using tools from convex analysis, optimal transport, and reproducing kernels, we construct a GAN that fulfills these conditions simultaneously. In the process, we explain and clarify the need for various existing GAN stabilization techniques, including Lipschitz constraints, gradient penalties, and smooth activation functions.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">generative adversarial networks, stability, smoothness, convex conjugate</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJeOekHKwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJxtgJBKDr" data-number="1513">
      <h4>
        <a href="/forum?id=rJxtgJBKDr">
            SNOW: Subscribing to Knowledge via Channel Pooling for Transfer &amp; Lifelong Learning of Convolutional Neural Networks
        </a>
      
        
          <a href="/pdf?id=rJxtgJBKDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ckyoo%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ckyoo@ibm.com">Chungkuk Yoo</a>, <a href="/profile?email=steve.kang%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="steve.kang@kaist.ac.kr">Bumsoo Kang</a>, <a href="/profile?email=thyeros%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thyeros@gmail.com">Minsik Cho</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rJxtgJBKDr-details-490" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJxtgJBKDr-details-490"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose SNOW, an efficient way of transfer and lifelong learning by subscribing knowledge of a source model for new tasks through a novel channel pooling block.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">SNOW is an efficient learning method to improve training/serving throughput as well as accuracy for transfer and lifelong learning of convolutional neural networks based on knowledge subscription. SNOW selects the top-K useful intermediate
      feature maps for a target task from a pre-trained and frozen source model through a novel channel pooling scheme, and utilizes them in the task-specific delta model. The source model is responsible for generating a large number of generic feature maps. Meanwhile, the delta model selectively subscribes to those feature maps and fuses them with its local ones to deliver high accuracy for the target task. Since a source model takes part in both training and serving of all target tasks
      in an inference-only mode, one source model can serve multiple delta models, enabling significant computation sharing. The sizes of such delta models are fractional of the source model, thus SNOW also provides model-size efficiency.
      Our experimental results show that SNOW offers a superior balance between accuracy and training/inference speed for various image classification tasks to the existing transfer and lifelong learning practices.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">channel pooling, efficient training and inferencing, lifelong learning, transfer learning, multi task</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJxtgJBKDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkeFl1HKwr" data-number="1514">
      <h4>
        <a href="/forum?id=SkeFl1HKwr">
            Empirical Studies on the Properties of Linear Regions in Deep Neural Networks
        </a>
      
        
          <a href="/pdf?id=SkeFl1HKwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xiao_zhang%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiao_zhang@hust.edu.cn">Xiao Zhang</a>, <a href="/profile?email=drwu%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="drwu@hust.edu.cn">Dongrui Wu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 28 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="#SkeFl1HKwr-details-279" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkeFl1HKwr-details-279"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, linear region, optimization</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">A deep neural networks (DNN) with piecewise linear activations can partition the input space into numerous small linear regions, where different linear functions are fitted. It is believed that the number of these regions represents the expressivity of a DNN. This paper provides a novel and meticulous perspective to look into DNNs: Instead of just counting the number of the linear regions, we study their local properties, such as the inspheres, the directions of the corresponding hyperplanes, the decision boundaries, and the relevance of the surrounding regions. We empirically observed that different optimization techniques lead to completely different linear regions, even though they result in similar classification accuracies. We hope our study can inspire the design of novel optimization techniques, and help discover and analyze the behaviors of DNNs.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkeFl1HKwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1ltg1rFDS" data-number="1515">
      <h4>
        <a href="/forum?id=S1ltg1rFDS">
            Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=S1ltg1rFDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ali.mousavi1988%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ali.mousavi1988@gmail.com">Ali Mousavi</a>, <a href="/profile?email=lihongli.cs%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lihongli.cs@gmail.com">Lihong Li</a>, <a href="/profile?email=dennyzhou%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dennyzhou@google.com">Qiang Liu</a>, <a href="/profile?email=lqiang%40cs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lqiang@cs.utexas.edu">Denny Zhou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#S1ltg1rFDS-details-778" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1ltg1rFDS-details-778"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present a novel approach for the off-policy estimation problem in infinite-horizon RL.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Off-policy estimation for long-horizon problems is important in many real-life applications such as healthcare and robotics, where high-fidelity simulators may not be available and on-policy evaluation is expensive or impossible.  Recently, \citet{liu18breaking} proposed an approach that avoids the curse of horizon suffered by typical importance-sampling-based methods. While showing promising results, this approach is limited in practice as it requires data being collected by a known behavior policy. In this work, we propose a novel approach that eliminates such limitations. In particular, we formulate the problem as solving for the fixed point of a "backward flow" operator and show that the fixed point solution gives the desired importance ratios of stationary distributions between the target and behavior policies.  We analyze its asymptotic consistency and finite-sample
      generalization. Experiments on benchmarks verify the effectiveness of our proposed approach.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, off-policy estimation, importance sampling, propensity score</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1ltg1rFDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkecl1rtwB" data-number="1517">
      <h4>
        <a href="/forum?id=rkecl1rtwB">
            PairNorm: Tackling Oversmoothing in GNNs
        </a>
      
        
          <a href="/pdf?id=rkecl1rtwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=lingxiao%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lingxiao@cmu.edu">Lingxiao Zhao</a>, <a href="/profile?email=lakoglu%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lakoglu@andrew.cmu.edu">Leman Akoglu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="#rkecl1rtwB-details-203" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkecl1rtwB-details-203"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We proposed a normalization layer for GNN models to solve the oversmoothing problem.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The performance of graph neural nets (GNNs) is known to gradually decrease with increasing number of layers. This decay is partly attributed to oversmoothing, where repeated graph convolutions eventually make node embeddings indistinguishable. We take a closer look at two different interpretations, aiming to quantify oversmoothing. Our main contribution is PairNorm, a novel normalization layer that is based on a careful analysis of the graph convolution operator, which prevents all node embeddings from becoming too similar. What is more, PairNorm is fast, easy to implement without any change to network architecture nor any additional parameters, and is broadly applicable to any GNN. Experiments on real-world graphs demonstrate that PairNorm makes deeper GCN, GAT, and SGC models more robust against oversmoothing, and significantly boosts performance for a new problem setting that benefits from deeper GNNs. Code is available at https://github.com/LingxiaoShawn/PairNorm.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/LingxiaoShawn/PairNorm</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Graph Neural Network, oversmoothing, normalization</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkecl1rtwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJlnxkSYPS" data-number="1520">
      <h4>
        <a href="/forum?id=rJlnxkSYPS">
            Unsupervised Clustering using Pseudo-semi-supervised Learning
        </a>
      
        
          <a href="/pdf?id=rJlnxkSYPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=divam%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="divam@cmu.edu">Divam Gupta</a>, <a href="/profile?email=ramjee%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ramjee@microsoft.com">Ramachandran Ramjee</a>, <a href="/profile?email=nipun.kwatra%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nipun.kwatra@microsoft.com">Nipun Kwatra</a>, <a href="/profile?email=muthian%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="muthian@microsoft.com">Muthian Sivathanu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#rJlnxkSYPS-details-237" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJlnxkSYPS-details-237"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Unsupervised Learning, Unsupervised Clustering, Deep Learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Using ensembles and pseudo labels for unsupervised clustering </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In this paper, we propose a framework that leverages semi-supervised models to improve unsupervised clustering performance. To leverage semi-supervised models, we first need to automatically generate labels, called pseudo-labels. We find that prior approaches for generating pseudo-labels hurt clustering performance because of their low accuracy. Instead, we use an ensemble of deep networks  to construct a similarity graph, from which we extract high accuracy pseudo-labels. The approach of finding high quality pseudo-labels using ensembles and training the semi-supervised model is iterated, yielding continued improvement. We show that our approach outperforms state of the art clustering results for multiple image and text datasets. For example, we achieve 54.6% accuracy for CIFAR-10 and 43.9% for 20news, outperforming state of the art by 8-12% in absolute terms.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/open?id=1rvlTYnSDD9UVAy2FkKilM4fGSE75v7Id</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJlnxkSYPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hke3gyHYwH" data-number="1521">
      <h4>
        <a href="/forum?id=Hke3gyHYwH">
            Simple and Effective Regularization Methods for Training on Noisily Labeled Data with Generalization Guarantee
        </a>
      
        
          <a href="/pdf?id=Hke3gyHYwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=huwei%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="huwei@cs.princeton.edu">Wei Hu</a>, <a href="/profile?email=zhiyuanli%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhiyuanli@cs.princeton.edu">Zhiyuan Li</a>, <a href="/profile?email=dingliy%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dingliy@cs.princeton.edu">Dingli Yu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#Hke3gyHYwH-details-304" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hke3gyHYwH-details-304"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Over-parameterized deep neural networks trained by simple first-order methods are known to be able to fit any labeling of data. Such over-fitting ability hinders generalization when mislabeled training examples are present. On the other hand, simple regularization methods like early-stopping can often achieve highly nontrivial performance on clean test data in these scenarios, a phenomenon not theoretically understood. This paper proposes and analyzes two simple and intuitive regularization methods: (i) regularization by the distance between the network parameters to initialization, and (ii) adding a trainable auxiliary variable to the network output for each training example. Theoretically, we prove that gradient descent training with either of these two methods leads to a generalization guarantee on the clean data distribution despite being trained using noisy labels. Our generalization analysis relies on the connection between wide neural network and neural tangent kernel (NTK). The generalization bound is independent of the network size, and is comparable to the bound one can get when there is no label noise. Experimental results verify the effectiveness of these methods on noisily labeled datasets.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning theory, regularization, noisy labels</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/drive/folders/1TDlUuL0I-EzIybjz2pMAgyaYP5F6dq6o</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hke3gyHYwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1laeJrKDB" data-number="1524">
      <h4>
        <a href="/forum?id=H1laeJrKDB">
            Controlling generative models with continuous factors of variations
        </a>
      
        
          <a href="/pdf?id=H1laeJrKDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=antoine.plumerault%40cea.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="antoine.plumerault@cea.fr">Antoine Plumerault</a>, <a href="/profile?email=herve.le-borgne%40cea.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="herve.le-borgne@cea.fr">Hervé Le Borgne</a>, <a href="/profile?email=celine.hudelot%40centralesupelec.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="celine.hudelot@centralesupelec.fr">Céline Hudelot</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#H1laeJrKDB-details-522" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1laeJrKDB-details-522"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A model to control the generation of images with GAN and beta-VAE with regard to scale and position of the objects</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recent deep generative models can provide photo-realistic images as well as visual or textual content embeddings useful to address various tasks of computer vision and natural language processing. Their usefulness is nevertheless often limited by the lack of control over the generative process or the poor understanding of the learned representation. To overcome these major issues, very recent works have shown the interest of studying the semantics of the latent space of generative models. In this paper, we propose to advance on the interpretability of the latent space of generative models by introducing a new method to find meaningful directions in the latent space of any generative model along which we can move to control precisely specific properties of the generated image like position or scale of the object in the image. Our method is weakly supervised and particularly well suited for the search of directions encoding simple transformations of the generated image, such as translation, zoom or color variations. We demonstrate the effectiveness of our method qualitatively and quantitatively, both for GANs and variational auto-encoders.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Generative models, factor of variation, GAN, beta-VAE, interpretable representation, interpretability</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1laeJrKDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxmb1rKDS" data-number="1538">
      <h4>
        <a href="/forum?id=ryxmb1rKDS">
            Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control
        </a>
      
        
          <a href="/pdf?id=ryxmb1rKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=y.zhong%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="y.zhong@princeton.edu">Yaofeng Desmond Zhong</a>, <a href="/profile?email=biswadip.dey%40siemens.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="biswadip.dey@siemens.com">Biswadip Dey</a>, <a href="/profile?email=amit.chakraborty%40siemens.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="amit.chakraborty@siemens.com">Amit Chakraborty</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#ryxmb1rKDS-details-536" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxmb1rKDS-details-536"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep Model Learning, Physics-based Priors, Control of Mechanical Systems</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This work enforces Hamiltonian dynamics with control to learn system models from embedded position and velocity data, and exploits this physically-consistent dynamics to synthesize model-based control via energy shaping.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In this paper, we introduce Symplectic ODE-Net (SymODEN), a deep learning framework which can infer the dynamics of a physical system, given by an ordinary differential equation (ODE), from observed state trajectories. To achieve better generalization with fewer training samples, SymODEN incorporates appropriate inductive bias by designing the associated computation graph in a physics-informed manner. In particular, we enforce Hamiltonian dynamics with control to learn the underlying dynamics in a transparent way, which can then be leveraged to draw insight about relevant physical aspects of the system, such as mass and potential energy. In addition, we propose a parametrization which can enforce this Hamiltonian formalism even when the generalized coordinate data is embedded in a high-dimensional space or we can only access velocity data instead of generalized momentum. This framework, by offering interpretable, physically-consistent models for physical systems, opens up new possibilities for synthesizing model-based control strategies.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/d-biswa/Symplectic-ODENet</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxmb1rKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJeY-1BKDS" data-number="1552">
      <h4>
        <a href="/forum?id=SJeY-1BKDS">
            Understanding l4-based Dictionary Learning: Interpretation, Stability, and Robustness
        </a>
      
        
          <a href="/pdf?id=SJeY-1BKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ysz%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ysz@berkeley.edu">Yuexiang Zhai</a>, <a href="/profile?email=hermish%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hermish@berkeley.edu">Hermish Mehta</a>, <a href="/profile?email=zyzhou%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zyzhou@stanford.edu">Zhengyuan Zhou</a>, <a href="/profile?email=yima%40eecs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yima@eecs.berkeley.edu">Yi Ma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="#SJeY-1BKDS-details-822" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJeY-1BKDS-details-822"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">L4-norm Maximization, Robust Dictionary Learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We compare the l4-norm based dictionary learning with PCA, ICA and show its stability as well as robustness.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recently, the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="478" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>ℓ</mi><mn>4</mn></msup></math></mjx-assistive-mml></mjx-container>-norm maximization has been proposed to solve the sparse dictionary learning (SDL) problem. The simple MSP (matching, stretching, and projection) algorithm proposed by \cite{zhai2019a} has proved surprisingly efficient and effective.  This paper aims to better understand this algorithm from its strong geometric and statistical connections with the classic PCA and ICA, as well as their associated fixed-point style algorithms. Such connections provide a unified way of viewing problems that pursue {\em principal}, {\em independent}, or {\em sparse} components of high-dimensional data. Our studies reveal additional good properties of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="479" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c34"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>ℓ</mi><mn>4</mn></msup></math></mjx-assistive-mml></mjx-container>-maximization: not only is the MSP algorithm for sparse coding insensitive to small noise, but it is also robust to outliers and resilient to sparse corruptions. We provide statistical justification for such inherently nice properties. To corroborate the theoretical analysis, we also provide extensive and compelling experimental evidence with both synthetic data and real images.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/hermish/ZMZM-ICLR-2020</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJeY-1BKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hygab1rKDS" data-number="1560">
      <h4>
        <a href="/forum?id=Hygab1rKDS">
            Quantum Algorithms for Deep Convolutional Neural Networks
        </a>
      
        
          <a href="/pdf?id=Hygab1rKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jkeren%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jkeren@gmail.com">Iordanis Kerenidis</a>, <a href="/profile?email=landman%40irif.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="landman@irif.fr">Jonas Landman</a>, <a href="/profile?email=anupamprakash1%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anupamprakash1@gmail.com">Anupam Prakash</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#Hygab1rKDS-details-776" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hygab1rKDS-details-776"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">quantum computing, quantum machine learning, convolutional neural network, theory, algorithm</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We provide the first algorithm for quantum computers implementing universal convolutional neural network with a speedup</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Quantum computing is a powerful computational paradigm with applications in several fields, including machine learning. In the last decade, deep learning, and in particular Convolutional Neural Networks (CNN), have become essential for applications in signal processing and image recognition. Quantum deep learning, however, remains a challenging problem, as it is difficult to implement non linearities with quantum unitaries. In this paper we propose a quantum algorithm for evaluating and training deep convolutional neural networks with potential speedups over classical CNNs for both the forward and backward passes. The quantum CNN (QCNN) reproduces completely the outputs of the classical CNN and allows for non linearities and pooling operations. The QCNN is in particular interesting for deep networks and could allow new frontiers in the image recognition domain, by allowing for many more convolution kernels, larger kernels, high dimensional inputs and high depth input channels. We also present numerical simulations for the classification of the MNIST dataset to provide practical evidence for the efficiency of the QCNN.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/JonasLandman/QCNN</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hygab1rKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1lJzyStvS" data-number="1564">
      <h4>
        <a href="/forum?id=B1lJzyStvS">
            Self-Supervised Learning of Appliance Usage
        </a>
      
        
          <a href="/pdf?id=B1lJzyStvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=cyhsu%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cyhsu@mit.edu">Chen-Yu Hsu</a>, <a href="/profile?email=zeitoun%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zeitoun@mit.edu">Abbas Zeitoun</a>, <a href="/profile?email=guanghe%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guanghe@csail.mit.edu">Guang-He Lee</a>, <a href="/profile?email=dina%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dina@csail.mit.edu">Dina Katabi</a>, <a href="/profile?email=tommi%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tommi@csail.mit.edu">Tommi Jaakkola</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#B1lJzyStvS-details-895" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1lJzyStvS-details-895"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Appliance usage, self-supervised learning, multi-modal learning, unsupervised learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We learn appliance usage patterns in homes without labels, using self-supervised learning with energy and location data</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Learning home appliance usage is important for understanding people's activities and optimizing energy consumption.  The problem is modeled as an event detection task, where the objective is to learn when a user turns an appliance on, and which appliance it is (microwave, hair dryer, etc.). Ideally, we would like to solve the problem in an unsupervised way so that the method can be applied to new homes and new appliances without any labels. To this end, we introduce a new deep learning model that takes input from two home sensors: 1) a smart electricity meter that outputs the total energy consumed by the home as a function of time, and 2) a motion sensor that outputs the locations of the residents over time.  The model learns the distribution of the residents' locations conditioned on the home energy signal. We show that this cross-modal prediction task allows us to detect when a particular appliance is used, and the location of the appliance in the home, all in a self-supervised manner, without any labeled data. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1lJzyStvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyeJf1HKvS" data-number="1565">
      <h4>
        <a href="/forum?id=HyeJf1HKvS">
            Deep Graph Matching Consensus
        </a>
      
        
          <a href="/pdf?id=HyeJf1HKvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=matthias.fey%40tu-dortmund.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthias.fey@tu-dortmund.de">Matthias Fey</a>, <a href="/profile?email=janeric.lenssen%40udo.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="janeric.lenssen@udo.edu">Jan E. Lenssen</a>, <a href="/profile?email=christopher.morris%40tu-dortmund.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="christopher.morris@tu-dortmund.de">Christopher Morris</a>, <a href="/profile?email=jonathan%40nnaisense.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonathan@nnaisense.com">Jonathan Masci</a>, <a href="/profile?email=nils.kriege%40tu-dortmund.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="nils.kriege@tu-dortmund.de">Nils M. Kriege</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HyeJf1HKvS-details-157" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyeJf1HKvS-details-157"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">graph matching, graph neural networks, neighborhood consensus, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We develop a deep graph matching architecture which refines initial correspondences in order to reach neighborhood consensus.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This work presents a two-stage neural architecture for learning and refining structural correspondences between graphs. First, we use localized node embeddings computed by a graph neural network to obtain an initial ranking of soft correspondences between nodes. Secondly, we employ synchronous message passing networks to iteratively re-rank the soft correspondences to reach a matching consensus in local neighborhoods between graphs. We show, theoretically and empirically, that our message passing scheme computes a well-founded measure of consensus for corresponding neighborhoods, which is then used to guide the iterative re-ranking process. Our purely local and sparsity-aware architecture scales well to large, real-world inputs while still being able to recover global correspondences consistently. We demonstrate the practical effectiveness of our method on real-world tasks from the fields of computer vision and entity alignment between knowledge graphs, on which we improve upon the current state-of-the-art.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/rusty1s/deep-graph-matching-consensus</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HyeJf1HKvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkllGyBFPH" data-number="1567">
      <h4>
        <a href="/forum?id=rkllGyBFPH">
            Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks
        </a>
      
        
          <a href="/pdf?id=rkllGyBFPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yubai.pku%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yubai.pku@gmail.com">Yu Bai</a>, <a href="/profile?email=jasondlee88%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jasondlee88@gmail.com">Jason D. Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rkllGyBFPH-details-292" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkllGyBFPH-details-292"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Wide neural networks can escape the NTK regime and couple with quadratic models, with provably nice optimization landscape and better generalization.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recent theoretical work has established connections between over-parametrized neural networks and linearized models governed by the Neural Tangent Kernels (NTKs). NTK theory leads to concrete convergence and generalization results, yet the empirical performance of neural networks are observed to exceed their linearized models, suggesting insufficiency of this theory.
      Towards closing this gap, we investigate the training of over-parametrized neural networks that are beyond the NTK regime yet still governed by the Taylor expansion of the network. We bring forward the idea of randomizing the neural networks, which allows them to escape their NTK and couple with quadratic models. We show that the optimization landscape of randomized two-layer networks are nice and amenable to escaping-saddle algorithms. We prove concrete generalization and expressivity results on these randomized networks, which lead to sample complexity bounds (of learning certain simple functions) that match the NTK and can in addition be better by a dimension factor when mild distributional assumptions are present. We demonstrate that our randomization technique can be generalized systematically beyond the quadratic case, by using it to find networks that are coupled with higher-order terms in their Taylor series.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Neural Tangent Kernels, over-parametrized neural networks, deep learning theory</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkllGyBFPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJlbGJrtDB" data-number="1570">
      <h4>
        <a href="/forum?id=SJlbGJrtDB">
            Dynamic Sparse Training: Find Efficient Sparse Network From Scratch With Trainable Masked Layers
        </a>
      
        
          <a href="/pdf?id=SJlbGJrtDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jjliu%40eee.hku.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jjliu@eee.hku.hk">Junjie LIU</a>, <a href="/profile?email=zhexu22-c%40my.cityu.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhexu22-c@my.cityu.edu.hk">Zhe XU</a>, <a href="/profile?email=rbshi%40eee.hku.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="rbshi@eee.hku.hk">Runbin SHI</a>, <a href="/profile?email=r.cheung%40cityu.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="r.cheung@cityu.edu.hk">Ray C. C. Cheung</a>, <a href="/profile?email=hso%40eee.hku.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="hso@eee.hku.hk">Hayden K.H. So</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="#SJlbGJrtDB-details-904" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJlbGJrtDB-details-904"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">neural network pruning, sparse learning, network compression, architecture search</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present a novel network pruning method that can find the optimal sparse structure during the training process with trainable pruning threshold</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present a novel network pruning algorithm called Dynamic Sparse Training that can jointly ﬁnd the optimal network parameters and sparse network structure in a uniﬁed optimization process with trainable pruning thresholds. These thresholds can have ﬁne-grained layer-wise adjustments dynamically via backpropagation. We demonstrate that our dynamic sparse training algorithm can easily train very sparse neural network models with little performance loss using the same training epochs as dense models. Dynamic Sparse Training achieves prior art performance compared with other sparse training algorithms on various network architectures. Additionally, we have several surprising observations that provide strong evidence to the effectiveness and efﬁciency of our algorithm. These observations reveal the underlying problems of traditional three-stage pruning algorithms and present the potential guidance provided by our algorithm to the design of more compact network architectures.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/junjieliu2910/DynamicSaprseTraining</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJlbGJrtDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJgzzJHtDB" data-number="1571">
      <h4>
        <a href="/forum?id=rJgzzJHtDB">
            Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference
        </a>
      
        
          <a href="/pdf?id=rJgzzJHtDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tkhu%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tkhu@tamu.edu">Ting-Kuei Hu</a>, <a href="/profile?email=wiwjp619%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wiwjp619@tamu.edu">Tianlong Chen</a>, <a href="/profile?email=htwang%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="htwang@tamu.edu">Haotao Wang</a>, <a href="/profile?email=atlaswang%40tamu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="atlaswang@tamu.edu">Zhangyang Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rJgzzJHtDB-details-260" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJgzzJHtDB-details-260"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial robustness, efficient inference</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Is it possible to co-design model accuracy, robustness and efficiency to achieve their triple wins? Yes!</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep networks were recently suggested to face the odds between accuracy (on clean natural images) and robustness (on adversarially perturbed images) (Tsipras et al., 2019). Such a dilemma is shown to be rooted in the inherently higher sample complexity (Schmidt et al., 2018) and/or model capacity (Nakkiran, 2019), for learning a high-accuracy and robust classifier. In view of that, give a classification task, growing the model capacity appears to help draw a win-win between accuracy and robustness, yet at the expense of model size and latency, therefore posing challenges for resource-constrained applications. Is it possible to co-design model accuracy, robustness and efficiency to achieve their triple wins? This paper studies multi-exit networks associated with input-adaptive efficient inference, showing their strong promise in achieving a “sweet point" in co-optimizing model accuracy, robustness, and efficiency. Our proposed solution, dubbed Robust Dynamic Inference Networks (RDI-Nets), allows for each input (either clean or adversarial) to adaptively choose one of the multiple output layers (early branches or the final one) to output its prediction. That multi-loss adaptivity adds new variations and flexibility to adversarial attacks and defenses, on which we present a systematical investigation. We show experimentally that by equipping existing backbones with such robust adaptive inference, the resulting RDI-Nets can achieve better accuracy and robustness, yet with over 30% computational savings, compared to the defended original models.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/TAMU-VITA/triple-wins</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJgzzJHtDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJgQfkSYDS" data-number="1573">
      <h4>
        <a href="/forum?id=BJgQfkSYDS">
            Neural Policy Gradient Methods: Global Optimality and Rates of Convergence
        </a>
      
        
          <a href="/pdf?id=BJgQfkSYDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=lingxiaowang2022%40u.northwestern.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lingxiaowang2022@u.northwestern.edu">Lingxiao Wang</a>, <a href="/profile?email=qicai2022%40u.northwestern.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qicai2022@u.northwestern.edu">Qi Cai</a>, <a href="/profile?email=zy6%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zy6@princeton.edu">Zhuoran Yang</a>, <a href="/profile?email=zhaoranwang%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaoranwang@gmail.com">Zhaoran Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#BJgQfkSYDS-details-414" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJgQfkSYDS-details-414"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Policy gradient methods with actor-critic schemes demonstrate tremendous empirical successes, especially when the actors and critics are parameterized by neural networks. However, it remains less clear whether such "neural" policy gradient methods converge to globally optimal policies and whether they even converge at all. We answer both the questions affirmatively in the overparameterized regime. In detail, we prove that neural natural policy gradient converges to a globally optimal policy at a sublinear rate. Also, we show that neural vanilla policy gradient converges sublinearly to a stationary point. Meanwhile, by relating the suboptimality of the stationary points to the~representation power of neural actor and critic classes, we prove the global optimality of all stationary points under mild regularity conditions. Particularly, we show that a key to the global optimality and convergence is the "compatibility" between the actor and critic, which is ensured by sharing neural architectures and random initializations across the actor and critic. To the best of our knowledge, our analysis establishes the first global optimality and convergence  guarantees for neural policy gradient methods. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJgQfkSYDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByedzkrKvH" data-number="1585">
      <h4>
        <a href="/forum?id=ByedzkrKvH">
            Double Neural Counterfactual Regret Minimization
        </a>
      
        
          <a href="/pdf?id=ByedzkrKvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ken.lh%40antfin.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ken.lh@antfin.com">Hui Li</a>, <a href="/profile?email=hkl163251%40antfin.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hkl163251@antfin.com">Kailiang Hu</a>, <a href="/profile?email=yaohua.zsh%40antfin.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaohua.zsh@antfin.com">Shaohua Zhang</a>, <a href="/profile?email=yuan.qi%40antfin.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuan.qi@antfin.com">Yuan Qi</a>, <a href="/profile?email=lsong%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lsong@cc.gatech.edu">Le Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="#ByedzkrKvH-details-308" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByedzkrKvH-details-308"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We proposed a double neural framework to solve large-scale imperfect information game. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Counterfactual regret minimization (CFR) is a fundamental and effective technique for solving Imperfect Information Games (IIG). However, the original CFR algorithm only works for discrete states and action spaces, and the resulting strategy is maintained as a tabular representation. Such tabular representation limits the method from being directly applied to large games. In this paper, we propose a double neural representation for the IIGs, where one neural network represents the cumulative regret, and the other represents the average strategy.  Such neural representations allow us to avoid manual game abstraction and carry out end-to-end optimization. To make the learning efficient, we also developed several novel techniques including a robust sampling method and a mini-batch Monte Carlo Counterfactual Regret Minimization (MCCFR) method, which may be of independent interests.  Empirically, on games tractable to tabular approaches, neural strategies trained with our algorithm converge comparably to their tabular counterparts, and significantly outperform those based on deep reinforcement learning.  On extremely large games with billions of decision nodes, our approach achieved strong performance while using hundreds of times less memory than the tabular CFR. On head-to-head matches of hands-up no-limit texas hold'em, our neural agent beat the strong agent ABS-CFR by <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="480" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c34"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>9.8</mn><mo>±</mo><mn>4.1</mn></math></mjx-assistive-mml></mjx-container> chips per game. It's a successful application of neural CFR in large games.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Counterfactual Regret Minimization, Imperfect Information game, Neural Strategy, Deep Learning, Robust Sampling</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByedzkrKvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1esMkHYPr" data-number="1591">
      <h4>
        <a href="/forum?id=S1esMkHYPr">
            GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation
        </a>
      
        
          <a href="/pdf?id=S1esMkHYPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=chenceshi%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenceshi@pku.edu.cn">Chence Shi*</a>, <a href="/profile?email=mkxu%40apex.sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="mkxu@apex.sjtu.edu.cn">Minkai Xu*</a>, <a href="/profile?email=zhaocheng.zhu%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhaocheng.zhu@umontreal.ca">Zhaocheng Zhu</a>, <a href="/profile?email=wnzhang%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wnzhang@sjtu.edu.cn">Weinan Zhang</a>, <a href="/profile?email=mzhang_cs%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="mzhang_cs@pku.edu.cn">Ming Zhang</a>, <a href="/profile?email=jian.tang%40hec.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="jian.tang@hec.ca">Jian Tang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>23 Replies</span>
        
        
      </div>
      
        <a href="#S1esMkHYPr-details-873" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1esMkHYPr-details-873"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A flow-based autoregressive model for molecular graph generation. Reaching state-of-the-art results on molecule generation and properties optimization.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Molecular graph generation is a fundamental problem for drug discovery and has been attracting growing attention. The problem is challenging since it requires not only generating chemically valid molecular structures but also optimizing their chemical properties in the meantime. Inspired by the recent progress in deep generative models, in this paper we propose a flow-based autoregressive model for graph generation called GraphAF. GraphAF combines the advantages of both autoregressive and flow-based approaches and enjoys: (1) high model flexibility for data density estimation; (2) efficient parallel computation for training; (3) an iterative sampling process, which allows leveraging chemical domain knowledge for valency checking. Experimental results show that GraphAF is able to generate 68\% chemically valid molecules even without chemical knowledge rules and 100\% valid molecules with chemical rules. The training process of GraphAF is two times faster than the existing state-of-the-art approach GCPN. After fine-tuning the model for goal-directed property optimization with reinforcement learning, GraphAF achieves state-of-the-art performance on both chemical property optimization and constrained property optimization. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">http://bit.ly/2lCkfsr</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Molecular graph generation, deep generative models, normalizing flows, autoregressive models</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1esMkHYPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyxnMyBKwB" data-number="1594">
      <h4>
        <a href="/forum?id=HyxnMyBKwB">
            The Gambler's Problem and Beyond
        </a>
      
        
          <a href="/pdf?id=HyxnMyBKwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=bxwang%40cse.cuhk.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="bxwang@cse.cuhk.edu.hk">Baoxiang Wang</a>, <a href="/profile?email=shuaili8%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="shuaili8@sjtu.edu.cn">Shuai Li</a>, <a href="/profile?email=jjli%40se.cuhk.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jjli@se.cuhk.edu.hk">Jiajin Li</a>, <a href="/profile?email=siuon%40cse.cuhk.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="siuon@cse.cuhk.edu.hk">Siu On Chan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#HyxnMyBKwB-details-807" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyxnMyBKwB-details-807"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">the gambler's problem, reinforcement learning, fractal, self-similarity, Bellman equation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This simple problem's optimal value function is fractal and is like a Cantor function.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We analyze the Gambler's problem, a simple reinforcement learning problem where the gambler has the chance to double or lose their bets until the target is reached. This is an early example introduced in the reinforcement learning textbook by Sutton and Barto (2018), where they mention an interesting pattern of the optimal value function with high-frequency components and repeating non-smooth points. It is however without further investigation. We provide the exact formula for the optimal value function for both the discrete and the continuous cases. Though simple as it might seem, the value function is pathological: fractal, self-similar, derivative taking either zero or infinity, not smooth on any interval, and not written as elementary functions. It is in fact one of the generalized Cantor functions, where it holds a complexity that has been uncharted thus far. Our analyses could lead insights into improving value function approximation, gradient-based algorithms, and Q-learning, in real applications and implementations.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HyxnMyBKwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1xCMyBtPS" data-number="1600">
      <h4>
        <a href="/forum?id=r1xCMyBtPS">
            Multilingual Alignment of Contextual Word Representations
        </a>
      
        
          <a href="/pdf?id=r1xCMyBtPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=stevencao%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="stevencao@berkeley.edu">Steven Cao</a>, <a href="/profile?email=kitaev%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kitaev@berkeley.edu">Nikita Kitaev</a>, <a href="/profile?email=klein%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="klein@berkeley.edu">Dan Klein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#r1xCMyBtPS-details-845" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1xCMyBtPS-details-845"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">multilingual, natural language processing, embedding alignment, BERT, word embeddings, transfer</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose procedures for evaluating and strengthening contextual embedding alignment and show that they both improve multilingual BERT's zero-shot XNLI transfer and provide useful insights into the model.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose procedures for evaluating and strengthening contextual embedding alignment and show that they are useful in analyzing and improving multilingual BERT. In particular, after our proposed alignment procedure, BERT exhibits significantly improved zero-shot performance on XNLI compared to the base model, remarkably matching pseudo-fully-supervised translate-train models for Bulgarian and Greek. Further, to measure the degree of alignment, we introduce a contextual version of word retrieval and show that it correlates well with downstream zero-shot transfer. Using this word retrieval task, we also analyze BERT and find that it exhibits systematic deficiencies, e.g. worse alignment for open-class parts-of-speech and word pairs written in different scripts, that are corrected by the alignment procedure. These results support contextual alignment as a useful concept for understanding large multilingual pre-trained models.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1xCMyBtPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rygGQyrFvH" data-number="1608">
      <h4>
        <a href="/forum?id=rygGQyrFvH">
            The Curious Case of Neural Text Degeneration
        </a>
      
        
          <a href="/pdf?id=rygGQyrFvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ahai%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ahai@cs.washington.edu">Ari Holtzman</a>, <a href="/profile?email=jbuys%40cs.uct.ac.za" class="profile-link" data-toggle="tooltip" data-placement="top" title="jbuys@cs.uct.ac.za">Jan Buys</a>, <a href="/profile?email=dul2%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dul2@cs.washington.edu">Li Du</a>, <a href="/profile?email=mbforbes%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mbforbes@cs.washington.edu">Maxwell Forbes</a>, <a href="/profile?email=yejin%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yejin@cs.washington.edu">Yejin Choi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#rygGQyrFvH-details-265" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rygGQyrFvH-details-265"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Current language generation systems either aim for high likelihood and devolve into generic repetition or miscalibrate their stochasticity—we provide evidence of both and propose a solution: Nucleus Sampling.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Despite considerable advances in neural language modeling, it remains an open question what the best decoding strategy is for text generation from a language model (e.g. to generate a story). The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks, maximization-based decoding methods such as beam search lead to degeneration — output text that is bland, incoherent, or gets stuck in repetitive loops.
      
      To address this we propose Nucleus Sampling, a simple but effective method to draw considerably higher quality text out of neural language models than previous decoding strategies. Our approach avoids text degeneration by truncating the unreliable tail of the probability distribution, sampling from the dynamic nucleus of tokens containing the vast majority of the probability mass.
      
      To properly examine current maximization-based and stochastic decoding methods, we compare generations from each of these methods to the distribution of human text along several axes such as likelihood, diversity, and repetition. Our results show that (1) maximization is an inappropriate decoding objective for open-ended text generation, (2) the probability distributions of the best current language models have an unreliable tail which needs to be truncated during generation and (3) Nucleus Sampling is currently the best available decoding strategy for generating long-form text that is both high-quality — as measured by human evaluation — and as diverse as human-written text.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">generation, text, NLG, NLP, natural language, natural language generation, language model, neural, neural language model</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/ari-holtzman/degen</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rygGQyrFvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkxdQkSYDB" data-number="1622">
      <h4>
        <a href="/forum?id=HkxdQkSYDB">
            Graph Convolutional Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=HkxdQkSYDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jiechuan.jiang%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiechuan.jiang@pku.edu.cn">Jiechuan Jiang</a>, <a href="/profile?email=cd46%40rice.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cd46@rice.edu">Chen Dun</a>, <a href="/profile?email=tjhuang%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="tjhuang@pku.edu.cn">Tiejun Huang</a>, <a href="/profile?email=zongqing.lu%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zongqing.lu@pku.edu.cn">Zongqing Lu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="#HkxdQkSYDB-details-367" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkxdQkSYDB-details-367"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Learning to cooperate is crucially important in multi-agent environments. The key is to understand the mutual interplay between agents. However, multi-agent environments are highly dynamic, where agents keep moving and their neighbors change quickly. This makes it hard to learn abstract representations of mutual interplay between agents. To tackle these difficulties, we propose graph convolutional reinforcement learning, where graph convolution adapts to the dynamics of the underlying graph of the multi-agent environment, and relation kernels capture the interplay between agents by their relation representations. Latent features produced by convolutional layers from gradually increased receptive fields are exploited to learn cooperation, and cooperation is further improved by temporal relation regularization for consistency. Empirically, we show that our method substantially outperforms existing methods in a variety of cooperative scenarios.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/PKU-AI-Edge/DGN/</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkxdQkSYDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyljQyBFDH" data-number="1629">
      <h4>
        <a href="/forum?id=SyljQyBFDH">
            Meta-Learning Deep Energy-Based Memory Models
        </a>
      
        
          <a href="/pdf?id=SyljQyBFDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=bartunov%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bartunov@google.com">Sergey Bartunov</a>, <a href="/profile?email=jwrae%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jwrae@google.com">Jack Rae</a>, <a href="/profile?email=osindero%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="osindero@google.com">Simon Osindero</a>, <a href="/profile?email=countzero%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="countzero@google.com">Timothy Lillicrap</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="#SyljQyBFDH-details-74" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyljQyBFDH-details-74"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Deep associative memory models using arbitrary neural networks as a storage.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study the problem of learning an associative memory model -- a system which is able to retrieve a remembered pattern based on its distorted or incomplete version.
      Attractor networks provide a sound model of associative memory: patterns are stored as attractors of the network dynamics and associative retrieval is performed by running the dynamics starting from a query pattern until it converges to an attractor. 
      In such models the dynamics are often implemented as an optimization procedure that minimizes an energy function, such as in the classical Hopfield network. 
      In general it is difficult to derive a writing rule for a given dynamics and energy that is both compressive and fast.
      Thus, most research in energy-based memory has been limited either to tractable energy models not expressive enough to handle complex high-dimensional objects such as natural images, or to models that do not offer fast writing.
      We present a novel meta-learning approach to energy-based memory models (EBMM) that allows one to use an arbitrary neural architecture as an energy model and quickly store patterns in its weights. 
      We demonstrate experimentally that our EBMM approach can build compressed memories for synthetic and natural data, and is capable of associative retrieval that outperforms existing memory systems in terms of the reconstruction error and compression rate.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">associative memory, energy-based memory, meta-learning, compressive memory</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SyljQyBFDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkl3m1BFDB" data-number="1632">
      <h4>
        <a href="/forum?id=rkl3m1BFDB">
            Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=rkl3m1BFDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=aatrey%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="aatrey@cs.umass.edu">Akanksha Atrey</a>, <a href="/profile?email=kclary%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kclary@cs.umass.edu">Kaleigh Clary</a>, <a href="/profile?email=jensen%40cs.umass.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jensen@cs.umass.edu">David Jensen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#rkl3m1BFDB-details-142" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkl3m1BFDB-details-142"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Proposing a new counterfactual-based methodology to evaluate the hypotheses generated from saliency maps about deep RL agent behavior. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Saliency maps are frequently used to support explanations of the behavior of deep reinforcement learning (RL) agents. However, a review of how saliency maps are used in practice indicates that the derived explanations are often unfalsifiable and can be highly subjective. We introduce an empirical approach grounded in counterfactual reasoning to test the hypotheses generated from saliency maps and assess the degree to which they correspond to the semantics of RL environments. We use Atari games, a common benchmark for deep RL, to evaluate three types of saliency maps. Our results show the extent to which existing claims about Atari games can be evaluated and suggest that saliency maps are best viewed as an exploratory tool rather than an explanatory tool.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">explainability, saliency maps, representations, deep reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/KDL-umass/saliency_maps</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkl3m1BFDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rklTmyBKPH" data-number="1635">
      <h4>
        <a href="/forum?id=rklTmyBKPH">
            Fast Neural Network Adaptation via Parameter Remapping and Architecture Search
        </a>
      
        
          <a href="/pdf?id=rklTmyBKPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jaminfong%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaminfong@hust.edu.cn">Jiemin Fang*</a>, <a href="/profile?email=yzsun%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yzsun@hust.edu.cn">Yuzhu Sun*</a>, <a href="/profile?email=kangjian.peng%40horizon.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="kangjian.peng@horizon.ai">Kangjian Peng*</a>, <a href="/profile?email=qian01.zhang%40horizon.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="qian01.zhang@horizon.ai">Qian Zhang</a>, <a href="/profile?email=yuan.li%40horizon.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuan.li@horizon.ai">Yuan Li</a>, <a href="/profile?email=liuwy%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="liuwy@hust.edu.cn">Wenyu Liu</a>, <a href="/profile?email=xgwang%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xgwang@hust.edu.cn">Xinggang Wang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 28 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#rklTmyBKPH-details-977" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rklTmyBKPH-details-977"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep neural networks achieve remarkable performance in many computer vision tasks. Most state-of-the-art~(SOTA) semantic segmentation and object detection approaches reuse neural network architectures designed for image classification as the backbone, commonly pre-trained on ImageNet. However, performance gains can be achieved by designing network architectures specifically for detection and segmentation, as shown by recent neural architecture search (NAS) research for detection and segmentation. One major challenge though, is that ImageNet pre-training of the search space representation (a.k.a. super network) or the searched networks incurs huge computational cost. In this paper, we propose a Fast Neural Network Adaptation (FNA) method, which can adapt both the architecture and parameters of a seed network (e.g. a high performing manually designed backbone) to become a network with different depth, width, or kernels via a Parameter Remapping technique, making it possible to utilize NAS for detection/segmentation tasks a lot more efficiently. In our experiments, we conduct FNA on MobileNetV2 to obtain new networks for both segmentation and detection that clearly out-perform existing networks designed both manually and by NAS. The total computation cost of FNA is significantly less than SOTA segmentation/detection NAS approaches: 1737<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="481" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>×</mo></math></mjx-assistive-mml></mjx-container> less than DPC, 6.8<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="482" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>×</mo></math></mjx-assistive-mml></mjx-container> less than Auto-DeepLab and 7.4<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="483" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>×</mo></math></mjx-assistive-mml></mjx-container> less than DetNAS. The code is available at https://github.com/JaminFong/FNA .</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/JaminFong/FNA</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rklTmyBKPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJl07ySKvS" data-number="1636">
      <h4>
        <a href="/forum?id=BJl07ySKvS">
            Guiding Program Synthesis by Learning to Generate Examples
        </a>
      
        
          <a href="/pdf?id=BJl07ySKvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=llaich%40ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="llaich@ethz.ch">Larissa Laich</a>, <a href="/profile?email=pavol.bielik%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="pavol.bielik@inf.ethz.ch">Pavol Bielik</a>, <a href="/profile?email=martin.vechev%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="martin.vechev@inf.ethz.ch">Martin Vechev</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 28 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#BJl07ySKvS-details-645" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJl07ySKvS-details-645"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">program synthesis, programming by examples</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">A key challenge of existing program synthesizers is ensuring that the synthesized program generalizes well. This can be difficult to achieve as the specification provided by the end user is often limited, containing as few as one or two input-output examples. In this paper we address this challenge via an iterative approach that finds ambiguities in the provided specification and learns to resolve these by generating additional input-output examples. The main insight is to reduce the problem of selecting which program generalizes well to the simpler task of deciding which output is correct. As a result, to train our probabilistic models, we can take advantage of the large amounts of data in the form of program outputs, which are often much easier to obtain than the corresponding ground-truth programs.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/eth-sri/guiding-synthesizers</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJl07ySKvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sye0XkBKvS" data-number="1637">
      <h4>
        <a href="/forum?id=Sye0XkBKvS">
            SNODE: Spectral Discretization of Neural ODEs for System Identification
        </a>
      
        
          <a href="/pdf?id=Sye0XkBKvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=alessio%40nnaisense.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alessio@nnaisense.com">Alessio Quaglino</a>, <a href="/profile?email=marco%40nnaisense.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="marco@nnaisense.com">Marco Gallieri</a>, <a href="/profile?email=jonathan%40nnaisense.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonathan@nnaisense.com">Jonathan Masci</a>, <a href="/profile?email=jan%40nnaisense.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jan@nnaisense.com">Jan Koutník</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#Sye0XkBKvS-details-190" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sye0XkBKvS-details-190"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper proposes the use of spectral element methods for fast and accurate training of Neural Ordinary Differential Equations for system identification.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper proposes the use of spectral element methods \citep{canuto_spectral_1988} for fast and accurate training of Neural Ordinary Differential Equations (ODE-Nets; \citealp{Chen2018NeuralOD}) for system identification. This is achieved by expressing their dynamics as a truncated series of Legendre polynomials. The series coefficients, as well as the network weights, are computed by minimizing the weighted sum of the loss function and the violation of the ODE-Net dynamics. The problem is solved by coordinate descent that alternately minimizes, with respect to the coefficients and the weights, two unconstrained sub-problems using standard backpropagation and gradient methods. The resulting optimization scheme is fully time-parallel and results in a low memory footprint. Experimental comparison to standard methods, such as backpropagation through explicit solvers and the adjoint technique \citep{Chen2018NeuralOD}, on training surrogate models of small and medium-scale dynamical systems shows that it is at least one order of magnitude faster at reaching a comparable value of the loss function. The corresponding testing MSE is one order of magnitude smaller as well, suggesting generalization capabilities increase.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Recurrent neural networks, system identification, neural ODEs</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Sye0XkBKvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1lxVyStPH" data-number="1640">
      <h4>
        <a href="/forum?id=H1lxVyStPH">
            Generalized Convolutional Forest Networks for Domain Generalization and Visual Recognition
        </a>
      
        
          <a href="/pdf?id=H1lxVyStPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jongbin.ryu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jongbin.ryu@gmail.com">Jongbin Ryu</a>, <a href="/profile?email=kwongitack%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kwongitack@gmail.com">Gitaek Kwon</a>, <a href="/profile?email=mhyang%40ucmerced.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mhyang@ucmerced.edu">Ming-Hsuan Yang</a>, <a href="/profile?email=jlim%40hanyang.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jlim@hanyang.ac.kr">Jongwoo Lim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#H1lxVyStPH-details-957" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1lxVyStPH-details-957"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">When constructing random forests, it is of prime importance to ensure high accuracy and low correlation of individual tree classifiers for good performance. Nevertheless, it is typically difficult for existing random forest methods to strike a good balance between these conflicting factors. In this work, we propose a generalized convolutional forest networks to learn a feature space to maximize the strength of individual tree classifiers while minimizing the respective correlation. The feature space is iteratively constructed by a probabilistic triplet sampling method based on the distribution obtained from the splits of the random forest. The sampling process is designed to pull the data of the same label together for higher strength and push away the data frequently falling to the same leaf nodes. We perform extensive experiments on five image classification and two domain generalization datasets with ResNet-50 and DenseNet-161 backbone networks. Experimental results show that the proposed algorithm performs favorably against state-of-the-art methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1lxVyStPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HylxE1HKwS" data-number="1641">
      <h4>
        <a href="/forum?id=HylxE1HKwS">
            Once-for-All: Train One Network and Specialize it for Efficient Deployment
        </a>
      
        
          <a href="/pdf?id=HylxE1HKwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=hancai%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hancai@mit.edu">Han Cai</a>, <a href="/profile?email=ganchuang1990%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ganchuang1990@gmail.com">Chuang Gan</a>, <a href="/profile?email=usedtobe%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="usedtobe@mit.edu">Tianzhe Wang</a>, <a href="/profile?email=zhangzk%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhangzk@mit.edu">Zhekai Zhang</a>, <a href="/profile?email=songhan%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="songhan@mit.edu">Song Han</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 30 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#HylxE1HKwS-details-578" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HylxE1HKwS-details-578"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce techniques to train a single once-for-all network that fits many hardware platforms.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We address the challenging problem of efficient inference across many devices and resource constraints, especially on edge devices.  Conventional approaches either manually design or use neural architecture search (NAS) to find a specialized neural network and train it from scratch for each case, which is computationally prohibitive (causing <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="484" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>C</mi><msub><mi>O</mi><mn>2</mn></msub></math></mjx-assistive-mml></mjx-container> emission as much as 5 cars' lifetime) thus unscalable. In this work, we propose to train a once-for-all (OFA) network that supports diverse architectural settings by decoupling training and search, to reduce the cost. We can quickly get a specialized sub-network by selecting from the OFA network without additional training. To efficiently train OFA networks, we also propose a novel progressive shrinking algorithm, a generalized pruning method that reduces the model size across many more dimensions than pruning (depth, width, kernel size, and resolution). It can obtain a surprisingly large number of sub-networks (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="485" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-script style="vertical-align: 0.393em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c39"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&gt;</mo><msup><mn>10</mn><mrow><mn>19</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>) that can fit different hardware platforms and latency constraints while maintaining the same level of accuracy as training independently. On diverse edge devices, OFA consistently outperforms state-of-the-art (SOTA) NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="486" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>C</mi><msub><mi>O</mi><mn>2</mn></msub></math></mjx-assistive-mml></mjx-container> emission. In particular, OFA achieves a new SOTA 80.0% ImageNet top-1 accuracy under the mobile setting (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="487" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c3C"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&lt;</mo></math></mjx-assistive-mml></mjx-container>600M MACs). OFA is the winning solution for the 3rd Low Power Computer Vision Challenge (LPCVC), DSP classification track and the 4th LPCVC, both classification track and detection track. Code and  50 pre-trained models (for many devices &amp; many latency constraints) are released at https://github.com/mit-han-lab/once-for-all. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Efficient Deep Learning, Specialized Neural Network Architecture, AutoML</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/mit-han-lab/once-for-all</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HylxE1HKwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1gZV1HYvS" data-number="1643">
      <h4>
        <a href="/forum?id=B1gZV1HYvS">
            Multi-Agent Interactions Modeling with Correlated Policies
        </a>
      
        
          <a href="/pdf?id=B1gZV1HYvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=minghuanliu%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="minghuanliu@sjtu.edu.cn">Minghuan Liu</a>, <a href="/profile?email=mingak%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="mingak@sjtu.edu.cn">Ming Zhou</a>, <a href="/profile?email=wnzhang%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wnzhang@sjtu.edu.cn">Weinan Zhang</a>, <a href="/profile?email=zhuangyuzheng%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhuangyuzheng@huawei.com">Yuzheng Zhuang</a>, <a href="/profile?email=w.j%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="w.j@huawei.com">Jun Wang</a>, <a href="/profile?email=liuwulong%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liuwulong@huawei.com">Wulong Liu</a>, <a href="/profile?email=yyu%40apex.sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yyu@apex.sjtu.edu.cn">Yong Yu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#B1gZV1HYvS-details-229" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1gZV1HYvS-details-229"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Modeling complex multi-agent interactions under multi-agent imitation learning framework with explicit modeling of correlated policies by approximating opponents’ policies. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In multi-agent systems, complex interacting behaviors arise due to the high correlations among agents. However, previous work on modeling multi-agent interactions from demonstrations is primarily constrained by assuming the independence among policies and their reward structures. 
      In this paper, we cast the multi-agent interactions modeling problem into a multi-agent imitation learning framework with explicit modeling of correlated policies by approximating opponents’ policies, which can recover agents' policies that can regenerate similar interactions. Consequently, we develop a Decentralized Adversarial Imitation Learning algorithm with Correlated policies (CoDAIL), which allows for decentralized training and execution. Various experiments demonstrate that CoDAIL can better regenerate complex interactions close to the demonstrators and outperforms state-of-the-art multi-agent imitation learning methods. Our code is available at \url{https://github.com/apexrl/CoDAIL}.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/apexrl/CoDAIL</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Multi-agent reinforcement learning, Imitation learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1gZV1HYvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJgWE1SFwS" data-number="1644">
      <h4>
        <a href="/forum?id=BJgWE1SFwS">
            PCMC-Net: Feature-based Pairwise Choice Markov Chains
        </a>
      
        
          <a href="/pdf?id=BJgWE1SFwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=alherit%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alherit@gmail.com">Alix Lhéritier</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#BJgWE1SFwS-details-868" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJgWE1SFwS-details-868"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a generic neural network architecture equipping Pairwise Choice Markov Chains choice models with amortized and automatic differentiation based inference using alternatives' and individuals' features.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Pairwise Choice Markov Chains (PCMC) have been recently introduced to overcome limitations of choice models based on traditional axioms unable to express empirical observations from modern behavior economics like context effects occurring when a choice between two options is altered by adding a third alternative. The inference approach that estimates the transition rates between each possible pair of alternatives via maximum likelihood suffers when the examples of each alternative are scarce and is inappropriate when new alternatives can be observed at test time. In this work, we propose an amortized inference approach for PCMC by embedding its definition into a neural network that represents transition rates as a function of the alternatives' and individual's features. We apply our construction to the complex case of airline itinerary booking where singletons are common (due to varying prices and individual-specific itineraries), and context effects and behaviors strongly dependent on market segments are observed. Experiments show our network significantly outperforming, in terms of prediction accuracy and logarithmic loss, feature engineered standard and latent class Multinomial Logit models as well as recent machine learning approaches.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">choice modeling, pairwise choice Markov chains, deep learning, amortized inference, automatic differentiation, airline itinerary choice modeling</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/alherit/PCMC-Net</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJgWE1SFwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byx4NkrtDS" data-number="1651">
      <h4>
        <a href="/forum?id=Byx4NkrtDS">
            Implementing Inductive bias for different navigation tasks through diverse RNN attrractors
        </a>
      
        
          <a href="/pdf?id=Byx4NkrtDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=fexutie%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fexutie@gmail.com">Tie XU</a>, <a href="/profile?email=omri.barak%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="omri.barak@gmail.com">Omri Barak</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#Byx4NkrtDS-details-109" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byx4NkrtDS-details-109"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">navigation, Recurrent Neural Networks, dynamics, inductive bias, pre-training, reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Task agnostic pre-training can shape RNN's attractor landscape, and form diverse inductive bias for different navigation tasks   </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Navigation is crucial for animal behavior and is assumed to require an internal representation of the external environment, termed a cognitive map. The precise form of this representation is often considered to be a metric representation of space. An internal representation, however, is judged by its contribution to performance on a given task, and may thus vary between different types of navigation tasks. Here we train a recurrent neural network that controls an agent performing several navigation tasks in a simple environment. To focus on internal representations, we split learning into a task-agnostic pre-training stage that modifies internal connectivity and a task-specific Q learning stage that controls the network's output. We show that pre-training shapes the attractor landscape of the networks, leading to either a continuous attractor, discrete attractors or a disordered state. These structures induce bias onto the Q-Learning phase, leading to a performance pattern across the tasks corresponding to metric and topological regularities. Our results show that, in recurrent networks, inductive bias takes the form of attractor landscapes -- which can be shaped by pre-training and analyzed using dynamical systems methods. Furthermore, we demonstrate that non-metric representations are useful for navigation tasks.  </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://anonymous.4open.science/r/539372c8-c17b-4b48-a7da-56392ed685c4/</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Byx4NkrtDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJgr4kSFDS" data-number="1652">
      <h4>
        <a href="/forum?id=BJgr4kSFDS">
            Query2box: Reasoning over Knowledge Graphs in Vector Space Using Box Embeddings
        </a>
      
        
          <a href="/pdf?id=BJgr4kSFDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=hyren%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hyren@cs.stanford.edu">Hongyu Ren*</a>, <a href="/profile?email=weihuahu%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="weihuahu@stanford.edu">Weihua Hu*</a>, <a href="/profile?email=jure%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jure@cs.stanford.edu">Jure Leskovec</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#BJgr4kSFDS-details-805" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJgr4kSFDS-details-805"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Answering a wide class of logical queries over knowledge graphs with box embeddings in vector space</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Answering complex logical queries on large-scale incomplete knowledge graphs (KGs) is a fundamental yet challenging task. Recently, a promising approach to this problem has been to embed KG entities as well as the query into a vector space such that entities that answer the query are embedded close to the query. However, prior work models queries as single points in the vector space, which is problematic because a complex query represents a potentially large set of its answer entities, but it is unclear how such a set can be represented as a single point. Furthermore, prior work can only handle queries that use conjunctions (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="488" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2227"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∧</mo></math></mjx-assistive-mml></mjx-container>) and existential quantifiers (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="489" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c2203"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">∃</mi></math></mjx-assistive-mml></mjx-container>). Handling queries with logical disjunctions (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="490" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2228"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∨</mo></math></mjx-assistive-mml></mjx-container>) remains an open problem. Here we propose query2box, an embedding-based framework for reasoning over arbitrary queries with <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="491" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2227"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∧</mo></math></mjx-assistive-mml></mjx-container>, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="492" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2228"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∨</mo></math></mjx-assistive-mml></mjx-container>, and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="493" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c2203"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">∃</mi></math></mjx-assistive-mml></mjx-container> operators in massive and incomplete KGs. Our main insight is that queries can be embedded as boxes (i.e., hyper-rectangles), where a set of points inside the box corresponds to a set of answer entities of the query. We show that conjunctions can be naturally represented as intersections of boxes and also prove a negative result that handling disjunctions would require embedding with dimension proportional to the number of KG entities. However, we show that by transforming queries into a Disjunctive Normal Form, query2box is capable of handling arbitrary logical queries with <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="494" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2227"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∧</mo></math></mjx-assistive-mml></mjx-container>, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="495" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2228"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∨</mo></math></mjx-assistive-mml></mjx-container>, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="496" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c2203"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">∃</mi></math></mjx-assistive-mml></mjx-container> in a scalable manner. We demonstrate the effectiveness of query2box on two large KGs and show that query2box achieves up to 25% relative improvement over the state of the art.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">knowledge graph embeddings, logical reasoning, query answering</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/hyren/query2box</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJgr4kSFDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1g8VkHFPH" data-number="1656">
      <h4>
        <a href="/forum?id=B1g8VkHFPH">
            Rethinking the Hyperparameters for Fine-tuning
        </a>
      
        
          <a href="/pdf?id=B1g8VkHFPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=hao.li.ict%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hao.li.ict@gmail.com">Hao Li</a>, <a href="/profile?email=pratikac%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pratikac@seas.upenn.edu">Pratik Chaudhari</a>, <a href="/profile?email=lancelot365%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lancelot365@gmail.com">Hao Yang</a>, <a href="/profile?email=michlam%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="michlam@amazon.com">Michael Lam</a>, <a href="/profile?email=avinash.a.ravichandran%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="avinash.a.ravichandran@gmail.com">Avinash Ravichandran</a>, <a href="/profile?email=bhotikar%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bhotikar@amazon.com">Rahul Bhotika</a>, <a href="/profile?email=soatto%40ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="soatto@ucla.edu">Stefano Soatto</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#B1g8VkHFPH-details-963" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1g8VkHFPH-details-963"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper re-examines several common practices of setting hyper-parameters for fine-tuning and identify optimal hyperparameter depends on source-target domain similarity.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Fine-tuning from pre-trained ImageNet models has become the de-facto standard for various computer vision tasks. Current practices for fine-tuning typically involve selecting an ad-hoc choice of hyperparameters and keeping them fixed to values normally used for training from scratch. This paper re-examines several common practices of setting hyperparameters for fine-tuning.  Our findings are based on extensive empirical evaluation for fine-tuning on various transfer learning benchmarks. (1) While prior works have thoroughly investigated learning rate and batch size, momentum for fine-tuning is a relatively unexplored parameter. We find that the value of momentum also affects fine-tuning performance and connect it with previous theoretical findings.  (2) Optimal hyperparameters for fine-tuning, in particular, the effective learning rate, are not only dataset dependent but also sensitive to the similarity between the source domain and target domain. This is in contrast to hyperparameters for training from scratch. (3) Reference-based regularization that keeps models close to the initial model does not necessarily apply for "dissimilar" datasets. Our findings challenge common practices of fine-tuning and encourages deep learning practitioners to rethink the hyperparameters for fine-tuning.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">fine-tuning, hyperparameter search, transfer learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1g8VkHFPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1edEyBKDS" data-number="1659">
      <h4>
        <a href="/forum?id=H1edEyBKDS">
            Plug and Play Language Models: A Simple Approach to Controlled Text Generation
        </a>
      
        
          <a href="/pdf?id=H1edEyBKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=dathathris%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dathathris@gmail.com">Sumanth Dathathri</a>, <a href="/profile?email=amadotto%40connect.ust.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="amadotto@connect.ust.hk">Andrea Madotto</a>, <a href="/profile?email=lan.janice.j%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lan.janice.j@gmail.com">Janice Lan</a>, <a href="/profile?email=jane.hung%40uber.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jane.hung@uber.com">Jane Hung</a>, <a href="/profile?email=mysterefrank%40uber.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mysterefrank@uber.com">Eric Frank</a>, <a href="/profile?email=piero%40uber.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="piero@uber.com">Piero Molino</a>, <a href="/profile?email=yosinski%40uber.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yosinski@uber.com">Jason Yosinski</a>, <a href="/profile?email=rosanne%40uber.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rosanne@uber.com">Rosanne Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 23 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>27 Replies</span>
        
        
      </div>
      
        <a href="#H1edEyBKDS-details-296" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1edEyBKDS-details-296"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">controlled text generation, generative models, conditional generative models, language modeling, transformer</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We control the topic and sentiment of text generation (almost) without any training. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Large transformer-based language models (LMs) trained on huge text corpora have shown unparalleled generation capabilities. However, controlling attributes of the generated language (e.g. switching topic or sentiment) is difficult without modifying the model architecture or fine-tuning on attribute-specific data and entailing the significant cost of retraining. We propose a simple alternative: the Plug and Play Language Model (PPLM) for controllable language generation, which combines a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. In the canonical scenario we present, the attribute models are simple classifiers consisting of a user-specified bag of words or a single learned layer with 100,000 times fewer parameters than the LM. Sampling entails a forward and backward pass in which gradients from the attribute model push the LM's hidden activations and thus guide the generation. Model samples demonstrate control over a range of topics and sentiment styles, and extensive automated and human annotated evaluations show attribute alignment and fluency. PPLMs are flexible in that any combination of differentiable attribute models may be used to steer text generation, which will allow for diverse and creative applications beyond the examples given in this paper.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/uber-research/PPLM</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1edEyBKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgqN1SYvr" data-number="1665">
      <h4>
        <a href="/forum?id=rkgqN1SYvr">
            Provable Benefit of Orthogonal Initialization in Optimizing Deep Linear Networks
        </a>
      
        
          <a href="/pdf?id=rkgqN1SYvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=huwei%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="huwei@cs.princeton.edu">Wei Hu</a>, <a href="/profile?email=xlc%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xlc@google.com">Lechao Xiao</a>, <a href="/profile?email=jpennin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jpennin@google.com">Jeffrey Pennington</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rkgqN1SYvr-details-717" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgqN1SYvr-details-717"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We provide for the first time a rigorous proof that orthogonal initialization speeds up convergence relative to Gaussian initialization, for deep linear networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The selection of initial parameter values for gradient-based optimization of deep neural networks is one of the most impactful hyperparameter choices in deep learning systems, affecting both convergence times and model performance. Yet despite significant empirical and theoretical analysis, relatively little has been proved about the concrete effects of different initialization schemes. In this work, we analyze the effect of initialization in deep linear networks, and provide for the first time a rigorous proof that drawing the initial weights from the orthogonal group speeds up convergence relative to the standard Gaussian initialization with iid weights. We show that for deep networks, the width needed for efficient convergence to a global minimum with orthogonal initializations is independent of the depth, whereas the width needed for efficient convergence with Gaussian initializations scales linearly in the depth. Our results demonstrate how the benefits of a good initialization can persist throughout learning, suggesting an explanation for the recent empirical successes found by initializing very deep non-linear networks according to the principle of dynamical isometry.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning theory, non-convex optimization, orthogonal initialization</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgqN1SYvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyxjNyrtPr" data-number="1666">
      <h4>
        <a href="/forum?id=HyxjNyrtPr">
            RGBD-GAN: Unsupervised 3D Representation Learning From Natural Image Datasets via RGBD Image Synthesis
        </a>
      
        
          <a href="/pdf?id=HyxjNyrtPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=noguchi%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="noguchi@mi.t.u-tokyo.ac.jp">Atsuhiro Noguchi</a>, <a href="/profile?email=harada%40mi.t.u-tokyo.ac.jp" class="profile-link" data-toggle="tooltip" data-placement="top" title="harada@mi.t.u-tokyo.ac.jp">Tatsuya Harada</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HyxjNyrtPr-details-909" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyxjNyrtPr-details-909"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">image generation, 3D vision, unsupervised representation learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">RGBD image generation for unsupervised camera parameter conditioning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Understanding three-dimensional (3D) geometries from two-dimensional (2D) images without any labeled information is promising for understanding the real world without incurring annotation cost. We herein propose a novel generative model, RGBD-GAN, which achieves unsupervised 3D representation learning from 2D images. The proposed method enables camera parameter--conditional image generation and depth image generation without any 3D annotations, such as camera poses or depth. We use an explicit 3D consistency loss for two RGBD images generated from different camera parameters, in addition to the ordinal GAN objective. The loss is simple yet effective for any type of image generator such as DCGAN and StyleGAN to be conditioned on camera parameters. Through experiments, we demonstrated that the proposed method could learn 3D representations from 2D images with various generator architectures.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HyxjNyrtPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyxhVkrYvr" data-number="1670">
      <h4>
        <a href="/forum?id=SyxhVkrYvr">
            Towards Verified Robustness under Text Deletion Interventions
        </a>
      
        
          <a href="/pdf?id=SyxhVkrYvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=johannes.welbl.14%40ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="johannes.welbl.14@ucl.ac.uk">Johannes Welbl</a>, <a href="/profile?email=posenhuang%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="posenhuang@google.com">Po-Sen Huang</a>, <a href="/profile?email=stanforth%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="stanforth@google.com">Robert Stanforth</a>, <a href="/profile?email=sgowal%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sgowal@google.com">Sven Gowal</a>, <a href="/profile?email=dvij%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dvij@google.com">Krishnamurthy (Dj) Dvijotham</a>, <a href="/profile?email=szummer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="szummer@google.com">Martin Szummer</a>, <a href="/profile?email=pushmeet%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pushmeet@google.com">Pushmeet Kohli</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SyxhVkrYvr-details-456" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyxhVkrYvr-details-456"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Formal verification of a specification on a model's prediction undersensitivity using Interval Bound Propagation</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Neural networks are widely used in Natural Language Processing, yet despite their empirical successes, their behaviour is brittle: they are both over-sensitive to small input changes, and under-sensitive to deletions of large fractions of input text. This paper aims to tackle under-sensitivity in the context of natural language inference by ensuring that models do not become more confident in their predictions as arbitrary subsets of words from the input text are deleted. We develop a novel technique for formal verification of this specification for models based on the popular decomposable attention mechanism by employing the efficient yet effective interval bound propagation (IBP) approach. Using this method we can efficiently prove, given a model, whether a particular sample is free from the under-sensitivity problem. We compare different training methods to address under-sensitivity, and compare metrics to measure it. In our experiments on the SNLI and MNLI datasets, we observe that IBP training leads to a significantly improved verified accuracy. On the SNLI test set, we can verify 18.4% of samples, a substantial improvement over only 2.8% using standard training.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">natural language processing, specification, verification, model undersensitivity, adversarial, interval bound propagation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SyxhVkrYvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hke0V1rKPS" data-number="1673">
      <h4>
        <a href="/forum?id=Hke0V1rKPS">
            Jacobian Adversarially Regularized Networks for Robustness
        </a>
      
        
          <a href="/pdf?id=Hke0V1rKPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=guoweial001%40e.ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="guoweial001@e.ntu.edu.sg">Alvin Chan</a>, <a href="/profile?email=ytay017%40e.ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="ytay017@e.ntu.edu.sg">Yi Tay</a>, <a href="/profile?email=asysong%40ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="asysong@ntu.edu.sg">Yew Soon Ong</a>, <a href="/profile?email=jie.fu%40polymtl.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="jie.fu@polymtl.ca">Jie Fu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#Hke0V1rKPS-details-40" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hke0V1rKPS-details-40"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We show that training classifiers to produce salient input Jacobian matrices with a GAN-like regularization can boost adversarial robustness.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Adversarial examples are crafted with imperceptible perturbations with the intent to fool neural networks. Against such attacks, adversarial training and its variants stand as the strongest defense to date. Previous studies have pointed out that robust models that have undergone adversarial training tend to produce more salient and interpretable Jacobian matrices than their non-robust counterparts. A natural question is whether a model trained with an objective to produce salient Jacobian can result in better robustness. This paper answers this question with affirmative empirical results. We propose Jacobian Adversarially Regularized Networks (JARN) as a method to optimize the saliency of a classifier's Jacobian by adversarially regularizing the model's Jacobian to resemble natural training images. Image classifiers trained with JARN show improved robust accuracy compared to standard models on the MNIST, SVHN and CIFAR-10 datasets, uncovering a new angle to boost robustness without using adversarial training.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial examples, robust machine learning, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hke0V1rKPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJexHkSFPS" data-number="1679">
      <h4>
        <a href="/forum?id=SJexHkSFPS">
            Thinking While Moving: Deep Reinforcement Learning with Concurrent Control
        </a>
      
        
          <a href="/pdf?id=SJexHkSFPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tedxiao%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tedxiao@google.com">Ted Xiao</a>, <a href="/profile?email=ejang%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ejang@google.com">Eric Jang</a>, <a href="/profile?email=dkalashnikov%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dkalashnikov@google.com">Dmitry Kalashnikov</a>, <a href="/profile?email=slevine%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="slevine@google.com">Sergey Levine</a>, <a href="/profile?email=julianibarz%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="julianibarz@google.com">Julian Ibarz</a>, <a href="/profile?email=karolhausman%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="karolhausman@google.com">Karol Hausman</a>, <a href="/profile?email=alexherzog%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexherzog@google.com">Alexander Herzog</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SJexHkSFPS-details-396" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJexHkSFPS-details-396"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep reinforcement learning, continuous-time, robotics</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Reinforcement learning formulation that allows agents to think and act at the same time, demonstrated on real-world robotic grasping.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study reinforcement learning in settings where sampling an action from the policy must be done concurrently with the time evolution of the controlled system, such as when a robot must decide on the next action while still performing the previous action. Much like a person or an animal, the robot must think and move at the same time, deciding on its next action before the previous one has completed. In order to develop an algorithmic framework for such concurrent control problems, we start with a continuous-time formulation of the Bellman equations, and then discretize them in a way that is aware of system delays. We instantiate this new class of approximate dynamic programming methods via a simple architectural extension to existing value-based deep reinforcement learning algorithms. We evaluate our methods on simulated benchmark tasks and a large-scale robotic grasping task where the robot must "think while moving."</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJexHkSFPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJxbHkrKDH" data-number="1681">
      <h4>
        <a href="/forum?id=SJxbHkrKDH">
            Evolutionary Population Curriculum for Scaling Multi-Agent Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=SJxbHkrKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=qianlong%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qianlong@cs.cmu.edu">Qian Long*</a>, <a href="/profile?email=footoredo%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="footoredo@sjtu.edu.cn">Zihan Zhou*</a>, <a href="/profile?email=abhinavg%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhinavg@cs.cmu.edu">Abhinav Gupta</a>, <a href="/profile?email=feif%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="feif@cs.cmu.edu">Fei Fang</a>, <a href="/profile?email=jxwuyi%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jxwuyi@gmail.com">Yi Wu†</a>, <a href="/profile?email=dragonwxl123%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dragonwxl123@gmail.com">Xiaolong Wang†</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SJxbHkrKDH-details-615" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJxbHkrKDH-details-615"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">multi-agent reinforcement learning, evolutionary learning, curriculum learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In multi-agent games, the complexity of the environment can grow exponentially as the number of agents increases, so it is particularly challenging to learn good policies when the agent population is large. In this paper, we introduce Evolutionary Population Curriculum (EPC), a curriculum learning paradigm that scales up Multi-Agent Reinforcement Learning (MARL) by progressively increasing the population of training agents in a stage-wise manner. Furthermore, EPC uses an evolutionary approach to fix an objective misalignment issue throughout the curriculum: agents successfully trained in an early stage with a small population are not necessarily the best candidates for adapting to later stages with scaled populations. Concretely, EPC maintains multiple sets of agents in each stage, performs mix-and-match and fine-tuning over these sets and promotes the sets of agents with the best adaptability to the next stage. We implement EPC on a popular MARL algorithm, MADDPG, and empirically show that our approach consistently outperforms baselines by a large margin as the number of agents grows exponentially. The source code and videos can be found at https://sites.google.com/view/epciclr2020.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/qian18long/epciclr2020</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJxbHkrKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1xMH1BtvB" data-number="1682">
      <h4>
        <a href="/forum?id=r1xMH1BtvB">
            ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators
        </a>
      
        
          <a href="/pdf?id=r1xMH1BtvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kevclark%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kevclark@cs.stanford.edu">Kevin Clark</a>, <a href="/profile?email=thangluong%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thangluong@google.com">Minh-Thang Luong</a>, <a href="/profile?email=qvl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qvl@google.com">Quoc V. Le</a>, <a href="/profile?email=manning%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="manning@cs.stanford.edu">Christopher D. Manning</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#r1xMH1BtvB-details-706" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1xMH1BtvB-details-706"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A text encoder trained to distinguish real input tokens from plausible fakes efficiently learns effective language representations.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Masked language modeling (MLM) pre-training methods such as BERT corrupt the input by replacing some tokens with [MASK] and then train a model to reconstruct the original tokens. While they produce good results when transferred to downstream NLP tasks, they generally require large amounts of compute to be effective. As an alternative, we propose a more sample-efficient pre-training task called replaced token detection. Instead of masking the input, our approach corrupts it by replacing some tokens with plausible alternatives sampled from a small generator network. Then, instead of training a model that predicts the original identities of the corrupted tokens, we train a discriminative model that predicts whether each token in the corrupted input was replaced by a generator sample or not. Thorough experiments demonstrate this new pre-training task is more efficient than MLM because the task is defined over all input tokens rather than just the small subset that was masked out. As a result, the contextual representations learned by our approach substantially outperform the ones learned by BERT given the same model size, data, and compute. The gains are particularly strong for small models; for example, we train a model on one GPU for 4 days that outperforms GPT (trained using 30x more compute) on the GLUE natural language understanding benchmark. Our approach also works well at scale, where it performs comparably to RoBERTa and XLNet while using less than 1/4 of their compute and outperforms them when using the same amount of compute.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Natural Language Processing, Representation Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/google-research/electra</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1xMH1BtvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SklGryBtwr" data-number="1684">
      <h4>
        <a href="/forum?id=SklGryBtwr">
            Environmental drivers of systematicity and generalization in a situated agent
        </a>
      
        
          <a href="/pdf?id=SklGryBtwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=felixhill%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="felixhill@google.com">Felix Hill</a>, <a href="/profile?email=lampinen%40stanford.edo" class="profile-link" data-toggle="tooltip" data-placement="top" title="lampinen@stanford.edo">Andrew Lampinen</a>, <a href="/profile?email=rgschneider%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rgschneider@google.com">Rosalia Schneider</a>, <a href="/profile?email=clarkstephen%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="clarkstephen@google.com">Stephen Clark</a>, <a href="/profile?email=botvinick%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="botvinick@google.com">Matthew Botvinick</a>, <a href="/profile?email=jlmcc%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jlmcc@google.com">James L. McClelland</a>, <a href="/profile?email=adamsantoro%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adamsantoro@google.com">Adam Santoro</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>23 Replies</span>
        
        
      </div>
      
        <a href="#SklGryBtwr-details-607" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SklGryBtwr-details-607"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">systematicitiy, systematic, generalization, combinatorial, agent, policy, language, compositionality</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We isolate the environmental and training factors that contribute to emergent systematic generalization in a situated language-learning agent</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The question of whether deep neural networks are good at generalising beyond their immediate training experience is of critical importance for learning-based approaches to AI. Here, we consider tests of out-of-sample generalisation that require an agent to respond to never-seen-before instructions by manipulating and positioning objects in a 3D Unity simulated room. We first describe a comparatively generic agent architecture that exhibits strong performance on these tests. We then identify three aspects of the training regime and environment that make a significant difference to its performance: (a) the number of object/word experiences in the training set; (b) the visual invariances afforded by the agent's perspective, or frame of reference; and (c) the variety of visual input inherent in the perceptual aspect of the agent's perception. Our findings indicate that the degree of generalisation that networks exhibit can depend critically on particulars of the environment in which a given task is instantiated. They further suggest that the propensity for neural networks to generalise in systematic ways may increase if, like human children, those networks have access to many frames of richly varying, multi-modal observations as they learn.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SklGryBtwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByxQB1BKwH" data-number="1685">
      <h4>
        <a href="/forum?id=ByxQB1BKwH">
            Abstract Diagrammatic Reasoning with Multiplex Graph Networks
        </a>
      
        
          <a href="/pdf?id=ByxQB1BKwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wd263%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="wd263@cam.ac.uk">Duo Wang</a>, <a href="/profile?email=mateja.jamnik%40cl.cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="mateja.jamnik@cl.cam.ac.uk">Mateja Jamnik</a>, <a href="/profile?email=pietro.lio%40cl.cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="pietro.lio@cl.cam.ac.uk">Pietro Lio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#ByxQB1BKwH-details-748" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByxQB1BKwH-details-748"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reasoning, Raven Progressive Matrices, graph neural networks, multiplex graphs</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">MXGNet is a multilayer, multiplex graph based architecture which achieves good performance on various diagrammatic reasoning tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Abstract reasoning, particularly in the visual domain, is a complex human ability, but it remains a challenging problem for artificial neural learning systems. In this work we propose MXGNet, a multilayer graph neural network for multi-panel diagrammatic reasoning tasks. MXGNet combines three powerful concepts, namely, object-level representation, graph neural networks and multiplex graphs, for solving visual reasoning tasks. MXGNet first extracts object-level representations for each element in all panels of the diagrams, and then forms a multi-layer multiplex graph capturing multiple relations between objects across different diagram panels. MXGNet summarises the multiple graphs extracted from the diagrams of the task, and uses this summarisation to pick the most probable answer from the given candidates. We have tested MXGNet on two types of diagrammatic reasoning tasks, namely Diagram Syllogisms and Raven Progressive Matrices (RPM). For an Euler Diagram Syllogism task MXGNet achieves state-of-the-art accuracy of 99.8%.  For PGM and RAVEN, two comprehensive datasets for RPM reasoning, MXGNet outperforms the state-of-the-art models by a considerable margin.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByxQB1BKwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylXBkrYDS" data-number="1686">
      <h4>
        <a href="/forum?id=rylXBkrYDS">
            A Baseline for Few-Shot Image Classification
        </a>
      
        
          <a href="/pdf?id=rylXBkrYDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=guneetdhillon%40utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="guneetdhillon@utexas.edu">Guneet Singh Dhillon</a>, <a href="/profile?email=pratikac%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pratikac@seas.upenn.edu">Pratik Chaudhari</a>, <a href="/profile?email=avinash.a.ravichandran%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="avinash.a.ravichandran@gmail.com">Avinash Ravichandran</a>, <a href="/profile?email=soattos%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="soattos@amazon.com">Stefano Soatto</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 23 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#rylXBkrYDS-details-739" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylXBkrYDS-details-739"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Transductive fine-tuning of a deep network is a strong baseline for few-shot image classification and outperforms the state-of-the-art on all standard benchmarks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Fine-tuning a deep network trained with the standard cross-entropy loss is a strong baseline for few-shot learning. When fine-tuned transductively, this outperforms the current state-of-the-art on standard datasets such as Mini-ImageNet, Tiered-ImageNet, CIFAR-FS and FC-100 with the same hyper-parameters. The simplicity of this approach enables us to demonstrate the first few-shot learning results on the ImageNet-21k dataset. We find that using a large number of meta-training classes results in high few-shot accuracies even for a large number of few-shot classes. We do not advocate our approach as the solution for few-shot learning, but simply use the results to highlight limitations of current benchmarks and few-shot protocols. We perform extensive studies on benchmark datasets to propose a metric that quantifies the "hardness" of a few-shot episode. This metric can be used to report the performance of few-shot algorithms in a more systematic way.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">few-shot learning, transductive learning, fine-tuning, baseline, meta-learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rylXBkrYDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJgVHkrYDH" data-number="1687">
      <h4>
        <a href="/forum?id=SJgVHkrYDH">
            Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering
        </a>
      
        
          <a href="/pdf?id=SJgVHkrYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=akari%40cs.washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="akari@cs.washington.edu">Akari Asai</a>, <a href="/profile?email=k.hashimoto%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="k.hashimoto@salesforce.com">Kazuma Hashimoto</a>, <a href="/profile?email=hannaneh%40washington.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hannaneh@washington.edu">Hannaneh Hajishirzi</a>, <a href="/profile?email=richard%40socher.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="richard@socher.org">Richard Socher</a>, <a href="/profile?email=cxiong%40salesforce.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cxiong@salesforce.com">Caiming Xiong</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 20 May 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="#SJgVHkrYDH-details-104" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJgVHkrYDH-details-104"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Graph-based recurrent retriever that learns to retrieve reasoning paths over Wikipedia Graph outperforms the most recent state of the art on HotpotQA by more than 14 points.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Answering questions that require multi-hop reasoning at web-scale necessitates retrieving multiple evidence documents, one of which often has little lexical or semantic relationship to the question. This paper introduces a new graph-based recurrent retrieval approach that learns to retrieve reasoning paths over the Wikipedia graph to answer multi-hop open-domain questions. Our retriever model trains a recurrent neural network that learns to sequentially retrieve evidence paragraphs in the reasoning path by conditioning on the previously retrieved documents. 
      Our reader model ranks the reasoning paths and extracts the answer span included in the best reasoning path.
      Experimental results show state-of-the-art results in three open-domain QA datasets, showcasing the effectiveness and robustness of our method. Notably, our method achieves significant improvement in HotpotQA, outperforming the previous best model by more than 14 points.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Multi-hop Open-domain Question Answering, Graph-based Retrieval, Multi-step Retrieval</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJgVHkrYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJlBSkHtDS" data-number="1690">
      <h4>
        <a href="/forum?id=BJlBSkHtDS">
            Padé Activation Units: End-to-end Learning of Flexible Activation Functions in Deep Networks
        </a>
      
        
          <a href="/pdf?id=BJlBSkHtDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=molina%40cs.tu-darmstadt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="molina@cs.tu-darmstadt.de">Alejandro Molina</a>, <a href="/profile?email=schramowski%40cs.tu-darmstadt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="schramowski@cs.tu-darmstadt.de">Patrick Schramowski</a>, <a href="/profile?email=kersting%40cs.tu-darmstadt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="kersting@cs.tu-darmstadt.de">Kristian Kersting</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#BJlBSkHtDS-details-25" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJlBSkHtDS-details-25"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce PAU, a new learnable activation function for neural networks. They free the network designers from the activation selection process and increase the test prediction accuracy.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The performance of deep network learning strongly depends on the choice of the non-linear activation function associated with each neuron. However, deciding on the best activation is non-trivial and the choice depends on the architecture, hyper-parameters, and even on the dataset. Typically these activations are fixed by hand before training. Here, we demonstrate how to eliminate the reliance on first picking fixed activation functions by using flexible parametric rational functions instead. The resulting Padé Activation Units (PAUs) can both approximate common activation functions and also learn new ones while providing compact representations. Our empirical evidence shows that end-to-end learning deep networks with PAUs can increase the predictive performance. Moreover, PAUs pave the way to approximations with provable robustness.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/ml-research/pau</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJlBSkHtDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJlKrkSFPH" data-number="1699">
      <h4>
        <a href="/forum?id=SJlKrkSFPH">
            A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES
        </a>
      
        
          <a href="/pdf?id=SJlKrkSFPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=dvij%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dvij@google.com">Krishnamurthy (Dj) Dvijotham</a>, <a href="/profile?email=j.hayes%40cs.ucl.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="j.hayes@cs.ucl.ac.uk">Jamie Hayes</a>, <a href="/profile?email=bballe%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bballe@google.com">Borja Balle</a>, <a href="/profile?email=zkolter%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zkolter@cs.cmu.edu">Zico Kolter</a>, <a href="/profile?email=chongliqin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chongliqin@google.com">Chongli Qin</a>, <a href="/profile?email=agyorgy%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="agyorgy@google.com">Andras Gyorgy</a>, <a href="/profile?email=kaix%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kaix@mit.edu">Kai Xiao</a>, <a href="/profile?email=sgowal%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sgowal@google.com">Sven Gowal</a>, <a href="/profile?email=pushmeet%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pushmeet@google.com">Pushmeet Kohli</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#SJlKrkSFPH-details-168" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJlKrkSFPH-details-168"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">verification of machine learning, certified robustness of neural networks</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJlKrkSFPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkgpBJrtvS" data-number="1708">
      <h4>
        <a href="/forum?id=SkgpBJrtvS">
            Contrastive Representation Distillation
        </a>
      
        
          <a href="/pdf?id=SkgpBJrtvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yonglong%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yonglong@mit.edu">Yonglong Tian</a>, <a href="/profile?email=dilipkay%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dilipkay@google.com">Dilip Krishnan</a>, <a href="/profile?email=phillipi%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="phillipi@mit.edu">Phillip Isola</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SkgpBJrtvS-details-643" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkgpBJrtvS-details-643"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Knowledge Distillation, Representation Learning, Contrastive Learning, Mutual Information</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Representation/knowledge distillation by maximizing mutual information between teacher and student</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">  Often we wish to transfer representational knowledge from one neural network to another. Examples include distilling a large network into a smaller one, transferring knowledge from one sensory modality to a second, or ensembling a collection of models into a single estimator. Knowledge distillation, the standard approach to these problems, minimizes the KL divergence between the probabilistic outputs of a teacher and student network. We demonstrate that this objective ignores important structural knowledge of the teacher network. This motivates an alternative objective by which we train a student to capture significantly more information in the teacher's representation of the data. We formulate this objective as contrastive learning. Experiments demonstrate that our resulting new objective outperforms knowledge distillation on a variety of knowledge transfer tasks, including single model compression, ensemble distillation, and cross-modal transfer. When combined with knowledge distillation, our method sets a state of the art in many transfer tasks, sometimes even outperforming the teacher network.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/HobbitLong/RepDistiller</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkgpBJrtvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyeaSkrYPH" data-number="1710">
      <h4>
        <a href="/forum?id=HyeaSkrYPH">
            Certified Defenses for Adversarial Patches
        </a>
      
        
          <a href="/pdf?id=HyeaSkrYPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=pchiang%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pchiang@cs.umd.edu">Ping-yeh Chiang*</a>, <a href="/profile?email=rn9zm%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rn9zm@cs.umd.edu">Renkun Ni*</a>, <a href="/profile?email=akader%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="akader@cs.umd.edu">Ahmed Abdelkader</a>, <a href="/profile?email=chenzhu%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenzhu@cs.umd.edu">Chen Zhu</a>, <a href="/profile?email=studer%40cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="studer@cornell.edu">Christoph Studor</a>, <a href="/profile?email=tomg%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tomg@cs.umd.edu">Tom Goldstein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 15 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#HyeaSkrYPH-details-657" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyeaSkrYPH-details-657"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Adversarial patch attacks are among one of the most practical threat models against real-world computer vision systems. This paper studies certified and empirical defenses against patch attacks. We begin with a set of experiments showing that most existing defenses, which work by pre-processing input images to mitigate adversarial patches, are easily broken by simple white-box adversaries. Motivated by this finding, we propose the first certified defense against patch attacks, and propose faster methods for its training. Furthermore, we experiment with different patch shapes for testing, obtaining surprisingly good robustness transfer across shapes, and present preliminary results on certified defense against sparse attacks. Our complete implementation can be found on: https://github.com/Ping-C/certifiedpatchdefense.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">certified defenses, patch attack, adversarial robustness, sparse defense</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/Ping-C/certifiedpatchdefense</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HyeaSkrYPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJlxIJBFDr" data-number="1715">
      <h4>
        <a href="/forum?id=HJlxIJBFDr">
            Sample Efficient Policy Gradient Methods with Recursive Variance Reduction
        </a>
      
        
          <a href="/pdf?id=HJlxIJBFDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=panxu%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="panxu@cs.ucla.edu">Pan Xu</a>, <a href="/profile?email=fxgao1160%40engineering.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fxgao1160@engineering.ucla.edu">Felicia Gao</a>, <a href="/profile?email=qgu%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="qgu@cs.ucla.edu">Quanquan Gu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HJlxIJBFDr-details-562" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJlxIJBFDr-details-562"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Improving the sample efficiency in reinforcement learning has been a long-standing research problem. In this work, we aim to reduce the sample complexity of existing policy gradient methods. We propose a novel policy gradient algorithm called SRVR-PG, which only requires <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="497" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mrow><mo>/</mo></mrow><msup><mi>ϵ</mi><mrow><mn>3</mn><mrow><mo>/</mo></mrow><mn>2</mn></mrow></msup><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>\footnote{<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="498" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c22C5"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> notation hides constant factors.} episodes to find an <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="499" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ϵ</mi></math></mjx-assistive-mml></mjx-container>-approximate stationary point of the nonconcave performance function <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="500" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-b mjx-i"><mjx-c class="mjx-c1D73D TEX-BI"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>J</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">θ</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> (i.e., <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="501" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-b mjx-i"><mjx-c class="mjx-c1D73D TEX-BI"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="bold-italic">θ</mi></math></mjx-assistive-mml></mjx-container> such that <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="502" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2225"></mjx-c></mjx-mo><mjx-mi class="mjx-n"><mjx-c class="mjx-c2207"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-b mjx-i"><mjx-c class="mjx-c1D73D TEX-BI"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-msubsup><mjx-mo class="mjx-n" noic="true"><mjx-c class="mjx-c2225"></mjx-c></mjx-mo><mjx-script style="vertical-align: -0.288em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-spacer style="margin-top: 0.18em;"></mjx-spacer><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msubsup><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2264"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo data-mjx-texclass="ORD" fence="false" stretchy="false">∥</mo><mi mathvariant="normal">∇</mi><mi>J</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">θ</mi><mo stretchy="false">)</mo><msubsup><mo data-mjx-texclass="ORD">∥</mo><mn>2</mn><mn>2</mn></msubsup><mo>≤</mo><mi>ϵ</mi></math></mjx-assistive-mml></mjx-container>). This sample complexity improves the existing result <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="503" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mrow><mo>/</mo></mrow><msup><mi>ϵ</mi><mrow><mn>5</mn><mrow><mo>/</mo></mrow><mn>3</mn></mrow></msup><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> for stochastic variance reduced policy gradient algorithms by a factor of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="504" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mrow><mo>/</mo></mrow><msup><mi>ϵ</mi><mrow><mn>1</mn><mrow><mo>/</mo></mrow><mn>6</mn></mrow></msup><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>. In addition, we also propose a variant of SRVR-PG with parameter exploration, which explores the initial policy parameter from a prior probability distribution. We conduct numerical experiments on classic control problems in reinforcement learning to validate the performance of our proposed algorithms.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Policy Gradient, Reinforcement Learning, Sample Efficiency</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJlxIJBFDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1egIyBFPS" data-number="1717">
      <h4>
        <a href="/forum?id=r1egIyBFPS">
            Deep Symbolic Superoptimization Without Human Knowledge
        </a>
      
        
          <a href="/pdf?id=r1egIyBFPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=hshi%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hshi@ucsd.edu">Hui Shi</a>, <a href="/profile?email=yang.zhang2%40ibm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yang.zhang2@ibm.com">Yang Zhang</a>, <a href="/profile?email=xinyun.chen%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xinyun.chen@berkeley.edu">Xinyun Chen</a>, <a href="/profile?email=yuandong%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuandong@fb.com">Yuandong Tian</a>, <a href="/profile?email=jzhao%40ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jzhao@ucsd.edu">Jishen Zhao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#r1egIyBFPS-details-594" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1egIyBFPS-details-594"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep  symbolic superoptimization refers to the task of applying deep learning methods to simplify symbolic expressions.   Existing approaches either perform supervised training on human-constructed datasets that defines equivalent expression pairs, or apply reinforcement learning with human-defined equivalent trans-formation actions.  In short,  almost all existing methods rely on human knowledge to define equivalence, which suffers from large labeling cost and learning bias, because it is almost impossible to define and comprehensive equivalent set. We thus propose HISS, a reinforcement learning framework for symbolic super-optimization that keeps human outside the loop.  HISS introduces a tree-LSTM encoder-decoder network with attention to ensure tractable learning.   Our experiments show that HISS can discover more simplification rules than existing human-dependent methods, and can learn meaningful embeddings for symbolic expressions, which are indicative of equivalence.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1egIyBFPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJgzLkBKPB" data-number="1721">
      <h4>
        <a href="/forum?id=SJgzLkBKPB">
            Explain Your Move: Understanding Agent Actions Using Specific and Relevant Feature Attribution
        </a>
      
        
          <a href="/pdf?id=SJgzLkBKPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=nikpuri%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nikpuri@adobe.com">Nikaash Puri</a>, <a href="/profile?email=dce.sukriti%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dce.sukriti@gmail.com">Sukriti Verma</a>, <a href="/profile?email=piygupta%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="piygupta@adobe.com">Piyush Gupta</a>, <a href="/profile?email=dhruvkayastha%40iitkgp.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="dhruvkayastha@iitkgp.ac.in">Dhruv Kayastha</a>, <a href="/profile?email=shripad%40smail.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="shripad@smail.iitm.ac.in">Shripad Deshmukh</a>, <a href="/profile?email=kbalaji%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kbalaji@adobe.com">Balaji Krishnamurthy</a>, <a href="/profile?email=sameer%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sameer@uci.edu">Sameer Singh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 04 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="#SJgzLkBKPB-details-783" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJgzLkBKPB-details-783"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a model-agnostic approach to explain the behaviour of black-box deep RL agents, trained to play Atari and board games, by highlighting relevant portions of the input state.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">As deep reinforcement learning (RL) is applied to more tasks, there is a need to visualize and understand the behavior of learned agents. Saliency maps explain agent behavior by highlighting the features of the input state that are most relevant for the agent in taking an action. Existing perturbation-based approaches to compute saliency often highlight regions of the input that are not relevant to the action taken by the agent. Our proposed approach, SARFA (Specific and Relevant Feature Attribution), generates more focused saliency maps by balancing two aspects (specificity and relevance) that capture different desiderata of saliency. The first captures the impact of perturbation on the relative expected reward of the action to be explained. The second downweighs irrelevant features that alter the relative expected rewards of actions other than the action to be explained. We compare SARFA with existing approaches on agents trained to play board games (Chess and Go) and Atari games (Breakout, Pong and Space Invaders). We show through illustrative examples (Chess, Atari, Go), human studies (Chess), and automated evaluation methods (Chess) that SARFA generates saliency maps that are more interpretable for humans than existing approaches. For the code release and demo videos, see: https://nikaashpuri.github.io/sarfa-saliency/.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://nikaashpuri.github.io/sarfa-saliency/</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep Reinforcement Learning, Saliency maps, Chess, Go, Atari, Interpretable AI, Explainable AI</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJgzLkBKPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1gX8kBtPr" data-number="1722">
      <h4>
        <a href="/forum?id=B1gX8kBtPr">
            Universal Approximation with Certified Networks
        </a>
      
        
          <a href="/pdf?id=B1gX8kBtPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mbaader%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="mbaader@inf.ethz.ch">Maximilian Baader</a>, <a href="/profile?email=matthew.mirman%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthew.mirman@inf.ethz.ch">Matthew Mirman</a>, <a href="/profile?email=martin.vechev%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="martin.vechev@inf.ethz.ch">Martin Vechev</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#B1gX8kBtPr-details-722" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1gX8kBtPr-details-722"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial robustness, universal approximation, certified network, interval bound propagation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We prove that for a large class of functions f there exists an interval certified robust network approximating f up to arbitrary precision.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Training neural networks to be certifiably robust is critical to ensure their safety against adversarial attacks. However, it is currently very difficult to train a neural network that is both accurate and certifiably robust. In this work we take a step towards addressing this challenge. We prove that for every continuous function <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="505" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></mjx-assistive-mml></mjx-container>, there exists a network <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="506" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> such that:
      (i) <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="507" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> approximates <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="508" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></mjx-assistive-mml></mjx-container> arbitrarily close, and (ii) simple interval bound propagation of a region <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="509" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi></math></mjx-assistive-mml></mjx-container> through <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="510" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container> yields a result that is arbitrarily close to the optimal output of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="511" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></mjx-assistive-mml></mjx-container> on <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="512" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D435 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi></math></mjx-assistive-mml></mjx-container>. Our result can be seen as a Universal Approximation Theorem for interval-certified ReLU networks. To the best of our knowledge, this is the first work to prove the existence of accurate, interval-certified networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/eth-sri/UniversalCertificationTheory</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1gX8kBtPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkeIIkHKvS" data-number="1730">
      <h4>
        <a href="/forum?id=rkeIIkHKvS">
            Measuring and Improving the Use of Graph Information in Graph Neural Networks
        </a>
      
        
          <a href="/pdf?id=rkeIIkHKvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yfhou%40cse.cuhk.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yfhou@cse.cuhk.edu.hk">Yifan Hou</a>, <a href="/profile?email=jzhang%40cse.cuhk.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jzhang@cse.cuhk.edu.hk">Jian Zhang</a>, <a href="/profile?email=jcheng%40cse.cuhk.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jcheng@cse.cuhk.edu.hk">James Cheng</a>, <a href="/profile?email=klma%40cse.cuhk.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="klma@cse.cuhk.edu.hk">Kaili Ma</a>, <a href="/profile?email=tbma%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="tbma@comp.nus.edu.sg">Richard T. B. Ma</a>, <a href="/profile?email=hzchen%40cse.cuhk.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="hzchen@cse.cuhk.edu.hk">Hongzhi Chen</a>, <a href="/profile?email=mcyang%40cse.cuhk.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="mcyang@cse.cuhk.edu.hk">Ming-Chang Yang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#rkeIIkHKvS-details-57" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkeIIkHKvS-details-57"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Graph neural networks (GNNs) have been widely used for representation learning on graph data. However, there is limited understanding on how much performance GNNs actually gain from graph data. This paper introduces a context-surrounding GNN framework and proposes two smoothness metrics to measure the quantity and quality of information obtained from graph data. A new, improved GNN model, called CS-GNN, is then devised to improve the use of graph information based on the smoothness values of a graph. CS-GNN is shown to achieve better performance than existing methods in different types of real graphs. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/yifan-h/CS-GNN</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkeIIkHKvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJgLLyrYwB" data-number="1731">
      <h4>
        <a href="/forum?id=HJgLLyrYwB">
            State-only Imitation with Transition Dynamics Mismatch
        </a>
      
        
          <a href="/pdf?id=HJgLLyrYwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=gangwan2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gangwan2@illinois.edu">Tanmay Gangwani</a>, <a href="/profile?email=jianpeng%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianpeng@illinois.edu">Jian Peng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#HJgLLyrYwB-details-267" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJgLLyrYwB-details-267"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Algorithm for imitation with state-only expert demonstrations; builds on adversarial-IRL; experiments with transition dynamics mismatch b/w expert and imitator</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Imitation Learning (IL) is a popular paradigm for training agents to achieve complicated goals by leveraging expert behavior, rather than dealing with the hardships of designing a correct reward function. With the environment modeled as a Markov Decision Process (MDP), most of the existing IL algorithms are contingent on the availability of expert demonstrations in the same MDP as the one in which a new imitator policy is to be learned. This is uncharacteristic of many real-life scenarios where discrepancies between the expert and the imitator MDPs are common, especially in the transition dynamics function. Furthermore, obtaining expert actions may be costly or infeasible, making the recent trend towards state-only IL (where expert demonstrations constitute only states or observations) ever so promising. Building on recent adversarial imitation approaches that are motivated by the idea of divergence minimization, we present a new state-only IL algorithm in this paper. It divides the overall optimization objective into two subproblems by introducing an indirection step and solves the subproblems iteratively. We show that our algorithm is particularly effective when there is a transition dynamics mismatch between the expert and imitator MDPs, while the baseline IL methods suffer from performance degradation. To analyze this, we construct several interesting MDPs by modifying the configuration parameters for the MuJoCo locomotion tasks from OpenAI Gym.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Imitation learning, Reinforcement Learning, Inverse Reinforcement Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/tgangwani/RL-Indirect-imitation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJgLLyrYwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByxdUySKvS" data-number="1734">
      <h4>
        <a href="/forum?id=ByxdUySKvS">
            Adversarial AutoAugment
        </a>
      
        
          <a href="/pdf?id=ByxdUySKvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zhangxinyu10%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhangxinyu10@huawei.com">Xinyu Zhang</a>, <a href="/profile?email=wangqiang168%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wangqiang168@huawei.com">Qiang Wang</a>, <a href="/profile?email=zhangjian157%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhangjian157@huawei.com">Jian Zhang</a>, <a href="/profile?email=zorro.zhongzhao%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zorro.zhongzhao@huawei.com">Zhao Zhong</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="#ByxdUySKvS-details-98" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByxdUySKvS-details-98"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Automatic Data Augmentation, Adversarial Learning, Reinforcement Learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce the idea of adversarial learning into automatic data augmentation to improve the generalization  of a targe network.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Data augmentation (DA) has been widely utilized to improve generalization in training deep neural networks. Recently, human-designed data augmentation has been gradually replaced by automatically learned augmentation policy. Through finding the best policy in well-designed search space of data augmentation, AutoAugment (Cubuk et al., 2019) can significantly improve validation accuracy on image classification tasks. However, this approach is not computationally practical for large-scale problems. In this paper, we develop an adversarial method to arrive at a computationally-affordable solution called Adversarial AutoAugment, which can simultaneously optimize target related object and augmentation policy search loss. The augmentation policy network attempts to increase the training loss of a target network through generating adversarial augmentation policies, while the target network can learn more robust features from harder examples to improve the generalization. In contrast to prior work, we reuse the computation in target network training for policy evaluation, and dispense with the retraining of the target network. Compared to AutoAugment, this leads to about 12x reduction in computing cost and 11x shortening in time overhead on ImageNet. We show experimental results of our approach on CIFAR-10/CIFAR-100, ImageNet, and demonstrate significant performance improvements over state-of-the-art. On CIFAR-10, we achieve a top-1 test error of 1.36%, which is the currently best performing single model. On ImageNet, we achieve a leading performance of top-1 accuracy 79.40% on ResNet-50 and 80.00% on ResNet-50-D without extra data.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByxdUySKvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJgd81SYwr" data-number="1735">
      <h4>
        <a href="/forum?id=BJgd81SYwr">
            Meta Dropout: Learning to Perturb Latent Features for Generalization
        </a>
      
        
          <a href="/pdf?id=BJgd81SYwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=haebeom.lee%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="haebeom.lee@kaist.ac.kr">Hae Beom Lee</a>, <a href="/profile?email=namsan%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="namsan@kaist.ac.kr">Taewook Nam</a>, <a href="/profile?email=eunhoy%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="eunhoy@kaist.ac.kr">Eunho Yang</a>, <a href="/profile?email=sjhwang82%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjhwang82@kaist.ac.kr">Sung Ju Hwang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#BJgd81SYwr-details-863" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJgd81SYwr-details-863"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/haebeom-lee/metadrop</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJgd81SYwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkgsUJrtDB" data-number="1741">
      <h4>
        <a href="/forum?id=HkgsUJrtDB">
            Rényi Fair Inference
        </a>
      
        
          <a href="/pdf?id=HkgsUJrtDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=baharlou%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="baharlou@usc.edu">Sina Baharlouei</a>, <a href="/profile?email=nouiehed%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nouiehed@usc.edu">Maher Nouiehed</a>, <a href="/profile?email=beirami%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="beirami@mit.edu">Ahmad Beirami</a>, <a href="/profile?email=razaviya%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="razaviya@usc.edu">Meisam Razaviyayn</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#HkgsUJrtDB-details-683" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkgsUJrtDB-details-683"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Machine learning algorithms have been increasingly deployed in critical automated decision-making systems that directly affect human lives. When these algorithms are solely trained to minimize the training/test error, they could suffer from systematic discrimination against individuals based on their sensitive attributes, such as gender or race. Recently, there has been a surge in machine learning society to develop algorithms for fair machine learning. 
      In particular, several adversarial learning procedures have been proposed to impose fairness. Unfortunately, these algorithms either can only impose fairness up to linear dependence between the variables, or they lack computational convergence guarantees. In this paper, we use Rényi correlation as a measure of fairness of machine learning models and develop a general training framework to impose fairness. In particular, we propose a min-max formulation which balances the accuracy and fairness when solved to optimality. For the case of discrete sensitive attributes, we suggest an iterative algorithm with theoretical convergence guarantee for solving the proposed min-max problem. Our algorithm and analysis are then specialized to fair classification and fair clustering problems. To demonstrate the performance of the proposed Rényi fair inference framework in practice, we compare it with well-known existing methods on several benchmark datasets. Experiments indicate that the proposed method has favorable empirical performance against state-of-the-art approaches.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkgsUJrtDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJlRUkrFPS" data-number="1748">
      <h4>
        <a href="/forum?id=SJlRUkrFPS">
            Learning transport cost from subset correspondence
        </a>
      
        
          <a href="/pdf?id=SJlRUkrFPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ruishan%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruishan@stanford.edu">Ruishan Liu</a>, <a href="/profile?email=akshay7%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="akshay7@gmail.com">Akshay Balsubramani</a>, <a href="/profile?email=jamesyzou%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jamesyzou@gmail.com">James Zou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SJlRUkrFPS-details-949" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJlRUkrFPS-details-949"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Learning to align multiple datasets is an important problem with many applications, and it is especially useful when we need to integrate multiple experiments or correct for confounding. Optimal transport (OT) is a principled approach to align  datasets, but a key challenge in applying OT is that we need to specify a cost function that accurately captures how the two datasets are related. Reliable cost functions are typically not available and practitioners often resort to using hand-crafted or Euclidean cost even if it may not be appropriate. In this work, we investigate how to learn the cost function using a small amount of side information which is often available. The side information we consider captures subset correspondence---i.e. certain subsets of points in the two data sets are known to be related. For example, we may have some images labeled as cars in both datasets; or we may have a common annotated cell type in single-cell data from two batches. We develop an end-to-end optimizer (OT-SI) that differentiates through the Sinkhorn algorithm and effectively learns the suitable cost function from side information. On systematic experiments in images, marriage-matching and single-cell RNA-seq, our method substantially outperform state-of-the-art benchmarks. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/drive/folders/1TSqWqF7k0j4WzZ67YshVzI0YYC7EK6tm?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJlRUkrFPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SklkDkSFPB" data-number="1750">
      <h4>
        <a href="/forum?id=SklkDkSFPB">
            BlockSwap: Fisher-guided Block Substitution for Network Compression on a Budget
        </a>
      
        
          <a href="/pdf?id=SklkDkSFPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jack.turner%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jack.turner@ed.ac.uk">Jack Turner</a>, <a href="/profile?email=elliot.j.crowley%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="elliot.j.crowley@ed.ac.uk">Elliot J. Crowley</a>, <a href="/profile?email=mob%40inf.ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="mob@inf.ed.ac.uk">Michael O'Boyle</a>, <a href="/profile?email=a.storkey%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.storkey@ed.ac.uk">Amos Storkey</a>, <a href="/profile?email=g.d.b.gray%40ed.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="g.d.b.gray@ed.ac.uk">Gavin Gray</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#SklkDkSFPB-details-588" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SklkDkSFPB-details-588"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A simple and effective method for reducing large neural networks to flexible parameter targets based on block substitution.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The desire to map neural networks to varying-capacity devices has led to the development of a wealth of compression techniques, many of which involve replacing standard convolutional blocks in a large network with cheap alternative blocks. However, not all blocks are created equally; for a required compute budget there may exist a potent combination of many different cheap blocks, though exhaustively searching for such a combination is prohibitively expensive. In this work, we develop BlockSwap: a fast algorithm for choosing networks with interleaved block types by passing a single minibatch of training data through randomly initialised networks and gauging their Fisher potential. These networks can then be used as students and distilled with the original large network as a teacher. We demonstrate the effectiveness of the chosen networks across CIFAR-10 and ImageNet for classification, and COCO for detection, and provide a comprehensive ablation study of our approach. BlockSwap quickly explores possible block configurations using a simple architecture ranking system, yielding highly competitive networks in orders of magnitude less time than most architecture search techniques (e.g. under 5 minutes on a single GPU for CIFAR-10).</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">model compression, architecture search, efficiency, budget, convolutional neural networks</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/BayesWatch/pytorch-blockswap</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SklkDkSFPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Syx1DkSYwB" data-number="1751">
      <h4>
        <a href="/forum?id=Syx1DkSYwB">
            Variance Reduction With Sparse Gradients
        </a>
      
        
          <a href="/pdf?id=Syx1DkSYwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=elibol%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="elibol@cs.berkeley.edu">Melih Elibol</a>, <a href="/profile?email=lihualei%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lihualei@stanford.edu">Lihua Lei</a>, <a href="/profile?email=jordan%40cs.berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jordan@cs.berkeley.edu">Michael I. Jordan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#Syx1DkSYwB-details-947" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Syx1DkSYwB-details-947"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">optimization, variance reduction, machine learning, deep neural networks</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We use sparsity to improve the computational complexity of variance reduction methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Variance reduction methods such as SVRG and SpiderBoost use a mixture of large and small batch gradients to reduce the variance of stochastic gradients. Compared to SGD, these methods require at least double the number of operations per update to model parameters. To reduce the computational cost of these methods, we introduce a new sparsity operator: The random-top-k operator. Our operator reduces computational complexity by estimating gradient sparsity exhibited in a variety of applications by combining the top-k operator and the randomized coordinate descent operator. With this operator, large batch gradients offer an extra benefit beyond variance reduction: A reliable estimate of gradient sparsity. Theoretically, our algorithm is at least as good as the best algorithm (SpiderBoost), and further excels in performance whenever the random-top-k operator captures gradient sparsity. Empirically, our algorithm consistently outperforms SpiderBoost using various models on various tasks including image classification, natural language processing, and sparse matrix factorization. We also provide empirical evidence to support the intuition behind our algorithm via a simple gradient entropy computation, which serves to quantify gradient sparsity at every iteration.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">http://s000.tinyupload.com/index.php?file_id=39477384063585848544</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Syx1DkSYwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byg1v1HKDB" data-number="1752">
      <h4>
        <a href="/forum?id=Byg1v1HKDB">
            Abductive Commonsense Reasoning
        </a>
      
        
          <a href="/pdf?id=Byg1v1HKDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=chandrab%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="chandrab@allenai.org">Chandra Bhagavatula</a>, <a href="/profile?email=ronanlb%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="ronanlb@allenai.org">Ronan Le Bras</a>, <a href="/profile?email=chaitanyam%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="chaitanyam@allenai.org">Chaitanya Malaviya</a>, <a href="/profile?email=keisukes%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="keisukes@allenai.org">Keisuke Sakaguchi</a>, <a href="/profile?email=arih%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="arih@allenai.org">Ari Holtzman</a>, <a href="/profile?email=hrashkin%40uw.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hrashkin@uw.edu">Hannah Rashkin</a>, <a href="/profile?email=dougd%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="dougd@allenai.org">Doug Downey</a>, <a href="/profile?email=scottyih%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="scottyih@fb.com">Wen-tau Yih</a>, <a href="/profile?email=yejinc%40allenai.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="yejinc@allenai.org">Yejin Choi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#Byg1v1HKDB-details-215" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byg1v1HKDB-details-215"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Abductive Reasoning, Commonsense Reasoning, Natural Language Inference, Natural Language Generation</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Abductive reasoning is inference to the most plausible explanation. For example, if Jenny finds her house in a mess when she returns from work, and remembers that she left a window open, she can hypothesize that a thief broke into her house and  caused  the  mess,  as  the  most  plausible  explanation.  While  abduction has long been considered to be at the core of how people interpret and read between the lines in natural language (Hobbs et al., 1988), there has been relatively little research in support of abductive natural language inference and generation. We present the first study that investigates the viability of language-based abductive reasoning.  We introduce a challenge dataset, ART, that consists of over 20k commonsense narrative contexts and 200k explanations. Based on this dataset, we conceptualize two new tasks – (i) Abductive NLI: a multiple-choice question answering task for choosing the more likely explanation, and (ii) Abductive NLG: a conditional generation task for explaining given observations in natural language. On Abductive NLI, the best model achieves 68.9% accuracy, well below human performance of 91.4%.  On Abductive NLG, the current best language generators struggle even more, as they lack reasoning capabilities that are trivial for humans. Our analysis leads to new insights into the types of reasoning that deep pre-trained language models fail to perform—despite their strong performance on the related but  more  narrowly  defined  task  of entailment NLI—pointing  to  interesting  avenues for future research.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Byg1v1HKDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Byg-wJSYDS" data-number="1756">
      <h4>
        <a href="/forum?id=Byg-wJSYDS">
            Discrepancy Ratio: Evaluating Model Performance When Even Experts Disagree on the Truth
        </a>
      
        
          <a href="/pdf?id=Byg-wJSYDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ilovchinsky%40butterflynetwork.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ilovchinsky@butterflynetwork.com">Igor Lovchinsky</a>, <a href="/profile?email=adaks%40butterflynetwork.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adaks@butterflynetwork.com">Alon Daks</a>, <a href="/profile?email=imalkin%40butterflynetwork.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="imalkin@butterflynetwork.com">Israel Malkin</a>, <a href="/profile?email=psamangouei%40butterflynetwork.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="psamangouei@butterflynetwork.com">Pouya Samangouei</a>, <a href="/profile?email=asaeedi%40butterflynetwork.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="asaeedi@butterflynetwork.com">Ardavan Saeedi</a>, <a href="/profile?email=yliu%40butterflynetwork.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yliu@butterflynetwork.com">Yang Liu</a>, <a href="/profile?email=ssankaranarayanan%40butterflynetwork.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ssankaranarayanan@butterflynetwork.com">Swami Sankaranarayanan</a>, <a href="/profile?email=tgafner%40butterflynetwork.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tgafner@butterflynetwork.com">Tomer Gafner</a>, <a href="/profile?email=bsternlieb%40butterflynetwork.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bsternlieb@butterflynetwork.com">Ben Sternlieb</a>, <a href="/profile?email=pmaher%40butterflynetwork.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pmaher@butterflynetwork.com">Patrick Maher</a>, <a href="/profile?email=nsilberman%40butterflynetwork.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nsilberman@butterflynetwork.com">Nathan Silberman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#Byg-wJSYDS-details-529" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Byg-wJSYDS-details-529"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Evaluation Metrics, Medical Imaging</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A framework for evaluating model performance when even experts disagree on what the ground truth is.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In most machine learning tasks unambiguous ground truth labels can easily be acquired. However, this luxury is often not afforded to many high-stakes, real-world scenarios such as medical image interpretation, where even expert human annotators typically exhibit very high levels of disagreement with one another. While prior works have focused on overcoming noisy labels during training, the question of how to evaluate models when annotators disagree about ground truth has remained largely unexplored. To address this, we propose the discrepancy ratio: a novel, task-independent and principled framework for validating machine learning models in the presence of high label noise. Conceptually, our approach evaluates a model by comparing its predictions to those of human annotators, taking into account the degree to which annotators disagree with one another. While our approach is entirely general, we show that in the special case of binary classification, our proposed metric can be evaluated in terms of simple, closed-form expressions that depend only on aggregate statistics of the labels and not on any individual label. Finally, we demonstrate how this framework can be used effectively to validate machine learning models using two real-world tasks from medical imaging. The discrepancy ratio metric reveals what conventional metrics do not: that our models not only vastly exceed the average human performance, but even exceed the performance of the best human experts in our datasets.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Byg-wJSYDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJgSwyBKvr" data-number="1764">
      <h4>
        <a href="/forum?id=HJgSwyBKvr">
            Weakly Supervised Disentanglement with Guarantees
        </a>
      
        
          <a href="/pdf?id=HJgSwyBKvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ruishu%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruishu@stanford.edu">Rui Shu</a>, <a href="/profile?email=cynnjjs%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cynnjjs@stanford.edu">Yining Chen</a>, <a href="/profile?email=abhishk%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhishk@google.com">Abhishek Kumar</a>, <a href="/profile?email=ermon%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ermon@cs.stanford.edu">Stefano Ermon</a>, <a href="/profile?email=pooleb%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pooleb@google.com">Ben Poole</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="#HJgSwyBKvr-details-890" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJgSwyBKvr-details-890"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">disentanglement, theory of disentanglement, representation learning, generative models</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We construct a theoretical framework for weakly supervised disentanglement and conducted lots of experiments to back up the theory.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Learning disentangled representations that correspond to factors of variation in real-world data is critical to interpretable and human-controllable machine learning. Recently, concerns about the viability of learning disentangled representations in a purely unsupervised manner has spurred a shift toward the incorporation of weak supervision. However, there is currently no formalism that identifies when and how weak supervision will guarantee disentanglement. To address this issue, we provide a theoretical framework to assist in analyzing the disentanglement guarantees (or lack thereof) conferred by weak supervision when coupled with learning algorithms based on distribution matching. We empirically verify the guarantees and limitations of several weak supervision methods (restricted labeling, match-pairing, and rank-pairing), demonstrating the predictive power and usefulness of our theoretical framework.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/google-research/google-research/tree/master/weak_disentangle</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJgSwyBKvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJlHwkBYDH" data-number="1766">
      <h4>
        <a href="/forum?id=SJlHwkBYDH">
            Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks
        </a>
      
        
          <a href="/pdf?id=SJlHwkBYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jdlin%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="jdlin@hust.edu.cn">Jiadong Lin</a>, <a href="/profile?email=cbsong%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="cbsong@hust.edu.cn">Chuanbiao Song</a>, <a href="/profile?email=brooklet60%40hust.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="brooklet60@hust.edu.cn">Kun He</a>, <a href="/profile?email=wanglw%40cis.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanglw@cis.pku.edu.cn">Liwei Wang</a>, <a href="/profile?email=jeh%40cs.cornell.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jeh@cs.cornell.edu">John E. Hopcroft</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 01 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SJlHwkBYDH-details-366" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJlHwkBYDH-details-366"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We proposed a Nesterov Iterative Fast Gradient Sign Method (NI-FGSM) and a Scale-Invariant attack Method (SIM) that can boost the transferability of adversarial examples for image classification.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep learning models are vulnerable to adversarial examples crafted by applying human-imperceptible perturbations on benign inputs. However, under the black-box setting, most existing adversaries often have a poor transferability to attack other defense models. In this work, from the perspective of regarding the adversarial example generation as an optimization process, we propose two new methods to improve the transferability of adversarial examples, namely Nesterov Iterative Fast Gradient Sign Method (NI-FGSM) and Scale-Invariant attack Method (SIM). NI-FGSM aims to adapt Nesterov accelerated gradient into the iterative attacks so as to effectively look ahead and improve the transferability of adversarial examples. While SIM is based on our discovery on the scale-invariant property of deep learning models, for which we leverage to optimize the adversarial perturbations over the scale copies of the input images so as to avoid "overfitting” on the white-box model being attacked and generate more transferable adversarial examples. NI-FGSM and SIM can be naturally integrated to build a robust gradient-based attack to generate more transferable adversarial examples against the defense models. Empirical results on ImageNet dataset demonstrate that our attack methods exhibit higher transferability and achieve higher attack success rates than state-of-the-art gradient-based attacks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/JHL-HUST/SI-NI-FGSM</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial examples, adversarial attack, transferability, Nesterov accelerated gradient, scale invariance</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJlHwkBYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJgIPJBFvH" data-number="1767">
      <h4>
        <a href="/forum?id=SJgIPJBFvH">
            Fantastic Generalization Measures and Where to Find Them
        </a>
      
        
          <a href="/pdf?id=SJgIPJBFvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ydjiang%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ydjiang@google.com">Yiding Jiang*</a>, <a href="/profile?email=neyshabur%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="neyshabur@google.com">Behnam Neyshabur*</a>, <a href="/profile?email=dilipkay%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dilipkay@google.com">Hossein Mobahi</a>, <a href="/profile?email=hmobahi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hmobahi@google.com">Dilip Krishnan</a>, <a href="/profile?email=bengio%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bengio@google.com">Samy Bengio</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#SJgIPJBFvH-details-542" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJgIPJBFvH-details-542"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We empirically study generalization measures over more than 2000 models, identify common pitfall in existing practice of studying generalization measures and provide some new bounds based on measures in our study.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Generalization of deep networks has been intensely researched in recent years, resulting in a number of theoretical bounds and empirically motivated measures. However, most papers proposing such measures only study a small set of models, leaving open the question of whether these measures are truly useful in practice. We present the first large scale study of generalization bounds and measures in deep networks. We train over two thousand CIFAR-10 networks with systematic changes in important hyper-parameters. We attempt to uncover potential causal relationships between each measure and generalization, by using rank correlation coefficient and its modified forms. We analyze the results and show that some of the studied measures are very promising for further research.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/open?id=1_6oUG94d0C3x7x2Vd935a2QqY-OaAWAM</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Generalization, correlation, experiments</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJgIPJBFvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJxwPJHFwS" data-number="1770">
      <h4>
        <a href="/forum?id=BJxwPJHFwS">
            Robustness Verification for Transformers
        </a>
      
        
          <a href="/pdf?id=BJxwPJHFwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zhouxingshichn%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhouxingshichn@gmail.com">Zhouxing Shi</a>, <a href="/profile?email=huan%40huan-zhang.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="huan@huan-zhang.com">Huan Zhang</a>, <a href="/profile?email=kw%40kwchang.net" class="profile-link" data-toggle="tooltip" data-placement="top" title="kw@kwchang.net">Kai-Wei Chang</a>, <a href="/profile?email=aihuang%40tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="aihuang@tsinghua.edu.cn">Minlie Huang</a>, <a href="/profile?email=chohsieh%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chohsieh@cs.ucla.edu">Cho-Jui Hsieh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 06 Sep 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#BJxwPJHFwS-details-166" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJxwPJHFwS-details-166"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose the first algorithm for verifying the robustness of Transformers.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Robustness verification that aims to formally certify the prediction behavior of neural networks has become an important tool for understanding model behavior and obtaining safety guarantees. However, previous methods can usually only handle neural networks with relatively simple architectures. In this paper, we consider the robustness verification problem for Transformers. Transformers have complex self-attention layers that pose many challenges for verification, including cross-nonlinearity and cross-position dependency, which have not been discussed in previous works. We resolve these challenges and develop the first robustness verification algorithm for Transformers. The certified robustness bounds computed by our method are significantly tighter than those by naive Interval Bound Propagation. These bounds also shed light on interpreting Transformers as they consistently reflect the importance of different words in sentiment analysis.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Robustness, Verification, Transformers</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/shizhouxing/Robustness-Verification-for-Transformers</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJxwPJHFwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJgcvJBFvB" data-number="1778">
      <h4>
        <a href="/forum?id=HJgcvJBFvB">
            Network Randomization: A Simple Technique for Generalization in Deep Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=HJgcvJBFvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kiminlee%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="kiminlee@kaist.ac.kr">Kimin Lee</a>, <a href="/profile?email=kibok%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kibok@umich.edu">Kibok Lee</a>, <a href="/profile?email=jinwoos%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jinwoos@kaist.ac.kr">Jinwoo Shin</a>, <a href="/profile?email=honglak%40eecs.umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="honglak@eecs.umich.edu">Honglak Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HJgcvJBFvB-details-493" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJgcvJBFvB-details-493"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep reinforcement learning, Generalization in visual domains</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a simple randomization technique for improving generalization in deep reinforcement learning across tasks with various unseen visual patterns.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep reinforcement learning (RL) agents often fail to generalize to unseen environments (yet semantically similar to trained agents), particularly when they are trained on high-dimensional state spaces, such as images. In this paper, we propose a simple technique to improve a generalization ability of deep RL agents by introducing a randomized (convolutional) neural network that randomly perturbs input observations. It enables trained agents to adapt to new domains by learning robust features invariant across varied and randomized environments. Furthermore, we consider an inference method based on the Monte Carlo approximation to reduce the variance induced by this randomization. We demonstrate the superiority of our method across 2D CoinRun, 3D DeepMind Lab exploration and 3D robotics control tasks: it significantly outperforms various regularization and data augmentation methods for the same purpose.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/pokaxpoka/netrand</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJgcvJBFvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rke2P1BFwS" data-number="1781">
      <h4>
        <a href="/forum?id=rke2P1BFwS">
            Tensor Decompositions for Temporal Knowledge Base Completion
        </a>
      
        
          <a href="/pdf?id=rke2P1BFwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=timothee.lax%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="timothee.lax@gmail.com">Timothée Lacroix</a>, <a href="/profile?email=guillaume.obozinski%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="guillaume.obozinski@epfl.ch">Guillaume Obozinski</a>, <a href="/profile?email=usunier%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="usunier@fb.com">Nicolas Usunier</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 08 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rke2P1BFwS-details-851" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rke2P1BFwS-details-851"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">knowledge base completion, temporal embeddings</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose new tensor decompositions and associated regularizers to obtain state of the art performances on temporal knowledge base completion.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Most algorithms for representation learning and link prediction in relational data have been designed for static data. However, the data they are applied to usually evolves with time, such as friend graphs in social networks or user interactions with items in recommender systems. This is also the case for knowledge bases, which contain facts such as (US, has president, B. Obama, [2009-2017]) that are valid only at certain points in time. For the problem of link prediction under temporal constraints, i.e., answering queries of the form (US, has president, ?, 2012), we propose a solution inspired by the canonical decomposition of tensors of order 4.
      We introduce new regularization schemes and present an extension of ComplEx that achieves state-of-the-art performance. Additionally, we propose a new dataset for knowledge base completion constructed from Wikidata, larger than previous benchmarks by an order of magnitude, as a new reference for evaluating temporal and non-temporal link prediction methods. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">http://s000.tinyupload.com/?file_id=37064871945432677939</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rke2P1BFwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkxTwkrKDB" data-number="1785">
      <h4>
        <a href="/forum?id=HkxTwkrKDB">
            On Universal Equivariant Set Networks
        </a>
      
        
          <a href="/pdf?id=HkxTwkrKDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=nimrod.segol%40weizmann.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="nimrod.segol@weizmann.ac.il">Nimrod Segol</a>, <a href="/profile?email=yaron.lipman%40weizmann.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="yaron.lipman@weizmann.ac.il">Yaron Lipman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HkxTwkrKDB-details-959" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkxTwkrKDB-details-959"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, universality, set functions, equivariance</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Settling permutation equivariance universality for popular deep models. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Using deep neural networks that are either invariant or equivariant to permutations in order to learn functions on unordered sets has become prevalent. The most popular, basic models are DeepSets (Zaheer et al. 2017) and PointNet (Qi et al. 2017). While known to be universal for approximating invariant functions, DeepSets and PointNet are not known to be universal when approximating equivariant set functions. On the other hand, several recent equivariant set architectures have been proven equivariant universal (Sannai et al. 2019, Keriven and Peyre 2019), however these models either use layers that are not permutation equivariant (in the standard sense) and/or use higher order tensor variables which are less practical. There is, therefore, a gap in understanding the universality of popular equivariant set models versus theoretical ones. 
      			
      In this paper we close this gap by proving that: (i) PointNet is not equivariant universal; and (ii) adding a single linear transmission  layer makes PointNet universal. We call this architecture PointNetST and argue it is the simplest permutation equivariant universal model known to date. Another consequence is that DeepSets is universal, and also PointNetSeg, a popular point cloud segmentation network (used e.g., in Qi et al. 2017) is universal.
      		
      The key theoretical tool used to prove the above results is an explicit characterization of all permutation equivariant polynomial layers. Lastly, we provide numerical experiments validating the theoretical results and comparing different permutation equivariant models.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkxTwkrKDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rklk_ySYPB" data-number="1788">
      <h4>
        <a href="/forum?id=rklk_ySYPB">
            Provable robustness against all adversarial <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="513" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>l</mi><mi>p</mi></msub></math></mjx-assistive-mml></mjx-container>-perturbations for <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="514" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo>≥</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container>
        </a>
      
        
          <a href="/pdf?id=rklk_ySYPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=francesco91.croce%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="francesco91.croce@gmail.com">Francesco Croce</a>, <a href="/profile?email=matthias.hein%40uni-tuebingen.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="matthias.hein@uni-tuebingen.de">Matthias Hein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 03 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rklk_ySYPB-details-634" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rklk_ySYPB-details-634"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce a method to train models with provable robustness wrt all the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="515" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>l</mi><mi>p</mi></msub></math></mjx-assistive-mml></mjx-container>-norms for <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="516" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo>≥</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container> simultaneously.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In recent years several adversarial attacks and defenses have been proposed. Often seemingly robust models turn out to be non-robust when more sophisticated attacks are used. One way out of this dilemma are provable robustness guarantees. While provably robust models for specific <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="517" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>l</mi><mi>p</mi></msub></math></mjx-assistive-mml></mjx-container>-perturbation models have been developed, we show that they do not come with any guarantee against other <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="518" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45E TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>l</mi><mi>q</mi></msub></math></mjx-assistive-mml></mjx-container>-perturbations. We propose a new regularization scheme, MMR-Universal, for ReLU networks which enforces robustness wrt <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="519" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>l</mi><mn>1</mn></msub></math></mjx-assistive-mml></mjx-container>- \textit{and} <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="520" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-n" size="s"><mjx-c class="mjx-c221E"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>l</mi><mi mathvariant="normal">∞</mi></msub></math></mjx-assistive-mml></mjx-container>-perturbations and show how that leads to the first provably robust models wrt any <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="521" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>l</mi><mi>p</mi></msub></math></mjx-assistive-mml></mjx-container>-norm for <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="522" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2265"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo>≥</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container>.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial robustness, provable guarantees</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/fra31/mmr-universal</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rklk_ySYPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1eyO1BFPr" data-number="1789">
      <h4>
        <a href="/forum?id=B1eyO1BFPr">
            Don't Use Large Mini-batches, Use Local SGD
        </a>
      
        
          <a href="/pdf?id=B1eyO1BFPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tao.lin%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="tao.lin@epfl.ch">Tao Lin</a>, <a href="/profile?email=sebastian.stich%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastian.stich@epfl.ch">Sebastian U. Stich</a>, <a href="/profile?email=kumarkshitijpatel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kumarkshitijpatel@gmail.com">Kumar Kshitij Patel</a>, <a href="/profile?email=martin.jaggi%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="martin.jaggi@epfl.ch">Martin Jaggi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="#B1eyO1BFPr-details-5" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1eyO1BFPr-details-5"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Mini-batch stochastic gradient methods (SGD) are state of the art for distributed training of deep neural networks. 
      Drastic increases in the mini-batch sizes have lead to key efficiency and scalability gains in recent years. 
      However, progress faces a major roadblock, as models trained with large batches often do not generalize well, i.e. they do not show good accuracy on new data.
      As a remedy, we propose a \emph{post-local} SGD and show that it significantly improves the generalization performance compared to large-batch training on standard benchmarks while enjoying the same efficiency (time-to-accuracy) and scalability. We further provide an extensive study of the communication efficiency vs. performance trade-offs associated with a host of \emph{local SGD} variants. 
      </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1eyO1BFPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1eWOJHKvB" data-number="1794">
      <h4>
        <a href="/forum?id=B1eWOJHKvB">
            Kernel of CycleGAN as a principal homogeneous space
        </a>
      
        
          <a href="/pdf?id=B1eWOJHKvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=nikita.moriakov%40radboudumc.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="nikita.moriakov@radboudumc.nl">Nikita Moriakov</a>, <a href="/profile?email=jonasadl%40kth.se" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonasadl@kth.se">Jonas Adler</a>, <a href="/profile?email=jonas.teuwen%40radboudumc.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonas.teuwen@radboudumc.nl">Jonas Teuwen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#B1eWOJHKvB-details-273" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1eWOJHKvB-details-273"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Generative models, CycleGAN</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">The space of approximate solutions of CycleGAN admits a lot of symmetry, and an identity loss does not fix this.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Unpaired image-to-image translation has attracted significant interest due to the invention of CycleGAN, a method which utilizes a combination of adversarial and cycle consistency losses to avoid the need for paired data. It is known that the CycleGAN problem might admit multiple solutions, and our goal in this paper is to analyze the space of exact solutions and to give perturbation bounds for approximate solutions. We show theoretically that the exact solution space is invariant with respect to automorphisms of the underlying probability spaces, and, furthermore, that the group of automorphisms acts freely and transitively on the space of exact solutions. We examine the case of zero pure CycleGAN loss first in its generality, and, subsequently, expand our analysis to approximate solutions for extended CycleGAN loss where identity loss term is included. In order to demonstrate that these results are applicable, we show that under mild conditions nontrivial smooth automorphisms exist. Furthermore, we provide empirical evidence that neural networks can learn these automorphisms with unexpected and unwanted results. We conclude that finding optimal solutions to the CycleGAN loss does not necessarily lead to the envisioned result in image-to-image translation tasks and that underlying hidden symmetries can render the result useless.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1eWOJHKvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxGuJrFvS" data-number="1796">
      <h4>
        <a href="/forum?id=ryxGuJrFvS">
            Distributionally Robust Neural Networks
        </a>
      
        
          <a href="/pdf?id=ryxGuJrFvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ssagawa%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ssagawa@cs.stanford.edu">Shiori Sagawa*</a>, <a href="/profile?email=koh.pangwei%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="koh.pangwei@gmail.com">Pang Wei Koh*</a>, <a href="/profile?email=thashim%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="thashim@stanford.edu">Tatsunori B. Hashimoto</a>, <a href="/profile?email=pliang%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pliang@cs.stanford.edu">Percy Liang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 02 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#ryxGuJrFvS-details-703" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxGuJrFvS-details-703"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Overparameterized neural networks can be distributionally robust, but only when you account for generalization. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Overparameterized neural networks can be highly accurate on average on an i.i.d. test set, yet consistently fail on atypical groups of the data (e.g., by learning spurious correlations that hold on average but not in such groups). Distributionally robust optimization (DRO) allows us to learn models that instead minimize the worst-case training loss over a set of pre-defined groups. However, we find that naively applying group DRO to overparameterized neural networks fails: these models can perfectly fit the training data, and any model with vanishing average training loss also already has vanishing worst-case training loss. Instead, the poor worst-case performance arises from poor generalization on some groups. By coupling group DRO models with increased regularization---stronger-than-typical L2 regularization or early stopping---we achieve substantially higher worst-group accuracies, with 10-40 percentage point improvements on a natural language inference task and two image tasks, while maintaining high average accuracies. Our results suggest that regularization is important for worst-group generalization in the overparameterized regime, even if it is not needed for average generalization. Finally, we introduce a stochastic optimization algorithm for the group DRO setting and provide convergence guarantees for the new algorithm.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">distributionally robust optimization, deep learning, robustness, generalization, regularization</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/kohpangwei/group_DRO</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxGuJrFvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkx7_1rKwS" data-number="1797">
      <h4>
        <a href="/forum?id=Hkx7_1rKwS">
            On Solving Minimax Optimization Locally: A Follow-the-Ridge Approach
        </a>
      
        
          <a href="/pdf?id=Hkx7_1rKwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yuanhao-16%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuanhao-16@mails.tsinghua.edu.cn">Yuanhao Wang*</a>, <a href="/profile?email=gdzhang%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gdzhang@cs.toronto.edu">Guodong Zhang*</a>, <a href="/profile?email=jba%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jba@cs.toronto.edu">Jimmy Ba</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>26 Replies</span>
        
        
      </div>
      
        <a href="#Hkx7_1rKwS-details-573" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkx7_1rKwS-details-573"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">minimax optimization, smooth differentiable games, local convergence, generative adversarial networks, optimization</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Many tasks in modern machine learning can be formulated as finding equilibria in sequential games. In particular, two-player zero-sum sequential games, also known as minimax optimization, have received growing interest. It is tempting to apply gradient descent to solve minimax optimization given its popularity and success in supervised learning. However, it has been noted that naive application of gradient descent fails to find some local minimax and can converge to non-local-minimax points. In this paper, we propose Follow-the-Ridge (FR), a novel algorithm that provably converges to and only converges to local minimax. We show theoretically that the algorithm addresses the notorious rotational behaviour of gradient dynamics, and is compatible with preconditioning and positive momentum. Empirically, FR solves toy minimax problems and improves the convergence of GAN training compared to the recent minimax optimization algorithms. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hkx7_1rKwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJxSOJStPr" data-number="1802">
      <h4>
        <a href="/forum?id=SJxSOJStPr">
            A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning
        </a>
      
        
          <a href="/pdf?id=SJxSOJStPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=soochan.lee%40vision.snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="soochan.lee@vision.snu.ac.kr">Soochan Lee</a>, <a href="/profile?email=junsooha%40hanyang.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="junsooha@hanyang.ac.kr">Junsoo Ha</a>, <a href="/profile?email=96lives%40snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="96lives@snu.ac.kr">Dongsu Zhang</a>, <a href="/profile?email=gunhee%40snu.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="gunhee@snu.ac.kr">Gunhee Kim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#SJxSOJStPr-details-295" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJxSOJStPr-details-295"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose an expansion-based approach for task-free continual learning for the first time. Our model consists of a set of neural network experts and expands the number of experts under the Bayesian nonparametric principle.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Despite the growing interest in continual learning, most of its contemporary works have been studied in a rather restricted setting where tasks are clearly distinguishable, and task boundaries are known during training. However, if our goal is to develop an algorithm that learns as humans do, this setting is far from realistic, and it is essential to develop a methodology that works in a task-free manner. Meanwhile, among several branches of continual learning, expansion-based methods have the advantage of eliminating catastrophic forgetting by allocating new resources to learn new data. In this work, we propose an expansion-based approach for task-free continual learning. Our model, named Continual Neural Dirichlet Process Mixture (CN-DPM), consists of a set of neural network experts that are in charge of a subset of the data. CN-DPM expands the number of experts in a principled way under the Bayesian nonparametric framework. With extensive experiments, we show that our model successfully performs task-free continual learning for both discriminative and generative tasks such as image classification and image generation.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">continual learning, task-free, task-agnostic</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/soochan-lee/CN-DPM</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJxSOJStPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryeHuJBtPH" data-number="1803">
      <h4>
        <a href="/forum?id=ryeHuJBtPH">
            Hyper-SAGNN: a self-attention based graph neural network for hypergraphs
        </a>
      
        
          <a href="/pdf?id=ryeHuJBtPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ruochiz%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruochiz@andrew.cmu.edu">Ruochi Zhang</a>, <a href="/profile?email=logic.zys%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="logic.zys@gmail.com">Yuesong Zou</a>, <a href="/profile?email=jianma%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jianma@cs.cmu.edu">Jian Ma</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#ryeHuJBtPH-details-337" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryeHuJBtPH-details-337"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">graph neural network, hypergraph, representation learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We develop a new self-attention based graph neural network called Hyper-SAGNN applicable to homogeneous and heterogeneous hypergraphs with variable hyperedge sizes that can fulfill tasks like node classification and hyperedge prediction. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Graph representation learning for hypergraphs can be utilized to extract patterns among higher-order interactions that are critically important in many real world problems. Current approaches designed for hypergraphs, however, are unable to handle different types of hypergraphs and are typically not generic for various learning tasks. Indeed, models that can predict variable-sized heterogeneous hyperedges have not been available. Here we develop a new self-attention based graph neural network called Hyper-SAGNN applicable to homogeneous and heterogeneous hypergraphs with variable hyperedge sizes. We perform extensive evaluations on multiple datasets, including four benchmark network datasets and two single-cell Hi-C datasets in genomics. We demonstrate that Hyper-SAGNN significantly outperforms state-of-the-art methods on traditional tasks while also achieving great performance on a new task called outsider identification. We believe that Hyper-SAGNN will be useful for graph representation learning to uncover complex higher-order interactions in different applications. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/drive/folders/1kIOc4SlAJllUJsrr2OnZ4izIQIw2JexU?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryeHuJBtPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyxjOyrKvr" data-number="1816">
      <h4>
        <a href="/forum?id=HyxjOyrKvr">
            Neural Epitome Search for Architecture-Agnostic Network Compression
        </a>
      
        
          <a href="/pdf?id=HyxjOyrKvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zhoudaquan21%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhoudaquan21@gmail.com">Daquan Zhou</a>, <a href="/profile?email=jinxiaojie%40bytedance.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jinxiaojie@bytedance.com">Xiaojie Jin</a>, <a href="/profile?email=andrewhoux%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="andrewhoux@gmail.com">Qibin Hou</a>, <a href="/profile?email=kaixin.wang%40u.nus.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kaixin.wang@u.nus.edu">Kaixin Wang</a>, <a href="/profile?email=yangjianchao%40bytedance.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yangjianchao@bytedance.com">Jianchao Yang</a>, <a href="/profile?email=elefjia%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="elefjia@nus.edu.sg">Jiashi Feng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HyxjOyrKvr-details-651" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyxjOyrKvr-details-651"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present a novel neural network compression method which can reuse the parameters efficiently to reduce the model size.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Traditional compression methods including network pruning, quantization, low rank factorization and knowledge distillation all assume that network architectures and parameters should be hardwired.  In this work, we propose a new perspective on network compression, i.e., network parameters can be disentangled from the architectures.  From this viewpoint, we present the Neural Epitome Search (NES), a new neural network compression approach that learns to find compact yet expressive epitomes for weight parameters of a specified network architecture end-to-end. The complete network to compress can be generated from the learned epitome via a novel transformation method that adaptively transforms the epitomes to match shapes of the given architecture. Compared with existing compression methods, NES allows the weight tensors to be independent of the architecture design and hence can achieve a good trade-off between model compression rate and performance given a specific model size constraint. Experiments demonstrate that, on ImageNet, when taking MobileNetV2 as backbone, our approach improves the full-model baseline by 1.47% in top-1 accuracy with 25% MAdd reduction and AutoML for Model Compression (AMC) by 2.5% with nearly the same compression ratio. Moreover, taking EfficientNet-B0 as baseline, our NES yields an improvement of 1.2% but are with 10% less MAdd.  In particular, our method achieves a new state-of-the-art results of 77.5% under mobile settings (&lt;350M MAdd). Code will be made publicly available.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Network Compression, Classification, Deep Learning, Weights Sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HyxjOyrKvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJxzFySKwH" data-number="1832">
      <h4>
        <a href="/forum?id=SJxzFySKwH">
            On the Equivalence between Positional Node Embeddings and Structural Graph Representations
        </a>
      
        
          <a href="/pdf?id=SJxzFySKwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=bsriniv%40purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bsriniv@purdue.edu">Balasubramaniam Srinivasan</a>, <a href="/profile?email=ribeiro%40cs.purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ribeiro@cs.purdue.edu">Bruno Ribeiro</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 22 Sep 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="#SJxzFySKwH-details-516" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJxzFySKwH-details-516"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We develop the foundations of a unifying theoretical framework connecting node embeddings and structural graph representations through invariant theory</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This work provides the first unifying theoretical framework for node (positional) embeddings and structural graph representations, bridging methods like matrix factorization and graph neural networks. Using invariant theory, we show that relationship between structural representations and node embeddings is analogous to that of a distribution and its samples. We prove that all tasks that can be performed by node embeddings can also be performed by structural representations and vice-versa. We also show that the concept of transductive and inductive learning is unrelated to node embeddings and graph representations, clearing another source of confusion in the literature. Finally, we introduce new practical guidelines to generating  and  using  node  embeddings, which further augments standard operating procedures used today.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Graph Neural Networks, Structural Graph Representations, Node Embeddings, Relational Learning, Invariant Theory, Theory, Deep Learning, Representational Power, Graph Isomorphism</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/PurdueMINDS/Equivalence</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJxzFySKwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1g8K1BFwS" data-number="1841">
      <h4>
        <a href="/forum?id=S1g8K1BFwS">
            Probability Calibration for Knowledge Graph Embedding Models
        </a>
      
        
          <a href="/pdf?id=S1g8K1BFwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tabacof%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tabacof@gmail.com">Pedro Tabacof</a>, <a href="/profile?email=luca.costabello%40accenture.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="luca.costabello@accenture.com">Luca Costabello</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#S1g8K1BFwS-details-1" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1g8K1BFwS-details-1"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a novel method to calibrate knowledge graph embedding models without the need of negative examples.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Knowledge graph embedding research has overlooked the problem of probability calibration. We show popular embedding models are indeed uncalibrated. That means probability estimates associated to predicted triples are unreliable. We present a novel method to calibrate a model when ground truth negatives are not available, which is the usual case in knowledge graphs. We propose to use Platt scaling and isotonic regression alongside our method. Experiments on three datasets with ground truth negatives show our contribution leads to well calibrated models when compared to the gold standard of using negatives. We get significantly better results than the uncalibrated models from all calibration methods. We show isotonic regression offers the best the performance overall, not without trade-offs. We also show that calibrated models reach state-of-the-art accuracy without the need to define relation-specific decision thresholds.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">knowledge graph embeddings, probability calibration, calibration, graph representation learning, knowledge graphs</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1g8K1BFwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BylsKkHYvH" data-number="1853">
      <h4>
        <a href="/forum?id=BylsKkHYvH">
            Why Not to Use Zero Imputation? Correcting Sparsity Bias in Training Neural Networks
        </a>
      
        
          <a href="/pdf?id=BylsKkHYvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=joonyoung.yi%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="joonyoung.yi@kaist.ac.kr">Joonyoung Yi</a>, <a href="/profile?email=sehkmg%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="sehkmg@kaist.ac.kr">Juhyuk Lee</a>, <a href="/profile?email=preppie%40yuhs.ac" class="profile-link" data-toggle="tooltip" data-placement="top" title="preppie@yuhs.ac">Kwang Joon Kim</a>, <a href="/profile?email=sjhwang82%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjhwang82@kaist.ac.kr">Sung Ju Hwang</a>, <a href="/profile?email=eunhoy%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="eunhoy@kaist.ac.kr">Eunho Yang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="#BylsKkHYvH-details-511" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BylsKkHYvH-details-511"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Handling missing data is one of the most fundamental problems in machine learning. Among many approaches, the simplest and most intuitive way is zero imputation, which treats the value of a missing entry simply as zero. However, many studies have experimentally confirmed that zero imputation results in suboptimal performances in training neural networks. Yet, none of the existing work has explained what brings such performance degradations. In this paper, we introduce the variable sparsity problem (VSP), which describes a phenomenon where the output of a predictive model largely varies with respect to the rate of missingness in the given input, and show that it adversarially affects the model performance. We first theoretically analyze this phenomenon and propose a simple yet effective technique to handle missingness, which we refer to as Sparsity Normalization (SN), that directly targets and resolves the VSP. We further experimentally validate SN on diverse benchmark datasets, to show that debiasing the effect of input-level sparsity improves the performance and stabilizes the training of neural networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Missing Data, Collaborative Filtering, Health Care, Tabular Data, High Dimensional Data, Deep Learning, Neural Networks</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/JoonyoungYi/sparsity-normalization</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BylsKkHYvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkx1qkrKPr" data-number="1862">
      <h4>
        <a href="/forum?id=Hkx1qkrKPr">
            DropEdge: Towards Deep Graph Convolutional Networks on Node Classification
        </a>
      
        
          <a href="/pdf?id=Hkx1qkrKPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yu.rong%40hotmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yu.rong@hotmail.com">Yu Rong</a>, <a href="/profile?email=hwenbing%40126.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hwenbing@126.com">Wenbing Huang</a>, <a href="/profile?email=tingyangxu%40tencent.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tingyangxu@tencent.com">Tingyang Xu</a>, <a href="/profile?email=jzhuang%40uta.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jzhuang@uta.edu">Junzhou Huang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>34 Replies</span>
        
        
      </div>
      
        <a href="#Hkx1qkrKPr-details-291" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkx1qkrKPr-details-291"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper proposes DropEdge, a novel and flexible technique to alleviate over-smoothing and overfitting issue in deep Graph Convolutional Networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Over-fitting and over-smoothing are two main obstacles of developing deep Graph Convolutional Networks (GCNs) for node classification. In particular, over-fitting weakens the generalization ability on small dataset, while over-smoothing impedes model training by isolating output representations from the input features with the increase in network depth. This paper proposes DropEdge, a novel and flexible technique to alleviate both issues. At its core, DropEdge randomly removes a certain number of edges from the input graph at each training epoch, acting like a data augmenter and also a message passing reducer. Furthermore, we theoretically demonstrate that DropEdge either reduces the convergence speed of over-smoothing or relieves the information loss caused by it. More importantly, our DropEdge is a general skill that can be equipped with many other backbone models (e.g. GCN, ResGCN, GraphSAGE, and JKNet) for enhanced performance. Extensive experiments on several benchmarks verify that DropEdge consistently improves the performance on a variety of both shallow and deep GCNs. The effect of DropEdge on preventing over-smoothing is empirically visualized and validated as well. Codes are released on~https://github.com/DropEdge/DropEdge.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">graph neural network, over-smoothing, over-fitting, dropedge, graph convolutional networks</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/DropEdge/DropEdge</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hkx1qkrKPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJe-91BtvH" data-number="1866">
      <h4>
        <a href="/forum?id=BJe-91BtvH">
            Masked Based Unsupervised Content Transfer
        </a>
      
        
          <a href="/pdf?id=BJe-91BtvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sagiebenaim%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sagiebenaim@gmail.com">Ron Mokady</a>, <a href="/profile?email=ron.mokady%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ron.mokady@gmail.com">Sagie Benaim</a>, <a href="/profile?email=wolf%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wolf@fb.com">Lior Wolf</a>, <a href="/profile?email=amit.bermano%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="amit.bermano@gmail.com">Amit Bermano</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#BJe-91BtvH-details-25" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJe-91BtvH-details-25"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We consider the problem of translating, in an unsupervised manner, between two domains where one contains some additional information compared to the other. The proposed method  disentangles the common and separate parts of these domains and, through the generation of a mask, focuses the attention of the underlying network to the desired augmentation alone, without wastefully reconstructing the entire target. This enables state-of-the-art quality and variety of content translation, as demonstrated through extensive quantitative and qualitative evaluation. Our method is also capable of adding the separate content of different guide images and domains as well as remove existing separate content. Furthermore, our method enables weakly-supervised semantic segmentation of the separate part of each domain, where only class labels are provided. Our code is available at https://github.com/rmokady/mbu-content-tansfer.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/rmokady/mbu-content-tansfer</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJe-91BtvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJlZ5ySKPH" data-number="1867">
      <h4>
        <a href="/forum?id=BJlZ5ySKPH">
            U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation
        </a>
      
        
          <a href="/pdf?id=BJlZ5ySKPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=takis0112%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="takis0112@gmail.com">Junho Kim</a>, <a href="/profile?email=minjaekim%40ncsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="minjaekim@ncsoft.com">Minjae Kim</a>, <a href="/profile?email=hwkang0131%40ncsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hwkang0131@ncsoft.com">Hyeonwoo Kang</a>, <a href="/profile?email=lkwanghee%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lkwanghee@gmail.com">Kwang Hee Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 28 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#BJlZ5ySKPH-details-962" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJlZ5ySKPH-details-962"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Image-to-Image Translation, Generative Attentional Networks, Adaptive Layer-Instance Normalization</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose a novel method for unsupervised image-to-image translation, which incorporates a new attention module and a new learnable normalization function in an end-to-end manner. The attention module guides our model to focus on more important regions distinguishing between source and target domains based on the attention map obtained by the auxiliary classifier. Unlike previous attention-based method which cannot handle the geometric changes between domains, our model can translate both images requiring holistic changes and images requiring large shape changes. Moreover, our new AdaLIN (Adaptive Layer-Instance Normalization) function helps our attention-guided model to flexibly control the amount of change in shape and texture by learned parameters depending on datasets. Experimental results show the superiority of the proposed method compared to the existing state-of-the-art models with a fixed network architecture and hyper-parameters. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/taki0112/UGATIT</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJlZ5ySKPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkem91rtDB" data-number="1871">
      <h4>
        <a href="/forum?id=rkem91rtDB">
            Inductive and Unsupervised Representation Learning on Graph Structured Objects
        </a>
      
        
          <a href="/pdf?id=rkem91rtDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wanglichenxj%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanglichenxj@gmail.com">Lichen Wang</a>, <a href="/profile?email=bzong%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bzong@nec-labs.com">Bo Zong</a>, <a href="/profile?email=maqq%40bu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="maqq@bu.edu">Qianqian Ma</a>, <a href="/profile?email=weicheng%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="weicheng@nec-labs.com">Wei Cheng</a>, <a href="/profile?email=jni%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jni@nec-labs.com">Jingchao Ni</a>, <a href="/profile?email=wyu%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wyu@nec-labs.com">Wenchao Yu</a>, <a href="/profile?email=yanchi%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yanchi@nec-labs.com">Yanchi Liu</a>, <a href="/profile?email=dsong%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dsong@nec-labs.com">Dongjin Song</a>, <a href="/profile?email=haifeng%40nec-labs.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="haifeng@nec-labs.com">Haifeng Chen</a>, <a href="/profile?email=yunfu%40ece.neu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yunfu@ece.neu.edu">Yun Fu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 25 May 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#rkem91rtDB-details-680" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkem91rtDB-details-680"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper proposed a novel framework for graph similarity learning in inductive and unsupervised scenario.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Inductive and unsupervised graph learning is a critical technique for predictive or information retrieval tasks where label information is difficult to obtain. It is also challenging to make graph learning inductive and unsupervised at the same time, as learning processes guided by reconstruction error based loss functions inevitably demand graph similarity evaluation that is usually computationally intractable. In this paper, we propose a general framework SEED (Sampling, Encoding, and Embedding Distributions) for inductive and unsupervised representation learning on graph structured objects. Instead of directly dealing with the computational challenges raised by graph similarity evaluation, given an input graph, the SEED framework samples a number of subgraphs whose reconstruction errors could be efficiently evaluated, encodes the subgraph samples into a collection of subgraph vectors, and employs the embedding of the subgraph vector distribution as the output vector representation for the input graph. By theoretical analysis, we demonstrate the close connection between SEED and graph isomorphism. Using public benchmark datasets, our empirical study suggests the proposed SEED framework is able to achieve up to 10% improvement, compared with competitive baseline methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Graph representation learning, Graph isomorphism, Graph similarity learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkem91rtDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bke89JBtvB" data-number="1879">
      <h4>
        <a href="/forum?id=Bke89JBtvB">
            Batch-shaping for learning conditional channel gated networks
        </a>
      
        
          <a href="/pdf?id=Bke89JBtvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=behtesha%40qti.qualcomm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="behtesha@qti.qualcomm.com">Babak Ehteshami Bejnordi</a>, <a href="/profile?email=tijmen%40qti.qualcomm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tijmen@qti.qualcomm.com">Tijmen Blankevoort</a>, <a href="/profile?email=mwelling%40qti.qualcomm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mwelling@qti.qualcomm.com">Max Welling</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 03 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#Bke89JBtvB-details-711" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bke89JBtvB-details-711"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A method that trains large capacity neural networks with significantly improved accuracy and lower dynamic computational cost</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present a method that trains large capacity neural networks with significantly improved accuracy and lower dynamic computational cost. This is achieved by gating the deep-learning architecture on a fine-grained-level. Individual convolutional maps are turned on/off conditionally on features in the network. To achieve this, we introduce a new residual block architecture that gates convolutional channels in a fine-grained manner. We also introduce a generally applicable tool batch-shaping that matches the marginal aggregate posteriors of features in a neural network to a pre-specified prior distribution. We use this novel technique to force gates to be more conditional on the data. We present results on CIFAR-10 and ImageNet datasets for image classification, and Cityscapes for semantic segmentation. Our results show that our method can slim down large architectures conditionally, such that the average computational cost on the data is on par with a smaller architecture, but with higher accuracy. In particular, on ImageNet, our ResNet50 and ResNet34 gated networks obtain 74.60% and 72.55% top-1 accuracy compared to the 69.76% accuracy of the baseline ResNet18 model, for similar complexity. We also show that the resulting networks automatically learn to use more features for difficult examples and fewer features for simple examples.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Conditional computation, channel gated networks, gating, Batch-shaping, distribution matching, image classification, semantic segmentation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Bke89JBtvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1xwcyHFDr" data-number="1880">
      <h4>
        <a href="/forum?id=B1xwcyHFDr">
            Learning Robust Representations via Multi-View Information Bottleneck
        </a>
      
        
          <a href="/pdf?id=B1xwcyHFDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=m.federici%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.federici@uva.nl">Marco Federici</a>, <a href="/profile?email=duttanjan%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="duttanjan@gmail.com">Anjan Dutta</a>, <a href="/profile?email=patrickforre%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="patrickforre@gmail.com">Patrick Forré</a>, <a href="/profile?email=nate%40kushman.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="nate@kushman.org">Nate Kushman</a>, <a href="/profile?email=zeynepakata%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zeynepakata@gmail.com">Zeynep Akata</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#B1xwcyHFDr-details-720" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1xwcyHFDr-details-720"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We extend the information bottleneck method to the unsupervised multiview setting and show state of the art results on standard datasets</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The information bottleneck principle provides an information-theoretic method for representation learning, by training an encoder to retain all information which is relevant for predicting the label while minimizing the amount of other, excess information in the representation. The original formulation, however, requires labeled data to identify the superfluous information.  In this work, we extend this ability to the multi-view unsupervised setting, where two views of the same underlying entity are provided but the label is unknown. This enables us to identify superfluous information as that not shared by both views. A theoretical analysis leads to the definition of a new multi-view model that produces state-of-the-art results on the Sketchy dataset and label-limited versions of the MIR-Flickr dataset.  We also extend our theory to the single-view setting by taking advantage of standard data augmentation techniques, empirically showing better generalization capabilities when compared to common unsupervised approaches for representation learning.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/mfederici/Multi-View-Information-Bottleneck</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Information Bottleneck, Multi-View Learning, Representation Learning, Information Theory</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1xwcyHFDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJeq9JBFvH" data-number="1887">
      <h4>
        <a href="/forum?id=SJeq9JBFvH">
            Deep probabilistic subsampling for task-adaptive compressed sensing
        </a>
      
        
          <a href="/pdf?id=SJeq9JBFvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=i.a.m.huijben%40tue.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="i.a.m.huijben@tue.nl">Iris A.M. Huijben</a>, <a href="/profile?email=basveeling%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="basveeling@gmail.com">Bastiaan S. Veeling</a>, <a href="/profile?email=r.j.g.v.sloun%40tue.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="r.j.g.v.sloun@tue.nl">Ruud J.G. van Sloun</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#SJeq9JBFvH-details-964" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJeq9JBFvH-details-964"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The field of deep learning is commonly concerned with optimizing predictive models using large pre-acquired datasets of densely sampled datapoints or signals. In this work, we demonstrate that the deep learning paradigm can be extended to incorporate a subsampling scheme that is jointly optimized under a desired minimum sample rate. We present Deep Probabilistic Subsampling (DPS), a widely applicable framework for task-adaptive compressed sensing that enables end-to end optimization of an optimal subset of signal samples with a subsequent model that performs a required task. We demonstrate strong performance on reconstruction and classification tasks of a toy dataset, MNIST, and CIFAR10 under stringent subsampling rates in both the pixel and the spatial frequency domain. Due to the task-agnostic nature of the framework, DPS is directly applicable to all real-world domains that benefit from sample rate reduction.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJeq9JBFvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJx0q1rtvS" data-number="1898">
      <h4>
        <a href="/forum?id=SJx0q1rtvS">
            Robust anomaly detection and backdoor attack detection via differential privacy
        </a>
      
        
          <a href="/pdf?id=SJx0q1rtvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=min.du%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="min.du@berkeley.edu">Min Du</a>, <a href="/profile?email=ruoxijia%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruoxijia@berkeley.edu">Ruoxi Jia</a>, <a href="/profile?email=dawnsong%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dawnsong@berkeley.edu">Dawn Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SJx0q1rtvS-details-371" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJx0q1rtvS-details-371"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper shows that differential privacy could improve the utility of outlier detection, novelty detection and backdoor attack detection, through both a theoretical analysis and extensive experimental results (constructed and real-world).</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Outlier detection and novelty detection are two important topics for anomaly detection. Suppose the majority of a dataset are drawn from a certain distribution, outlier detection and novelty detection both aim to detect data samples that do not fit the distribution. Outliers refer to data samples within this dataset, while novelties refer to new samples. In the meantime, backdoor poisoning attacks for machine learning models are achieved through injecting poisoning samples into the training dataset, which could be regarded as “outliers” that are intentionally added by attackers. Differential privacy has been proposed to avoid leaking any individual’s information, when aggregated analysis is performed on a given dataset. It is typically achieved by adding random noise, either directly to the input dataset, or to intermediate results of the aggregation mechanism. In this paper, we demonstrate that applying differential privacy could improve the utility of outlier detection and novelty detection, with an extension to detect poisoning samples in backdoor attacks. We first present a theoretical analysis on how differential privacy helps with the detection, and then conduct extensive experiments to validate the effectiveness of differential privacy in improving outlier detection, novelty detection, and backdoor attack detection.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://www.dropbox.com/sh/rt8qzii7wr07g6n/AAAbwokv2sfBeE9XAL2pXv_Aa?dl=0</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">outlier detection, novelty detection, backdoor attack detection, system log anomaly detection, differential privacy</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJx0q1rtvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1gHokBKwS" data-number="1913">
      <h4>
        <a href="/forum?id=B1gHokBKwS">
            Learning to Guide Random Search
        </a>
      
        
          <a href="/pdf?id=B1gHokBKwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ozansener%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ozansener@gmail.com">Ozan Sener</a>, <a href="/profile?email=vkoltun%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vkoltun@gmail.com">Vladlen Koltun</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#B1gHokBKwS-details-100" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1gHokBKwS-details-100"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We improve the sample-efficiency of the random search for functions defined on low-dimensional manifolds. Our method jointly learns the underlying manifold and optimizes the function.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We are interested in derivative-free optimization of high-dimensional functions. The sample complexity of existing methods is high and depends on problem dimensionality, unlike the dimensionality-independent rates of first-order methods. The recent success of deep learning suggests that many datasets lie on low-dimensional manifolds that can be represented by deep nonlinear models. We therefore consider derivative-free optimization of a high-dimensional function that lies on a latent low-dimensional manifold. We develop an online learning approach that learns this manifold while performing the optimization. In other words, we jointly learn the manifold and optimize the function. Our analysis suggests that the presented method significantly reduces sample complexity. We empirically evaluate the method on continuous optimization benchmarks and high-dimensional continuous control problems. Our method achieves significantly lower sample complexity than Augmented Random Search, Bayesian optimization, covariance matrix adaptation (CMA-ES), and other derivative-free optimization algorithms.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Random search, Derivative-free optimization, Learning continuous control</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/intel-isl/LMRS</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1gHokBKwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1lDoJSYDH" data-number="1917">
      <h4>
        <a href="/forum?id=B1lDoJSYDH">
            Lagrangian Fluid Simulation with Continuous Convolutions
        </a>
      
        
          <a href="/pdf?id=B1lDoJSYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=benjamin.ummenhofer%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="benjamin.ummenhofer@intel.com">Benjamin Ummenhofer</a>, <a href="/profile?email=lukas.prantl%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukas.prantl@tum.de">Lukas Prantl</a>, <a href="/profile?email=nils.thuerey%40tum.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="nils.thuerey@tum.de">Nils Thuerey</a>, <a href="/profile?email=vkoltun%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vkoltun@gmail.com">Vladlen Koltun</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#B1lDoJSYDH-details-117" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1lDoJSYDH-details-117"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We learn particle-based fluid simulation with convolutional networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present an approach to Lagrangian fluid simulation with a new type of convolutional network. Our networks process sets of moving particles, which describe fluids in space and time. Unlike previous approaches, we do not build an explicit graph structure to connect the particles but use spatial convolutions as the main differentiable operation that relates particles to their neighbors. To this end we present a simple, novel, and effective extension of N-D convolutions to the continuous domain. We show that our network architecture can simulate different materials, generalizes to arbitrary collision geometries, and can be used for inverse problems. In addition, we demonstrate that our continuous convolutions outperform prior formulations in terms of accuracy and speed.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">particle-based physics, fluid mechanics, continuous convolutions, material estimation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1lDoJSYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkxDoJBYPB" data-number="1918">
      <h4>
        <a href="/forum?id=rkxDoJBYPB">
            Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs
        </a>
      
        
          <a href="/pdf?id=rkxDoJBYPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=adipal%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adipal@google.com">Aditya Paliwal</a>, <a href="/profile?email=fgimeno%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fgimeno@google.com">Felix Gimeno</a>, <a href="/profile?email=vinair%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vinair@google.com">Vinod Nair</a>, <a href="/profile?email=yujiali%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yujiali@google.com">Yujia Li</a>, <a href="/profile?email=mlubin%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mlubin@google.com">Miles Lubin</a>, <a href="/profile?email=pushmeet%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pushmeet@google.com">Pushmeet Kohli</a>, <a href="/profile?email=vinyals%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vinyals@google.com">Oriol Vinyals</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rkxDoJBYPB-details-642" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkxDoJBYPB-details-642"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We use deep RL to learn a policy that directs the search of a genetic algorithm to better optimize the execution cost of computation graphs, and show improved results on real-world TensorFlow graphs.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require training the optimizer on the same graph to be optimized, we propose a learning approach that trains an optimizer offline and then generalizes to previously unseen graphs without further training. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, learning to optimize, combinatorial optimization, computation graphs, model parallelism, learning for systems</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkxDoJBYPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SylKikSYDH" data-number="1922">
      <h4>
        <a href="/forum?id=SylKikSYDH">
            Compressive Transformers for Long-Range Sequence Modelling
        </a>
      
        
          <a href="/pdf?id=SylKikSYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jwrae%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jwrae@google.com">Jack W. Rae</a>, <a href="/profile?email=apotapenko%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="apotapenko@google.com">Anna Potapenko</a>, <a href="/profile?email=sidmj%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sidmj@google.com">Siddhant M. Jayakumar</a>, <a href="/profile?email=chillier%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chillier@google.com">Chloe Hillier</a>, <a href="/profile?email=countzero%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="countzero@google.com">Timothy P. Lillicrap</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="#SylKikSYDH-details-828" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SylKikSYDH-details-828"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Long-range transformer using a compressive memory, achieves sota in wikitext-103 and enwik8 LM benchmarks, release a new book-level LM benchmark PG-19.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning. We find the Compressive Transformer obtains state-of-the-art language modelling results in the WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97bpc respectively. We also find it can model high-frequency speech effectively and can be used as a memory mechanism for RL, demonstrated on an object matching task. To promote the domain of long-range sequence learning, we propose a new open-vocabulary language modelling benchmark derived from books, PG-19.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">memory, language modeling, transformer, compression</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SylKikSYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HylAoJSKvH" data-number="1935">
      <h4>
        <a href="/forum?id=HylAoJSKvH">
            A Stochastic Derivative Free Optimization Method with Momentum
        </a>
      
        
          <a href="/pdf?id=HylAoJSKvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=eduard.gorbunov%40phystech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="eduard.gorbunov@phystech.edu">Eduard Gorbunov</a>, <a href="/profile?email=adel.bibi%40kaust.edu.sa" class="profile-link" data-toggle="tooltip" data-placement="top" title="adel.bibi@kaust.edu.sa">Adel Bibi</a>, <a href="/profile?email=ozan.sener%40intel.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ozan.sener@intel.com">Ozan Sener</a>, <a href="/profile?email=houcine.bergou%40kaust.edu.sa" class="profile-link" data-toggle="tooltip" data-placement="top" title="houcine.bergou@kaust.edu.sa">El Houcine Bergou</a>, <a href="/profile?email=peter.richtarik%40kaust.edu.sa" class="profile-link" data-toggle="tooltip" data-placement="top" title="peter.richtarik@kaust.edu.sa">Peter Richtarik</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HylAoJSKvH-details-888" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HylAoJSKvH-details-888"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We develop and analyze a new derivative free optimization algorithm with momentum and importance sampling with applications to continuous control.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We consider the problem of unconstrained minimization of a smooth objective
      function in <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="523" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c211D TEX-A"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.41em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mi>d</mi></msup></math></mjx-assistive-mml></mjx-container> in setting where only function evaluations are possible. We propose and analyze stochastic zeroth-order method with heavy ball momentum. In particular, we propose, SMTP, a momentum version of the stochastic three-point method (STP) Bergou et al. (2019). We show new complexity results for non-convex, convex and strongly convex functions. We test our method on a collection of learning to continuous control tasks on several MuJoCo Todorov et al. (2012) environments with varying difficulty and compare against STP, other state-of-the-art derivative-free optimization algorithms and against policy gradient methods. SMTP significantly outperforms STP and all other methods that we considered in our numerical experiments. Our second contribution is SMTP with importance sampling which we call SMTP_IS. We provide convergence analysis of this method for non-convex, convex and strongly convex objectives.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">derivative-free optimization, stochastic optimization, heavy ball momentum, importance sampling</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HylAoJSKvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SylzhkBtDB" data-number="1943">
      <h4>
        <a href="/forum?id=SylzhkBtDB">
            Understanding and Improving Information Transfer in Multi-Task Learning
        </a>
      
        
          <a href="/pdf?id=SylzhkBtDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=senwu%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="senwu@cs.stanford.edu">Sen Wu</a>, <a href="/profile?email=hongyang%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hongyang@cs.stanford.edu">Hongyang R. Zhang</a>, <a href="/profile?email=chrismre%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chrismre@stanford.edu">Christopher Ré</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 03 May 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#SylzhkBtDB-details-241" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SylzhkBtDB-details-241"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A Theoretical Study of Multi-Task Learning with Practical Implications for Improving Multi-Task Training and Transfer Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We investigate multi-task learning approaches that use a shared feature representation for all tasks. To better understand the transfer of task information, we study an architecture with a shared module for all tasks and a separate output module for each task. We study the theory of this setting on linear and ReLU-activated models. Our key observation is that whether or not tasks' data are well-aligned can significantly affect the performance of multi-task learning. We show that misalignment between task data can cause negative transfer (or hurt performance) and provide sufficient conditions for positive transfer. Inspired by the theoretical insights, we show that aligning tasks' embedding layers leads to performance gains for multi-task training and transfer learning on the GLUE benchmark and sentiment analysis tasks; for example, we obtained a 2.35% GLUE score average improvement on 5 GLUE tasks over BERT LARGE using our alignment method. We also design an SVD-based task re-weighting scheme and show that it improves the robustness of multi-task training on a multi-label image dataset.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Multi-Task Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SylzhkBtDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HklXn1BKDH" data-number="1945">
      <h4>
        <a href="/forum?id=HklXn1BKDH">
            Learning To Explore Using Active Neural SLAM
        </a>
      
        
          <a href="/pdf?id=HklXn1BKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=chaplot%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="chaplot@cs.cmu.edu">Devendra Singh Chaplot</a>, <a href="/profile?email=dhirajgandhi%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dhirajgandhi@fb.com">Dhiraj Gandhi</a>, <a href="/profile?email=saurabhg%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="saurabhg@illinois.edu">Saurabh Gupta</a>, <a href="/profile?email=abhinavg%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhinavg@cs.cmu.edu">Abhinav Gupta</a>, <a href="/profile?email=rsalakhu%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsalakhu@cs.cmu.edu">Ruslan Salakhutdinov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HklXn1BKDH-details-486" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HklXn1BKDH-details-486"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A modular and hierarchical approach to learn policies for exploring 3D environments.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This work presents a modular and hierarchical approach to learn policies for exploring 3D environments, called `Active Neural SLAM'. Our approach leverages the strengths of both classical and learning-based methods, by using analytical path planners with learned SLAM module, and global and local policies. The use of learning provides flexibility with respect to input modalities (in the SLAM module), leverages structural regularities of the world (in global policies), and provides robustness to errors in state estimation (in local policies). Such use of learning within each module retains its benefits, while at the same time, hierarchical decomposition and modular training allow us to sidestep the high sample complexities associated with training end-to-end policies. Our experiments in visually and physically realistic simulated 3D environments demonstrate the effectiveness of our approach over past learning and geometry-based approaches. The proposed model can also be easily transferred to the PointGoal task and was the winning entry of the CVPR 2019 Habitat PointGoal Navigation Challenge.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Navigation, Exploration</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/devendrachaplot/Neural-SLAM</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HklXn1BKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJem3yHKwH" data-number="1946">
      <h4>
        <a href="/forum?id=HJem3yHKwH">
            EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks
        </a>
      
        
          <a href="/pdf?id=HJem3yHKwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sen9%40purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sen9@purdue.edu">Sanchari Sen</a>, <a href="/profile?email=ravi%40cse.iitm.ac.in" class="profile-link" data-toggle="tooltip" data-placement="top" title="ravi@cse.iitm.ac.in">Balaraman Ravindran</a>, <a href="/profile?email=raghunathan%40purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="raghunathan@purdue.edu">Anand Raghunathan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#HJem3yHKwH-details-473" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJem3yHKwH-details-473"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">ensembles, mixed precision, robustness, adversarial attacks</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose ensembles of mixed-precision DNNs as a new form of defense against adversarial attacks</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their adoption in safety-critical applications such as self-driving cars, drones, and healthcare. Notably, DNNs are vulnerable to adversarial attacks in which small input perturbations can produce catastrophic misclassifications. In this work, we propose EMPIR, ensembles of quantized DNN models with different numerical precisions, as a new approach to increase robustness against adversarial attacks. EMPIR is based on the observation that quantized neural networks often demonstrate much higher robustness to adversarial attacks than full precision networks, but at the cost of a substantial loss in accuracy on the original (unperturbed) inputs. EMPIR overcomes this limitation to achieve the ``best of both worlds", i.e., the higher unperturbed accuracies of the full precision models combined with the higher robustness of the low precision models, by composing them in an ensemble. Further, as low precision DNN models have significantly lower computational and storage requirements than full precision models, EMPIR models only incur modest compute and memory overheads compared to a single full-precision model (&lt;25% in our evaluations). We evaluate EMPIR across a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10 and ImageNet) and under 4 different adversarial attacks. Our results indicate that EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5% for the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets respectively, when compared to single full-precision models, without sacrificing accuracy on the unperturbed inputs.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/sancharisen/EMPIR</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJem3yHKwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkxNh1Stvr" data-number="1948">
      <h4>
        <a href="/forum?id=rkxNh1Stvr">
            Quantifying Point-Prediction Uncertainty in Neural Networks via Residual Estimation with an I/O Kernel
        </a>
      
        
          <a href="/pdf?id=rkxNh1Stvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=qiuxin.nju%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qiuxin.nju@gmail.com">Xin Qiu</a>, <a href="/profile?email=elliot.meyerson%40cognizant.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="elliot.meyerson@cognizant.com">Elliot Meyerson</a>, <a href="/profile?email=risto%40cognizant.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="risto@cognizant.com">Risto Miikkulainen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="#rkxNh1Stvr-details-784" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkxNh1Stvr-details-784"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Uncertainty Estimation, Neural Networks, Gaussian Process</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Learning to Estimate Point-Prediction Uncertainty and Correct Output in Neural Networks</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Neural Networks (NNs) have been extensively used for a wide spectrum of real-world regression tasks, where the goal is to predict a numerical outcome such as revenue, effectiveness, or a quantitative result. In many such tasks, the point prediction is not enough: the uncertainty (i.e. risk or confidence) of that prediction must also be estimated. Standard NNs, which are most often used in such tasks, do not provide uncertainty information. Existing approaches address this issue by combining Bayesian models with NNs, but these models are hard to implement, more expensive to train, and usually do not predict as accurately as standard NNs. In this paper, a new framework (RIO) is developed that makes it possible to estimate uncertainty in any pretrained standard NN. The behavior of the NN is captured by modeling its prediction residuals with a Gaussian Process, whose kernel includes both the NN's input and its output. The framework is justified theoretically and evaluated in twelve real-world datasets, where it is found to (1) provide reliable estimates of uncertainty, (2) reduce the error of the point predictions, and (3) scale well to large datasets. Given that RIO can be applied to any standard NN without modifications to model architecture or training pipeline, it provides an important ingredient for building real-world NN applications.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/leaf-ai/rio-paper</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkxNh1Stvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1gBhkBFDH" data-number="1951">
      <h4>
        <a href="/forum?id=H1gBhkBFDH">
            B-Spline CNNs on Lie groups
        </a>
      
        
          <a href="/pdf?id=H1gBhkBFDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=e.j.bekkers%40tue.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="e.j.bekkers@tue.nl">Erik J Bekkers</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#H1gBhkBFDH-details-616" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1gBhkBFDH-details-616"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">equivariance, Lie groups, B-Splines, G-CNNs, deep learning, group convolution, computer vision, medical image analysis</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">The paper describes a flexible framework for building CNNs that are equivariant to a large class of transformations groups.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Group convolutional neural networks (G-CNNs) can be used to improve classical CNNs by equipping them with the geometric structure of groups. Central in the success of G-CNNs is the lifting of feature maps to higher dimensional disentangled representations, in which data characteristics are effectively learned, geometric data-augmentations are made obsolete, and predictable behavior under geometric transformations (equivariance) is guaranteed via group theory. Currently, however, the practical implementations of G-CNNs are limited to either discrete groups (that leave the grid intact) or continuous compact groups such as rotations (that enable the use of Fourier theory). In this paper we lift these limitations and propose a modular framework for the design and implementation of G-CNNs for arbitrary Lie groups. In our approach the differential structure of Lie groups is used to expand convolution kernels in a generic basis of B-splines that is defined on the Lie algebra. This leads to a flexible framework that enables localized, atrous, and deformable convolutions in G-CNNs by means of respectively localized, sparse and non-uniform B-spline expansions. The impact and potential of our approach is studied on two benchmark datasets: cancer detection in histopathology slides (PCam dataset) in which rotation equivariance plays a key role and facial landmark localization (CelebA dataset) in which scale equivariance is important. In both cases, G-CNN architectures outperform their classical 2D counterparts and the added value of atrous and localized group convolutions is studied in detail.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/ebekkers/gsplinets</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1gBhkBFDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skx82ySYPH" data-number="1953">
      <h4>
        <a href="/forum?id=Skx82ySYPH">
            Neural Outlier Rejection for Self-Supervised Keypoint Learning
        </a>
      
        
          <a href="/pdf?id=Skx82ySYPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jiexiong%40kth.se" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiexiong@kth.se">Jiexiong Tang</a>, <a href="/profile?email=hanme.kim%40tri.global" class="profile-link" data-toggle="tooltip" data-placement="top" title="hanme.kim@tri.global">Hanme Kim</a>, <a href="/profile?email=vitor.guizilini%40tri.global" class="profile-link" data-toggle="tooltip" data-placement="top" title="vitor.guizilini@tri.global">Vitor Guizilini</a>, <a href="/profile?email=sudeep.pillai%40tri.global" class="profile-link" data-toggle="tooltip" data-placement="top" title="sudeep.pillai@tri.global">Sudeep Pillai</a>, <a href="/profile?email=rares.ambrus%40tri.global" class="profile-link" data-toggle="tooltip" data-placement="top" title="rares.ambrus@tri.global">Rares Ambrus</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#Skx82ySYPH-details-526" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skx82ySYPH-details-526"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Self-Supervised Learning, Keypoint Detection, Outlier Rejection, Deep Learning</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Learning to extract distinguishable keypoints from a proxy task, outlier rejection.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Identifying salient points in images is a crucial component for visual odometry, Structure-from-Motion or SLAM algorithms. Recently, several learned keypoint methods have demonstrated compelling performance on challenging benchmarks.  However, generating consistent and accurate training data for interest-point detection in natural images still remains challenging, especially for human annotators. We introduce IO-Net (i.e. InlierOutlierNet), a novel proxy task for the self-supervision of keypoint detection, description and matching. By making the sampling of inlier-outlier sets from point-pair correspondences fully differentiable within the keypoint learning framework, we show that are able to simultaneously self-supervise keypoint description and improve keypoint matching. Second, we introduce KeyPointNet, a keypoint-network architecture that is especially amenable to robust keypoint detection and description. We design the network to allow local keypoint aggregation to avoid artifacts due to spatial discretizations commonly used for this task, and we improve fine-grained keypoint descriptor performance by taking advantage of efficient sub-pixel convolutions to upsample the descriptor feature-maps to a higher operating resolution. Through extensive experiments and ablative analysis, we show that the proposed self-supervised keypoint learning method greatly improves the quality of feature matching and homography estimation on challenging benchmarks over the state-of-the-art.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/TRI-ML/KP2D</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Skx82ySYPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SylO2yStDr" data-number="1958">
      <h4>
        <a href="/forum?id=SylO2yStDr">
            Reducing Transformer Depth on Demand with Structured Dropout
        </a>
      
        
          <a href="/pdf?id=SylO2yStDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=angelafan%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="angelafan@fb.com">Angela Fan</a>, <a href="/profile?email=egrave%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="egrave@fb.com">Edouard Grave</a>, <a href="/profile?email=ajoulin%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ajoulin@fb.com">Armand Joulin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="#SylO2yStDr-details-51" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SylO2yStDr-details-51"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Layerdrop, a form of structured dropout that allows you to train one model at training time and prune to any desired depth at test time. You can also use this to train even deeper models.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Overparametrized transformer networks have obtained state of the art results in various natural language processing tasks, such as machine translation, language modeling, and  question answering. These models contain hundreds of millions of parameters, necessitating a large amount of computation	and making them prone to overfitting. In this work, we explore LayerDrop, a form of structured dropout, which has a regularization effect during training and allows for efficient pruning at inference time. In particular, we show that it is possible to select sub-networks of any depth from one large network without having to finetune them and with limited impact on performance. We demonstrate the effectiveness of our	approach by improving the state of the art on machine translation, language modeling, summarization, question answering, and language understanding benchmarks. Moreover, we show that our approach leads to small BERT-like models of higher quality than when training from scratch or using distillation.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reduction, regularization, pruning, dropout, transformer</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SylO2yStDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJeT3yrtDr" data-number="1969">
      <h4>
        <a href="/forum?id=HJeT3yrtDr">
            Cross-Lingual Ability of Multilingual BERT: An Empirical Study
        </a>
      
        
          <a href="/pdf?id=HJeT3yrtDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kkarthi%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kkarthi@seas.upenn.edu">Karthikeyan K</a>, <a href="/profile?email=zihanw2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zihanw2@illinois.edu">Zihan Wang</a>, <a href="/profile?email=mayhew%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mayhew@seas.upenn.edu">Stephen Mayhew</a>, <a href="/profile?email=danroth%40seas.upenn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="danroth@seas.upenn.edu">Dan Roth</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HJeT3yrtDr-details-457" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJeT3yrtDr-details-457"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Comprehensive analysis on Linguistic Properties, Model Architecture, and Input and Learning Objective of cross-lingual ability of Multilingual BERT</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recent work has exhibited the surprising cross-lingual abilities of multilingual BERT (M-BERT) -- surprising since it is trained without any cross-lingual objective and with no aligned data. In this work, we provide a comprehensive study of the contribution of different components in M-BERT to its cross-lingual ability. We study the impact of linguistic properties of the languages, the architecture of the model, and the learning objectives. The experimental study is done in the context of three typologically different languages -- Spanish, Hindi, and Russian -- and using two conceptually different NLP tasks, textual entailment and named entity recognition. Among our key conclusions is the fact that the lexical overlap between languages plays a negligible role in the cross-lingual success, while the depth of the network is an integral part of it. All our models and implementations can be found on our project page: http://cogcomp.org/page/publication_view/900.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Cross-Lingual Learning, Multilingual BERT</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJeT3yrtDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkl03ySYDH" data-number="1972">
      <h4>
        <a href="/forum?id=rkl03ySYDH">
            SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition
        </a>
      
        
          <a href="/pdf?id=rkl03ySYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zxlin%40zju.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zxlin@zju.edu.cn">Zhixuan Lin</a>, <a href="/profile?email=yifu.wu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yifu.wu@gmail.com">Yi-Fu Wu</a>, <a href="/profile?email=pvskand%40protonmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pvskand@protonmail.com">Skand Vishwanath Peri</a>, <a href="/profile?email=ws383%40scarletmail.rutgers.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ws383@scarletmail.rutgers.edu">Weihao Sun</a>, <a href="/profile?email=singh.gautam.iitg%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="singh.gautam.iitg@gmail.com">Gautam Singh</a>, <a href="/profile?email=fei.deng%40rutgers.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fei.deng@rutgers.edu">Fei Deng</a>, <a href="/profile?email=jindong.jiang%40rutgers.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jindong.jiang@rutgers.edu">Jindong Jiang</a>, <a href="/profile?email=sjn.ahn%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjn.ahn@gmail.com">Sungjin Ahn</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#rkl03ySYDH-details-267" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkl03ySYDH-details-267"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a generative latent variable model for unsupervised scene decomposition that provides factorized object representation per foreground object while also decomposing background segments of complex morphology.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The ability to decompose complex multi-object scenes into meaningful abstractions like objects is fundamental to achieve higher-level cognition. Previous approaches for unsupervised object-oriented scene representation learning are either based on spatial-attention or scene-mixture approaches and limited in scalability which is a main obstacle towards modeling real-world scenes. In this paper, we propose a generative latent variable model, called SPACE, that provides a uniﬁed probabilistic modeling framework that combines the best of spatial-attention and scene-mixture approaches. SPACE can explicitly provide factorized object representations for foreground objects while also decomposing background segments of complex morphology. Previous models are good at either of these, but not both. SPACE also resolves the scalability problems of previous methods by incorporating parallel spatial-attention and thus is applicable to scenes with a large number of objects without performance degradations. We show through experiments on Atari and 3D-Rooms that SPACE achieves the above properties consistently in comparison to SPAIR, IODINE, and GENESIS. Results of our experiments can be found on our project website: https://sites.google.com/view/space-project-page</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Generative models, Unsupervised scene representation, Object-oriented representation, spatial attention</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkl03ySYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkg-TJBFPB" data-number="1978">
      <h4>
        <a href="/forum?id=rkg-TJBFPB">
            RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments
        </a>
      
        
          <a href="/pdf?id=rkg-TJBFPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=raileanu%40cs.nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="raileanu@cs.nyu.edu">Roberta Raileanu</a>, <a href="/profile?email=tim.rocktaeschel%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tim.rocktaeschel@gmail.com">Tim Rocktäschel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 01 May 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rkg-TJBFPB-details-367" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkg-TJBFPB-details-367"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, exploration, curiosity</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Reward agents for taking actions that lead to changes in the environment state.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Exploration in sparse reward environments remains one of the key challenges of model-free reinforcement learning. Instead of solely relying on extrinsic rewards provided by the environment, many state-of-the-art methods use intrinsic rewards to encourage exploration. However, we show that existing methods fall short in procedurally-generated environments where an agent is unlikely to visit a state more than once. We propose a novel type of intrinsic reward which encourages the agent to take actions that lead to significant changes in its learned state representation. We evaluate our method on multiple challenging procedurally-generated tasks in MiniGrid, as well as on tasks with high-dimensional observations used in prior work. Our experiments demonstrate that this approach is more sample efficient than existing exploration methods, particularly for procedurally-generated MiniGrid environments. Furthermore, we analyze the learned behavior as well as the intrinsic reward received by our agent. In contrast to previous approaches, our intrinsic reward does not diminish during the course of training and it rewards the agent substantially more for interacting with objects that it can control.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/facebookresearch/impact-driven-exploration</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkg-TJBFPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkxQp1StDH" data-number="1982">
      <h4>
        <a href="/forum?id=SkxQp1StDH">
            Low-dimensional statistical manifold embedding of directed graphs
        </a>
      
        
          <a href="/pdf?id=SkxQp1StDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=fun%40biba.uni-bremen.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="fun@biba.uni-bremen.de">Thorben Funke</a>, <a href="/profile?email=tian.guo0980%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tian.guo0980@gmail.com">Tian Guo</a>, <a href="/profile?email=alen.lancic%40math.hr" class="profile-link" data-toggle="tooltip" data-placement="top" title="alen.lancic@math.hr">Alen Lancic</a>, <a href="/profile?email=nino.antulov%40gess.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="nino.antulov@gess.ethz.ch">Nino Antulov-Fantulin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SkxQp1StDH-details-651" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkxQp1StDH-details-651"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a novel node embedding of directed graphs to statistical manifolds and analyze connections to divergence, geometry and efficient learning procedure.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose a novel node embedding of directed graphs to statistical manifolds, which is based on a global minimization of pairwise relative entropy and graph geodesics in a non-linear way. Each node is encoded with a probability density function over a measurable space. Furthermore, we analyze the connection of the geometrical properties of such embedding and their efficient learning procedure. Extensive experiments show that our proposed embedding is better preserving the global geodesic information of graphs, as well as outperforming existing embedding models on directed graphs in a variety of evaluation metrics, in an unsupervised setting.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">graph embedding, information geometry, graph representations</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkxQp1StDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJg76kStwH" data-number="1983">
      <h4>
        <a href="/forum?id=rJg76kStwH">
            Efficient Probabilistic Logic Reasoning with Graph Neural Networks
        </a>
      
        
          <a href="/pdf?id=rJg76kStwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yuyu%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuyu@gatech.edu">Yuyu Zhang</a>, <a href="/profile?email=xinshi.chen%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xinshi.chen@gatech.edu">Xinshi Chen</a>, <a href="/profile?email=yuanyang%40gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuanyang@gatech.edu">Yuan Yang</a>, <a href="/profile?email=arun.ramamurthy%40siemens.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="arun.ramamurthy@siemens.com">Arun Ramamurthy</a>, <a href="/profile?email=lbo%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lbo@illinois.edu">Bo Li</a>, <a href="/profile?email=yuan.qi%40antfin.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuan.qi@antfin.com">Yuan Qi</a>, <a href="/profile?email=lsong%40cc.gatech.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lsong@cc.gatech.edu">Le Song</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>20 Replies</span>
        
        
      </div>
      
        <a href="#rJg76kStwH-details-542" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJg76kStwH-details-542"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We employ graph neural networks in the variational EM framework for efficient inference and learning of Markov Logic Networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Markov Logic Networks (MLNs), which elegantly combine logic rules and probabilistic graphical models, can be used to address many knowledge graph problems. However, inference in MLN is computationally intensive, making the industrial-scale application of MLN very difficult. In recent years, graph neural networks (GNNs) have emerged as efficient and effective tools for large-scale graph problems. Nevertheless, GNNs do not explicitly incorporate prior logic rules into the models, and may require many labeled examples for a target task. In this paper, we explore the combination of MLNs and GNNs, and use graph neural networks for variational inference in MLN. We propose a GNN variant, named ExpressGNN, which strikes a nice balance between the representation power and the simplicity of the model. Our extensive experiments on several benchmark datasets demonstrate that ExpressGNN leads to effective and efficient probabilistic logic reasoning.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/expressGNN/ExpressGNN</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">probabilistic logic reasoning, Markov Logic Networks, graph neural networks</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJg76kStwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJe8pkHFwS" data-number="1990">
      <h4>
        <a href="/forum?id=BJe8pkHFwS">
            GraphSAINT: Graph Sampling Based Inductive Learning Method
        </a>
      
        
          <a href="/pdf?id=BJe8pkHFwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zengh%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zengh@usc.edu">Hanqing Zeng</a>, <a href="/profile?email=hongkuaz%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hongkuaz@usc.edu">Hongkuan Zhou</a>, <a href="/profile?email=ajiteshs%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ajiteshs@usc.edu">Ajitesh Srivastava</a>, <a href="/profile?email=rajgopal.kannan.civ%40mail.mil" class="profile-link" data-toggle="tooltip" data-placement="top" title="rajgopal.kannan.civ@mail.mil">Rajgopal Kannan</a>, <a href="/profile?email=prasanna%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="prasanna@usc.edu">Viktor Prasanna</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#BJe8pkHFwS-details-807" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJe8pkHFwS-details-807"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a graph sampling based minibatch construction method for training deep Graph Convolutional Networks on large graphs. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Graph Convolutional Networks (GCNs) are powerful models for learning representations of attributed graphs. To scale GCNs to large graphs, state-of-the-art methods use various layer sampling techniques to alleviate the "neighbor explosion" problem during minibatch training. We propose GraphSAINT, a graph sampling based inductive learning method that improves training efficiency and accuracy in a fundamentally different way. By changing perspective, GraphSAINT constructs minibatches by sampling the training graph, rather than the nodes or edges across GCN layers. Each iteration, a complete GCN is built from the properly sampled subgraph. Thus, we ensure fixed number of well-connected nodes in all layers. We further propose normalization technique to eliminate bias, and sampling algorithms for variance reduction. Importantly, we can decouple the sampling from the forward and backward propagation, and extend GraphSAINT with many architecture variants (e.g., graph attention, jumping connection).  GraphSAINT demonstrates superior performance in both accuracy and training time on five large graphs, and achieves new state-of-the-art F1 scores for PPI (0.995) and Reddit (0.970). </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/GraphSAINT/GraphSAINT</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Graph Convolutional Networks, Graph sampling, Network embedding</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJe8pkHFwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyxY6JHKwr" data-number="1997">
      <h4>
        <a href="/forum?id=HyxY6JHKwr">
            You Only Train Once: Loss-Conditional Training of Deep Networks
        </a>
      
        
          <a href="/pdf?id=HyxY6JHKwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=adosovitskiy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adosovitskiy@gmail.com">Alexey Dosovitskiy</a>, <a href="/profile?email=josip%40djolonga.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="josip@djolonga.com">Josip Djolonga</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HyxY6JHKwr-details-121" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyxY6JHKwr-details-121"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A method to train a single model simultaneously minimizing a family of loss functions instead of training a set of per-loss models.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In many machine learning problems, loss functions are weighted sums of several terms. A typical approach to dealing with these is to train multiple separate models with different selections of weights and then either choose the best one according to some criterion or keep multiple models if it is desirable to maintain a diverse set of solutions. This is inefficient both at training and at inference time. We propose a method that allows replacing multiple models trained on one loss function each by a single model trained on a distribution of losses. At test time a model trained this way can be conditioned to generate outputs corresponding to any loss from the training distribution of losses. We demonstrate this approach on three tasks with parametrized losses: beta-VAE, learned image compression, and fast style transfer.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, image generation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HyxY6JHKwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rke3TJrtPS" data-number="2002">
      <h4>
        <a href="/forum?id=rke3TJrtPS">
            Projection-Based Constrained Policy Optimization
        </a>
      
        
          <a href="/pdf?id=rke3TJrtPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ty3%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ty3@princeton.edu">Tsung-Yen Yang</a>, <a href="/profile?email=justinian.rosca%40siemens.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="justinian.rosca@siemens.com">Justinian Rosca</a>, <a href="/profile?email=karthikn%40cs.princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="karthikn@cs.princeton.edu">Karthik Narasimhan</a>, <a href="/profile?email=ramadge%40princeton.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ramadge@princeton.edu">Peter J. Ramadge</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rke3TJrtPS-details-452" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rke3TJrtPS-details-452"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a new algorithm that learns constraint-satisfying policies, and provide theoretical analysis and empirical demonstration in the context of reinforcement learning with constraints.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We consider the problem of learning control policies that optimize a reward function while satisfying constraints due to considerations of safety, fairness, or other costs. We propose a new algorithm - Projection-Based Constrained Policy Optimization (PCPO), an iterative method for optimizing policies in a two-step process - the first step performs an unconstrained update while the second step reconciles the constraint violation by projecting the policy back onto the constraint set. We theoretically analyze PCPO and provide a lower bound on reward improvement, as well as an upper bound on constraint violation for each policy update. We further characterize the convergence of PCPO with projection based on two different metrics - L2 norm and Kullback-Leibler divergence. Our empirical results over several control tasks demonstrate that our algorithm achieves superior performance, averaging more than 3.5 times less constraint violation and around 15% higher reward compared to state-of-the-art methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://sites.google.com/view/iclr2020-pcpo</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement learning with constraints, Safe reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rke3TJrtPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxC6kSYPr" data-number="2006">
      <h4>
        <a href="/forum?id=ryxC6kSYPr">
            Infinite-Horizon Differentiable Model Predictive Control
        </a>
      
        
          <a href="/pdf?id=ryxC6kSYPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sebastian.east%40bath.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastian.east@bath.edu">Sebastian East</a>, <a href="/profile?email=marco%40nnaisense.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="marco@nnaisense.com">Marco Gallieri</a>, <a href="/profile?email=jonathan%40nnaisense.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jonathan@nnaisense.com">Jonathan Masci</a>, <a href="/profile?email=jan%40nnaisense.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jan@nnaisense.com">Jan Koutnik</a>, <a href="/profile?email=mark.cannon%40eng.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="mark.cannon@eng.ox.ac.uk">Mark Cannon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#ryxC6kSYPr-details-550" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxC6kSYPr-details-550"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper proposes a differentiable linear quadratic Model Predictive Control (MPC) framework for safe imitation learning. The infinite-horizon cost is enforced using a terminal cost function obtained from the discrete-time algebraic Riccati equation (DARE), so that the learned controller can be proven to be stabilizing in closed-loop. A central contribution is the derivation of the analytical derivative of the solution of the DARE, thereby allowing the use of differentiation-based learning methods. A further contribution is the structure of the MPC optimization problem: an augmented Lagrangian method ensures that the MPC optimization is feasible throughout training whilst enforcing hard constraints on state and input, and a pre-stabilizing controller ensures that the MPC solution and derivatives are accurate at each iteration. The learning capabilities of the framework are demonstrated in a set of numerical studies. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Model Predictive Control, Riccati Equation, Imitation Learning, Safe Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxC6kSYPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkeAaJrKDS" data-number="2008">
      <h4>
        <a href="/forum?id=SkeAaJrKDS">
            Combining Q-Learning and Search with Amortized Value Estimates
        </a>
      
        
          <a href="/pdf?id=SkeAaJrKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jhamrick%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jhamrick@google.com">Jessica B. Hamrick</a>, <a href="/profile?email=vbapst%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vbapst@google.com">Victor Bapst</a>, <a href="/profile?email=alvarosg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alvarosg@google.com">Alvaro Sanchez-Gonzalez</a>, <a href="/profile?email=tpfaff%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tpfaff@google.com">Tobias Pfaff</a>, <a href="/profile?email=theophane%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="theophane@google.com">Theophane Weber</a>, <a href="/profile?email=lbuesing%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lbuesing@google.com">Lars Buesing</a>, <a href="/profile?email=peterbattaglia%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="peterbattaglia@google.com">Peter W. Battaglia</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="#SkeAaJrKDS-details-948" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkeAaJrKDS-details-948"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">model-based RL, Q-learning, MCTS, search</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a model-based method called "Search with Amortized Value Estimates" (SAVE) which leverages both real and planned experience by combining Q-learning with Monte-Carlo Tree Search, achieving strong performance with very small search budgets.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We introduce "Search with Amortized Value Estimates" (SAVE), an approach for combining model-free Q-learning with model-based Monte-Carlo Tree Search (MCTS). In SAVE, a learned prior over state-action values is used to guide MCTS, which estimates an improved set of state-action values. The new Q-estimates are then used in combination with real experience to update the prior. This effectively amortizes the value computation performed by MCTS, resulting in a cooperative relationship between model-free learning and model-based search. SAVE can be implemented on top of any Q-learning agent with access to a model, which we demonstrate by incorporating it into agents that perform challenging physical reasoning tasks and Atari. SAVE consistently achieves higher rewards with fewer training steps, and---in contrast to typical model-based search approaches---yields strong performance with very small search budgets. By combining real experience with information computed during search, SAVE demonstrates that it is possible to improve on both the performance of model-free learning and the computational cost of planning.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkeAaJrKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hye1RJHKwB" data-number="2009">
      <h4>
        <a href="/forum?id=Hye1RJHKwB">
            Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators
        </a>
      
        
          <a href="/pdf?id=Hye1RJHKwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=d.stoller%40qmul.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="d.stoller@qmul.ac.uk">Daniel Stoller</a>, <a href="/profile?email=sewert%40spotify.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sewert@spotify.com">Sebastian Ewert</a>, <a href="/profile?email=s.e.dixon%40qmul.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="s.e.dixon@qmul.ac.uk">Simon Dixon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#Hye1RJHKwB-details-354" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hye1RJHKwB-details-354"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We decompose the discriminator in a GAN in a principled way so that each component can be independently trained on different parts of the input. The resulting "FactorGAN" can be used for semi-supervised learning and in missing data scenarios.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Generative adversarial networks (GANs) have shown great success in applications such as image generation and inpainting.
      However, they typically require large datasets, which are often not available, especially in the context of prediction tasks such as image segmentation that require labels. Therefore, methods such as the CycleGAN use more easily available unlabelled data, but do not offer a way to leverage additional labelled data for improved performance. To address this shortcoming, we show how to factorise the joint data distribution into a set of lower-dimensional distributions along with their dependencies. This allows splitting the discriminator in a GAN into multiple "sub-discriminators" that can be independently trained from incomplete observations. Their outputs can be combined to estimate the density ratio between the joint real and the generator distribution, which enables training generators as in the original GAN framework. We apply our method to image generation, image segmentation and audio source separation, and obtain improved performance over a standard GAN when additional incomplete training examples are available. For the Cityscapes segmentation task in particular, our method also improves accuracy by an absolute 14.9% over CycleGAN while using only 25 additional paired examples.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://www.dropbox.com/s/gtc7m7pc4n2yt05/source.zip?dl=1</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Adversarial Learning, Semi-supervised Learning, Image generation, Image segmentation, Missing Data</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hye1RJHKwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkgGCkrKvH" data-number="2016">
      <h4>
        <a href="/forum?id=SkgGCkrKvH">
            Decentralized Deep Learning with Arbitrary Communication Compression
        </a>
      
        
          <a href="/pdf?id=SkgGCkrKvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=anastasia.koloskova%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="anastasia.koloskova@epfl.ch">Anastasia Koloskova*</a>, <a href="/profile?email=tao.lin%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="tao.lin@epfl.ch">Tao Lin*</a>, <a href="/profile?email=sebastian.stich%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastian.stich@epfl.ch">Sebastian U Stich</a>, <a href="/profile?email=martin.jaggi%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="martin.jaggi@epfl.ch">Martin Jaggi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SkgGCkrKvH-details-843" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkgGCkrKvH-details-843"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose Choco-SGD---decentralized SGD with compressed communication---for non-convex objectives and show its strong performance in various deep learning applications (on-device learning, datacenter case).</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Decentralized training of deep learning models is a key element for enabling data privacy and on-device learning over networks, as well as for efficient scaling to large compute clusters. As current approaches are limited by network bandwidth, we propose the use of communication compression in the decentralized training context. We show that Choco-SGD achieves linear speedup in the number of workers for arbitrary high compression ratios on general non-convex functions, and non-IID training data.  We demonstrate the practical performance of the algorithm in two key scenarios: the training of deep learning models (i) over decentralized user devices, connected by a peer-to-peer network and (ii) in a datacenter. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/epfml/ChocoSGD</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkgGCkrKvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SylL0krYPS" data-number="2026">
      <h4>
        <a href="/forum?id=SylL0krYPS">
            Toward Evaluating Robustness of Deep Reinforcement Learning with Continuous Control
        </a>
      
        
          <a href="/pdf?id=SylL0krYPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=twweng%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="twweng@mit.edu">Tsui-Wei Weng</a>, <a href="/profile?email=dvij%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dvij@google.com">Krishnamurthy (Dj) Dvijotham*</a>, <a href="/profile?email=juesato%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="juesato@google.com">Jonathan Uesato*</a>, <a href="/profile?email=kaix%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kaix@mit.edu">Kai Xiao*</a>, <a href="/profile?email=sgowal%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sgowal@google.com">Sven Gowal*</a>, <a href="/profile?email=stanforth%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="stanforth@google.com">Robert Stanforth*</a>, <a href="/profile?email=pushmeet%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="pushmeet@google.com">Pushmeet Kohli</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#SylL0krYPS-details-736" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SylL0krYPS-details-736"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We study the problem of continuous control agents in deep RL with adversarial attacks and proposed a two-step algorithm based on learned model dynamics. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep reinforcement learning has achieved great success in many previously difficult reinforcement learning tasks, yet recent studies show that deep RL agents are also unavoidably susceptible to adversarial perturbations, similar to deep neural networks in classification tasks. Prior works mostly focus on model-free adversarial attacks and agents with discrete actions. In this work, we study the problem of continuous control agents in deep RL with adversarial attacks and propose the first two-step algorithm based on learned model dynamics. Extensive experiments on various MuJoCo domains (Cartpole, Fish, Walker, Humanoid) demonstrate that our proposed framework is much more effective and efficient than model-free based attacks baselines in degrading agent performance as well as driving agents to unsafe states. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, reinforcement learning, robustness, adversarial examples</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SylL0krYPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxK0JBtPr" data-number="2033">
      <h4>
        <a href="/forum?id=ryxK0JBtPr">
            Gradient <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="524" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mn>1</mn></msub></math></mjx-assistive-mml></mjx-container> Regularization for Quantization Robustness
        </a>
      
        
          <a href="/pdf?id=ryxK0JBtPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=milada%40qti.qualcomm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="milada@qti.qualcomm.com">Milad Alizadeh</a>, <a href="/profile?email=behboodi%40qti.qualcomm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="behboodi@qti.qualcomm.com">Arash Behboodi</a>, <a href="/profile?email=mart%40qti.qualcomm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mart@qti.qualcomm.com">Mart van Baalen</a>, <a href="/profile?email=clouizos%40qti.qualcomm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="clouizos@qti.qualcomm.com">Christos Louizos</a>, <a href="/profile?email=tijmen%40qti.qualcomm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tijmen@qti.qualcomm.com">Tijmen Blankevoort</a>, <a href="/profile?email=mwelling%40qti.qualcomm.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mwelling@qti.qualcomm.com">Max Welling</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#ryxK0JBtPr-details-649" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxK0JBtPr-details-649"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We show that regularizing the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="525" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mn>1</mn></msub></math></mjx-assistive-mml></mjx-container>-norm of gradients improves robustness to post-training quantization in neural networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We analyze the effect of quantizing weights and activations of neural networks on their loss and derive a simple regularization scheme that improves robustness against post-training quantization. By training quantization-ready networks, our approach enables storing a single set of weights that can be quantized on-demand to different bit-widths as energy and memory requirements of the application change. Unlike quantization-aware training using the straight-through estimator that only targets a specific bit-width and requires access to training data and pipeline, our regularization-based method paves the way for ``on the fly'' post-training quantization to various bit-widths. We show that by modeling quantization as a <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="526" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-n" size="s"><mjx-c class="mjx-c221E"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mi mathvariant="normal">∞</mi></msub></math></mjx-assistive-mml></mjx-container>-bounded perturbation, the first-order term in the loss expansion can be regularized using the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="527" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mn>1</mn></msub></math></mjx-assistive-mml></mjx-container>-norm of gradients. We experimentally validate our method on different vision architectures on CIFAR-10 and ImageNet datasets and show that the regularization of a neural network using our method improves robustness against quantization noise.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">quantization, regularization, robustness, gradient regularization</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxK0JBtPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkxs0yHFPH" data-number="2037">
      <h4>
        <a href="/forum?id=rkxs0yHFPH">
            SpikeGrad: An ANN-equivalent Computation Model for Implementing Backpropagation with Spikes
        </a>
      
        
          <a href="/pdf?id=rkxs0yHFPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=johannes.thiele%40cea.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="johannes.thiele@cea.fr">Johannes C. Thiele</a>, <a href="/profile?email=olivier.bichler%40cea.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="olivier.bichler@cea.fr">Olivier Bichler</a>, <a href="/profile?email=antoine.dupret%40cea.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="antoine.dupret@cea.fr">Antoine Dupret</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#rkxs0yHFPH-details-187" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkxs0yHFPH-details-187"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">An implementation of the backpropagation algorithm using spiking neurons for forward and backward propagation.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Event-based neuromorphic systems promise to reduce the energy consumption of deep neural networks by replacing expensive floating point operations on dense matrices by low energy, sparse operations on spike events. While these systems can be trained increasingly well using approximations of the backpropagation algorithm, this usually requires high precision errors and is therefore incompatible with the typical communication infrastructure of neuromorphic circuits. In this work, we analyze how the gradient can be discretized into spike events when training a spiking neural network. To accelerate our simulation, we show that using a special implementation of the integrate-and-fire neuron allows us to describe the accumulated activations and errors of the spiking neural network in terms of an equivalent artificial neural network, allowing us to largely speed up training compared to an explicit simulation of all spike events. This way we are able to demonstrate that even for deep networks, the gradients can be discretized sufficiently well with spikes if the gradient is properly rescaled. This form of spike-based backpropagation enables us to achieve equivalent or better accuracies on the MNIST and CIFAR10 datasets than comparable state-of-the-art spiking neural networks trained with full precision gradients. The algorithm, which we call SpikeGrad, is based on only accumulation and comparison operations and can naturally exploit sparsity in the gradient computation, which makes it an interesting choice for a spiking neuromorphic systems with on-chip learning capacities.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">spiking neural network, neuromorphic engineering, backpropagation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkxs0yHFPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJlnC1rKPB" data-number="2040">
      <h4>
        <a href="/forum?id=HJlnC1rKPB">
            On the Relationship between Self-Attention and Convolutional Layers
        </a>
      
        
          <a href="/pdf?id=HJlnC1rKPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jean-baptiste.cordonnier%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="jean-baptiste.cordonnier@epfl.ch">Jean-Baptiste Cordonnier</a>, <a href="/profile?email=andreas.loukas%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="andreas.loukas@epfl.ch">Andreas Loukas</a>, <a href="/profile?email=martin.jaggi%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="martin.jaggi@epfl.ch">Martin Jaggi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HJlnC1rKPB-details-849" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJlnC1rKPB-details-849"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A self-attention layer can perform convolution and often learns to do so in practice.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recent trends of incorporating attention mechanisms in vision have led researchers to reconsider the supremacy of convolutional layers as a primary building block. Beyond helping CNNs to handle long-range dependencies, Ramachandran et al. (2019) showed that attention can completely replace convolution and achieve state-of-the-art performance on vision tasks. This raises the question: do learned attention layers operate similarly to convolutional layers? This work provides evidence that attention layers can perform convolution and, indeed, they often learn to do so in practice. Specifically, we prove that a multi-head self-attention layer with sufficient number of heads is at least as expressive as any convolutional layer. Our numerical experiments then show that self-attention layers attend to pixel-grid patterns similarly to CNN layers, corroborating our analysis. Our code is publicly available.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/epfml/attention-cnn</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">self-attention, attention, transformers, convolution, CNN, image, expressivity, capacity</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJlnC1rKPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyxJ1xBYDH" data-number="2046">
      <h4>
        <a href="/forum?id=HyxJ1xBYDH">
            Learning-Augmented Data Stream Algorithms
        </a>
      
        
          <a href="/pdf?id=HyxJ1xBYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=taj320%40lehigh.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="taj320@lehigh.edu">Tanqiu Jiang</a>, <a href="/profile?email=yili%40ntu.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="yili@ntu.edu.sg">Yi Li</a>, <a href="/profile?email=honghao_lin%40sjtu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="honghao_lin@sjtu.edu.cn">Honghao Lin</a>, <a href="/profile?email=24320152202802%40stu.xmu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="24320152202802@stu.xmu.edu.cn">Yisong Ruan</a>, <a href="/profile?email=dwoodruf%40andrew.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dwoodruf@andrew.cmu.edu">David P. Woodruff</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#HyxJ1xBYDH-details-772" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyxJ1xBYDH-details-772"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The data stream model is a fundamental model for processing massive data sets with limited memory and fast processing time. Recently Hsu et al. (2019) incorporated machine learning techniques into the data stream model in order to learn relevant patterns in the input data. Such techniques were encapsulated by training an oracle to predict item frequencies in the streaming model. In this paper we explore the full power of such an oracle, showing that it can be applied to a wide array of problems in data streams, sometimes resulting in the first optimal bounds for such problems. Namely, we apply the oracle to counting distinct elements on the difference of streams, estimating frequency moments, estimating cascaded aggregates, and estimating moments of geometric data streams. For the distinct elements problem, we obtain the first memory-optimal algorithms. For estimating the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="528" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi></math></mjx-assistive-mml></mjx-container>-th frequency moment for <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="529" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>0</mn><mo>&lt;</mo><mi>p</mi><mo>&lt;</mo><mn>2</mn></math></mjx-assistive-mml></mjx-container> we obtain the first algorithms with optimal update time. For estimating the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="530" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi></math></mjx-assistive-mml></mjx-container>-the frequency moment for <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="531" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3E"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo>&gt;</mo><mn>2</mn></math></mjx-assistive-mml></mjx-container> we obtain a quadratic saving in memory. We empirically validate our results, demonstrating also our improvements in practice. </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/open?id=1faroW4fFTM7ELVkZDtgiMBjUu1F-piQa</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">streaming algorithms, heavy hitters, F_p moment, distinct elements, cascaded norms</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HyxJ1xBYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1e-kxSKDH" data-number="2050">
      <h4>
        <a href="/forum?id=B1e-kxSKDH">
            Structured Object-Aware Physics Prediction for Video Modeling and Planning
        </a>
      
        
          <a href="/pdf?id=B1e-kxSKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kossen%40stud.uni-heidelberg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="kossen@stud.uni-heidelberg.de">Jannik Kossen</a>, <a href="/profile?email=stelzner%40cs.tu-darmstadt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="stelzner@cs.tu-darmstadt.de">Karl Stelzner</a>, <a href="/profile?email=marcel.hussing%40stud.tu-darmstadt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="marcel.hussing@stud.tu-darmstadt.de">Marcel Hussing</a>, <a href="/profile?email=c.voelcker%40stud.tu-darmstadt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="c.voelcker@stud.tu-darmstadt.de">Claas Voelcker</a>, <a href="/profile?email=kersting%40cs.tu-darmstadt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="kersting@cs.tu-darmstadt.de">Kristian Kersting</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#B1e-kxSKDH-details-588" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1e-kxSKDH-details-588"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a structured object-aware video prediction model, which explicitly reasons about objects and demonstrate that it provides high-quality long term video predictions for planning.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">When humans observe a physical system, they can easily locate components, understand their interactions, and anticipate future behavior, even in settings with complicated and previously unseen interactions. For computers, however, learning such models from videos in an unsupervised fashion is an unsolved research problem.  In this paper, we present STOVE, a novel state-space model for  videos, which explicitly reasons about objects and their positions, velocities, and interactions. It is constructed by combining an image model and a dynamics model in compositional manner and improves on previous work by reusing the dynamics model for inference, accelerating and regularizing training. STOVE predicts videos with convincing physical behavior over hundreds of timesteps, outperforms previous unsupervised models, and even approaches the performance of supervised baselines. We further demonstrate the strength of our model as a simulator for sample efficient model-based control, in a task with heavily interacting objects.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/ICLR20/STOVE</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">self-supervised learning, probabilistic deep learning, structured models, video prediction, physics prediction, planning, variational auteoncoders, model-based reinforcement learning, VAEs, unsupervised, variational, graph neural networks, tractable probabilistic models, attend-infer-repeat, relational learning, AIR, sum-product networks, object-oriented, object-centric, object-aware, MCTS</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1e-kxSKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hyl7ygStwB" data-number="2055">
      <h4>
        <a href="/forum?id=Hyl7ygStwB">
            Incorporating BERT into Neural Machine Translation
        </a>
      
        
          <a href="/pdf?id=Hyl7ygStwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=teslazhu%40mail.ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="teslazhu@mail.ustc.edu.cn">Jinhua Zhu</a>, <a href="/profile?email=yingce.xia%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yingce.xia@gmail.com">Yingce Xia</a>, <a href="/profile?email=wulijun3%40mail2.sysu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wulijun3@mail2.sysu.edu.cn">Lijun Wu</a>, <a href="/profile?email=di_he%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="di_he@pku.edu.cn">Di He</a>, <a href="/profile?email=taoqin%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="taoqin@microsoft.com">Tao Qin</a>, <a href="/profile?email=zhwg%40ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhwg@ustc.edu.cn">Wengang Zhou</a>, <a href="/profile?email=lihq%40ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="lihq@ustc.edu.cn">Houqiang Li</a>, <a href="/profile?email=tyliu%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tyliu@microsoft.com">Tieyan Liu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#Hyl7ygStwB-details-811" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hyl7ygStwB-details-811"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The recently proposed BERT (Devlin et al., 2019) has shown great power on a variety of natural language understanding tasks, such as text classification, reading comprehension, etc. However, how to effectively apply BERT to neural machine translation (NMT) lacks enough exploration. While BERT is more commonly used as fine-tuning instead of contextual embedding for downstream language understanding tasks, in NMT, our preliminary exploration of using BERT as contextual embedding is better than using for fine-tuning. This motivates us to think how to better leverage BERT for NMT along this direction. We propose a new algorithm named BERT-fused model, in which we first use BERT to extract representations for an input sequence, and then the representations are fused with each layer of the encoder and decoder of the NMT model through attention mechanisms. We conduct experiments on supervised (including sentence-level and document-level translations), semi-supervised and unsupervised machine translation, and achieve state-of-the-art results on seven benchmark datasets. Our code is available at https://github.com/bert-nmt/bert-nmt</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/bert-nmt/bert-nmt</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">BERT, Neural Machine Translation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hyl7ygStwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkeryxBtPB" data-number="2061">
      <h4>
        <a href="/forum?id=HkeryxBtPB">
            MMA Training: Direct Input Space Margin Maximization through Adversarial Training
        </a>
      
        
          <a href="/pdf?id=HkeryxBtPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=gavin.w.ding%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gavin.w.ding@gmail.com">Gavin Weiguang Ding</a>, <a href="/profile?email=yash.sharma%40bethgelab.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="yash.sharma@bethgelab.org">Yash Sharma</a>, <a href="/profile?email=yikchau.y.lui%40borealisai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yikchau.y.lui@borealisai.com">Kry Yik Chau Lui</a>, <a href="/profile?email=ruitong.huang%40borealisai.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ruitong.huang@borealisai.com">Ruitong Huang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="#HkeryxBtPB-details-433" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkeryxBtPB-details-433"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose MMA training to directly maximize input space margin in order to improve adversarial robustness primarily by removing the requirement of specifying a fixed distortion bound.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study adversarial robustness of neural networks from a margin maximization perspective, where margins are defined as the distances from inputs to a classifier's decision boundary.
      Our study shows that maximizing margins can be achieved by minimizing the adversarial loss on the decision boundary at the "shortest successful perturbation", demonstrating a close connection between adversarial losses and the margins. We propose Max-Margin Adversarial (MMA) training to directly maximize the margins to achieve adversarial robustness. 
      Instead of adversarial training with a fixed <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="532" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ϵ</mi></math></mjx-assistive-mml></mjx-container>, MMA offers an improvement by enabling adaptive selection of the "correct" <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="533" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D716 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ϵ</mi></math></mjx-assistive-mml></mjx-container> as the margin individually for each datapoint. In addition, we rigorously analyze adversarial training with the perspective of margin maximization, and provide an alternative interpretation for adversarial training, maximizing either a lower or an upper bound of the margins. Our experiments empirically confirm our theory and demonstrate MMA training's efficacy on the MNIST and CIFAR10 datasets w.r.t. <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="534" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-n" size="s"><mjx-c class="mjx-c221E"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mi mathvariant="normal">∞</mi></msub></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="535" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mn>2</mn></msub></math></mjx-assistive-mml></mjx-container> robustness.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">adversarial robustness, perturbation, margin maximization, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/BorealisAI/mma_training</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkeryxBtPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgU1gHtvr" data-number="2063">
      <h4>
        <a href="/forum?id=rkgU1gHtvr">
            Infinite-horizon Off-Policy Policy Evaluation with Multiple Behavior Policies
        </a>
      
        
          <a href="/pdf?id=rkgU1gHtvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=chenxinyun%40cuhk.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="chenxinyun@cuhk.edu.cn">Xinyun Chen</a>, <a href="/profile?email=luwang%40stu.ecnu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="luwang@stu.ecnu.edu.cn">Lu Wang</a>, <a href="/profile?email=hangyhan%40mail.ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="hangyhan@mail.ustc.edu.cn">Yizhe Hang</a>, <a href="/profile?email=hengge%40mail.sdu.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="hengge@mail.sdu.edu.cn">Heng Ge</a>, <a href="/profile?email=zhahy%40cuhk.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhahy@cuhk.edu.cn">Hongyuan Zha</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rkgU1gHtvr-details-582" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgU1gHtvr-details-582"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">off-policy policy evaluation, multiple importance sampling, kernel method, variance reduction</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A new partially policy-agnostic method for infinite-horizon off-policy policy evalution with multiple known or unknown behavior policies.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We consider off-policy policy evaluation when the trajectory data are generated by multiple behavior policies. Recent work has shown the key role played by the state or state-action stationary distribution corrections in the infinite horizon context for off-policy policy evaluation. We propose estimated mixture policy (EMP), a novel class of partially policy-agnostic methods to accurately estimate those quantities. With careful analysis, we show that EMP gives rise to estimates with reduced variance for estimating the state stationary distribution correction while it also offers a useful induction bias for estimating the state-action stationary distribution correction. In extensive experiments with both continuous and discrete environments, we demonstrate that our algorithm offers significantly improved accuracy compared to the state-of-the-art methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgU1gHtvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylwJxrYDS" data-number="2066">
      <h4>
        <a href="/forum?id=rylwJxrYDS">
            vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations
        </a>
      
        
          <a href="/pdf?id=rylwJxrYDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=alexei.b%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexei.b@gmail.com">Alexei Baevski</a>, <a href="/profile?email=stes%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="stes@fb.com">Steffen Schneider</a>, <a href="/profile?email=michael.auli%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael.auli@gmail.com">Michael Auli</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rylwJxrYDS-details-731" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylwJxrYDS-details-731"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Learn how to quantize speech signal and apply algorithms requiring discrete inputs to audio data such as BERT.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose vq-wav2vec to learn discrete representations of audio segments through a wav2vec-style self-supervised context prediction task. The algorithm uses either a gumbel softmax or online k-means clustering to quantize the dense representations. Discretization enables the direct application of algorithms from the NLP community which require discrete inputs. Experiments show that BERT pre-training achieves a new state of the art on TIMIT phoneme classification and WSJ speech recognition.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">speech recognition, speech representation learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rylwJxrYDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BygdyxHFDS" data-number="2067">
      <h4>
        <a href="/forum?id=BygdyxHFDS">
            Meta-learning curiosity algorithms
        </a>
      
        
          <a href="/pdf?id=BygdyxHFDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ferranalet%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ferranalet@gmail.com">Ferran Alet*</a>, <a href="/profile?email=martinfs%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="martinfs@mit.edu">Martin F. Schneider*</a>, <a href="/profile?email=tlp%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tlp@csail.mit.edu">Tomas Lozano-Perez</a>, <a href="/profile?email=lpk%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lpk@csail.mit.edu">Leslie Pack Kaelbling</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#BygdyxHFDS-details-245" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BygdyxHFDS-details-245"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">meta-learning, exploration, curiosity</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Meta-learning curiosity algorithms by searching through a rich space of programs yields novel designs that generalize across very different reinforcement-learning domains.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We hypothesize that curiosity is a mechanism found by evolution that encourages meaningful exploration early in an agent's life in order to expose it to experiences that enable it to obtain high rewards over the course of its lifetime. We formulate the problem of generating curious behavior as one of meta-learning: an outer loop will search over a space of curiosity mechanisms that dynamically adapt the agent's reward signal, and an inner loop will perform standard reinforcement learning using the adapted reward signal. However, current meta-RL methods based on transferring neural network weights have only generalized between very similar tasks. To broaden the generalization, we instead propose to meta-learn algorithms: pieces of code similar to those designed by humans in ML papers. Our rich language of programs combines neural networks with other building blocks such as buffers, nearest-neighbor modules and custom loss functions. We demonstrate the effectiveness of the approach empirically, finding two novel curiosity algorithms that perform on par or better than human-designed published curiosity algorithms in domains as disparate as grid navigation with image inputs, acrobot, lunar lander, ant and hopper.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/mfranzs/meta-learning-curiosity-algorithms</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BygdyxHFDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SygKyeHKDH" data-number="2069">
      <h4>
        <a href="/forum?id=SygKyeHKDH">
            Making Efficient Use of Demonstrations to Solve Hard Exploration Problems
        </a>
      
        
          <a href="/pdf?id=SygKyeHKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=caglarg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="caglarg@google.com">Caglar Gulcehre</a>, <a href="/profile?email=tpaine%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tpaine@google.com">Tom Le Paine</a>, <a href="/profile?email=bshahr%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="bshahr@google.com">Bobak Shahriari</a>, <a href="/profile?email=mdenil%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mdenil@google.com">Misha Denil</a>, <a href="/profile?email=mwhoffman%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mwhoffman@google.com">Matt Hoffman</a>, <a href="/profile?email=soyer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="soyer@google.com">Hubert Soyer</a>, <a href="/profile?email=tanburn%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tanburn@google.com">Richard Tanburn</a>, <a href="/profile?email=skapturowski%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="skapturowski@google.com">Steven Kapturowski</a>, <a href="/profile?email=ncr%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ncr@google.com">Neil Rabinowitz</a>, <a href="/profile?email=duncanwilliams%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="duncanwilliams@google.com">Duncan Williams</a>, <a href="/profile?email=gabrielbm%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gabrielbm@google.com">Gabriel Barth-Maron</a>, <a href="/profile?email=ziyu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ziyu@google.com">Ziyu Wang</a>, <a href="/profile?email=nandodefreitas%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="nandodefreitas@google.com">Nando de Freitas</a>, <a href="/profile?email=deepmind-worlds-team%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="deepmind-worlds-team@google.com">Worlds Team</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#SygKyeHKDH-details-275" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SygKyeHKDH-details-275"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce R2D3, an agent that makes efficient use of demonstrations to solve hard exploration problems in partially observable environments with highly variable initial conditions.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper introduces R2D3, an agent that makes efficient use of demonstrations to solve hard exploration problems in partially observable environments with highly variable initial conditions. We also introduce a suite of eight tasks that combine these three properties, and show that R2D3 can solve several of the tasks where other state of the art methods (both with and without demonstrations) fail to see even a single successful trajectory after tens of billions of steps of exploration.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">imitation learning, deep learning, reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SygKyeHKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkl9JlBYvr" data-number="2073">
      <h4>
        <a href="/forum?id=Hkl9JlBYvr">
            VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning
        </a>
      
        
          <a href="/pdf?id=Hkl9JlBYvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=luisa.zintgraf%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="luisa.zintgraf@cs.ox.ac.uk">Luisa Zintgraf</a>, <a href="/profile?email=kikos1988%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kikos1988@gmail.com">Kyriacos Shiarlis</a>, <a href="/profile?email=maximilian.igl%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maximilian.igl@gmail.com">Maximilian Igl</a>, <a href="/profile?email=sebastian.schulze%40eng.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastian.schulze@eng.ox.ac.uk">Sebastian Schulze</a>, <a href="/profile?email=yarin.gal%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yarin.gal@cs.ox.ac.uk">Yarin Gal</a>, <a href="/profile?email=katja.hofmann%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="katja.hofmann@microsoft.com">Katja Hofmann</a>, <a href="/profile?email=shimon.whiteson%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="shimon.whiteson@cs.ox.ac.uk">Shimon Whiteson</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#Hkl9JlBYvr-details-610" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkl9JlBYvr-details-610"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">VariBAD opens a path to tractable approximate Bayes-optimal exploration for deep RL using ideas from meta-learning, Bayesian RL, and approximate variational inference.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Trading off exploration and exploitation in an unknown environment is key to maximising expected return during learning. A Bayes-optimal policy, which does so optimally, conditions its actions not only on the environment state but on the agent’s uncertainty about the environment. Computing a Bayes-optimal policy is however intractable for all but the smallest tasks. In this paper, we introduce variational Bayes-Adaptive Deep RL (variBAD), a way to meta-learn to perform approximate inference in an unknown environment, and incorporate task uncer- tainty directly during action selection. In a grid-world domain, we illustrate how variBAD performs structured online exploration as a function of task uncertainty. We further evaluate variBAD on MuJoCo domains widely used in meta-RL and show that it achieves higher online return than existing methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Meta-Learning, Bayesian Reinforcement Learning, BAMDPs, Deep Reinforcement Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hkl9JlBYvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryl3ygHYDB" data-number="2077">
      <h4>
        <a href="/forum?id=ryl3ygHYDB">
            Lookahead: A Far-sighted Alternative of Magnitude-based Pruning
        </a>
      
        
          <a href="/pdf?id=ryl3ygHYDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sejun.park%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="sejun.park@kaist.ac.kr">Sejun Park*</a>, <a href="/profile?email=jaeho-lee%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaeho-lee@kaist.ac.kr">Jaeho Lee*</a>, <a href="/profile?email=swmo%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="swmo@kaist.ac.kr">Sangwoo Mo</a>, <a href="/profile?email=jinwoos%40kaist.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jinwoos@kaist.ac.kr">Jinwoo Shin</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="#ryl3ygHYDB-details-236" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryl3ygHYDB-details-236"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We study a multi-layer generalization of the magnitude-based pruning.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Magnitude-based pruning is one of the simplest methods for pruning neural networks. Despite its simplicity, magnitude-based pruning and its variants demonstrated remarkable performances for pruning modern architectures. Based on the observation that magnitude-based pruning indeed minimizes the Frobenius distortion of a linear operator corresponding to a single layer, we develop a simple pruning method, coined lookahead pruning, by extending the single layer optimization to a multi-layer optimization. Our experimental results demonstrate that the proposed method consistently outperforms magnitude-based pruning on various networks, including VGG and ResNet, particularly in the high-sparsity regime. See https://github.com/alinlab/lookahead_pruning for codes.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">network magnitude-based pruning</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/alinlab/lookahead_pruning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryl3ygHYDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJxWxxSYvB" data-number="2088">
      <h4>
        <a href="/forum?id=rJxWxxSYvB">
            Spike-based causal inference for weight alignment
        </a>
      
        
          <a href="/pdf?id=rJxWxxSYvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jordan.guerguiev%40utoronto.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="jordan.guerguiev@utoronto.ca">Jordan Guerguiev</a>, <a href="/profile?email=koerding%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="koerding@gmail.com">Konrad Kording</a>, <a href="/profile?email=blake.richards%40mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="blake.richards@mcgill.ca">Blake Richards</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rJxWxxSYvB-details-48" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJxWxxSYvB-details-48"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">causal, inference, weight, transport, rdd, regression, discontinuity, design, cifar10, biologically, plausible</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present a learning rule for feedback weights in a spiking neural network that addresses the weight transport problem.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In artificial neural networks trained with gradient descent, the weights used for processing stimuli are also used during backward passes to calculate gradients. For the real brain to approximate gradients, gradient information would have to be propagated separately, such that one set of synaptic weights is used for processing and another set is used for backward passes. This produces the so-called "weight transport problem" for biological models of learning, where the backward weights used to calculate gradients need to mirror the forward weights used to process stimuli. This weight transport problem has been considered so hard that popular proposals for biological learning assume that the backward weights are simply random, as in the feedback alignment algorithm. However, such random weights do not appear to work well for large networks. Here we show how the discontinuity introduced in a spiking system can lead to a solution to this problem. The resulting algorithm is a special case of an estimator used for causal inference in econometrics, regression discontinuity design. We show empirically that this algorithm rapidly makes the backward weights approximate the forward weights. As the backward weights become correct, this improves learning performance over feedback alignment on tasks such as Fashion-MNIST and CIFAR-10. Our results demonstrate that a simple learning rule in a spiking network can allow neurons to produce the right backward connections and thus solve the weight transport problem.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://anonfile.com/51V8Ge66n3/Code_zip</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJxWxxSYvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkg-xgrYvH" data-number="2089">
      <h4>
        <a href="/forum?id=Hkg-xgrYvH">
            Empirical Bayes Transductive Meta-Learning with Synthetic Gradients
        </a>
      
        
          <a href="/pdf?id=Hkg-xgrYvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=dom343%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dom343@gmail.com">Shell Xu Hu</a>, <a href="/profile?email=morepabl%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="morepabl@amazon.com">Pablo Garcia Moreno</a>, <a href="/profile?email=yang.xiao%40enpc.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="yang.xiao@enpc.fr">Yang Xiao</a>, <a href="/profile?email=xi.shen%40enpc.fr" class="profile-link" data-toggle="tooltip" data-placement="top" title="xi.shen@enpc.fr">Xi Shen</a>, <a href="/profile?email=guillaume.obozinski%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="guillaume.obozinski@epfl.ch">Guillaume Obozinski</a>, <a href="/profile?email=n.lawrence%40sheffield.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="n.lawrence@sheffield.ac.uk">Neil Lawrence</a>, <a href="/profile?email=damianou%40amazon.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="damianou@amazon.com">Andreas Damianou</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 26 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#Hkg-xgrYvH-details-726" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkg-xgrYvH-details-726"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose a meta-learning approach that learns from multiple tasks in a transductive setting, by leveraging the unlabeled query set in addition to the  support set to generate a more powerful model for each task. To develop our framework, we revisit the empirical Bayes formulation for multi-task learning.   The evidence lower bound of the marginal log-likelihood of empirical Bayes decomposes as a sum of local KL divergences between the variational posterior and the true posterior on the query set of each task.
      We derive a novel amortized variational inference that couples all the variational posteriors via a meta-model, which consists of a synthetic gradient   network and an initialization network. Each variational posterior is derived from synthetic gradient descent to approximate the true posterior on the query  set, although where we do not have access to the true gradient.
      Our results on the Mini-ImageNet and CIFAR-FS benchmarks for episodic few-shot classification outperform previous state-of-the-art methods. Besides, we conduct two zero-shot learning experiments to further explore the potential of the synthetic gradient.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Meta-learning, Empirical Bayes, Synthetic Gradient, Information Bottleneck</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/amzn/xfer</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a transductive meta-learning algorithm using synthetic gradients, analyze its generalization via information bottleneck, show SOTA results on few-shot learning.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hkg-xgrYvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rke7geHtwH" data-number="2093">
      <h4>
        <a href="/forum?id=rke7geHtwH">
            Keep Doing What Worked: Behavior Modelling Priors for Offline Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=rke7geHtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=siegeln%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="siegeln@google.com">Noah Siegel</a>, <a href="/profile?email=springenberg%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="springenberg@google.com">Jost Tobias Springenberg</a>, <a href="/profile?email=befelix%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="befelix@inf.ethz.ch">Felix Berkenkamp</a>, <a href="/profile?email=aabdolmaleki%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aabdolmaleki@google.com">Abbas Abdolmaleki</a>, <a href="/profile?email=neunertm%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="neunertm@google.com">Michael Neunert</a>, <a href="/profile?email=thomaslampe%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomaslampe@google.com">Thomas Lampe</a>, <a href="/profile?email=rhafner%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rhafner@google.com">Roland Hafner</a>, <a href="/profile?email=heess%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="heess@google.com">Nicolas Heess</a>, <a href="/profile?email=riedmiller%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="riedmiller@google.com">Martin Riedmiller</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 12 Jun 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rke7geHtwH-details-633" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rke7geHtwH-details-633"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We develop a method for stable offline reinforcement learning from logged data. The key is to regularize the RL policy towards a learned "advantage weighted" model of the data.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Off-policy reinforcement learning algorithms promise to be applicable in settings where only a fixed data-set (batch) of environment interactions is available and no new experience can be acquired. This property makes these algorithms appealing for real world problems such as robot control. In practice, however, standard off-policy algorithms fail in the batch setting for continuous control. In this paper, we propose a simple solution to this problem. It admits the use of data generated by arbitrary behavior policies and uses a learned prior -- the advantage-weighted behavior model (ABM) -- to bias the RL policy towards actions that have previously been executed and are likely to be successful on the new task. Our method can be seen as an extension of recent work on batch-RL that enables stable learning from conflicting data-sources. We find  improvements on competitive baselines in a variety of RL tasks -- including standard continuous control benchmarks and multi-task learning for simulated and real-world robots. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement Learning, Off-policy, Multitask, Continuous Control</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rke7geHtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1lPleBFvH" data-number="2102">
      <h4>
        <a href="/forum?id=r1lPleBFvH">
            Understanding the Limitations of Conditional Generative Models
        </a>
      
        
          <a href="/pdf?id=r1lPleBFvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ethanf%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ethanf@cs.toronto.edu">Ethan Fetaya</a>, <a href="/profile?email=j.jacobsen%40vectorinstitute.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="j.jacobsen@vectorinstitute.ai">Joern-Henrik Jacobsen</a>, <a href="/profile?email=wgrathwohl%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wgrathwohl@cs.toronto.edu">Will Grathwohl</a>, <a href="/profile?email=zemel%40cs.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zemel@cs.toronto.edu">Richard Zemel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#r1lPleBFvH-details-376" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1lPleBFvH-details-376"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Class-conditional generative models hold promise to overcome the shortcomings of their discriminative counterparts. They are a natural choice to solve discriminative tasks in a robust manner as they jointly optimize for predictive performance and accurate modeling of the input distribution. In this work, we investigate robust classification with likelihood-based generative models from a theoretical and practical perspective to investigate if they can deliver on their promises. Our analysis focuses on a spectrum of robustness properties: (1) Detection of worst-case outliers in the form of adversarial examples; (2) Detection of average-case outliers in the form of ambiguous inputs and (3) Detection of incorrectly labeled in-distribution inputs. 
      
      Our theoretical result reveals that it is impossible to guarantee detectability of adversarially-perturbed inputs even for near-optimal generative classifiers. Experimentally, we find that while we are able to train robust models for MNIST, robustness completely breaks down on CIFAR10. We relate this failure to various undesirable model properties that can be traced to the maximum likelihood training objective. Despite being a common choice in the literature, our results indicate that likelihood-based conditional generative models may are surprisingly ineffective for robust classification.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Conditional Generative Models, Generative Classifiers, Robustness, Adversarial Examples</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1lPleBFvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hyl9xxHYPr" data-number="2110">
      <h4>
        <a href="/forum?id=Hyl9xxHYPr">
            Demystifying Inter-Class Disentanglement
        </a>
      
        
          <a href="/pdf?id=Hyl9xxHYPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=avivga%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="avivga@gmail.com">Aviv Gabbay</a>, <a href="/profile?email=yedid%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="yedid@cs.huji.ac.il">Yedid Hoshen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#Hyl9xxHYPr-details-406" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hyl9xxHYPr-details-406"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Latent Optimization for Representation Disentanglement</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Learning to disentangle the hidden factors of variations within a set of observations is a key task for artificial intelligence. We present a unified formulation for class and content disentanglement and use it to illustrate the limitations of current methods. We therefore introduce LORD, a novel method based on Latent Optimization for Representation Disentanglement. We find that latent optimization, along with an asymmetric noise regularization, is superior to amortized inference for achieving disentangled representations. In extensive experiments, our method is shown to achieve better disentanglement performance than both adversarial and non-adversarial methods that use the same level of supervision. We further introduce a clustering-based approach for extending our method for settings that exhibit in-class variation with promising results on the task of domain translation.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/avivga/lord</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">disentanglement, latent optimization, domain translation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hyl9xxHYPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1g6xeSKDS" data-number="2115">
      <h4>
        <a href="/forum?id=S1g6xeSKDS">
            Mixed-curvature Variational Autoencoders
        </a>
      
        
          <a href="/pdf?id=S1g6xeSKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=oskopek%40oskopek.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="oskopek@oskopek.com">Ondrej Skopek</a>, <a href="/profile?email=oct%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="oct@mit.edu">Octavian-Eugen Ganea</a>, <a href="/profile?email=garyb%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="garyb@mit.edu">Gary Bécigneul</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#S1g6xeSKDS-details-819" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1g6xeSKDS-details-819"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">variational autoencoders, riemannian manifolds, non-Euclidean geometry</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Variational Autoencoders with latent spaces modeled as products of constant curvature Riemannian manifolds improve on image reconstruction over single-manifold variants.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Euclidean space has historically been the typical workhorse geometry for machine learning applications due to its power and simplicity. However, it has recently been shown that geometric spaces with constant non-zero curvature improve representations and performance on a variety of data types and downstream tasks. Consequently, generative models like Variational Autoencoders (VAEs) have been successfully generalized to elliptical and hyperbolic latent spaces. While these approaches work well on data with particular kinds of biases e.g. tree-like data for a hyperbolic VAE, there exists no generic approach unifying and leveraging all three models. We develop a Mixed-curvature Variational Autoencoder, an efficient way to train a VAE whose latent space is a product of constant curvature Riemannian manifolds, where the per-component curvature is fixed or learnable. This generalizes the Euclidean VAE to curved latent spaces and recovers it when curvatures of all latent space components go to 0.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/oskopek/mvae</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1g6xeSKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1x0lxrFPS" data-number="2118">
      <h4>
        <a href="/forum?id=r1x0lxrFPS">
            BinaryDuo: Reducing Gradient Mismatch in Binary Activation Network by Coupling Binary Activations
        </a>
      
        
          <a href="/pdf?id=r1x0lxrFPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=hyungjun.kim%40postech.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="hyungjun.kim@postech.ac.kr">Hyungjun Kim</a>, <a href="/profile?email=kyungsu.kim%40postech.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="kyungsu.kim@postech.ac.kr">Kyungsu Kim</a>, <a href="/profile?email=jinseok.kim%40postech.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jinseok.kim@postech.ac.kr">Jinseok Kim</a>, <a href="/profile?email=jaejoon%40postech.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="jaejoon@postech.ac.kr">Jae-Joon Kim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#r1x0lxrFPS-details-841" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1x0lxrFPS-details-841"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Binary Neural Networks (BNNs) have been garnering interest thanks to their compute cost reduction and memory savings. However, BNNs suffer from performance degradation mainly due to the gradient mismatch caused by binarizing activations. Previous works tried to address the gradient mismatch problem by reducing the discrepancy between activation functions used at forward pass and its differentiable approximation used at backward pass, which is an indirect measure. In this work, we use the gradient of smoothed loss function to better estimate the gradient mismatch in quantized neural network. Analysis using the gradient mismatch estimator indicates that using higher precision for activation is more effective than modifying the differentiable approximation of activation function. Based on the observation, we propose a new training scheme for binary activation networks called BinaryDuo in which two binary activations are coupled into a ternary activation during training. Experimental results show that BinaryDuo outperforms state-of-the-art BNNs on various benchmarks with the same amount of parameters and computing cost.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/Hyungjun-K1m/BinaryDuo</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1x0lxrFPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HklxbgBKvr" data-number="2123">
      <h4>
        <a href="/forum?id=HklxbgBKvr">
            Model-based reinforcement learning for biological sequence design
        </a>
      
        
          <a href="/pdf?id=HklxbgBKvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=christofa%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="christofa@google.com">Christof Angermueller</a>, <a href="/profile?email=ddohan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ddohan@google.com">David Dohan</a>, <a href="/profile?email=dbelanger%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dbelanger@google.com">David Belanger</a>, <a href="/profile?email=ramyadeshpande%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ramyadeshpande@google.com">Ramya Deshpande</a>, <a href="/profile?email=lcolwell%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lcolwell@google.com">Kevin Murphy</a>, <a href="/profile?email=kpmurphy%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kpmurphy@google.com">Lucy Colwell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 10 May 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HklxbgBKvr-details-692" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HklxbgBKvr-details-692"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We augment model-free policy learning with a sequence-level surrogate reward functions and count-based visitation bonus and demonstrate effectiveness in the large batch, low-round regime seen in designing DNA and protein sequences.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The ability to design biological structures such as DNA or proteins would have considerable medical and industrial impact. Doing so presents a challenging black-box optimization problem characterized by the large-batch, low round setting due to the need for labor-intensive wet lab evaluations. In response, we propose using reinforcement learning (RL) based on proximal-policy optimization (PPO) for biological sequence design. RL provides a flexible framework for optimization generative sequence models to achieve specific criteria, such as diversity among the high-quality sequences discovered. We propose a model-based variant of PPO, DyNA-PPO, to improve sample efficiency, where the policy for a new round is trained offline using a simulator fit on functional measurements from prior rounds. To accommodate the growing number of observations across rounds, the simulator model is automatically selected at each round from a pool of diverse models of varying capacity.  On the tasks of designing DNA transcription factor binding sites, designing antimicrobial proteins, and optimizing the energy of Ising models based on protein structure, we find that DyNA-PPO performs significantly better than existing methods in settings in which modeling is feasible, while still not performing worse in situations in which a reliable model cannot be learned.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, blackbox optimization, molecule design</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HklxbgBKvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hkem-lrtvH" data-number="2129">
      <h4>
        <a href="/forum?id=Hkem-lrtvH">
            BayesOpt Adversarial Attack
        </a>
      
        
          <a href="/pdf?id=Hkem-lrtvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=robin%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="robin@robots.ox.ac.uk">Binxin Ru</a>, <a href="/profile?email=adam.cobb%40worc.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="adam.cobb@worc.ox.ac.uk">Adam Cobb</a>, <a href="/profile?email=arno%40robots.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="arno@robots.ox.ac.uk">Arno Blaas</a>, <a href="/profile?email=yarin%40cs.ox.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yarin@cs.ox.ac.uk">Yarin Gal</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#Hkem-lrtvH-details-66" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hkem-lrtvH-details-66"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a query-efficient black-box attack which uses Bayesian optimisation in combination with Bayesian model selection to optimise over the adversarial perturbation and the optimal degree of search space dimension reduction. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Black-box adversarial attacks require a large number of attempts before finding successful adversarial examples that are visually indistinguishable from the original input. Current approaches relying on substitute model training, gradient estimation or genetic algorithms often require an excessive number of queries. Therefore, they are not suitable for real-world systems where the maximum query number is limited due to cost. We propose a query-efficient black-box attack which uses Bayesian optimisation in combination with Bayesian model selection to optimise over the adversarial perturbation and the optimal degree of search space dimension reduction. We demonstrate empirically that our method can achieve comparable success rates with 2-5 times fewer queries compared to previous state-of-the-art black-box attacks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/rubinxin/BayesOpt_Attack</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Black-box Adversarial Attack, Bayesian Optimisation, Gaussian Process</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hkem-lrtvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkgsWxrtPB" data-number="2149">
      <h4>
        <a href="/forum?id=HkgsWxrtPB">
            Meta Reinforcement Learning with Autonomous Inference of Subtask Dependencies
        </a>
      
        
          <a href="/pdf?id=HkgsWxrtPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=srsohn%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="srsohn@umich.edu">Sungryull Sohn</a>, <a href="/profile?email=hjwoo%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hjwoo@umich.edu">Hyunjae Woo</a>, <a href="/profile?email=jwook%40umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jwook@umich.edu">Jongwook Choi</a>, <a href="/profile?email=honglak%40eecs.umich.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="honglak@eecs.umich.edu">Honglak Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HkgsWxrtPB-details-4" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkgsWxrtPB-details-4"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Meta reinforcement learning, subtask graph</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A novel meta-RL method that infers latent subtask structure</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose and address a novel few-shot RL problem, where a task is characterized by a subtask graph which describes a set of subtasks and their dependencies that are unknown to the agent. The agent needs to quickly adapt to the task over few episodes during adaptation phase to maximize the return in the test phase. Instead of directly learning a meta-policy, we develop a Meta-learner with Subtask Graph Inference (MSGI), which infers the latent parameter of the task by interacting with the environment and maximizes the return given the latent parameter. To facilitate learning, we adopt an intrinsic reward inspired by upper confidence bound (UCB) that encourages efficient exploration. Our experiment results on two grid-world domains and StarCraft II environments show that the proposed method is able to accurately infer the latent task parameter, and to adapt more efficiently than existing meta RL and hierarchical RL methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkgsWxrtPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryx6WgStPB" data-number="2153">
      <h4>
        <a href="/forum?id=ryx6WgStPB">
            Hypermodels for Exploration
        </a>
      
        
          <a href="/pdf?id=ryx6WgStPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=vikranthd%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="vikranthd@google.com">Vikranth Dwaracherla</a>, <a href="/profile?email=lxlu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lxlu@google.com">Xiuyuan Lu</a>, <a href="/profile?email=mibrahimi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mibrahimi@google.com">Morteza Ibrahimi</a>, <a href="/profile?email=iosband%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="iosband@google.com">Ian Osband</a>, <a href="/profile?email=zhengwen%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhengwen@google.com">Zheng Wen</a>, <a href="/profile?email=benvanroy%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="benvanroy@google.com">Benjamin Van Roy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#ryx6WgStPB-details-115" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryx6WgStPB-details-115"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Hypermodels can encode posterior distributions similar to large ensembles at much smaller computational cost. This can facilitate significant improvements in exploration.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We study the use of hypermodels to represent epistemic uncertainty and guide exploration.
      This generalizes and extends the use of ensembles to approximate Thompson sampling. The computational cost of training an ensemble grows with its size, and as such, prior work has typically been limited to ensembles with tens of elements. We show that alternative hypermodels can enjoy dramatic efficiency gains, enabling behavior that would otherwise require hundreds or thousands of elements, and even succeed in situations where ensemble methods fail to learn regardless of size.
      This allows more accurate approximation of Thompson sampling as well as use of more sophisticated exploration schemes.  In particular, we consider an approximate form of information-directed sampling and demonstrate performance gains relative to Thompson sampling.  As alternatives to ensembles, we consider linear and neural network hypermodels, also known as hypernetworks.
      We prove that, with neural network base models, a linear hypermodel can represent essentially any distribution over functions, and as such, hypernetworks do not extend what can be represented.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">exploration, hypermodel, reinforcement learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryx6WgStPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkgeGeBYDB" data-number="2160">
      <h4>
        <a href="/forum?id=HkgeGeBYDB">
            RaPP: Novelty Detection with Reconstruction along Projection Pathway
        </a>
      
        
          <a href="/pdf?id=HkgeGeBYDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=khkim%40makinarocks.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="khkim@makinarocks.ai">Ki Hyun Kim</a>, <a href="/profile?email=sangwoo%40makinarocks.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="sangwoo@makinarocks.ai">Sangwoo Shim</a>, <a href="/profile?email=yongsub%40makinarocks.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="yongsub@makinarocks.ai">Yongsub Lim</a>, <a href="/profile?email=jongseob.jeon%40makinarocks.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="jongseob.jeon@makinarocks.ai">Jongseob Jeon</a>, <a href="/profile?email=jeongwoo%40makinarocks.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="jeongwoo@makinarocks.ai">Jeongwoo Choi</a>, <a href="/profile?email=kbc8894%40makinarocks.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="kbc8894@makinarocks.ai">Byungchan Kim</a>, <a href="/profile?email=andre%40makinarocks.ai" class="profile-link" data-toggle="tooltip" data-placement="top" title="andre@makinarocks.ai">Andre S. Yoon</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#HkgeGeBYDB-details-847" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkgeGeBYDB-details-847"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A new methodology for novelty detection by utilizing hidden space activation values obtained from a deep autoencoder.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose RaPP, a new methodology for novelty detection by utilizing hidden space activation values obtained from a deep autoencoder.
      Precisely, RaPP compares input and its autoencoder reconstruction not only in the input space but also in the hidden spaces.
      We show that if we feed a reconstructed input to the same autoencoder again, its activated values in a hidden space are equivalent to the corresponding reconstruction in that hidden space given the original input.
      In order to aggregate the hidden space activation values, we propose two metrics, which enhance the novelty detection performance.
      Through extensive experiments using diverse datasets, we validate that RaPP improves novelty detection performances of autoencoder-based approaches.
      Besides, we show that RaPP outperforms recent novelty detection methods evaluated on popular benchmarks.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/drive/folders/1sknl_i4zmvSsPYZdzYxbg66ZSYDZ_abg?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Novelty Detection, Anomaly Detection, Outlier Detection, Semi-supervised Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkgeGeBYDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJgZGeHFPH" data-number="2163">
      <h4>
        <a href="/forum?id=BJgZGeHFPH">
            Dynamics-Aware Embeddings
        </a>
      
        
          <a href="/pdf?id=BJgZGeHFPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wfwhitney%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wfwhitney@gmail.com">William Whitney</a>, <a href="/profile?email=ra2630%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ra2630@nyu.edu">Rajat Agarwal</a>, <a href="/profile?email=kyunghyun.cho%40nyu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kyunghyun.cho@nyu.edu">Kyunghyun Cho</a>, <a href="/profile?email=abhinavg%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhinavg@cs.cmu.edu">Abhinav Gupta</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#BJgZGeHFPH-details-354" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJgZGeHFPH-details-354"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">State and action embeddings which incorporate the dynamics improve exploration and RL from pixels.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In this paper we consider self-supervised representation learning to improve sample efficiency in reinforcement learning (RL). We propose a forward prediction objective for simultaneously learning embeddings of states and actions. These embeddings capture the structure of the environment's dynamics, enabling efficient policy learning. We demonstrate that our action embeddings alone improve the sample efficiency and peak performance of model-free RL on control from low-dimensional states. By combining state and action embeddings, we achieve efficient learning of high-quality policies on goal-conditioned continuous control from pixel observations in only 1-2 million environment steps.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/dyne-submission/dynamics-aware-embeddings</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">representation learning, reinforcement learning, rl</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJgZGeHFPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkxCzeHFDB" data-number="2193">
      <h4>
        <a href="/forum?id=HkxCzeHFDB">
            Functional Regularisation for  Continual Learning with Gaussian Processes
        </a>
      
        
          <a href="/pdf?id=HkxCzeHFDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mtitsias%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mtitsias@google.com">Michalis K. Titsias</a>, <a href="/profile?email=schwarzjn%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="schwarzjn@google.com">Jonathan Schwarz</a>, <a href="/profile?email=alexmatthews%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexmatthews@google.com">Alexander G. de G. Matthews</a>, <a href="/profile?email=razp%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="razp@google.com">Razvan Pascanu</a>, <a href="/profile?email=ywteh%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ywteh@google.com">Yee Whye Teh</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HkxCzeHFDB-details-904" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkxCzeHFDB-details-904"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Using inducing point sparse Gaussian process methods to overcome catastrophic forgetting in neural networks.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We introduce a framework for Continual Learning (CL) based on Bayesian inference over the function space rather than the parameters of a deep neural network. This method, referred to as functional regularisation for Continual Learning, avoids forgetting a previous task by constructing and memorising an approximate posterior belief over the underlying task-specific function. To achieve this we rely on a Gaussian process obtained by treating the weights of the last layer of a neural network as random and Gaussian distributed. Then, the training algorithm sequentially encounters tasks and constructs posterior beliefs over the task-specific functions by using inducing point sparse Gaussian process methods. At each step a new task is first learnt and then a summary is constructed consisting of (i) inducing inputs – a fixed-size subset of the task inputs selected such that it optimally represents the task – and (ii) a posterior distribution over the function values at these inputs. This summary then regularises learning of future tasks, through Kullback-Leibler regularisation terms. Our method thus unites approaches focused on (pseudo-)rehearsal with those derived from a sequential Bayesian inference perspective in a principled way, leading to strong results on accepted benchmarks.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Continual Learning, Gaussian Processes, Lifelong learning, Incremental Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkxCzeHFDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkxSmlBFvr" data-number="2209">
      <h4>
        <a href="/forum?id=BkxSmlBFvr">
            You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings
        </a>
      
        
          <a href="/pdf?id=BkxSmlBFvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=daniel%40informatik.uni-mannheim.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel@informatik.uni-mannheim.de">Daniel Ruffinelli</a>, <a href="/profile?email=broscheit%40informatik.uni-mannheim.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="broscheit@informatik.uni-mannheim.de">Samuel Broscheit</a>, <a href="/profile?email=rgemulla%40uni-mannheim.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="rgemulla@uni-mannheim.de">Rainer Gemulla</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>21 Replies</span>
        
        
      </div>
      
        <a href="#BkxSmlBFvr-details-802" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkxSmlBFvr-details-802"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We study the impact of training strategies on the performance of knowledge graph embeddings.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">knowledge graph embeddings, hyperparameter optimization</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/uma-pi1/kge</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BkxSmlBFvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1eqQeHFDS" data-number="2221">
      <h4>
        <a href="/forum?id=H1eqQeHFDS">
            AdvectiveNet: An Eulerian-Lagrangian Fluidic Reservoir for Point Cloud Processing     
        </a>
      
        
          <a href="/pdf?id=H1eqQeHFDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xingzhe.he95%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xingzhe.he95@gmail.com">Xingzhe He</a>, <a href="/profile?email=helen.l.cao.22%40dartmouth.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="helen.l.cao.22@dartmouth.edu">Helen Lu Cao</a>, <a href="/profile?email=bo.zhu%40dartmouth.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bo.zhu@dartmouth.edu">Bo Zhu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 04 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#H1eqQeHFDS-details-105" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1eqQeHFDS-details-105"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present a new grid-particle learning method to process point clouds motivated by computational fluid dynamics.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper presents a novel physics-inspired deep learning approach for point cloud processing motivated by the natural flow phenomena in fluid mechanics.  Our learning architecture jointly defines data in an Eulerian world space, using a static background grid, and a Lagrangian material space, using moving particles. By introducing this Eulerian-Lagrangian representation, we are able to naturally evolve and accumulate particle features using flow velocities generated from a generalized, high-dimensional force field.  We demonstrate the efficacy of this system by solving various point cloud classification and segmentation problems with state-of-the-art performance. The entire geometric reservoir and data flow mimic the pipeline of the classic PIC/FLIP scheme in modeling natural flow, bridging the disciplines of geometric machine learning and physical simulation.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/DIUDIUDIUDIUDIU/AdvectiveNet-An-Eulerian-Lagrangian-Fluidic-Reservoir-for-Point-Cloud-Processing</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Point Cloud Processing, Physical Reservoir Learning, Eulerian-Lagrangian Method, PIC/FLIP</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1eqQeHFDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sye57xStvB" data-number="2222">
      <h4>
        <a href="/forum?id=Sye57xStvB">
            Never Give Up: Learning Directed Exploration Strategies
        </a>
      
        
          <a href="/pdf?id=Sye57xStvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=adriap%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adriap@google.com">Adrià Puigdomènech Badia</a>, <a href="/profile?email=psprechmann%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="psprechmann@google.com">Pablo Sprechmann</a>, <a href="/profile?email=avlife%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="avlife@google.com">Alex Vitvitskyi</a>, <a href="/profile?email=danielguo%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="danielguo@google.com">Daniel Guo</a>, <a href="/profile?email=piot%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="piot@google.com">Bilal Piot</a>, <a href="/profile?email=skapturowski%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="skapturowski@google.com">Steven Kapturowski</a>, <a href="/profile?email=tieleman%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tieleman@google.com">Olivier Tieleman</a>, <a href="/profile?email=martinarjovsky%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="martinarjovsky@gmail.com">Martin Arjovsky</a>, <a href="/profile?email=apritzel%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="apritzel@google.com">Alexander Pritzel</a>, <a href="/profile?email=abolt%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="abolt@google.com">Andrew Bolt</a>, <a href="/profile?email=cblundell%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cblundell@google.com">Charles Blundell</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#Sye57xStvB-details-244" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sye57xStvB-details-244"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep reinforcement learning, exploration, intrinsic motivation</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a reinforcement learning agent to solve hard exploration games by learning a range of directed exploratory policies. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose a reinforcement learning agent to solve hard exploration games by learning a range of directed exploratory policies. We construct an episodic memory-based intrinsic reward using k-nearest neighbors over the agent's recent experience to train the directed exploratory policies, thereby encouraging the agent to repeatedly revisit all states in its environment. A self-supervised inverse dynamics model is used to train the embeddings of the nearest neighbour lookup, biasing the novelty signal towards what the agent can control. We employ the framework of Universal Value Function Approximators to simultaneously learn many directed exploration policies with the same neural network, with different trade-offs between exploration and exploitation. By using the same neural network for different degrees of exploration/exploitation, transfer is demonstrated from predominantly exploratory policies yielding effective exploitative policies. The proposed method can be incorporated to run with modern distributed RL agents that collect large amounts of experience from many actors running in parallel on separate environment instances. Our method doubles the performance of the base agent in all hard exploration in the Atari-57 suite while maintaining a very high score across the remaining games, obtaining a median human normalised score of 1344.0%. Notably, the proposed method is the first algorithm to achieve non-zero rewards (with a mean score of 8,400) in the game of Pitfall! without using demonstrations or hand-crafted features.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Sye57xStvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByexElSYDr" data-number="2235">
      <h4>
        <a href="/forum?id=ByexElSYDr">
            Fair Resource Allocation in Federated Learning
        </a>
      
        
          <a href="/pdf?id=ByexElSYDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tianli%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tianli@cmu.edu">Tian Li</a>, <a href="/profile?email=maziar.sanjabi%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="maziar.sanjabi@gmail.com">Maziar Sanjabi</a>, <a href="/profile?email=ahmad.beirami%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ahmad.beirami@gmail.com">Ahmad Beirami</a>, <a href="/profile?email=smithv%40cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="smithv@cmu.edu">Virginia Smith</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#ByexElSYDr-details-268" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByexElSYDr-details-268"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a novel optimization objective that encourages fairness in heterogeneous federated networks, and develop a scalable method to solve it.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Federated learning involves training statistical models in massive, heterogeneous networks. Naively minimizing an aggregate loss function in such a network may disproportionately advantage or disadvantage some of the devices. In this work, we propose q-Fair Federated Learning (q-FFL), a novel optimization objective inspired by fair resource allocation in wireless networks that encourages a more fair (specifically, a more uniform) accuracy distribution across devices in federated networks. To solve q-FFL, we devise a communication-efficient method, q-FedAvg, that is suited to federated networks. We validate both the effectiveness of q-FFL and the efficiency of q-FedAvg on a suite of federated datasets with both convex and non-convex models, and show that q-FFL (along with q-FedAvg) outperforms existing baselines in terms of the resulting fairness, flexibility, and efficiency.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">federated learning, fairness, distributed optimization</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/litian96/fair_flearn</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByexElSYDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1xMEerYvB" data-number="2240">
      <h4>
        <a href="/forum?id=B1xMEerYvB">
            Smooth markets: A basic mechanism for organizing gradient-based learners
        </a>
      
        
          <a href="/pdf?id=B1xMEerYvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=dbalduzzi%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dbalduzzi@google.com">David Balduzzi</a>, <a href="/profile?email=lejlot%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lejlot@google.com">Wojciech M. Czarnecki</a>, <a href="/profile?email=edwardhughes%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="edwardhughes@google.com">Tom Anthony</a>, <a href="/profile?email=jzl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jzl@google.com">Ian Gemp</a>, <a href="/profile?email=imgemp%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="imgemp@google.com">Edward Hughes</a>, <a href="/profile?email=twa%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="twa@google.com">Joel Leibo</a>, <a href="/profile?email=georgios.piliouras%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="georgios.piliouras@gmail.com">Georgios Piliouras</a>, <a href="/profile?email=thore%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thore@google.com">Thore Graepel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="#B1xMEerYvB-details-74" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1xMEerYvB-details-74"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce a class of n-player games suited to gradient-based methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">With the success of modern machine learning, it is becoming increasingly important to understand and control how learning algorithms interact. Unfortunately, negative results from game theory show there is little hope of understanding or controlling general n-player games. We therefore introduce smooth markets (SM-games), a class of n-player games with pairwise zero sum interactions. SM-games codify a common design pattern in machine learning that includes some GANs, adversarial training, and other recent algorithms. We show that SM-games are amenable to analysis and optimization using first-order methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">game theory, optimization, gradient descent, adversarial learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1xMEerYvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJgQ4lSFPH" data-number="2242">
      <h4>
        <a href="/forum?id=BJgQ4lSFPH">
            StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding
        </a>
      
        
          <a href="/pdf?id=BJgQ4lSFPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=hebian.ww%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hebian.ww@alibaba-inc.com">Wei Wang</a>, <a href="/profile?email=b.bi%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="b.bi@alibaba-inc.com">Bin Bi</a>, <a href="/profile?email=ym119608%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ym119608@alibaba-inc.com">Ming Yan</a>, <a href="/profile?email=wuchen.wc%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wuchen.wc@alibaba-inc.com">Chen Wu</a>, <a href="/profile?email=jiangnan.xjn%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiangnan.xjn@alibaba-inc.com">Jiangnan Xia</a>, <a href="/profile?email=zuyi.bzy%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zuyi.bzy@alibaba-inc.com">Zuyi Bao</a>, <a href="/profile?email=liwei.peng%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="liwei.peng@alibaba-inc.com">Liwei Peng</a>, <a href="/profile?email=luo.si%40alibaba-inc.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="luo.si@alibaba-inc.com">Luo Si</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 09 May 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#BJgQ4lSFPH-details-343" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJgQ4lSFPH-details-343"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Recently, the pre-trained language model, BERT (and its robustly optimized version RoBERTa), has attracted a lot of attention in natural language understanding (NLU), and achieved state-of-the-art accuracy in various NLU tasks, such as sentiment classification, natural language inference, semantic textual similarity and question answering. Inspired by the linearization exploration work of Elman, we extend BERT to a new model, StructBERT, by incorporating language structures into pre-training. Specifically, we pre-train StructBERT with two auxiliary tasks to make the most of the sequential order of words and sentences, which leverage language structures at the word and sentence levels, respectively. As a result, the new model is adapted to different levels of language understanding required by downstream tasks.
      
      The StructBERT with structural pre-training gives surprisingly good empirical results on a variety of downstream tasks, including pushing the state-of-the-art on the GLUE benchmark to 89.0 (outperforming all published models at the time of model submission), the F1 score on SQuAD v1.1 question answering to 93.0, the accuracy on SNLI to 91.7.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJgQ4lSFPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJg4NgBKvH" data-number="2244">
      <h4>
        <a href="/forum?id=BJg4NgBKvH">
            Training binary neural networks with real-to-binary convolutions
        </a>
      
        
          <a href="/pdf?id=BJg4NgBKvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=brais.mart%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="brais.mart@gmail.com">Brais Martinez</a>, <a href="/profile?email=psxjy3%40nottingham.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="psxjy3@nottingham.ac.uk">Jing Yang</a>, <a href="/profile?email=adrian%40adrianbulat.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="adrian@adrianbulat.com">Adrian Bulat</a>, <a href="/profile?email=yorgos.tzimiropoulos%40nottingham.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yorgos.tzimiropoulos@nottingham.ac.uk">Georgios Tzimiropoulos</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>17 Replies</span>
        
        
      </div>
      
        <a href="#BJg4NgBKvH-details-443" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJg4NgBKvH-details-443"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper shows how to train binary networks to within a few percent points (~3-5%) of the full precision counterpart. We first show how to build a strong baseline, which already achieves state-of-the-art accuracy, by combining recently proposed advances and carefully adjusting the optimization procedure. Secondly, we show that by attempting to minimize the discrepancy between the output of the binary and the corresponding real-valued convolution, additional significant accuracy gains can be obtained. We materialize this idea in two complementary ways: (1) with a loss function, during training, by matching the spatial attention maps computed at the output of the binary and real-valued convolutions, and (2) in a data-driven manner, by using the real-valued activations, available during inference prior to the binarization process, for re-scaling the activations right after the binary convolution. Finally, we show that, when putting all of our improvements together, the proposed model beats the current state of the art by more than 5% top-1 accuracy on ImageNet and reduces the gap to its real-valued counterpart to less than 3% and 5% top-1 accuracy on CIFAR-100 and ImageNet respectively when using a ResNet-18 architecture. Code available at https://github.com/brais-martinez/real2binary</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">binary networks</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJg4NgBKvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SylVNerFvr" data-number="2245">
      <h4>
        <a href="/forum?id=SylVNerFvr">
            Permutation Equivariant Models for Compositional Generalization in Language
        </a>
      
        
          <a href="/pdf?id=SylVNerFvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jg801%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jg801@cam.ac.uk">Jonathan Gordon</a>, <a href="/profile?email=dlp%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dlp@fb.com">David Lopez-Paz</a>, <a href="/profile?email=mbaroni%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mbaroni@fb.com">Marco Baroni</a>, <a href="/profile?email=dianeb%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dianeb@fb.com">Diane Bouchacourt</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SylVNerFvr-details-551" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SylVNerFvr-details-551"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a link between permutation equivariance and compositional generalization, and provide equivariant language models</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Humans understand novel sentences by composing meanings and roles of core language components. In contrast, neural network models for natural language modeling fail when such compositional generalization is required. The main contribution of this paper is to hypothesize that language compositionality is a form of group-equivariance. Based on this hypothesis, we propose a set of tools for constructing equivariant sequence-to-sequence models. Throughout a variety of experiments on the SCAN tasks, we analyze the behavior of existing models under the lens of equivariance, and demonstrate that our equivariant architecture is able to achieve the type compositional generalization required in human language understanding.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Compositionality, Permutation Equivariance, Language Processing</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/facebookresearch/Permutation-Equivariant-Seq2Seq</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SylVNerFvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJloElBYvB" data-number="2260">
      <h4>
        <a href="/forum?id=HJloElBYvB">
            Phase Transitions for the Information Bottleneck in Representation Learning
        </a>
      
        
          <a href="/pdf?id=HJloElBYvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tailin%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tailin@cs.stanford.edu">Tailin Wu</a>, <a href="/profile?email=iansf%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="iansf@google.com">Ian Fischer</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 14 May 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HJloElBYvB-details-650" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJloElBYvB-details-650"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We give a theoretical analysis of the Information Bottleneck objective to understand and predict observed phase transitions in the prediction vs. compression tradeoff.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In the Information Bottleneck (IB), when tuning the relative strength between compression and prediction terms, how do the two terms behave, and what's their relationship with the dataset and the learned representation? In this paper, we set out to answer these questions by studying multiple phase transitions in the IB objective: IB_β[p(z|x)] = I(X; Z) − βI(Y; Z) defined on the encoding distribution p(z|x) for input X, target Y and representation Z, where sudden jumps of dI(Y; Z)/dβ and prediction accuracy are observed with increasing β. We introduce a definition for IB phase transitions as a qualitative change of the IB loss landscape, and show that the transitions correspond to the onset of learning new classes. Using second-order calculus of variations, we derive a formula that provides a practical condition for IB phase transitions, and draw its connection with the Fisher information matrix for parameterized models. We provide two perspectives to understand the formula, revealing that each IB phase transition is finding a component of maximum (nonlinear) correlation between X and Y orthogonal to the learned representation, in close analogy with canonical-correlation analysis (CCA) in linear settings. Based on the theory, we present an algorithm for discovering phase transition points. Finally, we verify that our theory and algorithm accurately predict phase transitions in categorical datasets, predict the onset of learning new classes and class difficulty in MNIST, and predict prominent phase transitions in CIFAR10.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Information Theory, Representation Learning, Phase Transition</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJloElBYvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkejNgBtPB" data-number="2261">
      <h4>
        <a href="/forum?id=HkejNgBtPB">
            Variational Template Machine for Data-to-Text Generation
        </a>
      
        
          <a href="/pdf?id=HkejNgBtPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=rye18%40fudan.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="rye18@fudan.edu.cn">Rong Ye</a>, <a href="/profile?email=shiwenxian%40bytedance.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shiwenxian@bytedance.com">Wenxian Shi</a>, <a href="/profile?email=zhouhao.nlp%40bytedance.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhouhao.nlp@bytedance.com">Hao Zhou</a>, <a href="/profile?email=zywei%40fudan.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="zywei@fudan.edu.cn">Zhongyu Wei</a>, <a href="/profile?email=lileilab%40bytedance.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lileilab@bytedance.com">Lei Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HkejNgBtPB-details-594" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkejNgBtPB-details-594"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">How to generate descriptions from structured data organized in tables? Existing approaches using neural encoder-decoder models often suffer from lacking diversity. We claim that an open set of templates is crucial for enriching the phrase constructions and realizing varied generations.Learning such templates is prohibitive since it often requires a large paired &lt;table,description&gt;, which is seldom available. This paper explores the problem of automatically learning reusable "templates" from paired and non-paired data. We propose the variational template machine (VTM), a novel method to generate text descriptions from data tables. Our contributions include:  a) we carefully devise a specific model architecture and losses to explicitly disentangle text template and semantic content information, in the latent spaces, and b) we utilize both small parallel data and large raw text without aligned tables to enrich the template learning. Experiments on datasets from a variety of different domains show that VTM is able to generate more diversely while keeping a good fluency and quality. </span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkejNgBtPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1laNeBYPB" data-number="2266">
      <h4>
        <a href="/forum?id=r1laNeBYPB">
            Memory-Based Graph Networks
        </a>
      
        
          <a href="/pdf?id=r1laNeBYPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=amirhosein.khasahmadi%40mail.utoronto.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="amirhosein.khasahmadi@mail.utoronto.ca">Amir Hosein Khasahmadi</a>, <a href="/profile?email=kaveh.hassani%40autodesk.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kaveh.hassani@autodesk.com">Kaveh Hassani</a>, <a href="/profile?email=parsa.moradi73%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="parsa.moradi73@gmail.com">Parsa Moradi</a>, <a href="/profile?email=ljlee%40psi.toronto.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ljlee@psi.toronto.edu">Leo Lee</a>, <a href="/profile?email=quaid.morris%40utoronto.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="quaid.morris@utoronto.ca">Quaid Morris</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#r1laNeBYPB-details-29" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1laNeBYPB-details-29"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce an efficient memory layer to jointly learn representations and coarsen the input graphs.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Graph neural networks (GNNs) are a class of deep models that operate on data with arbitrary topology represented as graphs. We introduce an efficient memory layer for GNNs that can jointly learn node representations and coarsen the graph. We also introduce two new networks based on this layer: memory-based GNN (MemGNN) and graph memory network (GMN) that can learn hierarchical graph representations. The experimental results shows that the proposed models achieve state-of-the-art results in eight out of nine graph classification and regression benchmarks. We also show that the learned representations could correspond to chemical features in the molecule data.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Graph Neural Networks, Memory Networks, Hierarchial Graph Representation Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/amirkhas/GraphMemoryNet</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1laNeBYPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1gmrxHFvB" data-number="2278">
      <h4>
        <a href="/forum?id=S1gmrxHFvB">
            AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty
        </a>
      
        
          <a href="/pdf?id=S1gmrxHFvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=hendrycks%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="hendrycks@berkeley.edu">Dan Hendrycks*</a>, <a href="/profile?email=normanmu%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="normanmu@google.com">Norman Mu*</a>, <a href="/profile?email=cubuk%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="cubuk@google.com">Ekin Dogus Cubuk</a>, <a href="/profile?email=barretzoph%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="barretzoph@google.com">Barret Zoph</a>, <a href="/profile?email=gilmer%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="gilmer@google.com">Justin Gilmer</a>, <a href="/profile?email=balajiln%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="balajiln@google.com">Balaji Lakshminarayanan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>18 Replies</span>
        
        
      </div>
      
        <a href="#S1gmrxHFvB-details-74" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1gmrxHFvB-details-74"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We obtain state-of-the-art on robustness to data shifts, and we maintain calibration under data shift even though even when accuracy drops</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Modern deep neural networks can achieve high accuracy when the training distribution and test distribution are identically distributed, but this assumption is frequently violated in practice. When the train and test distributions are mismatched, accuracy can plummet. Currently there are few techniques that improve robustness to unforeseen data shifts encountered during deployment. In this work, we propose a technique to improve the robustness and uncertainty estimates of image classifiers. We propose AugMix, a data processing technique that is simple to implement, adds limited computational overhead, and helps models withstand unforeseen corruptions. AugMix significantly improves robustness and uncertainty measures on challenging image classification benchmarks, closing the gap between previous methods and the best possible performance in some cases by more than half. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">robustness, uncertainty</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/google-research/augmix</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1gmrxHFvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BylQSxHFwr" data-number="2280">
      <h4>
        <a href="/forum?id=BylQSxHFwr">
            AtomNAS: Fine-Grained End-to-End Neural Architecture Search
        </a>
      
        
          <a href="/pdf?id=BylQSxHFwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=meijieru%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="meijieru@gmail.com">Jieru Mei</a>, <a href="/profile?email=yingwei.li%40jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yingwei.li@jhu.edu">Yingwei Li</a>, <a href="/profile?email=xiaochen.lian%40bytedance.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiaochen.lian@bytedance.com">Xiaochen Lian</a>, <a href="/profile?email=jinxiaojie%40bytedance.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jinxiaojie@bytedance.com">Xiaojie Jin</a>, <a href="/profile?email=linjie.yang%40bytedance.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="linjie.yang@bytedance.com">Linjie Yang</a>, <a href="/profile?email=alan.l.yuille%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alan.l.yuille@gmail.com">Alan Yuille</a>, <a href="/profile?email=yangjianchao%40bytedance.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yangjianchao@bytedance.com">Jianchao Yang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#BylQSxHFwr-details-537" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BylQSxHFwr-details-537"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A new state-of-the-art on Imagenet for mobile setting</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Search space design is very critical to neural architecture search (NAS) algorithms. We propose a fine-grained search space comprised of atomic blocks, a minimal search unit that is much smaller than the ones used in recent NAS algorithms. This search space allows a mix of operations by composing different types of atomic blocks, while the search space in previous methods only allows homogeneous operations. Based on this search space, we propose a resource-aware architecture search framework which automatically assigns the computational resources (e.g., output channel numbers) for each operation by jointly considering the performance and the computational cost. In addition, to accelerate the search process, we propose a dynamic network shrinkage technique which prunes the atomic blocks with negligible influence on outputs on the fly.  Instead of a search-and-retrain two-stage paradigm, our method simultaneously searches and trains the target architecture. 
      Our method achieves state-of-the-art performance under several FLOPs configurations on ImageNet with a small searching cost.
      We open our entire codebase at: https://github.com/meijieru/AtomNAS.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Neural Architecture Search, Image Classification</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/meijieru/AtomNAS</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BylQSxHFwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1l4SgHKDH" data-number="2281">
      <h4>
        <a href="/forum?id=B1l4SgHKDH">
            Residual Energy-Based Models for Text Generation
        </a>
      
        
          <a href="/pdf?id=B1l4SgHKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=dengyuntian%40seas.harvard.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dengyuntian@seas.harvard.edu">Yuntian Deng</a>, <a href="/profile?email=yolo%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yolo@fb.com">Anton Bakhtin</a>, <a href="/profile?email=aszlam%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="aszlam@fb.com">Myle Ott</a>, <a href="/profile?email=ranzato%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ranzato@fb.com">Arthur Szlam</a>, Marc'Aurelio Ranzato
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 23 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#B1l4SgHKDH-details-966" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1l4SgHKDH-details-966"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We show that Energy-Based models when trained on the residual of an auto-regressive language model can be used effectively and efficiently to generate text. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Text generation is ubiquitous in many NLP tasks, from summarization, to dialogue and machine translation. The dominant parametric approach is based on locally normalized models which predict one word at a time. While these work remarkably well, they are plagued by exposure bias due to the greedy nature of the generation process. In this work, we investigate un-normalized energy-based models (EBMs) which operate not at the token but at the sequence level. In order to make training tractable, we first work in the residual of a pretrained locally normalized language model and second we train using noise contrastive estimation. Furthermore, since the EBM works at the sequence level, we can leverage pretrained bi-directional contextual representations, such as BERT and RoBERTa. Our experiments on two large language modeling datasets show that residual EBMs yield lower perplexity compared to locally normalized baselines. Moreover, generation via importance sampling is very efficient and of higher quality than the baseline models according to human evaluation.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">energy-based models, text generation</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1l4SgHKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkevSgrtPr" data-number="2288">
      <h4>
        <a href="/forum?id=rkevSgrtPr">
            A closer look at the approximation capabilities of neural networks
        </a>
      
        
          <a href="/pdf?id=rkevSgrtPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ernest_chong%40sutd.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="ernest_chong@sutd.edu.sg">Kai Fong Ernest Chong</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#rkevSgrtPr-details-83" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkevSgrtPr-details-83"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A quantitative refinement of the universal approximation theorem via an algebraic approach.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The universal approximation theorem, in one of its most general versions, says that if we consider only continuous activation functions σ, then a standard feedforward neural network with one hidden layer is able to approximate any continuous multivariate function f to any given approximation threshold ε, if and only if σ is non-polynomial. In this paper, we give a direct algebraic proof of the theorem. Furthermore we shall explicitly quantify the number of hidden units required for approximation. Specifically, if X in R^n is compact, then a neural network with n input units, m output units, and a single hidden layer with {n+d choose d} hidden units (independent of m and ε), can uniformly approximate any polynomial function f:X -&gt; R^m whose total degree is at most d for each of its m coordinate functions. In the general case that f is any continuous function, we show there exists some N in O(ε^{-n}) (independent of m), such that N hidden units would suffice to approximate f. We also show that this uniform approximation property (UAP) still holds even under seemingly strong conditions imposed on the weights. We highlight several consequences: (i) For any δ &gt; 0, the UAP still holds if we restrict all non-bias weights w in the last layer to satisfy |w| &lt; δ. (ii) There exists some λ&gt;0 (depending only on f and σ), such that the UAP still holds if we restrict all non-bias weights w in the first layer to satisfy |w|&gt;λ. (iii) If the non-bias weights in the first layer are *fixed* and randomly chosen from a suitable range, then the UAP holds with probability 1.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, approximation, universal approximation theorem</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkevSgrtPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rygjHxrYDB" data-number="2298">
      <h4>
        <a href="/forum?id=rygjHxrYDB">
            Deep Audio Priors Emerge From Harmonic Convolutional Networks
        </a>
      
        
          <a href="/pdf?id=rygjHxrYDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ztzhang%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ztzhang@mit.edu">Zhoutong Zhang</a>, <a href="/profile?email=wyy%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wyy@mit.edu">Yunyun Wang</a>, <a href="/profile?email=ganchuang1990%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ganchuang1990@gmail.com">Chuang Gan</a>, <a href="/profile?email=jiajunwu%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jiajunwu@mit.edu">Jiajun Wu</a>, <a href="/profile?email=jbt%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jbt@mit.edu">Joshua B. Tenenbaum</a>, <a href="/profile?email=torralba%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="torralba@mit.edu">Antonio Torralba</a>, <a href="/profile?email=billf%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="billf@mit.edu">William T. Freeman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="#rygjHxrYDB-details-540" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rygjHxrYDB-details-540"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A new operation called Harmonic Convolution makes deep network model audio priors without training.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Convolutional neural networks (CNNs) excel in image recognition and generation. Among many efforts to explain their effectiveness, experiments show that CNNs carry strong inductive biases that capture natural image priors. Do deep networks also have inductive biases for audio signals? In this paper, we empirically show that current network architectures for audio processing do not show strong evidence in capturing such priors. We propose Harmonic Convolution, an operation that helps deep networks distill priors in audio signals by explicitly utilizing the harmonic structure within. This is done by engineering the kernel to be supported by sets of harmonic series, instead of local neighborhoods for convolutional kernels. We show that networks using Harmonic Convolution can reliably model audio priors and achieve high performance in unsupervised audio restoration tasks. With Harmonic Convolution, they also achieve better generalization performance for sound source separation.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Audio, Deep Prior</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">http://dap.csail.mit.edu/</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rygjHxrYDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByglLlHFDS" data-number="2310">
      <h4>
        <a href="/forum?id=ByglLlHFDS">
            Expected Information Maximization: Using the I-Projection for Mixture Density Estimation
        </a>
      
        
          <a href="/pdf?id=ByglLlHFDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=philippbecker93%40googlemail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="philippbecker93@googlemail.com">Philipp Becker</a>, <a href="/profile?email=oleg%40robot-learning.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="oleg@robot-learning.de">Oleg Arenz</a>, <a href="/profile?email=geri%40robot-learning.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="geri@robot-learning.de">Gerhard Neumann</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#ByglLlHFDS-details-969" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByglLlHFDS-details-969"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A novel, non-adversarial, approach to learn latent variable models in general and mixture models in particular by computing the I-Projection solely based on samples.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Modelling highly multi-modal data is a challenging problem in machine learning. Most algorithms are based on maximizing the likelihood, which corresponds to the M(oment)-projection of the data distribution to the model distribution.
      The M-projection forces the model to average over modes it cannot represent. In contrast, the I(nformation)-projection ignores such modes in the data and concentrates on the modes the model can represent. Such behavior is appealing whenever we deal with highly multi-modal data where modelling single modes correctly is more important than covering all the modes. Despite this advantage, the I-projection is rarely used in practice due to the lack of algorithms that can efficiently optimize it based on data. In this work, we present a new algorithm called Expected Information Maximization (EIM) for computing the I-projection solely based on samples for general latent variable models, where we focus on Gaussian mixtures models and Gaussian mixtures of experts. Our approach applies a variational upper bound to the I-projection objective which decomposes the original objective into single objectives for each mixture component as well as for the coefficients, allowing an efficient optimization. Similar to GANs, our approach employs discriminators but uses a more stable optimization procedure, using a tight upper bound. We show that our algorithm is much more effective in computing the I-projection than recent GAN approaches and we illustrate the effectiveness of our approach for modelling multi-modal behavior on two pedestrian and traffic prediction datasets.  </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">density estimation, information projection, mixture models, generative learning, multimodal modeling</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/pbecker93/ExpectedInformationMaximization</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByglLlHFDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxWIgBFPS" data-number="2311">
      <h4>
        <a href="/forum?id=ryxWIgBFPS">
            A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms
        </a>
      
        
          <a href="/pdf?id=ryxWIgBFPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yoshua.bengio%40mila.quebec" class="profile-link" data-toggle="tooltip" data-placement="top" title="yoshua.bengio@mila.quebec">Yoshua Bengio</a>, <a href="/profile?email=tristan.deleu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tristan.deleu@gmail.com">Tristan Deleu</a>, <a href="/profile?email=nasim.rahaman%40tuebingen.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="nasim.rahaman@tuebingen.mpg.de">Nasim Rahaman</a>, <a href="/profile?email=rosemary.nan.ke%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="rosemary.nan.ke@gmail.com">Nan Rosemary Ke</a>, <a href="/profile?email=sebastien.lachapelle%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastien.lachapelle@umontreal.ca">Sebastien Lachapelle</a>, <a href="/profile?email=obilaniu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="obilaniu@gmail.com">Olexa Bilaniuk</a>, <a href="/profile?email=anirudhgoyal9119%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="anirudhgoyal9119@gmail.com">Anirudh Goyal</a>, <a href="/profile?email=chris.j.pal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chris.j.pal@gmail.com">Christopher Pal</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#ryxWIgBFPS-details-894" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxWIgBFPS-details-894"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This paper proposes a meta-learning objective based on speed of adaptation to transfer distributions to discover a modular decomposition and causal variables.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose to use a meta-learning objective that maximizes the speed of transfer on a modified distribution to learn how to modularize acquired knowledge. In particular, we focus on how to factor a joint distribution into appropriate conditionals, consistent with the causal directions. We explain when this can work, using the assumption that the changes in distributions are localized (e.g. to one of the marginals, for example due to an intervention on one of the variables). We prove that under this assumption of localized changes in causal mechanisms, the correct causal graph will tend to have only a few of its parameters with non-zero gradient, i.e. that need to be adapted (those of the modified variables). We argue and observe experimentally that this leads to faster adaptation, and use this property to define a meta-learning surrogate score which, in addition to a continuous parametrization of graphs, would favour correct causal graphs. Finally, motivated by the AI agent point of view (e.g. of a robot discovering its environment autonomously), we consider how the same objective can discover the causal variables themselves, as a transformation of observed low-level variables with no causal meaning. Experiments in the two-variable case validate the proposed ideas and theoretical results.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/ec6dde01667145e58de60f864e05a4/CausalOptimizationAnon</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">meta-learning, transfer learning, structure learning, modularity, causality</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxWIgBFPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJxGLlBtwH" data-number="2315">
      <h4>
        <a href="/forum?id=rJxGLlBtwH">
            On the interaction between supervision and self-play in emergent communication
        </a>
      
        
          <a href="/pdf?id=rJxGLlBtwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=rlowe1%40cs.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="rlowe1@cs.mcgill.ca">Ryan Lowe*</a>, <a href="/profile?email=abhinav.gupta%40umontreal.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhinav.gupta@umontreal.ca">Abhinav Gupta*</a>, <a href="/profile?email=jakobfoerster%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jakobfoerster@gmail.com">Jakob Foerster</a>, <a href="/profile?email=dkiela%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dkiela@fb.com">Douwe Kiela</a>, <a href="/profile?email=jpineau%40cs.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="top" title="jpineau@cs.mcgill.ca">Joelle Pineau</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 23 Jun 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rJxGLlBtwH-details-562" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJxGLlBtwH-details-562"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">A promising approach for teaching artificial agents to use natural language involves using human-in-the-loop training. However, recent work suggests that current machine learning methods are too data inefficient to be trained in this way from scratch. In this paper, we investigate the relationship between two categories of learning signals with the ultimate goal of improving sample efficiency: imitating human language data via supervised learning, and maximizing reward in a simulated multi-agent environment via self-play (as done in emergent communication), and introduce the term supervised self-play (S2P) for algorithms using both of these signals. We find that first training agents via supervised learning on human data followed by self-play outperforms the converse, suggesting that it is not beneficial to emerge languages from scratch. We then empirically investigate various S2P schedules that begin with supervised learning in two environments: a Lewis signaling game with symbolic inputs, and an image-based referential game with natural language descriptions. Lastly, we introduce population based approaches to S2P, which further improves the performance over single-agent methods.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">multi-agent communication, self-play, emergent languages</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/backpropper/s2p</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJxGLlBtwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJem8lSFwB" data-number="2317">
      <h4>
        <a href="/forum?id=SJem8lSFwB">
            Dynamic Model Pruning with Feedback
        </a>
      
        
          <a href="/pdf?id=SJem8lSFwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tao.lin%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="tao.lin@epfl.ch">Tao Lin</a>, <a href="/profile?email=sebastian.stich%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="sebastian.stich@epfl.ch">Sebastian U. Stich</a>, <a href="/profile?email=luis.barba%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="luis.barba@inf.ethz.ch">Luis Barba</a>, <a href="/profile?email=daniil.dmitriev%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniil.dmitriev@epfl.ch">Daniil Dmitriev</a>, <a href="/profile?email=martin.jaggi%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="martin.jaggi@epfl.ch">Martin Jaggi</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="#SJem8lSFwB-details-623" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJem8lSFwB-details-623"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep neural networks often have millions of parameters. This can hinder their deployment to low-end devices, not only due to high memory requirements but also because of increased latency at inference. We propose a novel model compression method that generates a sparse trained model without additional overhead: by allowing (i) dynamic allocation of the sparsity pattern and  (ii) incorporating feedback signal to reactivate prematurely pruned weights we obtain a performant sparse model in one single training pass (retraining is not needed, but can further improve the performance). We evaluate the method on CIFAR-10 and ImageNet, and show that the obtained sparse models can reach the state-of-the-art performance of dense models and further that their performance surpasses all previously proposed pruning schemes (that come without feedback mechanisms).</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">network pruning, dynamic reparameterization, model compression</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJem8lSFwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJxE8erKDH" data-number="2319">
      <h4>
        <a href="/forum?id=SJxE8erKDH">
            Latent Normalizing Flows for Many-to-Many Cross-Domain Mappings
        </a>
      
        
          <a href="/pdf?id=SJxE8erKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=mahajan%40aiphes.tu-darmstadt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="mahajan@aiphes.tu-darmstadt.de">Shweta Mahajan</a>, <a href="/profile?email=gurevych%40ukp.informatik.tu-darmstadt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="gurevych@ukp.informatik.tu-darmstadt.de">Iryna Gurevych</a>, <a href="/profile?email=stefan.roth%40visinf.tu-darmstadt.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="stefan.roth@visinf.tu-darmstadt.de">Stefan Roth</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 07 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#SJxE8erKDH-details-549" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJxE8erKDH-details-549"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Learned joint representations of images and text form the backbone of several important cross-domain tasks such as image captioning. Prior work mostly maps both domains into a common latent representation in a purely supervised fashion. This is rather restrictive, however, as the two domains follow distinct generative processes. Therefore, we propose a novel semi-supervised framework, which models shared information between domains and domain-specific information separately. 
      The information shared between the domains is aligned with an invertible neural network. Our model integrates normalizing flow-based priors for the domain-specific information, which allows us to learn diverse many-to-many mappings between the two domains. We demonstrate the effectiveness of our model on diverse tasks, including image captioning and text-to-image synthesis.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/visinf/lnfmm</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJxE8erKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1gEIerYwH" data-number="2320">
      <h4>
        <a href="/forum?id=S1gEIerYwH">
            Transferring Optimality Across Data Distributions via Homotopy Methods
        </a>
      
        
          <a href="/pdf?id=S1gEIerYwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=gargiani%40informatik.uni-freiburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="gargiani@informatik.uni-freiburg.de">Matilde Gargiani</a>, <a href="/profile?email=andrea.zanelli%40imtek.uni-freiburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="andrea.zanelli@imtek.uni-freiburg.de">Andrea Zanelli</a>, <a href="/profile?email=quoctd%40email.unc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="quoctd@email.unc.edu">Quoc Tran Dinh</a>, <a href="/profile?email=moritz.diehl%40imtek.uni-freiburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="moritz.diehl@imtek.uni-freiburg.de">Moritz Diehl</a>, <a href="/profile?email=fh%40cs.uni-freiburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="fh@cs.uni-freiburg.de">Frank Hutter</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#S1gEIerYwH-details-39" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1gEIerYwH-details-39"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a new homotopy-based method to transfer "optimality knowledge" across different data distributions in order to speed up training of deep models.  </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Homotopy methods, also known as continuation methods, are a powerful mathematical tool to efficiently solve various problems in numerical analysis, including complex non-convex optimization problems where no or only little prior knowledge regarding the localization of the solutions is available. 
      In this work, we propose a novel homotopy-based numerical method that can be used to transfer knowledge regarding the localization of an optimum across different task distributions in deep learning applications. We validate the proposed methodology with some empirical evaluations in the regression and classification scenarios, where it shows that superior numerical performance can be achieved in popular deep learning benchmarks, i.e. FashionMNIST, CIFAR-10, and draw connections with the widely used fine-tuning heuristic. In addition, we give more insights on the properties of a general homotopy method when used in combination with Stochastic Gradient Descent by conducting a general local theoretical analysis in a simplified setting. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">deep learning, numerical optimization, transfer learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1gEIerYwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rygwLgrYPB" data-number="2326">
      <h4>
        <a href="/forum?id=rygwLgrYPB">
            Regularizing activations in neural networks via distribution matching with the Wasserstein metric
        </a>
      
        
          <a href="/pdf?id=rygwLgrYPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tjoo%40estsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tjoo@estsoft.com">Taejong Joo</a>, <a href="/profile?email=emppunity%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="emppunity@gmail.com">Donggu Kang</a>, <a href="/profile?email=byungkim%40hanyang.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="top" title="byungkim@hanyang.ac.kr">Byunghoon Kim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 27 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rygwLgrYPB-details-547" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rygwLgrYPB-details-547"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Regularization and normalization have become indispensable components in training deep neural networks, resulting in faster training and improved generalization performance. We propose the projected error function regularization loss (PER) that encourages activations to follow the standard normal distribution. PER randomly projects activations onto one-dimensional space and computes the regularization loss in the projected space. PER is similar to the Pseudo-Huber loss in the projected space, thus taking advantage of both <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="536" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>L</mi><mn>1</mn></msup></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="537" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>L</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container> regularization losses. Besides, PER can capture the interaction between hidden units by projection vector drawn from a unit sphere. By doing so, PER minimizes the upper bound of the Wasserstein distance of order one between an empirical distribution of activations and the standard normal distribution. To the best of the authors' knowledge, this is the first work to regularize activations via distribution matching in the probability distribution space. We evaluate the proposed method on the image classification task and the word-level language modeling task.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">regularization, Wasserstein metric, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rygwLgrYPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByxaUgrFvH" data-number="2341">
      <h4>
        <a href="/forum?id=ByxaUgrFvH">
            Mutual Information Gradient Estimation for  Representation Learning
        </a>
      
        
          <a href="/pdf?id=ByxaUgrFvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wlj6816%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wlj6816@gmail.com">Liangjian Wen</a>, <a href="/profile?email=zhouyiji%40outlook.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhouyiji@outlook.com">Yiji Zhou</a>, <a href="/profile?email=ronghe1217%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ronghe1217@gmail.com">Lirong He</a>, <a href="/profile?email=mingyuan.zhou%40mccombs.utexas.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mingyuan.zhou@mccombs.utexas.edu">Mingyuan Zhou</a>, <a href="/profile?email=zenglin%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zenglin@gmail.com">Zenglin Xu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 13 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>19 Replies</span>
        
        
      </div>
      
        <a href="#ByxaUgrFvH-details-967" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByxaUgrFvH-details-967"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Mutual Information (MI) plays an important role in representation learning. However, MI is unfortunately intractable in continuous and high-dimensional settings. Recent advances establish tractable and scalable MI estimators to discover useful representation. However, most of the existing methods are not capable of providing an accurate estimation of MI with low-variance when the MI is large. We argue that directly estimating the gradients of MI is more appealing for representation learning than estimating MI in itself. To this end, we propose the Mutual Information Gradient Estimator (MIGE) for representation learning based on the score estimation of implicit distributions. MIGE exhibits a tight and smooth gradient estimation of MI in the high-dimensional and large-MI settings. We expand the applications of MIGE in both unsupervised learning of deep representations based on InfoMax and the Information Bottleneck method. Experimental results have indicated significant performance improvement in learning useful representation.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Mutual Information, Score Estimation, Representation Learning, Information Bottleneck</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByxaUgrFvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByeMPlHKPH" data-number="2353">
      <h4>
        <a href="/forum?id=ByeMPlHKPH">
            Lite Transformer with Long-Short Range Attention
        </a>
      
        
          <a href="/pdf?id=ByeMPlHKPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zhanghao.wu%40outlook.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhanghao.wu@outlook.com">Zhanghao Wu*</a>, <a href="/profile?email=zhijian%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhijian@mit.edu">Zhijian Liu*</a>, <a href="/profile?email=jilin%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jilin@mit.edu">Ji Lin</a>, <a href="/profile?email=yujunlin%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yujunlin@mit.edu">Yujun Lin</a>, <a href="/profile?email=songhan%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="songhan@mit.edu">Song Han</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 27 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#ByeMPlHKPH-details-257" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByeMPlHKPH-details-257"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Transformer has become ubiquitous in natural language processing (e.g., machine translation, question answering); however, it requires enormous amount of computations to achieve high performance, which makes it not suitable for mobile applications that are tightly constrained by the hardware resources and battery. In this paper, we present an efficient mobile NLP architecture, Lite Transformer to facilitate deploying mobile NLP applications on edge devices. The key primitive is the Long-Short Range Attention (LSRA), where one group of heads specializes in the local context modeling (by convolution) while another group specializes in the long-distance relationship modeling (by attention). Such specialization brings consistent improvement over the vanilla transformer on three well-established language tasks: machine translation, abstractive summarization, and language modeling. Under constrained resources (500M/100M MACs), Lite Transformer outperforms transformer on WMT'14 English-French by 1.2/1.7 BLEU, respectively. Lite Transformer reduces the computation of transformer base model by 2.5x with 0.3 BLEU score degradation. Combining with pruning and quantization, we further compressed the model size of Lite Transformer by 18.2x. For language modeling, Lite Transformer achieves 1.8 lower perplexity than the transformer at around 500M MACs. Notably, Lite Transformer outperforms the AutoML-based Evolved Transformer by 0.5 higher BLEU for the mobile NLP setting without the costly architecture search that requires more than 250 GPU years. Code has been made available at https://github.com/mit-han-lab/lite-transformer.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">efficient model, transformer</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByeMPlHKPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1lNPxHKDH" data-number="2356">
      <h4>
        <a href="/forum?id=H1lNPxHKDH">
            A Function Space View of Bounded Norm Infinite Width ReLU Nets: The Multivariate Case
        </a>
      
        
          <a href="/pdf?id=H1lNPxHKDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=gongie%40uchicago.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="gongie@uchicago.edu">Greg Ongie</a>, <a href="/profile?email=willett%40uchicago.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="willett@uchicago.edu">Rebecca Willett</a>, <a href="/profile?email=daniel.soudry%40technion.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="daniel.soudry@technion.ac.il">Daniel Soudry</a>, <a href="/profile?email=nati%40ttic.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="nati@ttic.edu">Nathan Srebro</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#H1lNPxHKDH-details-461" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1lNPxHKDH-details-461"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We characterize the space of functions realizable as a ReLU network with an unbounded number of units (infinite width), but where the Euclidean norm of the weights is bounded.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We give a tight characterization of the (vectorized Euclidean) norm of weights required to realize a function <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="538" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D453 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3A"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c211D TEX-A"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo><mjx-msup space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-ds mjx-b"><mjx-c class="mjx-c211D TEX-A"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.41em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo>:</mo><mrow><mi mathvariant="double-struck">R</mi></mrow><mo stretchy="false">→</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mi>d</mi></msup></math></mjx-assistive-mml></mjx-container> as a single hidden-layer ReLU network with an unbounded number of units (infinite width), extending the univariate characterization of Savarese et al. (2019) to the multivariate case.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">inductive bias, regularization, infinite-width networks, ReLU networks</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1lNPxHKDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Bke_DertPB" data-number="2365">
      <h4>
        <a href="/forum?id=Bke_DertPB">
            Adversarial Lipschitz Regularization
        </a>
      
        
          <a href="/pdf?id=Bke_DertPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=david.terjek92%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="david.terjek92@gmail.com">Dávid Terjék</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#Bke_DertPB-details-394" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Bke_DertPB-details-394"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">alternative to gradient penalty</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Generative adversarial networks (GANs) are one of the most popular approaches when it comes to training generative models, among which variants of Wasserstein GANs are considered superior to the standard GAN formulation in terms of learning stability and sample quality. However, Wasserstein GANs require the critic to be 1-Lipschitz, which is often enforced implicitly by penalizing the norm of its gradient, or by globally restricting its Lipschitz constant via weight normalization techniques. Training with a regularization term penalizing the violation of the Lipschitz constraint explicitly, instead of through the norm of the gradient, was found to be practically infeasible in most situations. Inspired by Virtual Adversarial Training, we propose a method called Adversarial Lipschitz Regularization, and show that using an explicit Lipschitz penalty is indeed viable and leads to competitive performance when applied to Wasserstein GANs, highlighting an important connection between Lipschitz regularization and adversarial training.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/open?id=11CVllq2OmppENKBQdqGIBz_BYTiiZVl_</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">generative adversarial networks, wasserstein generative adversarial networks, lipschitz regularization, adversarial training</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Bke_DertPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rklnDgHtDS" data-number="2375">
      <h4>
        <a href="/forum?id=rklnDgHtDS">
            Compositional Language Continual Learning
        </a>
      
        
          <a href="/pdf?id=rklnDgHtDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yuanpeng16%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuanpeng16@gmail.com">Yuanpeng Li</a>, <a href="/profile?email=lzhao4ever%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lzhao4ever@gmail.com">Liang Zhao</a>, <a href="/profile?email=kenneth.ward.church%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kenneth.ward.church@gmail.com">Kenneth Church</a>, <a href="/profile?email=mohamed.elhoseiny%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="mohamed.elhoseiny@gmail.com">Mohamed Elhoseiny</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rklnDgHtDS-details-978" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rklnDgHtDS-details-978"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Motivated by the human's ability to continually learn and gain knowledge over time, several research efforts have been pushing the limits of machines to constantly learn while alleviating catastrophic forgetting. Most of the existing methods have been focusing on continual learning of label prediction tasks, which have fixed input and output sizes. In this paper, we propose a new scenario of continual learning which handles sequence-to-sequence tasks common in language learning. We further propose an approach to use label prediction continual learning algorithm for sequence-to-sequence continual learning by leveraging compositionality. Experimental results show that the proposed method has significant improvement over state-of-the-art methods. It enables knowledge transfer and prevents catastrophic forgetting, resulting in more than 85% accuracy up to 100 stages, compared with less than 50% accuracy for baselines in instruction learning task. It also shows significant improvement in machine translation task. This is the first work to combine continual learning and compositionality for language learning, and we hope this work will make machines more helpful in various tasks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/yli1/CLCL</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Compositionality, Continual Learning, Lifelong Learning, Sequence to Sequence Modeling</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rklnDgHtDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkxawlHKDr" data-number="2378">
      <h4>
        <a href="/forum?id=rkxawlHKDr">
            End to End Trainable Active Contours via Differentiable Rendering
        </a>
      
        
          <a href="/pdf?id=rkxawlHKDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=shiretzet%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="shiretzet@gmail.com">Shir Gur</a>, <a href="/profile?email=shaharabany%40mail.tau.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="shaharabany@mail.tau.ac.il">Tal Shaharabany</a>, <a href="/profile?email=wolf%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="wolf@fb.com">Lior Wolf</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="#rkxawlHKDr-details-414" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkxawlHKDr-details-414"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present an image segmentation method that iteratively evolves a polygon. At each iteration, the vertices of the polygon are displaced based on the local value of a 2D shift map that is inferred from the input image via an encoder-decoder architecture. The main training loss that is used is the difference between the polygon shape and the ground truth segmentation mask. The network employs a neural renderer to create the polygon from its vertices, making the process fully differentiable. We demonstrate that our method outperforms the state of the art segmentation networks and deep active contour solutions in a variety of benchmarks, including medical imaging and aerial images.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkxawlHKDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJxkOlSYDH" data-number="2382">
      <h4>
        <a href="/forum?id=BJxkOlSYDH">
            Provable Filter Pruning for Efficient Neural Networks
        </a>
      
        
          <a href="/pdf?id=BJxkOlSYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=lucasl%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lucasl@mit.edu">Lucas Liebenwein</a>, <a href="/profile?email=baykal%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="baykal@mit.edu">Cenk Baykal</a>, <a href="/profile?email=hlang08%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="hlang08@gmail.com">Harry Lang</a>, <a href="/profile?email=dannyf.post%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dannyf.post@gmail.com">Dan Feldman</a>, <a href="/profile?email=rus%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rus@csail.mit.edu">Daniela Rus</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#BJxkOlSYDH-details-415" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJxkOlSYDH-details-415"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A sampling-based filter pruning approach for convolutional neural networks exhibiting provable guarantees on the size and performance of the pruned network.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present a provable, sampling-based approach for generating compact Convolutional Neural Networks (CNNs) by identifying and removing redundant filters from an over-parameterized network. Our algorithm uses a small batch of input data points to assign a saliency score to each filter and constructs an importance sampling distribution where filters that highly affect the output are sampled with correspondingly high probability. 
      In contrast to existing filter pruning approaches, our method is simultaneously data-informed, exhibits provable guarantees on the size and performance of the pruned network, and is widely applicable to varying network architectures and data sets. Our analytical bounds bridge the notions of compressibility and importance of network structures, which gives rise to a fully-automated procedure for identifying and preserving filters in layers that are essential to the network's performance. Our experimental evaluations on popular architectures and data sets show that our algorithm consistently generates sparser and more efficient models than those constructed by existing filter pruning approaches. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">theory, compression, filter pruning, neural networks</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/lucaslie/provable_pruning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJxkOlSYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgfdeBYvH" data-number="2390">
      <h4>
        <a href="/forum?id=rkgfdeBYvH">
            Effect of Activation Functions on the Training of Overparametrized Neural Nets
        </a>
      
        
          <a href="/pdf?id=rkgfdeBYvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=abhishekpanigrahi034%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="abhishekpanigrahi034@gmail.com">Abhishek Panigrahi</a>, <a href="/profile?email=ashetty1995%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ashetty1995@gmail.com">Abhishek Shetty</a>, <a href="/profile?email=navingo%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="navingo@microsoft.com">Navin Goyal</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>5 Replies</span>
        
        
      </div>
      
        <a href="#rkgfdeBYvH-details-155" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgfdeBYvH-details-155"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We provide theoretical results about the effect of activation function on the training of highly overparametrized 2-layer neural networks</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">It is well-known that overparametrized neural networks trained using gradient based methods quickly achieve small training error with appropriate hyperparameter settings. Recent papers have proved this statement theoretically for highly overparametrized networks under reasonable assumptions. These results either assume that the activation function is ReLU or they depend on the minimum eigenvalue of a certain Gram matrix. In the latter case, existing works only prove that this minimum eigenvalue is non-zero and do not provide quantitative bounds which require that this eigenvalue be large. Empirically, a number of alternative activation functions have been proposed which tend to perform better than ReLU at least in some settings but no clear understanding has emerged. This state of affairs underscores the importance of theoretically understanding the impact of activation functions on training. In the present paper, we provide theoretical results about the effect of activation function on the training of highly overparametrized 2-layer neural networks. A crucial property that governs the performance of an activation is whether or not it is smooth: 
      • For non-smooth activations such as ReLU, SELU, ELU, which are not smooth because there is a point where either the ﬁrst order or second order derivative is discontinuous, all eigenvalues of the associated Gram matrix are large under minimal assumptions on the data. 
      • For smooth activations such as tanh, swish, polynomial, which have derivatives of all orders at all points, the situation is more complex: if the subspace spanned by the data has small dimension then the minimum eigenvalue of the Gram matrix can be small leading to slow training. But if the dimension is large and the data satisﬁes another mild condition, then the eigenvalues are large. If we allow deep networks, then the small data dimension is not a limitation provided that the depth is sufﬁcient. 
      We discuss a number of extensions and applications of these results.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/file/d/1Erj761XggITFSlcdiJJ8fKAkoEALU4L8/view?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">activation functions, deep learning theory, neural networks</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgfdeBYvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJe4_xSFDB" data-number="2394">
      <h4>
        <a href="/forum?id=rJe4_xSFDB">
            Lipschitz constant estimation of Neural Networks via sparse polynomial optimization
        </a>
      
        
          <a href="/pdf?id=rJe4_xSFDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=fabian.latorre%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="fabian.latorre@epfl.ch">Fabian Latorre</a>, <a href="/profile?email=paul.rolland%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="paul.rolland@epfl.ch">Paul Rolland</a>, <a href="/profile?email=volkan.cevher%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="volkan.cevher@epfl.ch">Volkan Cevher</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#rJe4_xSFDB-details-730" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJe4_xSFDB-details-730"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We introduce LiPopt, a polynomial optimization framework for computing increasingly tighter upper bound on the Lipschitz constant of neural networks. The underlying optimization problems boil down to either linear (LP) or semidefinite (SDP) programming. We show how to use the sparse connectivity of a network, to significantly reduce the complexity of computation. This is specially useful for convolutional as well as pruned neural networks. We conduct experiments on networks with random weights as well as networks trained on MNIST, showing that in the particular case of the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="539" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-n" size="s"><mjx-c class="mjx-c221E"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mi mathvariant="normal">∞</mi></msub></math></mjx-assistive-mml></mjx-container>-Lipschitz constant, our approach yields superior estimates as compared to other baselines available in the literature.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://drive.google.com/drive/folders/1bkj0H6Thgd9sjRloyq9NBP0uO0v704E9?usp=sharing</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">robust networks, Lipschitz constant, polynomial optimization</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">LP-based upper bounds on the Lipschitz constant of Neural Networks</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJe4_xSFDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylrdxHFDr" data-number="2397">
      <h4>
        <a href="/forum?id=rylrdxHFDr">
            State Alignment-based Imitation Learning
        </a>
      
        
          <a href="/pdf?id=rylrdxHFDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=fliu%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fliu@eng.ucsd.edu">Fangchen Liu</a>, <a href="/profile?email=z6ling%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="z6ling@eng.ucsd.edu">Zhan Ling</a>, <a href="/profile?email=t3mu%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="t3mu@eng.ucsd.edu">Tongzhou Mu</a>, <a href="/profile?email=haosu%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="haosu@eng.ucsd.edu">Hao Su</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="#rylrdxHFDr-details-83" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylrdxHFDr-details-83"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Consider an imitation learning problem that the imitator and the expert have different dynamics models. Most of existing imitation learning methods fail because they focus on the imitation of actions. We propose a novel state alignment-based imitation learning method to train the imitator by following the state sequences in the expert demonstrations as much as possible. The alignment of states comes from both local and global perspectives. We combine them into a reinforcement learning framework by a regularized policy update objective. We show the superiority of our method on standard imitation learning settings as well as the challenging settings in which the expert and the imitator have different dynamics models.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Imitation learning, Reinforcement Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rylrdxHFDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkl8dlHYvB" data-number="2398">
      <h4>
        <a href="/forum?id=rkl8dlHYvB">
            Learning to Group: A Bottom-Up Framework for 3D Part Discovery in Unseen Categories
        </a>
      
        
          <a href="/pdf?id=rkl8dlHYvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=luotg%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="luotg@pku.edu.cn">Tiange Luo</a>, <a href="/profile?email=kaichun%40cs.stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kaichun@cs.stanford.edu">Kaichun Mo</a>, <a href="/profile?email=z2huang%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="z2huang@eng.ucsd.edu">Zhiao Huang</a>, <a href="/profile?email=jxuat%40connect.ust.hk" class="profile-link" data-toggle="tooltip" data-placement="top" title="jxuat@connect.ust.hk">Jiarui Xu</a>, <a href="/profile?email=sy89128%40mail.ustc.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="sy89128@mail.ustc.edu.cn">Siyu Hu</a>, <a href="/profile?email=wanglw%40cis.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="wanglw@cis.pku.edu.cn">Liwei Wang</a>, <a href="/profile?email=haosu%40eng.ucsd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="haosu@eng.ucsd.edu">Hao Su</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 28 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rkl8dlHYvB-details-312" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkl8dlHYvB-details-312"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A zero-shot segmentation framework for 3D shapes. Model the segmentation as a decision-making process, we propose an iterative method to dynamically extend the receptive field for achieving universal shape segmentation.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We address the problem of learning to discover 3D parts for objects in unseen categories. Being able to learn the geometry prior of parts and transfer this prior to unseen categories pose fundamental challenges on data-driven shape segmentation approaches. Formulated as a contextual bandit problem, we propose a learning-based iterative grouping framework which learns a grouping policy to progressively merge small part proposals into bigger ones in a bottom-up fashion. At the core of our approach is to restrict the local context for extracting part-level features, which encourages the generalizability to novel categories. On a recently proposed large-scale fine-grained 3D part dataset, PartNet, we demonstrate that our method can transfer knowledge of parts learned from 3 training categories to 21 unseen testing categories without seeing any annotated samples. Quantitative comparisons against four strong shape segmentation baselines show that we achieve the state-of-the-art performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Shape Segmentation, Zero-Shot Learning, Learning Representations</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/tiangeluo/Learning-to-Group</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkl8dlHYvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJl8_eHYvS" data-number="2399">
      <h4>
        <a href="/forum?id=HJl8_eHYvS">
            Discriminative Particle Filter Reinforcement Learning for Complex Partial observations
        </a>
      
        
          <a href="/pdf?id=HJl8_eHYvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xiao-ma%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="xiao-ma@comp.nus.edu.sg">Xiao Ma</a>, <a href="/profile?email=karkus%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="karkus@comp.nus.edu.sg">Peter Karkus</a>, <a href="/profile?email=dyhsu%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="dyhsu@comp.nus.edu.sg">David Hsu</a>, <a href="/profile?email=leews%40comp.nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="leews@comp.nus.edu.sg">Wee Sun Lee</a>, <a href="/profile?email=nan.ye%40uq.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="nan.ye@uq.edu.au">Nan Ye</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HJl8_eHYvS-details-900" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJl8_eHYvS-details-900"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce DPFRL, a framework for reinforcement learning under partial and complex observations with an importance-weighted particle filter</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep reinforcement learning is successful in decision making for sophisticated games, such as Atari, Go, etc. 
      However, real-world decision making often requires reasoning with partial information extracted from complex visual observations. This paper presents  Discriminative Particle Filter Reinforcement Learning (DPFRL), a new reinforcement learning framework for complex partial observations. DPFRL encodes a differentiable particle filter in the neural network policy for explicit reasoning with partial observations over time. The particle filter maintains a belief using learned discriminative update, which is trained end-to-end for decision making. We show that using the discriminative update instead of standard generative models results in significantly improved performance, especially for tasks with complex visual observations, because they circumvent the difficulty of modeling complex observations that are irrelevant to decision making.
      In addition, to extract features from the particle belief, we propose a new type of belief feature based on the moment generating function. DPFRL outperforms state-of-the-art POMDP RL models in Flickering Atari Games, an existing POMDP RL benchmark, and in Natural Flickering Atari Games, a new, more challenging POMDP RL benchmark introduced in this paper.  Further,  DPFRL performs well for visual navigation with real-world data in the Habitat environment.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reinforcement Learning, Partial Observability, Differentiable Particle Filtering</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJl8_eHYvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Sye_OgHFwH" data-number="2403">
      <h4>
        <a href="/forum?id=Sye_OgHFwH">
            Unrestricted Adversarial Examples via Semantic Manipulation
        </a>
      
        
          <a href="/pdf?id=Sye_OgHFwH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=bhattad2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="bhattad2@illinois.edu">Anand Bhattad</a>, <a href="/profile?email=mchong6%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mchong6@illinois.edu">Min Jin Chong</a>, <a href="/profile?email=kl2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kl2@illinois.edu">Kaizhao Liang</a>, <a href="/profile?email=lbo%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lbo@illinois.edu">Bo Li</a>, <a href="/profile?email=daf%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="daf@illinois.edu">D. A. Forsyth</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#Sye_OgHFwH-details-407" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Sye_OgHFwH-details-407"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce unrestricted perturbations that manipulate semantically meaningful image-based visual descriptors - color and texture - in order to generate effective and  photorealistic adversarial examples.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Machine learning models, especially deep neural networks (DNNs), have been shown to be vulnerable against adversarial examples which are carefully crafted samples with a small magnitude of the perturbation.  Such adversarial perturbations are usually restricted by bounding their <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="540" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i" noic="true"><mjx-c class="mjx-c4C TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">L</mi></mrow><mi>p</mi></msub></math></mjx-assistive-mml></mjx-container> norm such that they are imperceptible, and thus many current defenses can exploit this property to reduce their adversarial impact.  In this paper, we instead introduce "unrestricted" perturbations that manipulate semantically meaningful image-based visual descriptors - color and texture - in order to generate effective and photorealistic adversarial examples. We show that these semantically aware perturbations are effective against JPEG compression, feature squeezing and adversarially trained model. We also show that the proposed methods can effectively be applied to both image classification and image captioning tasks on complex datasets such as ImageNet and MSCOCO. In addition, we conduct comprehensive user studies to show that our generated semantic adversarial examples are photorealistic to humans despite large magnitude perturbations when compared to other attacks.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://www.dropbox.com/s/69zx437t1dgo41b/semantic_attack_code.zip?dl=0 </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Adversarial Examples, Semantic Manipulation, Image Colorization, Texture Transfer</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Sye_OgHFwH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="H1lK_lBtvS" data-number="2406">
      <h4>
        <a href="/forum?id=H1lK_lBtvS">
            Classification-Based Anomaly Detection for General Data
        </a>
      
        
          <a href="/pdf?id=H1lK_lBtvS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=liron.bergman%40mail.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="liron.bergman@mail.huji.ac.il">Liron Bergman</a>, <a href="/profile?email=yedid%40cs.huji.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="yedid@cs.huji.ac.il">Yedid Hoshen</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#H1lK_lBtvS-details-682" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="H1lK_lBtvS-details-682"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Anomaly detection method that uses: openset techniques for better generalization, random-transformation classification for non-image data.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Anomaly detection, finding patterns that substantially deviate from those seen previously, is one of the fundamental problems of artificial intelligence. Recently, classification-based methods were shown to achieve superior results on this task. In this work, we present a unifying view and propose an open-set method, GOAD, to relax current generalization assumptions. Furthermore, we extend the applicability of transformation-based methods to non-image data using random affine transformations. Our method is shown to obtain state-of-the-art accuracy and is applicable to broad data types. The strong performance of our method is extensively validated on multiple datasets from different domains.  </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">anomaly detection</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=H1lK_lBtvS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJgpugrKPS" data-number="2415">
      <h4>
        <a href="/forum?id=HJgpugrKPS">
            Scale-Equivariant Steerable Networks
        </a>
      
        
          <a href="/pdf?id=HJgpugrKPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=sosnovikivan%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sosnovikivan@gmail.com">Ivan Sosnovik</a>, <a href="/profile?email=szmajamichal%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="szmajamichal@gmail.com">Michał Szmaja</a>, <a href="/profile?email=a.w.m.smeulders%40uva.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="a.w.m.smeulders@uva.nl">Arnold Smeulders</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 08 Jun 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HJgpugrKPS-details-214" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJgpugrKPS-details-214"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The effectiveness of Convolutional Neural Networks (CNNs) has been substantially attributed to their built-in property of translation equivariance. However, CNNs do not have embedded mechanisms to handle other types of transformations. In this work, we pay attention to scale changes, which regularly appear in various tasks due to the changing distances between the objects and the camera. First, we introduce the general theory for building scale-equivariant convolutional networks with steerable filters. We develop scale-convolution and generalize other common blocks to be scale-equivariant. We demonstrate the computational efficiency and numerical stability of the proposed method. We compare the proposed models to the previously developed methods for scale equivariance and local scale invariance. We demonstrate state-of-the-art results on the MNIST-scale dataset and on the STL-10 dataset in the supervised learning setting.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Scale Equivariance, Steerable Filters</span>
          </li>
          <li>
            <strong class="note-content-field">Spotlight Video:</strong>
            <span class="note-content-value ">https://iclr.cc/virtual_2020/poster_HJgpugrKPS.html</span>
          </li>
          <li>
            <strong class="note-content-field">Slides:</strong>
            <span class="note-content-value ">https://iclr.cc/virtual_2020/poster_HJgpugrKPS.html</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/isosnovik/sesn</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJgpugrKPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SkxxtgHKPS" data-number="2421">
      <h4>
        <a href="/forum?id=SkxxtgHKPS">
            On Generalization Error Bounds of Noisy Gradient Methods for Non-Convex Learning
        </a>
      
        
          <a href="/pdf?id=SkxxtgHKPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ljiian83%40mail.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ljiian83@mail.tsinghua.edu.cn">Jian Li</a>, <a href="/profile?email=luo-xy19%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="luo-xy19@mails.tsinghua.edu.cn">Xuanyuan Luo</a>, <a href="/profile?email=mqiao%40stanford.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mqiao@stanford.edu">Mingda Qiao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>16 Replies</span>
        
        
      </div>
      
        <a href="#SkxxtgHKPS-details-154" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SkxxtgHKPS-details-154"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We give some generalization error bounds of noisy gradient methods such as SGLD, Langevin dynamics, noisy momentum and so forth.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Generalization error (also known as the out-of-sample error) measures how well the hypothesis learned from training data generalizes to previously unseen data. Proving tight generalization error bounds is a central question in statistical learning  theory.   In  this  paper,  we  obtain  generalization  error  bounds  for  learning general  non-convex  objectives,  which  has  attracted  significant  attention  in  recent years.   We develop a new framework,  termed Bayes-Stability,  for proving algorithm-dependent generalization error bounds.  The new framework combines ideas from both the PAC-Bayesian theory and the notion of algorithmic stability.  Applying the Bayes-Stability method, we obtain new data-dependent generalization bounds for stochastic gradient Langevin dynamics (SGLD) and several other noisy gradient methods (e.g., with momentum, mini-batch and acceleration, Entropy-SGD). Our result recovers (and is typically tighter than) a recent result in Mou et al. (2018) and improves upon the results in Pensia et al. (2018).  Our experiments demonstrate that our data-dependent bounds can distinguish randomly labelled data from normal data, which provides an explanation to the intriguing phenomena observed in Zhang et al. (2017a). We also study the setting where the total loss is the sum of a bounded loss and an additiona l`2 regularization term. We obtain new generalization bounds for the continuous Langevin dynamic in this setting by developing a new Log-Sobolev inequality for the parameter distribution at any time. Our new bounds are more desirable when the noise level of the processis not very small, and do not become vacuous even when T tends to infinity.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">learning theory, generalization, nonconvex learning, stochastic gradient descent, Langevin dynamics</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SkxxtgHKPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1lxKlSKPH" data-number="2422">
      <h4>
        <a href="/forum?id=S1lxKlSKPH">
            Consistency Regularization for Generative Adversarial Networks
        </a>
      
        
          <a href="/pdf?id=S1lxKlSKPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zhanghan%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhanghan@google.com">Han Zhang</a>, <a href="/profile?email=zizhaoz%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="zizhaoz@google.com">Zizhao Zhang</a>, <a href="/profile?email=augustusodena%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="augustusodena@google.com">Augustus Odena</a>, <a href="/profile?email=honglak%40google.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="honglak@google.com">Honglak Lee</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#S1lxKlSKPH-details-330" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1lxKlSKPH-details-330"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Generative Adversarial Networks (GANs) are known to be difficult to train, despite considerable research effort. Several regularization techniques for stabilizing training have been proposed, but they introduce non-trivial computational overheads and interact poorly with existing techniques like spectral normalization. In this work, we propose a simple, effective training stabilizer based on the notion of consistency regularization—a popular technique in the semi-supervised learning literature. In particular, we augment data passing into the GAN discriminator and penalize the sensitivity of the discriminator to these augmentations. We conduct a series of experiments to demonstrate that consistency regularization works effectively with spectral normalization and various GAN architectures, loss functions and optimizer settings. Our method achieves the best FID scores for unconditional image generation compared to other regularization methods on CIFAR-10 and CelebA. Moreover, Our consistency regularized GAN (CR-GAN) improves state of-the-art FID scores for conditional generation from 14.73 to 11.48 on CIFAR-10 and from 8.73 to 6.66 on ImageNet-2012.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Generative Adversarial Networks, Consistency Regularization, GAN</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1lxKlSKPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJleKgrKwS" data-number="2423">
      <h4>
        <a href="/forum?id=rJleKgrKwS">
            Differentiable learning of numerical rules in knowledge graphs
        </a>
      
        
          <a href="/pdf?id=rJleKgrKwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=poweiw%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="poweiw@cs.cmu.edu">Po-Wei Wang</a>, <a href="/profile?email=daria.stepanova%40de.bosch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="daria.stepanova@de.bosch.com">Daria Stepanova</a>, <a href="/profile?email=csaba.domokos%40de.bosch.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="csaba.domokos@de.bosch.com">Csaba Domokos</a>, <a href="/profile?email=zkolter%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="zkolter@cs.cmu.edu">J. Zico Kolter</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rJleKgrKwS-details-307" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJleKgrKwS-details-307"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We present an efficient approach to integrating numerical comparisons into differentiable rule learning in knowledge graphs</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Rules over a knowledge graph (KG) capture interpretable patterns in data and can be used for KG cleaning and completion. Inspired by the TensorLog differentiable logic framework, which compiles rule inference into a sequence of differentiable operations, recently a method called Neural LP has been proposed for learning the parameters as well as the structure of rules. However, it is limited with respect to the treatment of numerical features like age, weight or scientific measurements. We address this limitation by extending Neural LP to learn rules with numerical values, e.g., ”People younger than 18 typically live with their parents“. We demonstrate how dynamic programming and cumulative sum operations can be exploited to ensure efficiency of such extension. Our novel approach allows us to extract more expressive rules with aggregates, which are of higher quality and yield more accurate predictions compared to rules learned by the state-of-the-art methods, as shown by our experiments on synthetic and real-world datasets.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">knowledge graphs, rule learning, differentiable neural logic</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJleKgrKwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJgMFxrYPB" data-number="2427">
      <h4>
        <a href="/forum?id=BJgMFxrYPB">
            Learning to Move with Affordance Maps
        </a>
      
        
          <a href="/pdf?id=BJgMFxrYPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=wq%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wq@cs.cmu.edu">William Qi</a>, <a href="/profile?email=raviteja.mullapudi%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="raviteja.mullapudi@gmail.com">Ravi Teja Mullapudi</a>, <a href="/profile?email=saurabhg%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="saurabhg@illinois.edu">Saurabh Gupta</a>, <a href="/profile?email=deva%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="deva@cs.cmu.edu">Deva Ramanan</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#BJgMFxrYPB-details-795" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJgMFxrYPB-details-795"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We address the task of autonomous exploration and navigation using spatial affordance maps that can be learned in a self-supervised manner, these outperform classic geometric baselines while being more sample efficient than contemporary RL algorithms</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The ability to autonomously explore and navigate a physical space is a fundamental requirement for virtually any mobile autonomous agent, from household robotic vacuums to autonomous vehicles. Traditional SLAM-based approaches for exploration and navigation largely focus on leveraging scene geometry, but fail to model dynamic objects (such as other agents) or semantic constraints (such as wet floors or doorways). Learning-based RL agents are an attractive alternative because they can incorporate both semantic and geometric information, but are notoriously sample inefficient, difficult to generalize to novel settings, and are difficult to interpret. In this paper, we combine the best of both worlds with a modular approach that {\em learns} a spatial representation of a scene that is trained to be effective when coupled with traditional geometric planners. Specifically, we design an agent that learns to predict a spatial affordance map that elucidates what parts of a scene are navigable through active self-supervised experience gathering. In contrast to most simulation environments that assume a static world, we evaluate our approach in the VizDoom simulator, using large-scale randomly-generated maps containing a variety of dynamic actors and hazards. We show that learned affordance maps can be used to augment traditional approaches for both exploration and navigation, providing significant improvements in performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">navigation, exploration</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/wqi/A2L</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJgMFxrYPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HklQYxBKwS" data-number="2429">
      <h4>
        <a href="/forum?id=HklQYxBKwS">
            Neural tangent kernels, transportation mappings, and universal approximation
        </a>
      
        
          <a href="/pdf?id=HklQYxBKwS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ziweiji2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ziweiji2@illinois.edu">Ziwei Ji</a>, <a href="/profile?email=mjt%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="mjt@illinois.edu">Matus Telgarsky</a>, <a href="/profile?email=rxian2%40illinois.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rxian2@illinois.edu">Ruicheng Xian</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#HklQYxBKwS-details-386" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HklQYxBKwS-details-386"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">The NTK linearization is a universal approximator, even when looking arbitrarily close to initialization</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">This paper establishes rates of universal approximation for the shallow neural tangent kernel (NTK): network weights are only allowed microscopic changes from random initialization, which entails that activations are mostly unchanged, and the network is nearly equivalent to its linearization. Concretely, the paper has two main contributions: a generic scheme to approximate functions with the NTK by sampling from transport mappings between the initial weights and their desired values, and the construction of transport mappings via Fourier transforms. Regarding the first contribution, the proof scheme provides another perspective on how the NTK regime arises from rescaling: redundancy in the weights due to resampling allows individual weights to be scaled down. Regarding the second contribution, the most notable transport mapping asserts that roughly <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="541" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FF TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow><mo>/</mo></mrow><msup><mi>δ</mi><mrow><mn>10</mn><mi>d</mi></mrow></msup></math></mjx-assistive-mml></mjx-container> nodes are sufficient to approximate continuous functions, where <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="542" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FF TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>δ</mi></math></mjx-assistive-mml></mjx-container> depends on the continuity properties of the target function. By contrast, nearly the same proof yields a bound of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="543" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D6FF TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mrow><mo>/</mo></mrow><msup><mi>δ</mi><mrow><mn>2</mn><mi>d</mi></mrow></msup></math></mjx-assistive-mml></mjx-container> for shallow ReLU networks; this gap suggests a tantalizing direction for future work, separating shallow ReLU networks and their linearization.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Neural Tangent Kernel, universal approximation, Barron, transport mapping</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HklQYxBKwS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJxrKgStDH" data-number="2433">
      <h4>
        <a href="/forum?id=SJxrKgStDH">
            SCALOR: Generative World Models with Scalable Object Representations
        </a>
      
        
          <a href="/pdf?id=SJxrKgStDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=jindong.jiang%40rutgers.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jindong.jiang@rutgers.edu">Jindong Jiang*</a>, <a href="/profile?email=sj620%40scarletmail.rutgers.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sj620@scarletmail.rutgers.edu">Sepehr Janghorbani*</a>, <a href="/profile?email=gdm%40demelo.org" class="profile-link" data-toggle="tooltip" data-placement="top" title="gdm@demelo.org">Gerard De Melo</a>, <a href="/profile?email=sjn.ahn%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="sjn.ahn@gmail.com">Sungjin Ahn</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#SJxrKgStDH-details-340" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJxrKgStDH-details-340"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Scalability in terms of object density in a scene is a primary challenge in unsupervised sequential object-oriented representation learning. Most of the previous models have been shown to work only on scenes with a few objects. In this paper, we propose SCALOR, a probabilistic generative world model for learning SCALable Object-oriented Representation of a video. With the proposed spatially parallel attention and proposal-rejection mechanisms, SCALOR can deal with orders of magnitude larger numbers of objects compared to the previous state-of-the-art models. Additionally, we introduce a background module that allows SCALOR to model complex dynamic backgrounds as well as many foreground objects in the scene. We demonstrate that SCALOR can deal with crowded scenes containing up to a hundred objects while jointly modeling complex dynamic backgrounds. Importantly, SCALOR is the ﬁrst unsupervised object representation model shown to work for natural scenes containing several tens of moving objects.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJxrKgStDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SyevYxHtDB" data-number="2438">
      <h4>
        <a href="/forum?id=SyevYxHtDB">
            Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks
        </a>
      
        
          <a href="/pdf?id=SyevYxHtDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=orekondy%40mpi-inf.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="orekondy@mpi-inf.mpg.de">Tribhuvanesh Orekondy</a>, <a href="/profile?email=schiele%40mpi-inf.mpg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="schiele@mpi-inf.mpg.de">Bernt Schiele</a>, <a href="/profile?email=fritz%40cispa.saarland" class="profile-link" data-toggle="tooltip" data-placement="top" title="fritz@cispa.saarland">Mario Fritz</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>11 Replies</span>
        
        
      </div>
      
        <a href="#SyevYxHtDB-details-928" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SyevYxHtDB-details-928"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose the first approach that can resist DNN model stealing/extraction attacks</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">High-performance Deep Neural Networks (DNNs) are increasingly deployed in many real-world applications e.g., cloud prediction APIs. Recent advances in model functionality stealing attacks via black-box access (i.e., inputs in, predictions out) threaten the business model of such applications, which require a lot of time, money, and effort to develop. Existing defenses take a passive role against stealing attacks, such as by truncating predicted information. We find such passive defenses ineffective against DNN stealing attacks. In this paper, we propose the first defense which actively perturbs predictions targeted at poisoning the training objective of the attacker. We find our defense effective across a wide range of challenging datasets and DNN model stealing attacks, and additionally outperforms existing defenses. Our defense is the first that can withstand highly accurate model stealing attacks for tens of thousands of queries, amplifying the attacker's error rate up to a factor of 85<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="544" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>×</mo></math></mjx-assistive-mml></mjx-container> with minimal impact on the utility for benign users.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">model functionality stealing, adversarial machine learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SyevYxHtDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJxycxHKDS" data-number="2456">
      <h4>
        <a href="/forum?id=rJxycxHKDS">
            Domain Adaptive Multibranch Networks
        </a>
      
        
          <a href="/pdf?id=rJxycxHKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=roger.bermudez%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="roger.bermudez@epfl.ch">Róger Bermúdez-Chacón</a>, <a href="/profile?email=mathieu.salzmann%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="mathieu.salzmann@epfl.ch">Mathieu Salzmann</a>, <a href="/profile?email=pascal.fua%40epfl.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="pascal.fua@epfl.ch">Pascal Fua</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#rJxycxHKDS-details-854" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJxycxHKDS-details-854"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A Multiflow Network is a dynamic architecture for domain adaptation that learns potentially different computational graphs per domain, so as to map them to a common representation where inference can be performed in a domain-agnostic fashion.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We tackle unsupervised domain adaptation by accounting for the fact that different domains may need to be processed differently to arrive to a common feature representation effective for recognition. To this end, we introduce a deep learning framework where each domain undergoes a different sequence of operations, allowing some, possibly more complex, domains to go through more computations than others.
      This contrasts with  state-of-the-art domain adaptation techniques that force all domains to be processed with the same series of operations, even when using multi-stream architectures whose parameters are not shared.
      As evidenced by our experiments, the greater flexibility of our method translates to higher accuracy. Furthermore, it allows us to handle any number of domains simultaneously.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Domain Adaptation, Computer Vision</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJxycxHKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1eB5xSFvr" data-number="2469">
      <h4>
        <a href="/forum?id=B1eB5xSFvr">
            DiffTaichi: Differentiable Programming for Physical Simulation
        </a>
      
        
          <a href="/pdf?id=B1eB5xSFvr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=yuanmhu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="yuanmhu@gmail.com">Yuanming Hu</a>, <a href="/profile?email=lukea%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukea@mit.edu">Luke Anderson</a>, <a href="/profile?email=tzumao%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tzumao@berkeley.edu">Tzu-Mao Li</a>, <a href="/profile?email=qisu%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="qisu@adobe.com">Qi Sun</a>, <a href="/profile?email=ncarr%40adobe.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ncarr@adobe.com">Nathan Carr</a>, <a href="/profile?email=jrk%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jrk@berkeley.edu">Jonathan Ragan-Kelley</a>, <a href="/profile?email=fredo%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fredo@mit.edu">Fredo Durand</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#B1eB5xSFvr-details-949" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1eB5xSFvr-details-949"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We study the problem of learning and optimizing through physical simulations via differentiable programming, using our proposed DiffSim programming language and compiler.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We present DiffTaichi, a new differentiable programming language tailored for building high-performance differentiable physical simulators. Based on an imperative programming language, DiffTaichi generates gradients of simulation steps using source code transformations that preserve arithmetic intensity and parallelism. A light-weight tape is used to record the whole simulation program structure and replay the gradient kernels in a reversed order, for end-to-end backpropagation.
      We demonstrate the performance and productivity of our language in gradient-based learning and optimization tasks on 10 different physical simulators. For example, a differentiable elastic object simulator written in our language is 4.2x shorter than the hand-engineered CUDA version yet runs as fast, and is 188x faster than the TensorFlow implementation.
      Using our differentiable programs, neural network controllers are typically optimized within only tens of iterations.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/yuanming-hu/difftaichi</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Differentiable programming, robotics, optimal control, physical simulation, machine learning system</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1eB5xSFvr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJxI5gHKDr" data-number="2473">
      <h4>
        <a href="/forum?id=BJxI5gHKDr">
            Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning
        </a>
      
        
          <a href="/pdf?id=BJxI5gHKDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=ars.ashuha%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ars.ashuha@gmail.com">Arsenii Ashukha</a>, <a href="/profile?email=alex.grig.lyzhov%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="alex.grig.lyzhov@gmail.com">Alexander Lyzhov</a>, <a href="/profile?email=dmolch111%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="dmolch111@gmail.com">Dmitry Molchanov</a>, <a href="/profile?email=vetrovd%40yandex.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="vetrovd@yandex.ru">Dmitry Vetrov</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 18 Jul 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#BJxI5gHKDr-details-237" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJxI5gHKDr-details-237"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We highlight the problems with common metrics of in-domain uncertainty and perform a broad study of modern ensembling techniques.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Uncertainty estimation and ensembling methods go hand-in-hand. Uncertainty estimation is one of the main benchmarks for assessment of ensembling performance. At the same time, deep learning ensembles have provided state-of-the-art results in uncertainty estimation. In this work, we focus on in-domain uncertainty for image classification. We explore the standards for its quantification and point out pitfalls of existing metrics. Avoiding these pitfalls, we perform a broad study of different ensembling techniques. To provide more insight in this study, we introduce the deep ensemble equivalent score (DEE) and show that many sophisticated ensembling techniques are equivalent to an ensemble of only few independently trained networks in terms of test performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">uncertainty, in-domain uncertainty, deep ensembles, ensemble learning, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/bayesgroup/pytorch-ensembles</span>
          </li>
          <li>
            <strong class="note-content-field">Slides:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJxI5gHKDr&amp;name=slides" class="attachment-download-link" title="Download Slides" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
          <li>
            <strong class="note-content-field">Spotlight Video:</strong>
            <span class="note-content-value ">https://iclr.cc/virtual_2020/poster_BJxI5gHKDr.html</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJxI5gHKDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HkxjqxBYDB" data-number="2485">
      <h4>
        <a href="/forum?id=HkxjqxBYDB">
            Episodic Reinforcement Learning with Associative Memory
        </a>
      
        
          <a href="/pdf?id=HkxjqxBYDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=guangxiangzhu%40outlook.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="guangxiangzhu@outlook.com">Guangxiang Zhu*</a>, <a href="/profile?email=linzc16%40mails.tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="linzc16@mails.tsinghua.edu.cn">Zichuan Lin*</a>, <a href="/profile?email=ygw%40tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="ygw@tsinghua.edu.cn">Guangwen Yang</a>, <a href="/profile?email=chongjie%40tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="chongjie@tsinghua.edu.cn">Chongjie Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HkxjqxBYDB-details-642" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HkxjqxBYDB-details-642"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Sample efficiency has been one of the major challenges for deep reinforcement learning. Non-parametric episodic control has been proposed to speed up parametric reinforcement learning by rapidly latching on previously successful policies. However, previous work on episodic reinforcement learning neglects the relationship between states and only stored the experiences as unrelated items. To improve sample efficiency of reinforcement learning, we propose a novel framework, called Episodic Reinforcement Learning with Associative Memory (ERLAM), which associates related experience trajectories to enable reasoning effective strategies. We build a graph on top of states in memory based on state transitions and develop a reverse-trajectory propagation strategy to allow rapid value propagation through the graph. We use the non-parametric associative memory as early guidance for a parametric reinforcement learning model. Results on navigation domain and Atari games show our framework achieves significantly higher sample efficiency than state-of-the-art episodic reinforcement learning models.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep Reinforcement Learning, Episodic Control, Episodic Memory, Associative Memory, Non-Parametric Method, Sample Efficiency</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HkxjqxBYDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ByeWogStDS" data-number="2497">
      <h4>
        <a href="/forum?id=ByeWogStDS">
            Sub-policy Adaptation for Hierarchical Reinforcement Learning
        </a>
      
        
          <a href="/pdf?id=ByeWogStDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=alexli1%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="alexli1@berkeley.edu">Alexander Li</a>, <a href="/profile?email=florensa%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="florensa@berkeley.edu">Carlos Florensa</a>, <a href="/profile?email=iclavera%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="iclavera@berkeley.edu">Ignasi Clavera</a>, <a href="/profile?email=pabbeel%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="pabbeel@berkeley.edu">Pieter Abbeel</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#ByeWogStDS-details-744" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ByeWogStDS-details-744"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose HiPPO, a stable Hierarchical Reinforcement Learning algorithm that can train several levels of the hierarchy simultaneously, giving good performance both in skill discovery and adaptation.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Hierarchical reinforcement learning is a promising approach to tackle long-horizon decision-making problems with sparse rewards. Unfortunately, most methods still decouple the lower-level skill acquisition process and the training of a higher level that controls the skills in a new task. Leaving the skills fixed can lead to significant sub-optimality in the transfer setting. In this work, we propose a novel algorithm to discover a set of skills, and continuously adapt them along with the higher level even when training on a new task. Our main contributions are two-fold. First, we derive a new hierarchical policy gradient with an unbiased latent-dependent baseline, and we introduce Hierarchical Proximal Policy Optimization (HiPPO), an on-policy method to efficiently train all levels of the hierarchy jointly. Second, we propose a method of training time-abstractions that improves the robustness of the obtained skills to environment changes.  Code and videos are available at sites.google.com/view/hippo-rl.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Hierarchical Reinforcement Learning, Transfer, Skill Discovery</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://anonymous.4open.science/r/de105a6d-8f8b-405e-b90a-54ab74adcb17/</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ByeWogStDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylmoxrFDH" data-number="2503">
      <h4>
        <a href="/forum?id=rylmoxrFDH">
            Critical initialisation in continuous approximations of binary neural networks
        </a>
      
        
          <a href="/pdf?id=rylmoxrFDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=george.stamatescu%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="george.stamatescu@gmail.com">George Stamatescu</a>, <a href="/profile?email=federicagerace91%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="federicagerace91@gmail.com">Federica Gerace</a>, <a href="/profile?email=carlo.lucibello%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="carlo.lucibello@gmail.com">Carlo Lucibello</a>, <a href="/profile?email=ian.fuss%40adelaide.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="ian.fuss@adelaide.edu.au">Ian Fuss</a>, <a href="/profile?email=lang.white%40adelaide.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="lang.white@adelaide.edu.au">Langford White</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rylmoxrFDH-details-31" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylmoxrFDH-details-31"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">signal propagation theory applied to continuous surrogates of binary nets;  counter intuitive initialisation; reparameterisation trick not helpful</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The training of stochastic neural network models with binary (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="545" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>±</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container>) weights and activations via continuous surrogate networks is investigated. We derive new surrogates using a novel derivation based on writing the stochastic neural network as a Markov chain. This derivation also encompasses existing variants of the surrogates presented in the literature. Following this, we theoretically study the surrogates at initialisation. We derive, using mean field theory, a set of scalar equations describing how input signals propagate through the randomly initialised networks. The equations reveal whether so-called critical initialisations exist for each surrogate network, where the network can be trained to arbitrary depth. Moreover, we predict theoretically and confirm numerically, that common weight initialisation schemes used in standard continuous networks, when applied to the mean values of the stochastic binary weights, yield poor training performance. This study shows that, contrary to common intuition, the means of the stochastic binary weights should be initialised close to <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="546" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-cB1"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>±</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container>, for deeper networks to be trainable.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rylmoxrFDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryloogSKDS" data-number="2513">
      <h4>
        <a href="/forum?id=ryloogSKDS">
            Deep Orientation Uncertainty Learning based on a Bingham Loss
        </a>
      
        
          <a href="/pdf?id=ryloogSKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=igilitschenski%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="igilitschenski@mit.edu">Igor Gilitschenski</a>, <a href="/profile?email=rsahoo%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rsahoo@mit.edu">Roshni Sahoo</a>, <a href="/profile?email=wilkos%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="wilkos@mit.edu">Wilko Schwarting</a>, <a href="/profile?email=amini%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="amini@mit.edu">Alexander Amini</a>, <a href="/profile?email=sertac%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="sertac@mit.edu">Sertac Karaman</a>, <a href="/profile?email=rus%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rus@csail.mit.edu">Daniela Rus</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#ryloogSKDS-details-238" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryloogSKDS-details-238"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A method for learning to predict uncertainties over orientations using the Bingham Distribution</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Reasoning about uncertain orientations is one of the core problems in many perception tasks such as object pose estimation or motion estimation. In these scenarios, poor illumination conditions, sensor limitations, or appearance invariance may result in highly uncertain estimates. In this work, we propose a novel learning-based representation for orientation uncertainty. By characterizing uncertainty over unit quaternions with the Bingham distribution, we formulate a loss that naturally captures the antipodal symmetry of the representation. We discuss the interpretability of the learned distribution parameters and demonstrate the feasibility of our approach on several challenging real-world pose estimation tasks involving uncertain orientations.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Orientation Estimation, Directional Statistics, Bingham Distribution</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryloogSKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="r1g6ogrtDr" data-number="2517">
      <h4>
        <a href="/forum?id=r1g6ogrtDr">
            Co-Attentive Equivariant Neural Networks: Focusing Equivariance On Transformations Co-Occurring in Data
        </a>
      
        
          <a href="/pdf?id=r1g6ogrtDr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=d.w.romeroguzman%40vu.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="d.w.romeroguzman@vu.nl">David W. Romero</a>, <a href="/profile?email=m.hoogendoorn%40vu.nl" class="profile-link" data-toggle="tooltip" data-placement="top" title="m.hoogendoorn@vu.nl">Mark Hoogendoorn</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="#r1g6ogrtDr-details-499" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="r1g6ogrtDr-details-499"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We utilize attention to restrict equivariant neural networks to the set or co-occurring transformations in data. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Equivariance is a nice property to have as it produces much more parameter efficient neural architectures and preserves the structure of the input through the feature mapping. Even though some combinations of transformations might never appear (e.g. an upright face with a horizontal nose), current equivariant architectures consider the set of all possible transformations in a transformation group when learning feature representations. Contrarily, the human visual system is able to attend to the set of relevant transformations occurring in the environment and utilizes this information to assist and improve object recognition. Based on this observation, we modify conventional equivariant feature mappings such that they are able to attend to the set of co-occurring transformations in data and generalize this notion to act on groups consisting of multiple symmetries. We show that our proposed co-attentive equivariant neural networks consistently outperform conventional rotation equivariant and rotation &amp; reflection equivariant neural networks on rotated MNIST and CIFAR-10.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://www.dropbox.com/sh/2gghao89strdotw/AAAYJ6XclnfeoS3AfN9Z-n5Wa?dl=0</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Equivariant Neural Networks, Attention Mechanisms, Deep Learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=r1g6ogrtDr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hyx0slrFvH" data-number="2519">
      <h4>
        <a href="/forum?id=Hyx0slrFvH">
            Mixed Precision DNNs: All you need is a good parametrization
        </a>
      
        
          <a href="/pdf?id=Hyx0slrFvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=stefan.uhlich%40sony.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="stefan.uhlich@sony.com">Stefan Uhlich</a>, <a href="/profile?email=lukas.mauch%40sony.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lukas.mauch@sony.com">Lukas Mauch</a>, <a href="/profile?email=fabien.cardinaux%40sony.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="fabien.cardinaux@sony.com">Fabien Cardinaux</a>, <a href="/profile?email=kazuki.yoshiyama%40sony.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kazuki.yoshiyama@sony.com">Kazuki Yoshiyama</a>, <a href="/profile?email=javier.alonso%40sony.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="javier.alonso@sony.com">Javier Alonso Garcia</a>, <a href="/profile?email=stephen.tiedemann%40sony.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="stephen.tiedemann@sony.com">Stephen Tiedemann</a>, <a href="/profile?email=thomas.kemp%40sony.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="thomas.kemp@sony.com">Thomas Kemp</a>, <a href="/profile?email=akira.b.nakamura%40sony.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="akira.b.nakamura@sony.com">Akira Nakamura</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>15 Replies</span>
        
        
      </div>
      
        <a href="#Hyx0slrFvH-details-535" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hyx0slrFvH-details-535"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Efficient deep neural network (DNN) inference on mobile or embedded devices typically involves quantization of the network parameters and activations. In particular, mixed precision networks achieve better performance than networks with homogeneous bitwidth for the same size constraint. Since choosing the optimal bitwidths is not straight forward, training methods, which can learn them, are desirable. Differentiable quantization with straight-through gradients allows to learn the quantizer's parameters using gradient methods. We show that a suited parametrization of the quantizer is the key to achieve a stable training and a good final performance. Specifically, we propose to parametrize the quantizer with the step size and dynamic range. The bitwidth can then be inferred from them. Other parametrizations, which explicitly use the bitwidth, consistently perform worse. We confirm our findings with experiments on CIFAR-10 and ImageNet and we obtain mixed precision DNNs with learned quantization parameters, achieving state-of-the-art performance.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep Neural Network Compression, Quantization, Straight through gradients</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hyx0slrFvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkg1ngrFPr" data-number="2521">
      <h4>
        <a href="/forum?id=rkg1ngrFPr">
            Information Geometry of Orthogonal Initializations and Training
        </a>
      
        
          <a href="/pdf?id=rkg1ngrFPr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=piotr.sokol%40stonybrook.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="piotr.sokol@stonybrook.edu">Piotr Aleksander Sokół</a>, <a href="/profile?email=memming.park%40stonybrook.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="memming.park@stonybrook.edu">Il Memming Park</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>12 Replies</span>
        
        
      </div>
      
        <a href="#rkg1ngrFPr-details-111" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkg1ngrFPr-details-111"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">nearly isometric DNN initializations imply low parameter space curvature, and a lower condition number, but that's not always great</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">    Recently mean field theory has been successfully used to analyze properties
          of wide, random neural networks. It gave rise to a prescriptive theory for
          initializing feed-forward neural networks with orthogonal weights, which
          ensures that both the forward propagated activations and the backpropagated
          gradients are near <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="547" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mn>2</mn></msub></math></mjx-assistive-mml></mjx-container> isometries and as a consequence training is
          orders of magnitude faster. Despite strong empirical performance, the
          mechanisms by which critical initializations confer an advantage in the
          optimization of deep neural networks are poorly understood. Here we show a
          novel connection between the maximum curvature of the optimization landscape
          (gradient smoothness) as measured by the Fisher information matrix (FIM) and
          the spectral radius of the input-output Jacobian, which partially explains
          why more isometric networks can train much faster. Furthermore, given that
          orthogonal weights are necessary to ensure that gradient norms are
          approximately preserved at initialization, we experimentally investigate the
          benefits of maintaining orthogonality throughout training, and we conclude
          that manifold optimization of weights performs well regardless of the
          smoothness of the gradients. Moreover, we observe a surprising yet robust
          behavior of highly isometric initializations --- even though such networks
          have a lower FIM condition number \emph{at initialization}, and therefore by
          analogy to convex functions should be easier to optimize, experimentally
          they prove to be much harder to train with stochastic gradient descent. We
          conjecture the FIM condition number plays a non-trivial role in the optimization.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/PiotrSokol/info-geom</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Fisher, mean-field, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkg1ngrFPr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rJxe3xSYDS" data-number="2523">
      <h4>
        <a href="/forum?id=rJxe3xSYDS">
            Extreme Classification via Adversarial Softmax Approximation
        </a>
      
        
          <a href="/pdf?id=rJxe3xSYDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=rbamler%40uci.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rbamler@uci.edu">Robert Bamler</a>, <a href="/profile?email=stephan.mandt%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="stephan.mandt@gmail.com">Stephan Mandt</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#rJxe3xSYDS-details-667" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rJxe3xSYDS-details-667"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">An efficient, unbiased approximation of the softmax loss function for extreme classification</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Training a classifier over a large number of classes, known as 'extreme classification', has become a topic of major interest with applications in technology, science, and e-commerce. Traditional softmax regression induces a gradient cost proportional to the number of classes C, which often is prohibitively expensive. A popular scalable softmax approximation relies on uniform negative sampling, which suffers from slow convergence due a poor signal-to-noise ratio. In this paper, we propose a simple training method for drastically enhancing the gradient signal by drawing negative samples from an adversarial model that mimics the data distribution. Our contributions are three-fold: (i) an adversarial sampling mechanism that produces negative samples at a cost only logarithmic in C, thus still resulting in cheap gradient updates; (ii) a mathematical proof that this adversarial sampling minimizes the gradient variance while any bias due to non-uniform sampling can be removed; (iii) experimental results on large scale data sets that show a reduction of the training time by an order of magnitude relative to several competitive baselines.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/mandt-lab/adversarial-negative-sampling</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Extreme classification, negative sampling</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rJxe3xSYDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJx-3grYDB" data-number="2526">
      <h4>
        <a href="/forum?id=HJx-3grYDB">
            Learning Nearly Decomposable Value Functions Via Communication Minimization
        </a>
      
        
          <a href="/pdf?id=HJx-3grYDB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tonghanwang1996%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="tonghanwang1996@gmail.com">Tonghan Wang*</a>, <a href="/profile?email=1040594377%40qq.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="1040594377@qq.com">Jianhao Wang*</a>, <a href="/profile?email=chongyeezheng%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="chongyeezheng@gmail.com">Chongyi Zheng</a>, <a href="/profile?email=chongjie%40tsinghua.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="chongjie@tsinghua.edu.cn">Chongjie Zhang</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 30 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#HJx-3grYDB-details-971" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJx-3grYDB-details-971"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Reinforcement learning encounters major challenges in multi-agent settings, such as scalability and non-stationarity. Recently, value function factorization learning emerges as a promising way to address these challenges in collaborative multi-agent systems. However, existing methods have been focusing on learning fully decentralized value functions, which are not efficient for tasks requiring communication. To address this limitation, this paper presents a novel framework for learning nearly decomposable Q-functions (NDQ) via communication minimization, with which agents act on their own most of the time but occasionally send messages to other agents in order for effective coordination. This framework hybridizes value function factorization learning and communication learning by introducing two information-theoretic regularizers. These regularizers are maximizing mutual information between agents' action selection and communication messages while minimizing the entropy of messages between agents. We show how to optimize these regularizers in a way that is easily integrated with existing value function factorization methods such as QMIX. Finally, we demonstrate that, on the StarCraft unit micromanagement benchmark, our framework significantly outperforms baseline methods and allows us to cut off more than <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="548" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>80</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> of communication without sacrificing the performance. The videos of our experiments are available at https://sites.google.com/view/ndq.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Multi-agent reinforcement learning, Nearly decomposable value function, Minimized communication, Multi-agent systems</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/TonghanWang/NDQ</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJx-3grYDB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rylb3eBtwr" data-number="2527">
      <h4>
        <a href="/forum?id=rylb3eBtwr">
            Robust Subspace Recovery Layer for Unsupervised Anomaly Detection
        </a>
      
        
          <a href="/pdf?id=rylb3eBtwr" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=laixx313%40umn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="laixx313@umn.edu">Chieh-Hsin Lai</a>, <a href="/profile?email=dzou%40umn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dzou@umn.edu">Dongmian Zou</a>, <a href="/profile?email=lerman%40umn.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lerman@umn.edu">Gilad Lerman</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#rylb3eBtwr-details-907" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rylb3eBtwr-details-907"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">This work proposes an autoencoder with a novel robust subspace recovery layer for unsupervised anomaly detection and demonstrates state-of-the-art results on various datasets.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We propose a neural network for unsupervised anomaly detection with a novel robust subspace recovery layer (RSR layer). This layer seeks to extract the underlying subspace from a latent representation of the given data and removes outliers that lie away from this subspace. It is used within an autoencoder. The encoder maps the data into a latent space, from which the RSR layer extracts the subspace. The decoder then smoothly maps back the underlying subspace to a ``manifold" close to the original inliers. Inliers and outliers are distinguished according to the distances between the original and mapped positions (small for inliers and large for outliers). Extensive numerical experiments with both image and document datasets demonstrate state-of-the-art precision and recall. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">robust subspace recovery, unsupervised anomaly detection, outliers, latent space, autoencoder</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rylb3eBtwr&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxB2lBtvH" data-number="2535">
      <h4>
        <a href="/forum?id=ryxB2lBtvH">
            Learning to Coordinate Manipulation Skills via Skill Behavior Diversification
        </a>
      
        
          <a href="/pdf?id=ryxB2lBtvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=lee504%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="lee504@usc.edu">Youngwoon Lee</a>, <a href="/profile?email=jingyuny%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="jingyuny@usc.edu">Jingyun Yang</a>, <a href="/profile?email=limjj%40usc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="limjj@usc.edu">Joseph J. Lim</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#ryxB2lBtvH-details-58" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxB2lBtvH-details-58"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose to tackle complex tasks of multiple agents by learning composable primitive skills and coordination of the skills. </span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">When mastering a complex manipulation task, humans often decompose the task into sub-skills of their body parts, practice the sub-skills independently, and then execute the sub-skills together. Similarly, a robot with multiple end-effectors can perform complex tasks by coordinating sub-skills of each end-effector. To realize temporal and behavioral coordination of skills, we propose a modular framework that first individually trains sub-skills of each end-effector with skill behavior diversification, and then learns to coordinate end-effectors using diverse behaviors of the skills. We demonstrate that our proposed framework is able to efficiently coordinate skills to solve challenging collaborative control tasks such as picking up a long bar, placing a block inside a container while pushing the container with two robot arms, and pushing a box with two ant agents. Videos and code are available at https://clvrai.com/coordination</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">reinforcement learning, hierarchical reinforcement learning, modular framework, skill coordination, bimanual manipulation</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/clvrai/coordination</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxB2lBtvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="SJx9ngStPH" data-number="2547">
      <h4>
        <a href="/forum?id=SJx9ngStPH">
            NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search
        </a>
      
        
          <a href="/pdf?id=SJx9ngStPH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zelaa%40cs.uni-freiburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="zelaa@cs.uni-freiburg.de">Arber Zela</a>, <a href="/profile?email=siemsj%40cs.uni-freiburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="siemsj@cs.uni-freiburg.de">Julien Siems</a>, <a href="/profile?email=fh%40cs.uni-freiburg.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="fh@cs.uni-freiburg.de">Frank Hutter</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#SJx9ngStPH-details-525" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="SJx9ngStPH-details-525"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">One-shot neural architecture search (NAS) has played a crucial role in making
      NAS methods computationally feasible in practice. Nevertheless, there is still a
      lack of understanding on how these weight-sharing algorithms exactly work due
      to the many factors controlling the dynamics of the process. In order to allow
      a scientific study of these components, we introduce a general framework for
      one-shot NAS that can be instantiated to many recently-introduced variants and
      introduce a general benchmarking framework that draws on the recent large-scale
      tabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot
      NAS methods. To showcase the framework, we compare several state-of-the-art
      one-shot NAS methods, examine how sensitive they are to their hyperparameters
      and how they can be improved by tuning their hyperparameters, and compare their
      performance to that of blackbox optimizers for NAS-Bench-101.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/automl/nasbench-1shot1</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Neural Architecture Search, Deep Learning, Computer Vision</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=SJx9ngStPH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BJlahxHYDS" data-number="2553">
      <h4>
        <a href="/forum?id=BJlahxHYDS">
            Conservative Uncertainty Estimation By Fitting  Prior Networks
        </a>
      
        
          <a href="/pdf?id=BJlahxHYDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kamil.ciosek%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="kamil.ciosek@microsoft.com">Kamil Ciosek</a>, <a href="/profile?email=fortuin%40inf.ethz.ch" class="profile-link" data-toggle="tooltip" data-placement="top" title="fortuin@inf.ethz.ch">Vincent Fortuin</a>, <a href="/profile?email=ryoto%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="ryoto@microsoft.com">Ryota Tomioka</a>, <a href="/profile?email=katja.hofmann%40microsoft.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="katja.hofmann@microsoft.com">Katja Hofmann</a>, <a href="/profile?email=ret26%40cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="ret26@cam.ac.uk">Richard Turner</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 17 Apr 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>22 Replies</span>
        
        
      </div>
      
        <a href="#BJlahxHYDS-details-422" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BJlahxHYDS-details-422"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We provide theoretical support to uncertainty estimates for deep learning obtained fitting random priors.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Obtaining high-quality uncertainty estimates is essential for many applications of deep neural networks. In this paper, we theoretically justify a scheme for estimating uncertainties, based on sampling from a prior distribution. Crucially, the uncertainty estimates are shown to be conservative in the sense that they never underestimate a posterior uncertainty obtained by a hypothetical Bayesian algorithm. We also show concentration, implying that the uncertainty estimates converge to zero as we get more data. Uncertainty estimates obtained from random priors can be adapted to any deep network architecture and trained using standard supervised learning pipelines. We provide experimental evaluation of random priors on calibration and out-of-distribution detection on typical computer vision tasks, demonstrating that they outperform deep ensembles in practice.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">uncertainty quantification, deep learning, Gaussian process, epistemic uncertainty, random network, prior, Bayesian inference</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/microsoft/conservative-uncertainty-estimation-random-priors</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BJlahxHYDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="rkgg6xBYDH" data-number="2560">
      <h4>
        <a href="/forum?id=rkgg6xBYDH">
            Understanding Generalization in Recurrent Neural Networks
        </a>
      
        
          <a href="/pdf?id=rkgg6xBYDH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=zhtu3055%40uni.sydney.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="zhtu3055@uni.sydney.edu.au">Zhuozhuo Tu</a>, <a href="/profile?email=fengxiang.he%40sydney.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="fengxiang.he@sydney.edu.au">Fengxiang He</a>, <a href="/profile?email=dacheng.tao%40sydney.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="dacheng.tao@sydney.edu.au">Dacheng Tao</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 27 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#rkgg6xBYDH-details-215" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="rkgg6xBYDH-details-215"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In this work, we develop the theory for analyzing the generalization performance of recurrent neural networks. We first present a new generalization bound for recurrent neural networks based on matrix 1-norm and Fisher-Rao norm. The definition of Fisher-Rao norm relies on a structural lemma about the gradient of RNNs. This new generalization bound assumes that the covariance matrix of the input data is positive definite, which might limit its use in practice. To address this issue, we propose to add random noise to the input data and prove a generalization bound for training with random noise, which is an extension of the former one. Compared with existing results, our generalization bounds have no explicit dependency on the size of networks. We also discover that Fisher-Rao norm for RNNs can be interpreted as a measure of gradient, and incorporating this gradient measure not only can tighten the bound, but allows us to build a relationship between generalization and trainability. Based on the bound, we theoretically analyze the effect of covariance of features on generalization of RNNs and discuss how weight decay and gradient clipping in the training can help improve generalization. </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">generalization, recurrent neural networks, learning theory</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We prove generalization bounds for recurrent neural networks based on matrix 1-norm and Fisher-Rao norm.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=rkgg6xBYDH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyebplHYwB" data-number="2564">
      <h4>
        <a href="/forum?id=HyebplHYwB">
            The Shape of Data: Intrinsic Distance for Data Distributions
        </a>
      
        
          <a href="/pdf?id=HyebplHYwB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=tsitsulin%40bit.uni-bonn.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="tsitsulin@bit.uni-bonn.de">Anton Tsitsulin</a>, <a href="/profile?email=marina.munkhoeva%40skolkovotech.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="marina.munkhoeva@skolkovotech.ru">Marina Munkhoeva</a>, <a href="/profile?email=davide%40cs.au.dk" class="profile-link" data-toggle="tooltip" data-placement="top" title="davide@cs.au.dk">Davide Mottin</a>, <a href="/profile?email=piekarras%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="piekarras@gmail.com">Panagiotis Karras</a>, <a href="/profile?email=bron%40cs.technion.ac.il" class="profile-link" data-toggle="tooltip" data-placement="top" title="bron@cs.technion.ac.il">Alex Bronstein</a>, <a href="/profile?email=i.oseledets%40skoltech.ru" class="profile-link" data-toggle="tooltip" data-placement="top" title="i.oseledets@skoltech.ru">Ivan Oseledets</a>, <a href="/profile?email=mueller%40bit.uni-bonn.de" class="profile-link" data-toggle="tooltip" data-placement="top" title="mueller@bit.uni-bonn.de">Emmanuel Mueller</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HyebplHYwB-details-714" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyebplHYwB-details-714"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose a metric for comparing data distributions based on their geometry while not relying on any positional information.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">The ability to represent and compare machine learning models is crucial in order to quantify subtle model changes, evaluate generative models, and gather insights on neural network architectures. Existing techniques for comparing data distributions focus on global data properties such as mean and covariance; in that sense, they are extrinsic and uni-scale. We develop a first-of-its-kind intrinsic and multi-scale method for characterizing and comparing data manifolds, using a lower-bound of the spectral variant of the Gromov-Wasserstein inter-manifold distance, which compares all data moments. In a thorough experimental study, we demonstrate that our method effectively discerns the structure of data manifolds even on unaligned data of different dimensionalities; moreover, we showcase its efficacy in evaluating the quality of generative models.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/xgfs/imd</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Deep Learning, Generative Models, Nonlinear Dimensionality Reduction, Manifold Learning, Similarity and Distance Learning, Spectral Methods</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HyebplHYwB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="S1erpeBFPB" data-number="2572">
      <h4>
        <a href="/forum?id=S1erpeBFPB">
            How to 0wn the NAS in Your Spare Time
        </a>
      
        
          <a href="/pdf?id=S1erpeBFPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=shhong%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="shhong@cs.umd.edu">Sanghyun Hong</a>, <a href="/profile?email=michael.davinroy%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="michael.davinroy@gmail.com">Michael Davinroy</a>, <a href="/profile?email=cankaya%40umiacs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="cankaya@umiacs.umd.edu">Yiǧitcan Kaya</a>, <a href="/profile?email=danadach%40ece.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="danadach@ece.umd.edu">Dana Dachman-Soled</a>, <a href="/profile?email=tdumitra%40umiacs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tdumitra@umiacs.umd.edu">Tudor Dumitraş</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>10 Replies</span>
        
        
      </div>
      
        <a href="#S1erpeBFPB-details-359" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="S1erpeBFPB-details-359"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We design an algorithm that reconstructs the key components of a novel deep learning system by exploiting a small amount of information leakage from a cache side-channel attack, Flush+Reload.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">New data processing pipelines and novel network architectures increasingly drive the success of deep learning. In consequence, the industry considers top-performing architectures as intellectual property and devotes considerable computational resources to discovering such architectures through neural architecture search (NAS). This provides an incentive for adversaries to steal these novel architectures; when used in the cloud, to provide Machine Learning as a Service (MLaaS), the adversaries also have an opportunity to reconstruct the architectures by exploiting a range of hardware side-channels. However, it is challenging to reconstruct novel architectures and pipelines without knowing the computational graph (e.g., the layers, branches or skip connections), the architectural parameters (e.g., the number of filters in a convolutional layer) or the specific pre-processing steps (e.g. embeddings). In this paper, we design an algorithm that reconstructs the key components of a novel deep learning system by exploiting a small amount of information leakage from a cache side-channel attack, Flush+Reload. We use Flush+Reload to infer the trace of computations and the timing for each computation. Our algorithm then generates candidate computational graphs from the trace and eliminates incompatible candidates through a parameter estimation process. We implement our algorithm in PyTorch and Tensorflow. We demonstrate experimentally that we can reconstruct MalConv, a novel data pre-processing pipeline for malware detection, and ProxylessNAS-CPU, a novel network architecture for the ImageNet classification optimized to run on CPUs, without knowing the architecture family. In both cases, we achieve 0% error. These results suggest hardware side channels are a practical attack vector against MLaaS, and more efforts should be devoted to understanding their impact on the security of deep learning systems.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Reconstructing Novel Deep Learning Systems</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/Sanghyun-Hong/How-to-0wn-NAS-in-Your-Spare-Time</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=S1erpeBFPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="B1xSperKvH" data-number="2573">
      <h4>
        <a href="/forum?id=B1xSperKvH">
            Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike Timing Dependent Backpropagation
        </a>
      
        
          <a href="/pdf?id=B1xSperKvH" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=rathi2%40purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="rathi2@purdue.edu">Nitin Rathi</a>, <a href="/profile?email=srinivg%40purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="srinivg@purdue.edu">Gopalakrishnan Srinivasan</a>, <a href="/profile?email=priya.panda%40yale.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="priya.panda@yale.edu">Priyadarshini Panda</a>, <a href="/profile?email=kaushik%40purdue.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="kaushik@purdue.edu">Kaushik Roy</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#B1xSperKvH-details-29" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="B1xSperKvH-details-29"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Spiking Neural Networks (SNNs) operate with asynchronous discrete events (or spikes) which can potentially lead to higher energy-efficiency in neuromorphic hardware implementations. Many works have shown that an SNN for inference can be formed by copying the weights from a trained Artificial Neural Network (ANN) and setting the firing threshold for each layer as the maximum input received in that layer. These type of converted SNNs require a large number of time steps to achieve competitive accuracy which diminishes the energy savings. The number of time steps can be reduced by training SNNs with spike-based backpropagation from scratch, but that is computationally expensive and slow. To address these challenges, we present a computationally-efficient training technique for deep SNNs. We propose a hybrid training methodology: 1) take a converted SNN and use its weights and thresholds as an initialization step for spike-based backpropagation, and 2) perform incremental spike-timing dependent backpropagation (STDB) on this carefully initialized network to obtain an SNN that converges within few epochs and requires fewer time steps for input processing. STDB is performed with a novel surrogate gradient function defined using neuron's spike time. The weight update is proportional to the difference in spike timing between the current time step and the most recent time step the neuron generated an output spike. The SNNs trained with our hybrid conversion-and-STDB training perform at <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="549" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo></mjx-texatom></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>10</mn><mrow><mo>×</mo></mrow><mrow><mo>−</mo></mrow><mn>25</mn><mrow><mo>×</mo></mrow></math></mjx-assistive-mml></mjx-container> fewer number of time steps and achieve similar accuracy compared to purely converted SNNs. The proposed training methodology converges in less than <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="550" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>20</mn></math></mjx-assistive-mml></mjx-container> epochs of spike-based backpropagation for most standard image classification datasets, thereby greatly reducing the training complexity compared to training SNNs from scratch. We perform experiments on CIFAR-10, CIFAR-100 and ImageNet datasets for both VGG and ResNet architectures. We achieve top-1 accuracy of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="551" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c39"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>65.19</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> for ImageNet dataset on SNN with <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="552" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>250</mn></math></mjx-assistive-mml></mjx-container> time steps, which is <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="553" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo></mjx-texatom></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>10</mn><mrow><mo>×</mo></mrow></math></mjx-assistive-mml></mjx-container> faster compared to converted SNNs with similar accuracy.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/nitin-rathi/hybrid-snn-conversion</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">spiking neural networks, ann-snn conversion, spike-based backpropagation, imagenet</span>
          </li>
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">A hybrid training technique that combines ANN-SNN conversion and spike-based backpropagation to optimize training effort and inference latency.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=B1xSperKvH&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HJxdTxHYvB" data-number="2579">
      <h4>
        <a href="/forum?id=HJxdTxHYvB">
            BREAKING  CERTIFIED  DEFENSES:  SEMANTIC  ADVERSARIAL  EXAMPLES  WITH  SPOOFED  ROBUSTNESS  CERTIFICATES
        </a>
      
        
          <a href="/pdf?id=HJxdTxHYvB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=amin%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="amin@cs.umd.edu">Amin Ghiasi</a>, <a href="/profile?email=ashafahi%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="ashafahi@cs.umd.edu">Ali Shafahi</a>, <a href="/profile?email=tomg%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="tomg@cs.umd.edu">Tom Goldstein</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>7 Replies</span>
        
        
      </div>
      
        <a href="#HJxdTxHYvB-details-535" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HJxdTxHYvB-details-535"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Defenses against adversarial attacks can be classified into certified and non-certified. Certifiable defenses make networks robust within a certain <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" role="presentation" tabindex="0" ctxtmenu_counter="554" style="font-size: 113.1%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i" noic="true"><mjx-c class="mjx-c2113"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role="presentation" unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>ℓ</mi><mi>p</mi></msub></math></mjx-assistive-mml></mjx-container>-bounded radius, so that it is impossible for the adversary to make adversarial examples in the certificate bound. We present an attack that maintains the imperceptibility property of adversarial examples while being outside of the certified radius. Furthermore, the proposed "Shadow Attack" can fool certifiably robust networks by producing an imperceptible adversarial example that gets misclassified and produces a strong ``spoofed'' certificate.</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HJxdTxHYvB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Skxd6gSYDS" data-number="2580">
      <h4>
        <a href="/forum?id=Skxd6gSYDS">
            Query-efficient Meta Attack to Deep Neural Networks
        </a>
      
        
          <a href="/pdf?id=Skxd6gSYDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=dujiawei%40u.nus.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="dujiawei@u.nus.edu">Jiawei Du</a>, <a href="/profile?email=hu.zhang-1%40student.uts.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="hu.zhang-1@student.uts.edu.au">Hu Zhang</a>, <a href="/profile?email=joey.tianyi.zhou%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="joey.tianyi.zhou@gmail.com">Joey Tianyi Zhou</a>, <a href="/profile?email=yi.yang%40uts.edu.au" class="profile-link" data-toggle="tooltip" data-placement="top" title="yi.yang@uts.edu.au">Yi Yang</a>, <a href="/profile?email=elefjia%40nus.edu.sg" class="profile-link" data-toggle="tooltip" data-placement="top" title="elefjia@nus.edu.sg">Jiashi Feng</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>14 Replies</span>
        
        
      </div>
      
        <a href="#Skxd6gSYDS-details-865" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Skxd6gSYDS-details-865"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Black-box attack methods aim to infer suitable attack patterns to targeted DNN models by only using output feedback of the models and the corresponding input queries. However, due to lack of prior and inefficiency in leveraging the query and feedback information, existing methods are mostly query-intensive for obtaining effective attack patterns. In this work, we propose a meta attack approach that is capable of attacking a targeted  model with much fewer queries. Its high query-efficiency stems from effective utilization of  meta learning approaches in learning generalizable prior abstraction from the previously observed attack patterns and exploiting  such prior to help infer attack patterns from only a few queries and outputs. Extensive experiments on MNIST, CIFAR10 and tiny-Imagenet demonstrate that our meta-attack method can remarkably reduce the number of model queries without sacrificing the attack performance. Besides, the obtained meta attacker is not restricted to a particular model but can be used easily with a fast adaptive ability to attack a variety of models. Our code will be released to the public.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Adversarial attack, Meta learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Skxd6gSYDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="HyeYTgrFPB" data-number="2582">
      <h4>
        <a href="/forum?id=HyeYTgrFPB">
            Massively Multilingual Sparse Word Representations
        </a>
      
        
          <a href="/pdf?id=HyeYTgrFPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=berendg%40inf.u-szeged.hu" class="profile-link" data-toggle="tooltip" data-placement="top" title="berendg@inf.u-szeged.hu">Gábor Berend</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>9 Replies</span>
        
        
      </div>
      
        <a href="#HyeYTgrFPB-details-556" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="HyeYTgrFPB-details-556"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We propose an efficient algorithm for determining multilingually comparable sparse word representations that we release for 27 typologically diverse languages.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">In this paper, we introduce Mamus for constructing multilingual sparse word representations. Our algorithm operates by determining a shared set of semantic units which get reutilized across languages, providing it a competitive edge both in terms of speed and evaluation performance. We demonstrate that our proposed algorithm behaves competitively to strong baselines through a series of rigorous experiments performed towards downstream applications spanning over dependency parsing, document classification and natural language inference. Additionally, our experiments relying on the QVEC-CCA evaluation score suggests that the proposed sparse word representations convey an increased interpretability as opposed to alternative approaches. Finally, we are releasing our multilingual sparse word representations for the 27 typologically diverse set of languages that we conducted our various experiments on.</span>
          </li>
          <li>
            <strong class="note-content-field">Code:</strong>
            <span class="note-content-value ">https://github.com/begab/mamus</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">sparse word representations, multilinguality, sparse coding</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=HyeYTgrFPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="Hyg96gBKPS" data-number="2583">
      <h4>
        <a href="/forum?id=Hyg96gBKPS">
            Monotonic Multihead Attention
        </a>
      
        
          <a href="/pdf?id=Hyg96gBKPS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=xutai_ma%40jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="xutai_ma@jhu.edu">Xutai Ma</a>, <a href="/profile?email=juancarabina%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="juancarabina@fb.com">Juan Miguel Pino</a>, <a href="/profile?email=jcross%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jcross@fb.com">James Cross</a>, <a href="/profile?email=lie%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lie@fb.com">Liezl Puzon</a>, <a href="/profile?email=jgu%40fb.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="jgu@fb.com">Jiatao Gu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>13 Replies</span>
        
        
      </div>
      
        <a href="#Hyg96gBKPS-details-31" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="Hyg96gBKPS-details-31"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Make the transformer streamable with monotonic attention.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Simultaneous machine translation models start generating a target sequence before they have encoded or read the source sequence. Recent approach for this task either apply a fixed policy on transformer, or a learnable monotonic attention on a weaker recurrent neural network based structure. In this paper, we propose a new attention mechanism, Monotonic Multihead Attention (MMA), which introduced the monotonic attention mechanism to multihead attention. We also introduced two novel interpretable approaches for latency control that are specifically designed for multiple attentions. We apply MMA to the simultaneous machine translation task and demonstrate better latency-quality tradeoffs compared to MILk, the previous state-of-the-art approach.
      </span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">Simultaneous Translation, Transformer, Monotonic Attention</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=Hyg96gBKPS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="BkeoaeHKDS" data-number="2585">
      <h4>
        <a href="/forum?id=BkeoaeHKDS">
            Gradients as Features for Deep Representation Learning
        </a>
      
        
          <a href="/pdf?id=BkeoaeHKDS" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=fmu%40cs.wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="fmu@cs.wisc.edu">Fangzhou Mu</a>, <a href="/profile?email=yliang%40cs.wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yliang@cs.wisc.edu">Yingyu Liang</a>, <a href="/profile?email=yin.li%40wisc.edu" class="profile-link" data-toggle="tooltip" data-placement="top" title="yin.li@wisc.edu">Yin Li</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#BkeoaeHKDS-details-897" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="BkeoaeHKDS-details-897"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">Given a pre-trained model, we explored the per-sample gradients of the model parameters relative to a task-specific loss, and constructed a linear model that combines gradients of model parameters and the activation of the model.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">We address the challenging problem of deep representation learning -- the efficient adaption of a pre-trained deep network to different tasks. Specifically, we propose to explore gradient-based features. These features are gradients of the model parameters with respect to a task-specific loss given an input sample. Our key innovation is the design of a linear model that incorporates both gradient and activation of the pre-trained network. We demonstrate that our model provides a local linear approximation to an underlying deep model, and discuss important theoretical insights. Moreover, we present an efficient algorithm for the training and inference of our model without computing the actual gradients. Our method is evaluated across a number of representation-learning tasks on several datasets and using different network architectures. Strong results are obtained in all settings, and are well-aligned with our theoretical insights.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">representation learning, gradient features, deep learning</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=BkeoaeHKDS&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
    <li class="note " data-id="ryxyCeHtPB" data-number="2594">
      <h4>
        <a href="/forum?id=ryxyCeHtPB">
            Pay Attention to Features, Transfer Learn Faster CNNs
        </a>
      
        
          <a href="/pdf?id=ryxyCeHtPB" class="pdf-link" title="Download PDF" target="_blank"><img src="/images/pdf_icon_blue.svg"></a>
        
        
      </h4>
      
      
      
      <div class="note-authors">
        <a href="/profile?email=kf.wang%40siat.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="kf.wang@siat.ac.cn">Kafeng Wang</a>, <a href="/profile?email=xt.gao%40siat.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="top" title="xt.gao@siat.ac.cn">Xitong Gao</a>, <a href="/profile?email=yiren.zhao%40cl.cam.ac.uk" class="profile-link" data-toggle="tooltip" data-placement="top" title="yiren.zhao@cl.cam.ac.uk">Yiren Zhao</a>, <a href="/profile?email=lixingjian%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="lixingjian@baidu.com">Xingjian Li</a>, <a href="/profile?email=doudejing%40baidu.com" class="profile-link" data-toggle="tooltip" data-placement="top" title="doudejing@baidu.com">Dejing Dou</a>, <a href="/profile?email=czxu%40um.edu.mo" class="profile-link" data-toggle="tooltip" data-placement="top" title="czxu@um.edu.mo">Cheng-Zhong Xu</a>
      </div>
      
      <div class="note-meta-info">
        <span class="date">26 Sep 2019 (modified: 11 Mar 2020)</span>
          <span class="item">ICLR 2020 Conference Blind Submission</span>
          <span class="readers">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span>
        
          <span>8 Replies</span>
        
        
      </div>
      
        <a href="#ryxyCeHtPB-details-304" class="note-contents-toggle" role="button" data-toggle="collapse" aria-expanded="false">Show details</a><div class="collapse" id="ryxyCeHtPB-details-304"><div class="note-contents-collapse"><ul class="list-unstyled note-content">
          <li>
            <strong class="note-content-field">TL;DR:</strong>
            <span class="note-content-value ">We introduce attentive feature distillation and selection, to fine-tune a large model and produce a faster one.</span>
          </li>
          <li>
            <strong class="note-content-field">Abstract:</strong>
            <span class="note-content-value ">Deep convolutional neural networks are now widely deployed in vision applications, but a limited size of training data can restrict their task performance. Transfer learning offers the chance for CNNs to learn with limited data samples by transferring knowledge from models pretrained on large datasets. Blindly transferring all learned features from the source dataset, however, brings unnecessary computation to CNNs on the target task. In this paper, we propose attentive feature distillation and selection (AFDS), which not only adjusts the strength of transfer learning regularization but also dynamically determines the important features to transfer. By deploying AFDS on ResNet-101, we achieved a state-of-the-art computation reduction at the same accuracy budget, outperforming all existing transfer learning methods. With a 10x MACs reduction budget, a ResNet-101 equipped with AFDS transfer learned from ImageNet to Stanford Dogs 120, can achieve an accuracy 11.07% higher than its best competitor.</span>
          </li>
          <li>
            <strong class="note-content-field">Keywords:</strong>
            <span class="note-content-value ">transfer learning, pruning, faster CNNs</span>
          </li>
          <li>
            <strong class="note-content-field">Original Pdf:</strong>
            <span class="note-content-value "><a href="/attachment?id=ryxyCeHtPB&amp;name=original_pdf" class="attachment-download-link" title="Download Original Pdf" target="_blank"><span class="glyphicon glyphicon-download-alt" aria-hidden="true"></span> &nbsp;pdf</a></span>
          </li>
      </ul>
      </div></div>
      
      
      
      
    </li>
</ul>