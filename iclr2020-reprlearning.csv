Multi-Scale Representation Learning for Spatial Feature Distributions using Grid Cells|"Gengchen Mai
Krzysztof Janowicz
Bo Yan
Rui Zhu
Ling Cai
Ni Lao"|"grid cell
space encoding
spatially explicit model
multi-scale periodic representation
unsupervised learning"|we propose a representation learning model called space2vec to encode the absolute positions and spatial relationships of places.|https://openreview.net/attachment?id=rJljdh4KDH&name=original_pdf|https://github.com/gengchenmai/space2vec
InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization|"Fan-Yun Sun
Jordan Hoffman
Vikas Verma
Jian Tang"|"graph-level representation learning
mutual information maximization"||https://openreview.net/attachment?id=r1lfF2NYvH&name=original_pdf|https://github.com/fanyun-sun/InfoGraph
Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds|"Lukas Prantl
Nuttapong Chentanez
Stefan Jeschke
Nils Thuerey"|"point clouds
spatio-temporal representations
lagrangian data
temporal coherence
super-resolution
denoising"|we propose a generative neural network approach for temporally coherent point clouds.|https://openreview.net/attachment?id=BJeKh3VYDH&name=original_pdf|
DDSP: Differentiable Digital Signal Processing|"Jesse Engel
Lamtharn (Hanoi) Hantrakul
Chenjie Gu
Adam Roberts"|"dsp
audio
music
nsynth
wavenet
wavernn
vocoder
synthesizer
sound
signal
processing
tensorflow
autoencoder
disentanglement"|better audio synthesis by combining interpretable dsp with end-to-end learning.|https://openreview.net/attachment?id=B1x1ma4tDr&name=original_pdf|https://github.com/magenta/ddsp
Conditional Learning of Fair Representations|"Han Zhao
Amanda Coston
Tameem Adel
Geoffrey J. Gordon"|"algorithmic fairness
representation learning"|we propose a novel algorithm for learning fair representations that can simultaneously mitigate two notions of disparity among different demographic subgroups.|https://openreview.net/attachment?id=Hkekl0NFPr&name=original_pdf|
Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees|"Binghong Chen
Bo Dai
Qinjie Lin
Guo Ye
Han Liu
Le Song"|"learning to plan
representation learning
learning to design algorithm
reinforcement learning
meta learning"|we propose a meta path planning algorithm which exploits a novel attention-based neural module that can learn generalizable structures from prior experiences to drastically reduce the sample requirement for solving new path planning problems.|https://openreview.net/attachment?id=rJgJDAVKvB&name=original_pdf|https://github.com/NeurEXT/NEXT-learning-to-plan/blob/master/main.ipynb
Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?|"Simon S. Du
Sham M. Kakade
Ruosong Wang
Lin F. Yang"|"reinforcement learning
function approximation
lower bound
representation"|exponential lower bounds for value-based and policy-based reinforcement learning with function approximation.|https://openreview.net/attachment?id=r1genAVKPB&name=original_pdf|
Dream to Control: Learning Behaviors by Latent Imagination|"Danijar Hafner
Timothy Lillicrap
Jimmy Ba
Mohammad Norouzi"|"world model
latent dynamics
imagination
planning by backprop
policy optimization
planning
reinforcement learning
control
representations
latent variable model
visual control
value function"|we present dreamer, an agent that learns long-horizon behaviors purely by latent imagination using analytic value gradients.|https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf|https://danijar.com/dreamer
Self-labelling via simultaneous clustering and representation learning|"Asano YM.
Rupprecht C.
Vedaldi A."|"self-supervision
feature representation learning
clustering"|we propose a self-supervised learning formulation that simultaneously learns feature representations and useful dataset labels by optimizing the common cross-entropy loss for features _and_ labels, while maximizing information.|https://openreview.net/attachment?id=Hyx-jyBFPr&name=original_pdf|
Differentiation of Blackbox Combinatorial Solvers|"Marin Vlastelica Pogančić
Anselm Paulus
Vit Musil
Georg Martius
Michal Rolinek"|"combinatorial algorithms
deep learning
representation learning
optimization"|in this work, we present a method that implements an efficient backward pass through blackbox implementations of combinatorial solvers with linear objective functions.|https://openreview.net/attachment?id=BkevoJSYPB&name=original_pdf|https://sites.google.com/view/combinatorialgradients/home
Disentanglement by Nonlinear ICA with General Incompressible-flow Networks (GIN)|"Peter Sorrenson
Carsten Rother
Ullrich Köthe"|"disentanglement
nonlinear ica
representation learning
feature discovery
theoretical justification"||https://openreview.net/attachment?id=rygeHgSFDH&name=original_pdf|
Unbiased Contrastive Divergence Algorithm for Training Energy-Based Latent Variable Models|"Yixuan Qiu
Lingsong Zhang
Xiao Wang"|"energy model
restricted boltzmann machine
contrastive divergence
unbiased markov chain monte carlo
distribution coupling"|we have developed a new training algorithm for energy-based latent variable models that completely removes the bias of contrastive divergence.|https://openreview.net/attachment?id=r1eyceSYPr&name=original_pdf|
PROGRESSIVE LEARNING AND DISENTANGLEMENT OF HIERARCHICAL REPRESENTATIONS|"Zhiyuan Li
Jaideep Vitthal Murkute
Prashnna Kumar Gyawali
Linwei Wang"|"generative model
disentanglement
progressive learning
vae"|we proposed a progressive learning method to improve learning and disentangling latent representations at different levels of abstraction.|https://openreview.net/attachment?id=SJxpsxrYPS&name=original_pdf|
